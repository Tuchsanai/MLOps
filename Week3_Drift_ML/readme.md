# การเปลี่ยนแปลง (Drift) ใน Machine Learning: Data Drift, Model Drift และ Concept Drift

## บทนำ

ในสาขา Machine Learning (ML) หรือการเรียนรู้ของเครื่อง การพัฒนาโมเดลที่ทำงานได้ดีในสภาพแวดล้อมการฝึกฝน (training environment) เป็นเพียงจุดเริ่มต้นเท่านั้น เมื่อนำโมเดลไปใช้งานจริงในระบบ production ปัญหาที่มักเกิดขึ้นบ่อยครั้งคือ **การเปลี่ยนแปลง หรือ Drift** ซึ่งหมายถึงการที่ประสิทธิภาพของโมเดลค่อยๆ ลดลงหรือเสื่อมสภาพ เนื่องจากข้อมูลนำเข้า สภาพแวดล้อม หรือความสัมพันธ์เชิงสถิติที่โมเดลเรียนรู้มาเปลี่ยนแปลงไปจากช่วงเวลาที่ฝึกฝน ส่งผลให้โมเดลไม่สามารถคาดการณ์ได้อย่างแม่นยำเหมือนเดิม

Drift ถือเป็นความท้าทายที่หลีกเลี่ยงไม่ได้ โดยเฉพาะในระบบที่เกี่ยวข้องกับข้อมูลแบบไดนามิก เช่น การพยากรณ์สภาพอากาศ การตรวจจับการฉ้อโกงทางการเงิน หรือระบบแนะนำสินค้าบนแพลตฟอร์มอีคอมเมิร์ซ หากขาดการตรวจสอบและปรับปรุงอย่างสม่ำเสมอ โมเดลอาจกลายเป็นเครื่องมือที่ล้าสมัย ให้ผลลัพธ์ที่ผิดพลาด และอาจนำไปสู่ความสูญเสียทางธุรกิจหรือความเสี่ยงด้านความปลอดภัย ตัวอย่างเช่น ในอุตสาหกรรมการแพทย์ โมเดลที่ใช้ตรวจจับโรคจากภาพถ่ายเอ็กซเรย์อาจทำงานผิดพลาดหากข้อมูลผู้ป่วยเปลี่ยนไปตามการระบาดของโรคใหม่ๆ

โดยทั่วไป Drift สามารถแบ่งออกเป็น 3 ประเภทหลัก ได้แก่:

1. **Data Drift** – การเปลี่ยนแปลงในรูปแบบหรือการกระจาย (distribution) ของข้อมูลนำเข้า
2. **Model Drift** – การเสื่อมสภาพหรือการลดลงของประสิทธิภาพโมเดลเอง
3. **Concept Drift** – การเปลี่ยนแปลงในความสัมพันธ์พื้นฐานระหว่างข้อมูลนำเข้าและผลลัพธ์

ในบทความนี้ เราจะอธิบายแต่ละประเภทอย่างละเอียด พร้อมสาเหตุที่เกิดขึ้น ตัวอย่างจากสถานการณ์จริง วิธีการตรวจจับและตรวจสอบ รวมถึงแนวทางแก้ไขปัญหา เพื่อให้ผู้อ่านสามารถนำไปประยุกต์ใช้ในโครงการ ML ของตนเองได้

---

## 1. Data Drift (การเปลี่ยนแปลงข้อมูล)

**ความหมาย:**
Data Drift เกิดขึ้นเมื่อการกระจาย (distribution) ของข้อมูลนำเข้า (input data) ที่โมเดลได้รับเปลี่ยนแปลงไปจากข้อมูลที่ใช้ในการฝึกฝน แม้ว่าความสัมพันธ์ระหว่างข้อมูลนำเข้าและผลลัพธ์ (output) จะยังคงเดิมอยู่ แต่รูปแบบของข้อมูลที่เปลี่ยนไปอาจทำให้โมเดลไม่สามารถปรับตัวได้ ส่งผลให้ความแม่นยำลดลง โดยเฉพาะในระบบที่ข้อมูลมีการอัพเดตแบบเรียลไทม์

**สาเหตุ:**
- **การเปลี่ยนแปลงตามเวลาและฤดูกาล:** เช่น พฤติกรรมผู้ใช้ที่เปลี่ยนไปตามเทศกาลหรือเหตุการณ์โลก เช่น การช้อปปิ้งออนไลน์ที่พุ่งสูงในช่วง Black Friday
- **แหล่งข้อมูลใหม่หรือการเปลี่ยนแปลงอุปกรณ์:** เช่น การเปลี่ยนจากเซ็นเซอร์รุ่นเก่าเป็นรุ่นใหม่ที่วัดค่าได้ละเอียดกว่า
- **Sampling bias หรือความเอนเอียงในการสุ่มข้อมูล:** เช่น กลุ่มผู้ใช้เปลี่ยนจากประชากรในเมืองใหญ่ไปเป็นพื้นที่ชนบท ซึ่งมีลักษณะข้อมูลต่างกัน
- **ปัญหาทางเทคนิค:** เช่น ความผิดปกติจากสัญญาณรบกวน (noise) ในเซ็นเซอร์ หรือการเปลี่ยนรูปแบบข้อมูล (data format) จากการอัพเดตระบบ

**ตัวอย่าง:**
- **ระบบตรวจจับการฉ้อโกงทางการเงิน:** ในช่วงปกติ โมเดลฝึกด้วยข้อมูลธุรกรรมส่วนใหญ่จากร้านค้าออฟไลน์ แต่ในยุคโควิด-19 ผู้ใช้หันมาซื้อของออนไลน์มากขึ้น ส่งผลให้ distribution ของข้อมูล เช่น มูลค่าธุรกรรมเฉลี่ยและประเภทบัตรเครดิต เปลี่ยนไป ทำให้โมเดลตรวจจับการโกงได้น้อยลง
- **Computer Vision สำหรับการจดจำวัตถุ:** โมเดลที่ฝึกด้วยภาพถ่ายกลางวันส่วนใหญ่ แต่เมื่อใช้งานจริงในระบบกล้องวงจรปิด จะได้รับภาพกลางคืนที่มีแสงน้อยและสีสันต่างกัน ส่งผลให้อัตราความผิดพลาดสูงขึ้น
- **IoT สำหรับตรวจวัดคุณภาพอากาศ:** หากเปลี่ยนเซ็นเซอร์วัด PM2.5 จากรุ่นเก่าเป็นรุ่นใหม่ที่มีความไวสูงกว่า ค่าที่วัดได้อาจสูงขึ้นโดยไม่เกี่ยวกับมลพิษจริง ส่งผลให้โมเดลพยากรณ์มลพิษคลาดเคลื่อน
- **ตัวอย่างเพิ่มเติม:** ในแอปพลิเคชันแนะนำเพลง โมเดลฝึกด้วยข้อมูลจากผู้ใช้ในอเมริกา แต่เมื่อขยายไปยังตลาดเอเชีย รสนิยมเพลงและแนวเพลงที่ฟังจะต่างกันมาก

**วิธีตรวจจับและตรวจสอบ:**
เพื่อตรวจสอบ Data Drift ควรใช้เครื่องมือเชิงสถิติและ visualization อย่างสม่ำเสมอ เช่น:
- **Descriptive statistics:** คำนวณค่าเฉลี่ย (mean), ความแปรปรวน (variance), และ skewness ของข้อมูลนำเข้า แล้วเปรียบเทียบกับข้อมูลฝึกฝน
- **Statistical tests:** เช่น Kolmogorov-Smirnov (KS) Test สำหรับข้อมูลต่อเนื่อง หรือ Chi-Square Test สำหรับข้อมูลหมวดหมู่ เพื่อวัดความแตกต่างใน distribution
- **Visualization:** สร้าง histogram, boxplot หรือ scatter plot เพื่อดูการกระจายข้อมูลแบบภาพ
- **Monitoring tools:** ใช้ไลบรารีอย่าง Evidently AI สำหรับรายงานอัตโนมัติ, Alibi Detect สำหรับการตรวจจับ outlier, หรือ Prometheus สำหรับการตรวจสอบแบบเรียลไทม์ในระบบ production
การตรวจสอบควรทำเป็น routine เช่น ทุกสัปดาห์หรือเมื่อข้อมูลใหม่เข้ามาเกิน threshold ที่กำหนด

**วิธีแก้ไข:**
- **Retraining โมเดล:** ฝึกโมเดลใหม่ด้วยข้อมูลล่าสุดเพื่อปรับให้เข้ากับ distribution ใหม่
- **Normalization และ feature engineering:** ปรับข้อมูลให้อยู่ใน scale เดียวกัน เช่น ใช้ z-score normalization
- **Ensemble models:** ใช้หลายโมเดลผสมกันเพื่อเพิ่ม robustness
- **Continuous monitoring:** ตั้งระบบ alert เมื่อตรวจพบ drift เพื่อให้ทีมงานปรับปรุงทันที

---

## 2. Model Drift (การเปลี่ยนแปลงโมเดล)

**ความหมาย:**
Model Drift คือการที่ประสิทธิภาพของโมเดลลดลงโดยตรง แม้ว่าข้อมูลนำเข้าอาจไม่เปลี่ยนแปลงมากนัก แต่เกิดจากปัจจัยภายในโมเดลเองหรือสภาพแวดล้อมภายนอก ทำให้โมเดลไม่สามารถรักษาความแม่นยำได้ในระยะยาว เหมือนกับเครื่องจักรที่เสื่อมสภาพตามเวลา

**สาเหตุ:**
- **Overfitting กับข้อมูลเก่า:** โมเดลเรียนรู้เฉพาะ pattern ในข้อมูลฝึกฝนแต่ไม่ generalize ได้ดี
- **ผลกระทบจาก Drift อื่นๆ:** เช่น Data Drift หรือ Concept Drift ที่สะสมมา
- **ปัญหาทางเทคนิค:** เช่น การอัพเดต hardware/software ที่ทำให้การคำนวณเปลี่ยนไป
- **ปัจจัยภายนอก:** เช่น การเปลี่ยนกฎหมายหรือนโยบายที่กระทบต่อการใช้งานโมเดล เช่น GDPR ที่เปลี่ยนวิธีจัดการข้อมูลส่วนบุคคล

**ตัวอย่าง:**
- **การพยากรณ์ราคาหุ้น:** โมเดลทำงานดีในตลาดปกติ แต่เมื่อเกิดวิกฤติเศรษฐกิจ เช่น การล้มละลายของธนาคารใหญ่ในปี 2008 โมเดลไม่สามารถปรับตัวได้ ส่งผลให้การพยากรณ์ผิดพลาดมาก
- **แชทบอทสำหรับบริการลูกค้า:** ในตอนแรกตอบคำถามได้ดี แต่เมื่อผู้ใช้เริ่มใช้ slang หรือภาษาย่อใหม่ๆ จากโซเชียลมีเดีย เช่น "lol" หรือ "brb" โมเดลเข้าใจผิดและตอบไม่ตรงประเด็น
- **ระบบตรวจสอบ defect ในโรงงานผลิต:** โมเดลฝึกด้วยข้อมูลจากเครื่องจักรใหม่ แต่เมื่อเครื่องจักรเสื่อมสภาพหลังใช้งาน 1-2 ปี คุณภาพภาพถ่าย defect เปลี่ยนไป ทำให้โมเดลตรวจจับได้น้อยลง
- **ตัวอย่างเพิ่มเติม:** ในระบบแนะนำหนังบน Netflix โมเดลอาจเสื่อมประสิทธิภาพเมื่อผู้ใช้เปลี่ยนพฤติกรรมจากการดูซีรีส์ไปเป็นหนังสั้นจาก TikTok

**วิธีตรวจจับและตรวจสอบ:**
- **Monitoring metrics:** ติดตามตัวชี้วัดอย่าง accuracy, precision, recall, F1-score หรือ AUC-ROC แล้วเปรียบเทียบกับ baseline
- **A/B testing:** ทดสอบโมเดลเวอร์ชันเก่าและใหม่กับข้อมูลจริงเพื่อวัดความแตกต่าง
- **Error analysis:** วิเคราะห์ข้อผิดพลาด เช่น ใช้ confusion matrix เพื่อหา pattern ของความผิดพลาด
- **Monitoring tools:** ใช้ MLflow สำหรับ tracking experiment, TensorBoard สำหรับ visualization metrics หรือ Kubeflow สำหรับ pipeline monitoring ในระบบ cloud
การตรวจสอบควรรวมการ audit เป็นระยะ เช่น ทุกเดือน เพื่อตรวจหาสัญญาณเสื่อมสภาพตั้งแต่เนิ่นๆ

**วิธีแก้ไข:**
- **Retrain หรือ fine-tune:** ฝึกโมเดลใหม่ด้วยข้อมูลล่าสุดหรือปรับพารามิเตอร์บางส่วน
- **Ensemble models:** รวมหลายโมเดลเพื่อชดเชยจุดอ่อน
- **AutoML สำหรับ retrain อัตโนมัติ:** ใช้เครื่องมืออย่าง Google AutoML หรือ H2O.ai เพื่อฝึกโมเดลใหม่โดยอัตโนมัติ
- **Version control:** ใช้ Git หรือ DVC เพื่อ rollback ไปยังเวอร์ชันเก่าที่ทำงานดีหากเกิดปัญหา

---

## 3. Concept Drift (การเปลี่ยนแปลงแนวคิด)

**ความหมาย:**
Concept Drift คือการเปลี่ยนแปลงในความสัมพันธ์พื้นฐานระหว่างข้อมูลนำเข้า (input) และผลลัพธ์ (output หรือ target variable) แม้ว่าการกระจายของ input จะยังคงเหมือนเดิม แต่ pattern หรือกฎเกณฑ์ที่เชื่อมโยงระหว่างกันเปลี่ยนไป ทำให้โมเดลที่ฝึกด้วยกฎเกณฑ์เก่าไม่สามารถใช้งานได้

**ประเภทของ Concept Drift:**
- **Sudden Drift:** เกิดขึ้นอย่างรวดเร็ว เช่น จากเหตุการณ์ภัยพิบัติที่เปลี่ยนพฤติกรรมสังคมทันที
- **Gradual Drift:** ค่อยๆ เปลี่ยนแปลง เช่น การเปลี่ยนรสนิยมของผู้บริโภคตามเทรนด์สังคม
- **Incremental Drift:** เปลี่ยนทีละน้อยและสะสม เช่น การพัฒนาเทคโนโลยีที่ค่อยๆ กระทบ pattern ข้อมูล
- **Recurring Drift:** เกิดซ้ำตามรอบ เช่น การเปลี่ยนพฤติกรรมซื้อของตามฤดูกาล

**สาเหตุ:**
- การเปลี่ยนแปลงทางสังคม เศรษฐกิจ หรือสิ่งแวดล้อมที่กระทบต่อพฤติกรรมพื้นฐาน
- การพัฒนาเทคโนโลยีใหม่ที่เปลี่ยนกฎเกณฑ์ เช่น การมาของ AI ที่เปลี่ยนวิธีการโกง
- เหตุการณ์ไม่คาดคิด เช่น การระบาดของโรคที่เปลี่ยน pattern การเดินทาง

**ตัวอย่าง:**
- **Fraud detection:** เดิมโกงด้วยบัตรเครดิตปลอม แต่เปลี่ยนเป็น phishing ทางอีเมล ทำให้ความสัมพันธ์ระหว่าง transaction features และ fraud label เปลี่ยนไป
- **วิทยาศาสตร์ภูมิอากาศ:** Climate change ทำให้ pattern การตกฝนเปลี่ยนจากฤดูฝนปกติไปเป็นฝนตกหนักแบบไม่แน่นอน
- **การตลาดดิจิทัล:** วัยรุ่นเดิมใช้ Facebook แต่หันมา TikTok ทำให้โมเดลแนะนำเนื้อหาบน Facebook ไม่ทำงานเพราะ user behavior เปลี่ยน
- **ตัวอย่างเพิ่มเติม:** ในระบบพยากรณ์การจราจร โมเดลเดิมอาศัย pattern การเดินทางปกติ แต่หลังจาก Work From Home กลายเป็น norm ในยุคหลังโควิด ความสัมพันธ์ระหว่างเวลาและปริมาณรถเปลี่ยนไป

**วิธีตรวจจับและตรวจสอบ:**
- **Algorithms เฉพาะ:** ใช้ Page-Hinkley Test สำหรับ sudden drift, ADWIN (Adaptive Windowing) สำหรับ gradual drift, หรือ DDM/EDDM (Drift Detection Method) สำหรับ monitoring performance
- **Label vs prediction monitoring:** เปรียบเทียบ prediction ของโมเดลกับ ground truth labels ที่ได้จาก human feedback
- **Tools:** ไลบรารีอย่าง River สำหรับ online ML, Scikit-Multiflow สำหรับ stream data processing หรือ Apache Kafka สำหรับ real-time monitoring
การตรวจสอบควรใช้ threshold-based alerting เช่น หาก error rate เพิ่มเกิน 10% ให้แจ้งเตือนทันที

**วิธีแก้ไข:**
- **Online learning:** ใช้โมเดลที่เรียนรู้แบบ incremental เช่น Incremental Decision Trees
- **Sliding window technique:** ใช้ข้อมูลล่าสุดใน window เวลาที่กำหนดเพื่อฝึกโมเดล
- **Adaptive models หรือ meta-learning:** สร้างโมเดลที่ปรับตัวเองได้ เช่น Few-Shot Learning
- **Human-in-the-loop:** รวมมนุษย์ในการตรวจสอบและ label ข้อมูลใหม่เพื่อปรับโมเดล

---

## ตารางสรุป

| ประเภท Drift      | ความหมายหลัก                                                        | ตัวอย่างหลัก (พร้อมรายละเอียด)                                                                 | วิธีตรวจจับและตรวจสอบ (รวมเครื่องมือ)                                                                 | วิธีแก้ไข (พร้อมแนวทางปฏิบัติ)                                                   |
| ----------------- | ------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------- |
| **Data Drift**    | Distribution ของ input data เปลี่ยน แต่ความสัมพันธ์ input–output คงเดิม | - ธุรกรรมบัตรเครดิตช่วงโควิด (จากออฟไลน์เป็นออนไลน์)<br>- ภาพกลางวัน vs กลางคืนใน CV<br>- เซ็นเซอร์ PM2.5 รุ่นใหม่<br>- แนะนำเพลงจากตลาดต่างภูมิภาค | - Stats (mean, variance, skewness)<br>- KS Test, Chi-Square<br>- Visualization (histogram, boxplot)<br>- Evidently AI, Alibi Detect, Prometheus | - Retrain ด้วยข้อมูลใหม่<br>- Normalization (z-score)<br>- Ensemble models<br>- Continuous monitoring ด้วย alert |
| **Model Drift**   | ประสิทธิภาพโมเดลลดลงจากตัวโมเดลหรือ external factors                | - พยากรณ์หุ้นในวิกฤติ (จากตลาดปกติเป็น chaotic)<br>- แชทบอทกับ slang ใหม่<br>- ตรวจ defect เมื่อเครื่องจักรเสื่อม<br>- แนะนำหนังเมื่อพฤติกรรมเปลี่ยน | - Metrics (accuracy, F1-score, AUC)<br>- A/B testing<br>- Error analysis (confusion matrix)<br>- MLflow, TensorBoard, Kubeflow | - Retrain/Fine-tune พารามิเตอร์<br>- Ensemble<br>- AutoML อัตโนมัติ<br>- Version control (Git/DVC) |
| **Concept Drift** | ความสัมพันธ์ input–output เปลี่ยน แม้ input distribution ไม่เปลี่ยน | - Fraud: บัตรปลอม → phishing<br>- Climate change เปลี่ยน pattern ฝน<br>- Social media shift (Facebook → TikTok)<br>- จราจรหลัง WFH | - Page-Hinkley, ADWIN, DDM/EDDM<br>- Label vs prediction comparison<br>- River, Scikit-Multiflow, Apache Kafka | - Online learning (incremental)<br>- Sliding window<br>- Adaptive models (meta-learning)<br>- Human-in-the-loop feedback |

---

## บทสรุป

Drift ใน Machine Learning ถือเป็นปัญหาหลักที่กระทบต่อความเสถียร ความน่าเชื่อถือ และอายุการใช้งานของโมเดล ไม่ว่าจะเป็น Data Drift ที่เปลี่ยนรูปแบบข้อมูล Model Drift ที่ทำให้โมเดลเสื่อมสภาพ หรือ Concept Drift ที่พลิกผันความสัมพันธ์พื้นฐาน ทั้งหมดนี้มักเกิดขึ้นพร้อมกันและส่งผลกระทบต่อกัน การจัดการ Drift จึงเป็นส่วนสำคัญของ MLOps (Machine Learning Operations) ซึ่งต้องอาศัยการ monitoring อย่างต่อเนื่อง การ retraining อัตโนมัติ และการ adaptation เพื่อให้โมเดลสามารถปรับตัวเข้ากับโลกที่เปลี่ยนแปลงได้ โดยองค์กรที่ประสบความสำเร็จ เช่น Google หรือ Amazon มักลงทุนในระบบตรวจสอบ Drift เพื่อลดความเสี่ยงและรักษาประสิทธิภาพในระยะยาว หากนำแนวทางเหล่านี้ไปใช้ จะช่วยให้โครงการ ML ของคุณยั่งยืนและให้ผลลัพธ์ที่เชื่อถือได้มากขึ้น