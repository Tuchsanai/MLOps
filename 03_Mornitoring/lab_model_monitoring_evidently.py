# %% [markdown]
# # LAB: Model Monitoring with Evidently AI
# ## Section 1: Foundation & Model Performance Monitoring
#
# **à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œà¸à¸²à¸£à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰:**
# - à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸«à¸¥à¸±à¸à¸à¸²à¸£ Model Monitoring à¹à¸¥à¸°à¸„à¸§à¸²à¸¡à¸ªà¸³à¸„à¸±à¸à¹ƒà¸™à¸à¸²à¸£ deploy à¹‚à¸¡à¹€à¸”à¸¥
# - à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Evidently AI à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸•à¸´à¸”à¸•à¸²à¸¡à¸„à¸¸à¸“à¸ à¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸¥à¸°à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸à¹‚à¸¡à¹€à¸”à¸¥
# - à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š Data Drift à¹à¸¥à¸° Target Drift
# - à¸ªà¸£à¹‰à¸²à¸‡ Report à¹à¸¥à¸° Test Suite à¸ªà¸³à¸«à¸£à¸±à¸š monitoring

# %% [markdown]
# ---
# # LAB 1.1: Introduction to Evidently AI
#
# ## à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ
# - à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡à¹à¸¥à¸°à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² Evidently
# - à¸—à¸³à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡ Report à¹à¸¥à¸° Test Suite
# - à¸ªà¸£à¹‰à¸²à¸‡ Report à¹à¸£à¸à¸ˆà¸²à¸ dataset à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡

# %% [markdown]
# ### 1.1.1 à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ Evidently AI
#
# Evidently à¹€à¸›à¹‡à¸™ open-source Python library à¸ªà¸³à¸«à¸£à¸±à¸š ML model monitoring
# à¸Šà¹ˆà¸§à¸¢à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸„à¸¸à¸“à¸ à¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥, à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸à¹‚à¸¡à¹€à¸”à¸¥, à¹à¸¥à¸° data drift

# %%
# à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ library à¸—à¸µà¹ˆà¸ˆà¸³à¹€à¸›à¹‡à¸™
# !pip install evidently scikit-learn pandas numpy

# %%
# Import libraries à¸—à¸µà¹ˆà¸ˆà¸³à¹€à¸›à¹‡à¸™
import pandas as pd
import numpy as np
from sklearn.datasets import load_iris, load_breast_cancer, fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Evidently imports
from evidently import ColumnMapping
from evidently.report import Report
from evidently.metric_preset import DataDriftPreset, DataQualityPreset
from evidently.metric_preset import ClassificationPreset, RegressionPreset
from evidently.metrics import *
from evidently.test_suite import TestSuite
from evidently.test_preset import DataDriftTestPreset, DataQualityTestPreset
from evidently.tests import *

import warnings
warnings.filterwarnings('ignore')

print("âœ… Import libraries à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

# %% [markdown]
# ### 1.1.2 à¸—à¸³à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¹à¸™à¸§à¸„à¸´à¸” Model Monitoring
#
# **à¸—à¸³à¹„à¸¡à¸•à¹‰à¸­à¸‡à¸—à¸³ Model Monitoring?**
#
# 1. **Data Drift**: à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ production à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¹„à¸›à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰ train
# 2. **Model Degradation**: à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸à¹‚à¸¡à¹€à¸”à¸¥à¸¥à¸”à¸¥à¸‡à¹€à¸¡à¸·à¹ˆà¸­à¹€à¸§à¸¥à¸²à¸œà¹ˆà¸²à¸™à¹„à¸›
# 3. **Data Quality Issues**: à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸¡à¸µà¸›à¸±à¸à¸«à¸² missing values, outliers
# 4. **Concept Drift**: à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œà¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ features à¹à¸¥à¸° target à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹„à¸›

# %%
# à¹‚à¸«à¸¥à¸” dataset à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡ - Breast Cancer Dataset
print("=" * 60)
print("ğŸ“Š à¹‚à¸«à¸¥à¸” Breast Cancer Dataset")
print("=" * 60)

# à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
cancer = load_breast_cancer()
df = pd.DataFrame(cancer.data, columns=cancer.feature_names)
df['target'] = cancer.target

print(f"\nğŸ“Œ à¸‚à¸™à¸²à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥: {df.shape}")
print(f"ğŸ“Œ à¸ˆà¸³à¸™à¸§à¸™ Features: {len(cancer.feature_names)}")
print(f"ğŸ“Œ Classes: {cancer.target_names}")
print(f"\nğŸ“Œ à¸à¸²à¸£à¸à¸£à¸°à¸ˆà¸²à¸¢à¸‚à¸­à¸‡ Target:")
print(df['target'].value_counts())

# %%
# à¹à¸ªà¸”à¸‡à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
print("\nğŸ“‹ à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ 5 à¹à¸–à¸§à¹à¸£à¸:")
df.head()

# %% [markdown]
# ### 1.1.3 à¹à¸šà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸›à¹‡à¸™ Reference à¹à¸¥à¸° Current
#
# à¹ƒà¸™ Model Monitoring à¹€à¸£à¸²à¸ˆà¸°à¹à¸šà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸›à¹‡à¸™:
# - **Reference Data**: à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰ train à¹‚à¸¡à¹€à¸”à¸¥ (baseline)
# - **Current Data**: à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¸¡à¹ˆà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š (production data)

# %%
# à¹à¸šà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸›à¹‡à¸™ Reference à¹à¸¥à¸° Current
# à¸ªà¸¡à¸¡à¸•à¸´ 70% à¹à¸£à¸à¹€à¸›à¹‡à¸™ reference, 30% à¸«à¸¥à¸±à¸‡à¹€à¸›à¹‡à¸™ current
split_index = int(len(df) * 0.7)

reference_data = df.iloc[:split_index].copy()
current_data = df.iloc[split_index:].copy()

print("=" * 60)
print("ğŸ“Š à¸à¸²à¸£à¹à¸šà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Reference vs Current")
print("=" * 60)
print(f"\nğŸ“Œ Reference Data: {reference_data.shape[0]} rows")
print(f"ğŸ“Œ Current Data: {current_data.shape[0]} rows")

# %% [markdown]
# ### 1.1.4 à¸ªà¸£à¹‰à¸²à¸‡ Report à¹à¸£à¸à¸”à¹‰à¸§à¸¢ Evidently
#
# Evidently à¸¡à¸µ 2 components à¸«à¸¥à¸±à¸:
# 1. **Report**: à¸ªà¸£à¹‰à¸²à¸‡ visualization à¹à¸¥à¸° metrics
# 2. **Test Suite**: à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹€à¸‡à¸·à¹ˆà¸­à¸™à¹„à¸‚à¹à¸¥à¸° pass/fail

# %%
# à¸ªà¸£à¹‰à¸²à¸‡ Data Drift Report
print("=" * 60)
print("ğŸ“Š à¸ªà¸£à¹‰à¸²à¸‡ Data Drift Report")
print("=" * 60)

# à¸à¸³à¸«à¸™à¸” column mapping
column_mapping = ColumnMapping(
    target='target',
    numerical_features=cancer.feature_names.tolist()
)

# à¸ªà¸£à¹‰à¸²à¸‡ Report à¸”à¹‰à¸§à¸¢ DataDriftPreset
data_drift_report = Report(metrics=[
    DataDriftPreset()
])

# à¸£à¸±à¸™ report
data_drift_report.run(
    reference_data=reference_data,
    current_data=current_data,
    column_mapping=column_mapping
)

print("âœ… à¸ªà¸£à¹‰à¸²à¸‡ Data Drift Report à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

# %%
# à¹à¸ªà¸”à¸‡à¸œà¸¥ Report à¹ƒà¸™à¸£à¸¹à¸›à¹à¸šà¸š dictionary
drift_results = data_drift_report.as_dict()

print("\nğŸ“‹ à¸ªà¸£à¸¸à¸›à¸œà¸¥ Data Drift:")
print("-" * 40)

# à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ dataset drift
dataset_drift = drift_results['metrics'][0]['result']
print(f"ğŸ“Œ Dataset Drift Detected: {dataset_drift['dataset_drift']}")
print(f"ğŸ“Œ Number of Drifted Features: {dataset_drift['number_of_drifted_columns']}")
print(f"ğŸ“Œ Share of Drifted Features: {dataset_drift['share_of_drifted_columns']:.2%}")

# %%
# à¸šà¸±à¸™à¸—à¸¶à¸ Report à¹€à¸›à¹‡à¸™ HTML file
data_drift_report.save_html("report_data_drift.html")
print("\nğŸ’¾ à¸šà¸±à¸™à¸—à¸¶à¸ Report à¹€à¸›à¹‡à¸™à¹„à¸Ÿà¸¥à¹Œ 'report_data_drift.html' à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

# %% [markdown]
# ### 1.1.5 à¸ªà¸£à¹‰à¸²à¸‡ Test Suite
#
# Test Suite à¹ƒà¸Šà¹‰à¸ªà¸³à¸«à¸£à¸±à¸šà¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹€à¸‡à¸·à¹ˆà¸­à¸™à¹„à¸‚à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´
# à¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¹ƒà¸Šà¹‰à¹ƒà¸™ CI/CD pipeline

# %%
# à¸ªà¸£à¹‰à¸²à¸‡ Test Suite à¸ªà¸³à¸«à¸£à¸±à¸š Data Drift
print("=" * 60)
print("ğŸ§ª à¸ªà¸£à¹‰à¸²à¸‡ Test Suite à¸ªà¸³à¸«à¸£à¸±à¸š Data Drift")
print("=" * 60)

data_drift_test_suite = TestSuite(tests=[
    DataDriftTestPreset()
])

data_drift_test_suite.run(
    reference_data=reference_data,
    current_data=current_data,
    column_mapping=column_mapping
)

print("âœ… à¸£à¸±à¸™ Test Suite à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

# %%
# à¹à¸ªà¸”à¸‡à¸œà¸¥ Test Suite
test_results = data_drift_test_suite.as_dict()

print("\nğŸ“‹ à¸ªà¸£à¸¸à¸›à¸œà¸¥ Test Suite:")
print("-" * 40)

# à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™ tests à¸—à¸µà¹ˆ pass/fail
summary = test_results['summary']
print(f"ğŸ“Œ Total Tests: {summary['total_tests']}")
print(f"âœ… Passed: {summary['success_tests']}")
print(f"âŒ Failed: {summary['failed_tests']}")

# %%
# à¸šà¸±à¸™à¸—à¸¶à¸ Test Suite à¹€à¸›à¹‡à¸™ HTML
data_drift_test_suite.save_html("test_suite_data_drift.html")
print("\nğŸ’¾ à¸šà¸±à¸™à¸—à¸¶à¸ Test Suite à¹€à¸›à¹‡à¸™à¹„à¸Ÿà¸¥à¹Œ 'test_suite_data_drift.html' à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

# %% [markdown]
# ### ğŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸” LAB 1.1
#
# 1. à¸¥à¸­à¸‡à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ dataset à¹€à¸›à¹‡à¸™ Iris dataset à¹à¸¥à¸°à¸ªà¸£à¹‰à¸²à¸‡ Data Drift Report
# 2. à¸¥à¸­à¸‡à¸›à¸£à¸±à¸š split ratio à¹€à¸›à¹‡à¸™ 80:20 à¹à¸¥à¸°à¸ªà¸±à¸‡à¹€à¸à¸•à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ
# 3. à¸ªà¸³à¸£à¸§à¸ˆ metrics à¸­à¸·à¹ˆà¸™à¹† à¹ƒà¸™ drift_results

# %%
# à¸à¸·à¹‰à¸™à¸—à¸µà¹ˆà¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸³à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”
# TODO: à¹€à¸‚à¸µà¸¢à¸™à¹‚à¸„à¹‰à¸”à¸‚à¸­à¸‡à¸„à¸¸à¸“à¸—à¸µà¹ˆà¸™à¸µà¹ˆ




# %% [markdown]
# ---
# # LAB 1.2: Data Quality Monitoring
#
# ## à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ
# - à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š missing values, duplicates
# - à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ data integrity à¹à¸¥à¸° consistency
# - à¸ªà¸£à¹‰à¸²à¸‡ Data Quality Report à¹à¸¥à¸°à¸•à¸±à¹‰à¸‡ threshold alerts

# %% [markdown]
# ### 1.2.1 à¸—à¸³à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆ Data Quality
#
# **Data Quality Dimensions:**
# - **Completeness**: à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸„à¸£à¸šà¸–à¹‰à¸§à¸™ (à¹„à¸¡à¹ˆà¸¡à¸µ missing values)
# - **Uniqueness**: à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸‹à¹‰à¸³ (duplicates)
# - **Validity**: à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸Šà¹ˆà¸§à¸‡à¸—à¸µà¹ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡
# - **Consistency**: à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸­à¸”à¸„à¸¥à¹‰à¸­à¸‡à¸à¸±à¸™

# %%
# à¸ªà¸£à¹‰à¸²à¸‡ dataset à¸—à¸µà¹ˆà¸¡à¸µà¸›à¸±à¸à¸«à¸² Data Quality
print("=" * 60)
print("ğŸ“Š à¸ªà¸£à¹‰à¸²à¸‡ Dataset à¸—à¸µà¹ˆà¸¡à¸µà¸›à¸±à¸à¸«à¸² Data Quality")
print("=" * 60)

# à¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ reference à¹€à¸”à¸´à¸¡
df_quality = reference_data.copy()

# à¹€à¸à¸´à¹ˆà¸¡ missing values
np.random.seed(42)
missing_indices = np.random.choice(df_quality.index, size=20, replace=False)
df_quality.loc[missing_indices, 'mean radius'] = np.nan

# à¹€à¸à¸´à¹ˆà¸¡ duplicate rows
duplicates = df_quality.sample(10, random_state=42)
df_quality = pd.concat([df_quality, duplicates], ignore_index=True)

# à¹€à¸à¸´à¹ˆà¸¡ outliers
outlier_indices = np.random.choice(df_quality.index, size=5, replace=False)
df_quality.loc[outlier_indices, 'mean area'] = df_quality['mean area'].max() * 10

print(f"ğŸ“Œ à¸‚à¸™à¸²à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸‡à¹€à¸à¸´à¹ˆà¸¡à¸›à¸±à¸à¸«à¸²: {df_quality.shape}")
print(f"ğŸ“Œ Missing values in 'mean radius': {df_quality['mean radius'].isna().sum()}")
print(f"ğŸ“Œ Duplicate rows: {df_quality.duplicated().sum()}")

# %%
# à¸ªà¸£à¹‰à¸²à¸‡ Data Quality Report
print("\n" + "=" * 60)
print("ğŸ“Š à¸ªà¸£à¹‰à¸²à¸‡ Data Quality Report")
print("=" * 60)

# à¸­à¸±à¸à¹€à¸”à¸— column mapping
quality_column_mapping = ColumnMapping(
    target='target',
    numerical_features=[col for col in df_quality.columns if col != 'target']
)

# à¸ªà¸£à¹‰à¸²à¸‡ Report
data_quality_report = Report(metrics=[
    DataQualityPreset()
])

data_quality_report.run(
    current_data=df_quality,
    reference_data=reference_data,
    column_mapping=quality_column_mapping
)

print("âœ… à¸ªà¸£à¹‰à¸²à¸‡ Data Quality Report à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

# %%
# à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ Data Quality
quality_results = data_quality_report.as_dict()

print("\nğŸ“‹ à¸ªà¸£à¸¸à¸›à¸œà¸¥ Data Quality:")
print("-" * 40)

# à¹à¸ªà¸”à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸šà¸·à¹‰à¸­à¸‡à¸•à¹‰à¸™
for metric in quality_results['metrics']:
    metric_id = metric['metric']
    if 'DatasetSummaryMetric' in metric_id:
        result = metric['result']['current']
        print(f"ğŸ“Œ à¸ˆà¸³à¸™à¸§à¸™à¹à¸–à¸§: {result['number_of_rows']}")
        print(f"ğŸ“Œ à¸ˆà¸³à¸™à¸§à¸™ columns: {result['number_of_columns']}")
        print(f"ğŸ“Œ Missing values: {result['number_of_missing_values']}")
        print(f"ğŸ“Œ Duplicate rows: {result['number_of_duplicated_rows']}")

# %%
# à¸šà¸±à¸™à¸—à¸¶à¸ Report
data_quality_report.save_html("report_data_quality.html")
print("\nğŸ’¾ à¸šà¸±à¸™à¸—à¸¶à¸ Report à¹€à¸›à¹‡à¸™à¹„à¸Ÿà¸¥à¹Œ 'report_data_quality.html' à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

# %% [markdown]
# ### 1.2.2 à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Missing Values à¹à¸šà¸šà¸¥à¸°à¹€à¸­à¸µà¸¢à¸”

# %%
# à¸ªà¸£à¹‰à¸²à¸‡ Report à¹€à¸‰à¸à¸²à¸° Missing Values
print("=" * 60)
print("ğŸ“Š à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ Missing Values")
print("=" * 60)

missing_report = Report(metrics=[
    DatasetMissingValuesMetric()
])

missing_report.run(
    current_data=df_quality,
    reference_data=reference_data,
    column_mapping=quality_column_mapping
)

missing_results = missing_report.as_dict()

print("\nğŸ“‹ à¸ªà¸£à¸¸à¸› Missing Values:")
print("-" * 40)

missing_data = missing_results['metrics'][0]['result']['current']
print(f"ğŸ“Œ Total Missing Values: {missing_data['number_of_missing_values']}")
print(f"ğŸ“Œ Share of Missing Values: {missing_data['share_of_missing_values']:.2%}")
print(f"ğŸ“Œ Columns with Missing: {missing_data['number_of_columns_with_missing_values']}")

# %% [markdown]
# ### 1.2.3 à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Duplicates

# %%
# à¸ªà¸£à¹‰à¸²à¸‡ Report à¹€à¸‰à¸à¸²à¸° Duplicates
print("=" * 60)
print("ğŸ“Š à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ Duplicate Rows")
print("=" * 60)

duplicates_report = Report(metrics=[
    DatasetDuplicatedRowsMetric()
])

duplicates_report.run(
    current_data=df_quality,
    reference_data=reference_data,
    column_mapping=quality_column_mapping
)

dup_results = duplicates_report.as_dict()

print("\nğŸ“‹ à¸ªà¸£à¸¸à¸› Duplicates:")
print("-" * 40)

dup_data = dup_results['metrics'][0]['result']['current']
print(f"ğŸ“Œ Duplicate Rows: {dup_data['number_of_duplicated_rows']}")
print(f"ğŸ“Œ Share of Duplicates: {dup_data['share_of_duplicated_rows']:.2%}")

# %% [markdown]
# ### 1.2.4 à¸ªà¸£à¹‰à¸²à¸‡ Test Suite à¸ªà¸³à¸«à¸£à¸±à¸š Data Quality

# %%
# à¸ªà¸£à¹‰à¸²à¸‡ Test Suite à¸à¸£à¹‰à¸­à¸¡ threshold
print("=" * 60)
print("ğŸ§ª à¸ªà¸£à¹‰à¸²à¸‡ Test Suite à¸ªà¸³à¸«à¸£à¸±à¸š Data Quality")
print("=" * 60)

data_quality_test = TestSuite(tests=[
    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š missing values à¹„à¸¡à¹ˆà¹€à¸à¸´à¸™ 5%
    TestShareOfMissingValues(lte=0.05),

    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š duplicate rows à¹„à¸¡à¹ˆà¹€à¸à¸´à¸™ 2%
    TestNumberOfDuplicatedRows(lte=10),

    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š columns à¸—à¸µà¹ˆà¸¡à¸µ missing values
    TestNumberOfColumnsWithMissingValues(lte=2),

    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸ˆà¸³à¸™à¸§à¸™à¹à¸–à¸§
    TestNumberOfRows(gte=100),
])

data_quality_test.run(
    current_data=df_quality,
    reference_data=reference_data,
    column_mapping=quality_column_mapping
)

print("âœ… à¸£à¸±à¸™ Test Suite à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

# %%
# à¹à¸ªà¸”à¸‡à¸œà¸¥ Test Suite
quality_test_results = data_quality_test.as_dict()

print("\nğŸ“‹ à¸œà¸¥à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š Data Quality:")
print("-" * 40)

for test in quality_test_results['tests']:
    test_name = test['name']
    status = "âœ… PASS" if test['status'] == 'SUCCESS' else "âŒ FAIL"
    print(f"{status}: {test_name}")

# %%
# à¸šà¸±à¸™à¸—à¸¶à¸ Test Suite
data_quality_test.save_html("test_suite_data_quality.html")
print("\nğŸ’¾ à¸šà¸±à¸™à¸—à¸¶à¸ Test Suite à¹€à¸›à¹‡à¸™à¹„à¸Ÿà¸¥à¹Œ 'test_suite_data_quality.html' à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

# %% [markdown]
# ### 1.2.5 à¸ªà¸£à¹‰à¸²à¸‡ Custom Data Quality Checks

# %%
# à¸ªà¸£à¹‰à¸²à¸‡ Test Suite à¹à¸šà¸š Custom
print("=" * 60)
print("ğŸ§ª Custom Data Quality Tests")
print("=" * 60)

custom_quality_test = TestSuite(tests=[
    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸„à¹ˆà¸²à¹ƒà¸™ column à¹€à¸‰à¸à¸²à¸°
    TestColumnShareOfMissingValues(column_name='mean radius', lte=0.1),

    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸„à¹ˆà¸² mean à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸Šà¹ˆà¸§à¸‡
    TestColumnMean(column_name='mean area', gt=0),

    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸„à¹ˆà¸² min/max
    TestColumnMin(column_name='mean radius', gt=0),
])

custom_quality_test.run(
    current_data=df_quality,
    reference_data=reference_data,
    column_mapping=quality_column_mapping
)

# à¹à¸ªà¸”à¸‡à¸œà¸¥
custom_results = custom_quality_test.as_dict()
print("\nğŸ“‹ à¸œà¸¥à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š Custom:")
print("-" * 40)

for test in custom_results['tests']:
    test_name = test['name']
    status = "âœ… PASS" if test['status'] == 'SUCCESS' else "âŒ FAIL"
    print(f"{status}: {test_name}")

# %% [markdown]
# ### ğŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸” LAB 1.2
#
# 1. à¸ªà¸£à¹‰à¸²à¸‡ Test Suite à¸—à¸µà¹ˆà¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² missing values à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸° column à¹„à¸¡à¹ˆà¹€à¸à¸´à¸™ 3%
# 2. à¹€à¸à¸´à¹ˆà¸¡ outliers à¹ƒà¸«à¹‰à¸à¸±à¸š column à¸­à¸·à¹ˆà¸™à¹† à¹à¸¥à¸°à¹ƒà¸Šà¹‰ Evidently à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š
# 3. à¸ªà¸£à¹‰à¸²à¸‡ alert à¹€à¸¡à¸·à¹ˆà¸­à¸à¸š duplicate rows à¹€à¸à¸´à¸™ 5%

# %%
# à¸à¸·à¹‰à¸™à¸—à¸µà¹ˆà¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸³à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”
# TODO: à¹€à¸‚à¸µà¸¢à¸™à¹‚à¸„à¹‰à¸”à¸‚à¸­à¸‡à¸„à¸¸à¸“à¸—à¸µà¹ˆà¸™à¸µà¹ˆ




# %% [markdown]
# ---
# # LAB 1.3: Model Performance Tracking
#
# ## à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ
# - à¸•à¸´à¸”à¸•à¸²à¸¡ classification metrics (Accuracy, Precision, Recall, F1)
# - à¸•à¸´à¸”à¸•à¸²à¸¡ regression metrics (MAE, RMSE, RÂ²)
# - à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š performance à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ reference vs current data

# %% [markdown]
# ### 1.3.1 à¹€à¸•à¸£à¸µà¸¢à¸¡à¹‚à¸¡à¹€à¸”à¸¥ Classification

# %%
# à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸š Classification
print("=" * 60)
print("ğŸ“Š à¹€à¸•à¸£à¸µà¸¢à¸¡à¹‚à¸¡à¹€à¸”à¸¥ Classification")
print("=" * 60)

# à¹‚à¸«à¸¥à¸” Breast Cancer Dataset
cancer = load_breast_cancer()
X = pd.DataFrame(cancer.data, columns=cancer.feature_names)
y = pd.Series(cancer.target, name='target')

# à¹à¸šà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

print(f"ğŸ“Œ Training set: {X_train.shape[0]} samples")
print(f"ğŸ“Œ Test set: {X_test.shape[0]} samples")

# %%
# Train à¹‚à¸¡à¹€à¸”à¸¥
print("\n" + "=" * 60)
print("ğŸ¤– Training Random Forest Classifier")
print("=" * 60)

clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)

# Predict
y_train_pred = clf.predict(X_train)
y_test_pred = clf.predict(X_test)

# à¸„à¸³à¸™à¸§à¸“ probability
y_train_proba = clf.predict_proba(X_train)[:, 1]
y_test_proba = clf.predict_proba(X_test)[:, 1]

print("âœ… Training à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

# %%
# à¸„à¸³à¸™à¸§à¸“ metrics à¹à¸šà¸š manual
print("\nğŸ“‹ Performance Metrics (Manual Calculation):")
print("-" * 40)
print(f"ğŸ“Œ Training Accuracy: {accuracy_score(y_train, y_train_pred):.4f}")
print(f"ğŸ“Œ Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}")
print(f"ğŸ“Œ Test Precision: {precision_score(y_test, y_test_pred):.4f}")
print(f"ğŸ“Œ Test Recall: {recall_score(y_test, y_test_pred):.4f}")
print(f"ğŸ“Œ Test F1-Score: {f1_score(y_test, y_test_pred):.4f}")

# %% [markdown]
# ### 1.3.2 à¸ªà¸£à¹‰à¸²à¸‡ Classification Performance Report

# %%
# à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸š Evidently
print("=" * 60)
print("ğŸ“Š à¸ªà¸£à¹‰à¸²à¸‡ Classification Performance Report")
print("=" * 60)

# à¸ªà¸£à¹‰à¸²à¸‡ DataFrame à¸ªà¸³à¸«à¸£à¸±à¸š reference (training)
reference_clf = X_train.copy()
reference_clf['target'] = y_train.values
reference_clf['prediction'] = y_train_pred

# à¸ªà¸£à¹‰à¸²à¸‡ DataFrame à¸ªà¸³à¸«à¸£à¸±à¸š current (test)
current_clf = X_test.copy()
current_clf['target'] = y_test.values
current_clf['prediction'] = y_test_pred

print(f"ğŸ“Œ Reference data shape: {reference_clf.shape}")
print(f"ğŸ“Œ Current data shape: {current_clf.shape}")

# %%
# à¸à¸³à¸«à¸™à¸” Column Mapping
clf_column_mapping = ColumnMapping(
    target='target',
    prediction='prediction',
    numerical_features=cancer.feature_names.tolist()
)

# à¸ªà¸£à¹‰à¸²à¸‡ Classification Report
clf_report = Report(metrics=[
    ClassificationPreset()
])

clf_report.run(
    reference_data=reference_clf,
    current_data=current_clf,
    column_mapping=clf_column_mapping
)

print("âœ… à¸ªà¸£à¹‰à¸²à¸‡ Classification Report à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

# %%
# à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ
clf_results = clf_report.as_dict()

print("\nğŸ“‹ Classification Metrics à¸ˆà¸²à¸ Evidently:")
print("-" * 40)

for metric in clf_results['metrics']:
    metric_id = metric['metric']
    if 'ClassificationQualityMetric' in metric_id:
        current = metric['result']['current']
        reference = metric['result']['reference']

        print("\nğŸ”¹ Current Data (Test Set):")
        print(f"   Accuracy: {current['accuracy']:.4f}")
        print(f"   Precision: {current['precision']:.4f}")
        print(f"   Recall: {current['recall']:.4f}")
        print(f"   F1: {current['f1']:.4f}")

        print("\nğŸ”¹ Reference Data (Training Set):")
        print(f"   Accuracy: {reference['accuracy']:.4f}")
        print(f"   Precision: {reference['precision']:.4f}")
        print(f"   Recall: {reference['recall']:.4f}")
        print(f"   F1: {reference['f1']:.4f}")

# %%
# à¸šà¸±à¸™à¸—à¸¶à¸ Report
clf_report.save_html("report_classification_performance.html")
print("\nğŸ’¾ à¸šà¸±à¸™à¸—à¸¶à¸ Report à¹€à¸›à¹‡à¸™à¹„à¸Ÿà¸¥à¹Œ 'report_classification_performance.html' à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

# %% [markdown]
# ### 1.3.3 à¹€à¸•à¸£à¸µà¸¢à¸¡à¹‚à¸¡à¹€à¸”à¸¥ Regression

# %%
# à¹‚à¸«à¸¥à¸” California Housing Dataset
print("=" * 60)
print("ğŸ“Š à¹€à¸•à¸£à¸µà¸¢à¸¡à¹‚à¸¡à¹€à¸”à¸¥ Regression")
print("=" * 60)

housing = fetch_california_housing()
X_reg = pd.DataFrame(housing.data, columns=housing.feature_names)
y_reg = pd.Series(housing.target, name='target')

# à¹à¸šà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(
    X_reg, y_reg, test_size=0.3, random_state=42
)

print(f"ğŸ“Œ Training set: {X_train_reg.shape[0]} samples")
print(f"ğŸ“Œ Test set: {X_test_reg.shape[0]} samples")

# %%
# Train à¹‚à¸¡à¹€à¸”à¸¥ Regression
print("\n" + "=" * 60)
print("ğŸ¤– Training Random Forest Regressor")
print("=" * 60)

reg = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
reg.fit(X_train_reg, y_train_reg)

# Predict
y_train_reg_pred = reg.predict(X_train_reg)
y_test_reg_pred = reg.predict(X_test_reg)

print("âœ… Training à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

# %%
# à¸„à¸³à¸™à¸§à¸“ Regression metrics à¹à¸šà¸š manual
print("\nğŸ“‹ Regression Metrics (Manual Calculation):")
print("-" * 40)
print(f"ğŸ“Œ Training MAE: {mean_absolute_error(y_train_reg, y_train_reg_pred):.4f}")
print(f"ğŸ“Œ Test MAE: {mean_absolute_error(y_test_reg, y_test_reg_pred):.4f}")
print(f"ğŸ“Œ Test RMSE: {np.sqrt(mean_squared_error(y_test_reg, y_test_reg_pred)):.4f}")
print(f"ğŸ“Œ Test RÂ²: {r2_score(y_test_reg, y_test_reg_pred):.4f}")

# %% [markdown]
# ### 1.3.4 à¸ªà¸£à¹‰à¸²à¸‡ Regression Performance Report

# %%
# à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸š Evidently
print("=" * 60)
print("ğŸ“Š à¸ªà¸£à¹‰à¸²à¸‡ Regression Performance Report")
print("=" * 60)

# à¸ªà¸£à¹‰à¸²à¸‡ DataFrame
reference_reg = X_train_reg.copy()
reference_reg['target'] = y_train_reg.values
reference_reg['prediction'] = y_train_reg_pred

current_reg = X_test_reg.copy()
current_reg['target'] = y_test_reg.values
current_reg['prediction'] = y_test_reg_pred

# Column Mapping
reg_column_mapping = ColumnMapping(
    target='target',
    prediction='prediction',
    numerical_features=housing.feature_names.tolist()
)

# à¸ªà¸£à¹‰à¸²à¸‡ Regression Report
reg_report = Report(metrics=[
    RegressionPreset()
])

reg_report.run(
    reference_data=reference_reg,
    current_data=current_reg,
    column_mapping=reg_column_mapping
)

print("âœ… à¸ªà¸£à¹‰à¸²à¸‡ Regression Report à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

# %%
# à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ
reg_results = reg_report.as_dict()

print("\nğŸ“‹ Regression Metrics à¸ˆà¸²à¸ Evidently:")
print("-" * 40)

for metric in reg_results['metrics']:
    metric_id = metric['metric']
    if 'RegressionQualityMetric' in metric_id:
        current = metric['result']['current']
        reference = metric['result']['reference']

        print("\nğŸ”¹ Current Data (Test Set):")
        print(f"   MAE: {current['mean_abs_error']:.4f}")
        print(f"   RMSE: {np.sqrt(current['mean_error']**2 + current['error_std']**2):.4f}")
        print(f"   RÂ²: {current['r2_score']:.4f}")

        print("\nğŸ”¹ Reference Data (Training Set):")
        print(f"   MAE: {reference['mean_abs_error']:.4f}")
        print(f"   RÂ²: {reference['r2_score']:.4f}")

# %%
# à¸šà¸±à¸™à¸—à¸¶à¸ Report
reg_report.save_html("report_regression_performance.html")
print("\nğŸ’¾ à¸šà¸±à¸™à¸—à¸¶à¸ Report à¹€à¸›à¹‡à¸™à¹„à¸Ÿà¸¥à¹Œ 'report_regression_performance.html' à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

# %% [markdown]
# ### 1.3.5 à¸ªà¸£à¹‰à¸²à¸‡ Test Suite à¸ªà¸³à¸«à¸£à¸±à¸š Model Performance

# %%
# Classification Performance Tests
print("=" * 60)
print("ğŸ§ª Classification Performance Tests")
print("=" * 60)

clf_perf_test = TestSuite(tests=[
    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Accuracy à¹„à¸¡à¹ˆà¸•à¹ˆà¸³à¸à¸§à¹ˆà¸² 90%
    TestAccuracyScore(gte=0.90),

    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Precision à¹„à¸¡à¹ˆà¸•à¹ˆà¸³à¸à¸§à¹ˆà¸² 85%
    TestPrecisionScore(gte=0.85),

    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Recall à¹„à¸¡à¹ˆà¸•à¹ˆà¸³à¸à¸§à¹ˆà¸² 85%
    TestRecallScore(gte=0.85),

    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š F1 à¹„à¸¡à¹ˆà¸•à¹ˆà¸³à¸à¸§à¹ˆà¸² 85%
    TestF1Score(gte=0.85),
])

clf_perf_test.run(
    reference_data=reference_clf,
    current_data=current_clf,
    column_mapping=clf_column_mapping
)

# à¹à¸ªà¸”à¸‡à¸œà¸¥
clf_test_results = clf_perf_test.as_dict()
print("\nğŸ“‹ à¸œà¸¥à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š Classification Performance:")
print("-" * 40)

for test in clf_test_results['tests']:
    test_name = test['name']
    status = "âœ… PASS" if test['status'] == 'SUCCESS' else "âŒ FAIL"
    print(f"{status}: {test_name}")

# %%
# Regression Performance Tests
print("\n" + "=" * 60)
print("ğŸ§ª Regression Performance Tests")
print("=" * 60)

reg_perf_test = TestSuite(tests=[
    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š MAE à¹„à¸¡à¹ˆà¹€à¸à¸´à¸™ 0.5
    TestValueMAE(lte=0.5),

    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š RMSE à¹„à¸¡à¹ˆà¹€à¸à¸´à¸™ 0.7
    TestValueRMSE(lte=0.7),

    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š RÂ² à¹„à¸¡à¹ˆà¸•à¹ˆà¸³à¸à¸§à¹ˆà¸² 0.7
    TestValueR2Score(gte=0.7),
])

reg_perf_test.run(
    reference_data=reference_reg,
    current_data=current_reg,
    column_mapping=reg_column_mapping
)

# à¹à¸ªà¸”à¸‡à¸œà¸¥
reg_test_results = reg_perf_test.as_dict()
print("\nğŸ“‹ à¸œà¸¥à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š Regression Performance:")
print("-" * 40)

for test in reg_test_results['tests']:
    test_name = test['name']
    status = "âœ… PASS" if test['status'] == 'SUCCESS' else "âŒ FAIL"
    print(f"{status}: {test_name}")

# %% [markdown]
# ### ğŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸” LAB 1.3
#
# 1. à¸¥à¸­à¸‡à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹‚à¸¡à¹€à¸”à¸¥à¹€à¸›à¹‡à¸™ LogisticRegression à¹à¸¥à¸°à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š metrics
# 2. à¸ªà¸£à¹‰à¸²à¸‡ Test Suite à¸—à¸µà¹ˆà¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² performance à¸‚à¸­à¸‡ current à¹„à¸¡à¹ˆà¸•à¹ˆà¸³à¸à¸§à¹ˆà¸² reference à¹€à¸à¸´à¸™ 5%
# 3. à¸—à¸”à¸¥à¸­à¸‡ train à¹‚à¸¡à¹€à¸”à¸¥à¸”à¹‰à¸§à¸¢ hyperparameters à¸—à¸µà¹ˆà¹à¸•à¸à¸•à¹ˆà¸²à¸‡à¸à¸±à¸™à¹à¸¥à¸°à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸œà¸¥

# %%
# à¸à¸·à¹‰à¸™à¸—à¸µà¹ˆà¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸³à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”
# TODO: à¹€à¸‚à¸µà¸¢à¸™à¹‚à¸„à¹‰à¸”à¸‚à¸­à¸‡à¸„à¸¸à¸“à¸—à¸µà¹ˆà¸™à¸µà¹ˆ




# %% [markdown]
# ---
# # LAB 1.4: Target Drift Detection
#
# ## à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ
# - à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸‚à¸­à¸‡ target distribution
# - à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ prediction drift
# - à¸ªà¸£à¹‰à¸²à¸‡ alerts à¹€à¸¡à¸·à¹ˆà¸­ target drift à¹€à¸à¸´à¸™à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸à¸³à¸«à¸™à¸”

# %% [markdown]
# ### 1.4.1 à¸—à¸³à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆ Target Drift
#
# **Target Drift** à¹€à¸à¸´à¸”à¸‚à¸¶à¹‰à¸™à¹€à¸¡à¸·à¹ˆà¸­:
# - à¸à¸²à¸£à¸à¸£à¸°à¸ˆà¸²à¸¢à¸‚à¸­à¸‡ target variable à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡
# - Prediction à¸‚à¸­à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¹„à¸›à¸ˆà¸²à¸ reference
#
# **à¸ªà¸²à¹€à¸«à¸•à¸¸à¸—à¸µà¹ˆà¸à¸šà¸šà¹ˆà¸­à¸¢:**
# - à¸¤à¸”à¸¹à¸à¸²à¸¥ (seasonality)
# - à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸à¸¤à¸•à¸´à¸à¸£à¸£à¸¡à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰
# - External factors (à¹€à¸¨à¸£à¸©à¸à¸à¸´à¸ˆ, à¸à¸²à¸£à¹à¸‚à¹ˆà¸‡à¸‚à¸±à¸™)

# %%
# à¸ªà¸£à¹‰à¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸¡à¸µ Target Drift
print("=" * 60)
print("ğŸ“Š à¸ªà¸£à¹‰à¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸¡à¸µ Target Drift")
print("=" * 60)

# à¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Classification à¸ˆà¸²à¸à¸à¹ˆà¸­à¸™à¸«à¸™à¹‰à¸²
# à¸ªà¸£à¹‰à¸²à¸‡ current data à¸—à¸µà¹ˆà¸¡à¸µ target distribution à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹„à¸›

# Reference: à¸ªà¸±à¸”à¸ªà¹ˆà¸§à¸™ target à¸›à¸à¸•à¸´
reference_target_drift = reference_clf.copy()

# Current: à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸ªà¸±à¸”à¸ªà¹ˆà¸§à¸™ target (à¹€à¸à¸´à¹ˆà¸¡ class 1)
current_target_drift = current_clf.copy()

# à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ target à¸šà¸²à¸‡à¸ªà¹ˆà¸§à¸™à¸ˆà¸²à¸ 0 à¹€à¸›à¹‡à¸™ 1 à¹€à¸à¸·à¹ˆà¸­à¸ˆà¸³à¸¥à¸­à¸‡ drift
np.random.seed(42)
change_indices = current_target_drift[current_target_drift['target'] == 0].sample(
    frac=0.3, random_state=42
).index
current_target_drift.loc[change_indices, 'target'] = 1

print("\nğŸ“‹ à¸à¸²à¸£à¸à¸£à¸°à¸ˆà¸²à¸¢à¸‚à¸­à¸‡ Target:")
print("-" * 40)
print("\nğŸ”¹ Reference Data:")
print(reference_target_drift['target'].value_counts(normalize=True))
print("\nğŸ”¹ Current Data (with drift):")
print(current_target_drift['target'].value_counts(normalize=True))

# %% [markdown]
# ### 1.4.2 à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š Target Drift

# %%
# à¸ªà¸£à¹‰à¸²à¸‡ Target Drift Report
print("=" * 60)
print("ğŸ“Š à¸ªà¸£à¹‰à¸²à¸‡ Target Drift Report")
print("=" * 60)

target_drift_report = Report(metrics=[
    TargetDriftMetric()
])

target_drift_report.run(
    reference_data=reference_target_drift,
    current_data=current_target_drift,
    column_mapping=clf_column_mapping
)

print("âœ… à¸ªà¸£à¹‰à¸²à¸‡ Target Drift Report à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

# %%
# à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ
target_drift_results = target_drift_report.as_dict()

print("\nğŸ“‹ à¸œà¸¥à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š Target Drift:")
print("-" * 40)

for metric in target_drift_results['metrics']:
    if 'TargetDriftMetric' in metric['metric']:
        result = metric['result']
        print(f"ğŸ“Œ Drift Detected: {result['drift_detected']}")
        print(f"ğŸ“Œ Drift Score (p-value): {result['drift_score']:.6f}")
        print(f"ğŸ“Œ Statistical Test: {result['stattest_name']}")

# %%
# à¸šà¸±à¸™à¸—à¸¶à¸ Report
target_drift_report.save_html("report_target_drift.html")
print("\nğŸ’¾ à¸šà¸±à¸™à¸—à¸¶à¸ Report à¹€à¸›à¹‡à¸™à¹„à¸Ÿà¸¥à¹Œ 'report_target_drift.html' à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

# %% [markdown]
# ### 1.4.3 à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š Prediction Drift

# %%
# à¸ªà¸£à¹‰à¸²à¸‡ Prediction Drift
print("=" * 60)
print("ğŸ“Š à¸ªà¸£à¹‰à¸²à¸‡ Prediction Drift Report")
print("=" * 60)

# à¸ªà¸£à¹‰à¸²à¸‡ prediction à¹ƒà¸«à¸¡à¹ˆà¸ªà¸³à¸«à¸£à¸±à¸š current data à¸—à¸µà¹ˆà¸¡à¸µ drift
# (à¹ƒà¸™à¸à¸£à¸“à¸µà¸ˆà¸£à¸´à¸‡ prediction à¸­à¸²à¸ˆà¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹€à¸¡à¸·à¹ˆà¸­ input data à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™)

# à¸ˆà¸³à¸¥à¸­à¸‡à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸‚à¸­à¸‡ prediction
current_pred_drift = current_target_drift.copy()
np.random.seed(42)
flip_indices = np.random.choice(
    current_pred_drift.index,
    size=int(len(current_pred_drift) * 0.2),
    replace=False
)
current_pred_drift.loc[flip_indices, 'prediction'] = 1 - current_pred_drift.loc[flip_indices, 'prediction']

print(f"ğŸ“Œ à¸ˆà¸³à¸™à¸§à¸™ predictions à¸—à¸µà¹ˆà¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™: {len(flip_indices)}")

# %%
# à¸ªà¸£à¹‰à¸²à¸‡ Report à¸ªà¸³à¸«à¸£à¸±à¸š Prediction Drift
prediction_drift_report = Report(metrics=[
    ColumnDriftMetric(column_name='prediction')
])

prediction_drift_report.run(
    reference_data=reference_target_drift,
    current_data=current_pred_drift,
    column_mapping=clf_column_mapping
)

# à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸œà¸¥
pred_drift_results = prediction_drift_report.as_dict()

print("\nğŸ“‹ à¸œà¸¥à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š Prediction Drift:")
print("-" * 40)

for metric in pred_drift_results['metrics']:
    if 'ColumnDriftMetric' in metric['metric']:
        result = metric['result']
        print(f"ğŸ“Œ Column: {result['column_name']}")
        print(f"ğŸ“Œ Drift Detected: {result['drift_detected']}")
        print(f"ğŸ“Œ Drift Score: {result['drift_score']:.6f}")

# %% [markdown]
# ### 1.4.4 à¸ªà¸£à¹‰à¸²à¸‡ Test Suite à¸ªà¸³à¸«à¸£à¸±à¸š Target Drift

# %%
# Test Suite à¸ªà¸³à¸«à¸£à¸±à¸š Target Drift
print("=" * 60)
print("ğŸ§ª Target Drift Test Suite")
print("=" * 60)

target_drift_test = TestSuite(tests=[
    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¹„à¸¡à¹ˆà¸¡à¸µ target drift
    TestColumnDrift(column_name='target'),

    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¹„à¸¡à¹ˆà¸¡à¸µ prediction drift
    TestColumnDrift(column_name='prediction'),
])

target_drift_test.run(
    reference_data=reference_target_drift,
    current_data=current_pred_drift,
    column_mapping=clf_column_mapping
)

# à¹à¸ªà¸”à¸‡à¸œà¸¥
target_test_results = target_drift_test.as_dict()
print("\nğŸ“‹ à¸œà¸¥à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š Target Drift:")
print("-" * 40)

for test in target_test_results['tests']:
    test_name = test['name']
    status = "âœ… PASS" if test['status'] == 'SUCCESS' else "âŒ FAIL"
    desc = test.get('description', '')
    print(f"{status}: {test_name}")

# %%
# à¸šà¸±à¸™à¸—à¸¶à¸ Test Suite
target_drift_test.save_html("test_suite_target_drift.html")
print("\nğŸ’¾ à¸šà¸±à¸™à¸—à¸¶à¸ Test Suite à¹€à¸›à¹‡à¸™à¹„à¸Ÿà¸¥à¹Œ 'test_suite_target_drift.html' à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

# %% [markdown]
# ### 1.4.5 à¸ªà¸£à¹‰à¸²à¸‡ Comprehensive Drift Report

# %%
# à¸£à¸§à¸¡à¸—à¸¸à¸ metrics à¹ƒà¸™ Report à¹€à¸”à¸µà¸¢à¸§
print("=" * 60)
print("ğŸ“Š à¸ªà¸£à¹‰à¸²à¸‡ Comprehensive Drift Report")
print("=" * 60)

comprehensive_report = Report(metrics=[
    DataDriftPreset(),
    TargetDriftMetric(),
    ColumnDriftMetric(column_name='prediction'),
])

comprehensive_report.run(
    reference_data=reference_target_drift,
    current_data=current_pred_drift,
    column_mapping=clf_column_mapping
)

print("âœ… à¸ªà¸£à¹‰à¸²à¸‡ Comprehensive Report à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

# %%
# à¸šà¸±à¸™à¸—à¸¶à¸ Report
comprehensive_report.save_html("report_comprehensive_drift.html")
print("\nğŸ’¾ à¸šà¸±à¸™à¸—à¸¶à¸ Report à¹€à¸›à¹‡à¸™à¹„à¸Ÿà¸¥à¹Œ 'report_comprehensive_drift.html' à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

# %% [markdown]
# ### 1.4.6 à¸ªà¸£à¹‰à¸²à¸‡ Alert System

# %%
# à¸ªà¸£à¹‰à¸²à¸‡à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸š Alert
def check_drift_alerts(reference_data, current_data, column_mapping, thresholds=None):
    """
    à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š drift à¹à¸¥à¸°à¸ªà¹ˆà¸‡ alerts

    Parameters:
    - reference_data: DataFrame à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ reference
    - current_data: DataFrame à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ current
    - column_mapping: ColumnMapping object
    - thresholds: dict à¸à¸³à¸«à¸™à¸” threshold à¸ªà¸³à¸«à¸£à¸±à¸š alerts

    Returns:
    - dict: à¸œà¸¥à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹à¸¥à¸° alerts
    """
    if thresholds is None:
        thresholds = {
            'drift_share': 0.3,  # à¹à¸ˆà¹‰à¸‡à¹€à¸•à¸·à¸­à¸™à¸–à¹‰à¸² drift features à¹€à¸à¸´à¸™ 30%
            'target_drift_pvalue': 0.05,  # à¹à¸ˆà¹‰à¸‡à¹€à¸•à¸·à¸­à¸™à¸–à¹‰à¸² p-value < 0.05
        }

    alerts = []

    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Data Drift
    drift_report = Report(metrics=[DataDriftPreset()])
    drift_report.run(reference_data=reference_data, current_data=current_data,
                     column_mapping=column_mapping)
    drift_results = drift_report.as_dict()

    dataset_drift = drift_results['metrics'][0]['result']
    drift_share = dataset_drift['share_of_drifted_columns']

    if drift_share > thresholds['drift_share']:
        alerts.append({
            'type': 'DATA_DRIFT',
            'severity': 'HIGH',
            'message': f"âš ï¸ Data drift detected! {drift_share:.1%} of features have drifted (threshold: {thresholds['drift_share']:.1%})"
        })

    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Target Drift
    target_report = Report(metrics=[TargetDriftMetric()])
    target_report.run(reference_data=reference_data, current_data=current_data,
                      column_mapping=column_mapping)
    target_results = target_report.as_dict()

    target_drift = target_results['metrics'][0]['result']

    if target_drift['drift_detected']:
        alerts.append({
            'type': 'TARGET_DRIFT',
            'severity': 'CRITICAL',
            'message': f"ğŸš¨ Target drift detected! p-value: {target_drift['drift_score']:.6f}"
        })

    return {
        'data_drift_share': drift_share,
        'target_drift_detected': target_drift['drift_detected'],
        'target_drift_pvalue': target_drift['drift_score'],
        'alerts': alerts
    }

# %%
# à¸—à¸”à¸ªà¸­à¸š Alert System
print("=" * 60)
print("ğŸ”” Alert System")
print("=" * 60)

alert_results = check_drift_alerts(
    reference_data=reference_target_drift,
    current_data=current_pred_drift,
    column_mapping=clf_column_mapping
)

print("\nğŸ“‹ à¸ªà¸£à¸¸à¸›à¸œà¸¥à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š:")
print("-" * 40)
print(f"ğŸ“Œ Data Drift Share: {alert_results['data_drift_share']:.1%}")
print(f"ğŸ“Œ Target Drift Detected: {alert_results['target_drift_detected']}")
print(f"ğŸ“Œ Target Drift p-value: {alert_results['target_drift_pvalue']:.6f}")

print("\nğŸ“‹ Alerts:")
print("-" * 40)
if alert_results['alerts']:
    for alert in alert_results['alerts']:
        print(f"[{alert['severity']}] {alert['type']}: {alert['message']}")
else:
    print("âœ… à¹„à¸¡à¹ˆà¸¡à¸µ alerts")

# %% [markdown]
# ### ğŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸” LAB 1.4
#
# 1. à¸—à¸”à¸¥à¸­à¸‡à¸ªà¸£à¹‰à¸²à¸‡ drift à¸”à¹‰à¸§à¸¢à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ target distribution à¹ƒà¸™à¸£à¸°à¸”à¸±à¸šà¸•à¹ˆà¸²à¸‡à¹† (10%, 20%, 50%)
# 2. à¸ªà¸£à¹‰à¸²à¸‡ Alert System à¸—à¸µà¹ˆà¸ªà¹ˆà¸‡ notification à¹€à¸¡à¸·à¹ˆà¸­à¸•à¸£à¸§à¸ˆà¸à¸š drift
# 3. à¸—à¸”à¸¥à¸­à¸‡à¹ƒà¸Šà¹‰ statistical test à¸­à¸·à¹ˆà¸™à¹† à¹ƒà¸™ Evidently (chi-square, KS test, etc.)

# %%
# à¸à¸·à¹‰à¸™à¸—à¸µà¹ˆà¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸³à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”
# TODO: à¹€à¸‚à¸µà¸¢à¸™à¹‚à¸„à¹‰à¸”à¸‚à¸­à¸‡à¸„à¸¸à¸“à¸—à¸µà¹ˆà¸™à¸µà¹ˆ




# %% [markdown]
# ---
# # à¸ªà¸£à¸¸à¸› Section 1
#
# ## à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¹„à¸”à¹‰à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰
#
# ### LAB 1.1: Introduction to Evidently AI
# - à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡à¹à¸¥à¸°à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Evidently à¹€à¸šà¸·à¹‰à¸­à¸‡à¸•à¹‰à¸™
# - à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆ Report à¹à¸¥à¸° Test Suite
# - à¸ªà¸£à¹‰à¸²à¸‡ Data Drift Report
#
# ### LAB 1.2: Data Quality Monitoring
# - à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š missing values à¹à¸¥à¸° duplicates
# - à¸ªà¸£à¹‰à¸²à¸‡ Data Quality Report
# - à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² threshold alerts
#
# ### LAB 1.3: Model Performance Tracking
# - à¸•à¸´à¸”à¸•à¸²à¸¡ Classification metrics (Accuracy, Precision, Recall, F1)
# - à¸•à¸´à¸”à¸•à¸²à¸¡ Regression metrics (MAE, RMSE, RÂ²)
# - à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š performance à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ reference vs current
#
# ### LAB 1.4: Target Drift Detection
# - à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š Target Drift
# - à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š Prediction Drift
# - à¸ªà¸£à¹‰à¸²à¸‡ Alert System

# %% [markdown]
# ## Best Practices à¸ªà¸³à¸«à¸£à¸±à¸š Model Monitoring
#
# 1. **à¸à¸³à¸«à¸™à¸” Baseline à¸—à¸µà¹ˆà¸Šà¸±à¸”à¹€à¸ˆà¸™**: à¹€à¸à¹‡à¸š reference data à¸—à¸µà¹ˆà¸¡à¸µà¸„à¸¸à¸“à¸ à¸²à¸
# 2. **Monitor à¸ªà¸¡à¹ˆà¸³à¹€à¸ªà¸¡à¸­**: à¸•à¸±à¹‰à¸‡ schedule à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š
# 3. **à¸•à¸±à¹‰à¸‡ Threshold à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡**: à¸›à¸£à¸±à¸šà¸•à¸²à¸¡à¸šà¸£à¸´à¸šà¸—à¸‚à¸­à¸‡ business
# 4. **à¸ªà¸£à¹‰à¸²à¸‡ Alert System**: à¹à¸ˆà¹‰à¸‡à¹€à¸•à¸·à¸­à¸™à¸—à¸±à¸™à¸—à¸µà¹€à¸¡à¸·à¹ˆà¸­à¸à¸šà¸›à¸±à¸à¸«à¸²
# 5. **à¹€à¸à¹‡à¸š Log à¹à¸¥à¸° History**: à¹€à¸à¸·à¹ˆà¸­à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ trend

# %%
# à¸ªà¸£à¸¸à¸› files à¸—à¸µà¹ˆà¸ªà¸£à¹‰à¸²à¸‡
print("=" * 60)
print("ğŸ“ Files à¸—à¸µà¹ˆà¸ªà¸£à¹‰à¸²à¸‡à¸ˆà¸²à¸ Lab à¸™à¸µà¹‰")
print("=" * 60)
print("""
1. report_data_drift.html - Data Drift Report
2. test_suite_data_drift.html - Data Drift Test Suite
3. report_data_quality.html - Data Quality Report
4. test_suite_data_quality.html - Data Quality Test Suite
5. report_classification_performance.html - Classification Performance Report
6. report_regression_performance.html - Regression Performance Report
7. report_target_drift.html - Target Drift Report
8. test_suite_target_drift.html - Target Drift Test Suite
9. report_comprehensive_drift.html - Comprehensive Drift Report
""")
print("âœ… Lab Section 1 à¹€à¸ªà¸£à¹‡à¸ˆà¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œ!")

# %% [markdown]
# ---
# ---
# # Section 2: Feature Drift & Data Drift
#
# **à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œà¸à¸²à¸£à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰:**
# - à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸„à¸§à¸²à¸¡à¹à¸•à¸à¸•à¹ˆà¸²à¸‡à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ Data Drift à¹à¸¥à¸° Feature Drift
# - à¹ƒà¸Šà¹‰ Statistical Tests à¸•à¹ˆà¸²à¸‡à¹† à¹ƒà¸™à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š Drift
# - à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ Drift à¹ƒà¸™à¸£à¸°à¸”à¸±à¸š Feature à¹à¸•à¹ˆà¸¥à¸°à¸•à¸±à¸§
# - à¸ªà¸£à¹‰à¸²à¸‡à¸à¸¥à¸¢à¸¸à¸—à¸˜à¹Œà¹ƒà¸™à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£à¸à¸±à¸š Drift

# %% [markdown]
# ---
# # LAB 2.1: Understanding Data Drift
#
# ## à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ
# - à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¹à¸™à¸§à¸„à¸´à¸”à¹à¸¥à¸°à¸›à¸£à¸°à¹€à¸ à¸—à¸‚à¸­à¸‡ Data Drift
# - à¸ªà¸£à¹‰à¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸³à¸¥à¸­à¸‡à¸—à¸µà¹ˆà¸¡à¸µ Drift à¹à¸šà¸šà¸•à¹ˆà¸²à¸‡à¹†
# - à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š Dataset-level Drift

# %% [markdown]
# ### 2.1.1 à¸›à¸£à¸°à¹€à¸ à¸—à¸‚à¸­à¸‡ Data Drift
#
# **Data Drift** à¸„à¸·à¸­à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸‚à¸­à¸‡ distribution à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ à¸‹à¸¶à¹ˆà¸‡à¹à¸šà¹ˆà¸‡à¹€à¸›à¹‡à¸™:
#
# 1. **Covariate Shift**: Input features à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡ à¹à¸•à¹ˆà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œà¸à¸±à¸š target à¸„à¸‡à¸—à¸µà¹ˆ
# 2. **Prior Probability Shift**: Target distribution à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡
# 3. **Concept Drift**: à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œà¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ features à¹à¸¥à¸° target à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹„à¸›
#
# **à¸ªà¸²à¹€à¸«à¸•à¸¸à¸‚à¸­à¸‡ Data Drift:**
# - à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸•à¸²à¸¡à¸¤à¸”à¸¹à¸à¸²à¸¥ (Seasonality)
# - à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸à¸¤à¸•à¸´à¸à¸£à¸£à¸¡à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰
# - à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸‚à¸­à¸‡ data collection process
# - External events (à¹€à¸¨à¸£à¸©à¸à¸à¸´à¸ˆ, à¸ªà¸±à¸‡à¸„à¸¡, à¸à¸²à¸£à¹à¸‚à¹ˆà¸‡à¸‚à¸±à¸™)

# %%
# Import libraries à¸ªà¸³à¸«à¸£à¸±à¸š Section 2
import pandas as pd
import numpy as np
from sklearn.datasets import load_breast_cancer, make_classification
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler

from evidently import ColumnMapping
from evidently.report import Report
from evidently.metric_preset import DataDriftPreset
from evidently.metrics import *
from evidently.test_suite import TestSuite
from evidently.test_preset import DataDriftTestPreset
from evidently.tests import *

import warnings
warnings.filterwarnings('ignore')

print("=" * 60)
print("ğŸ“š Section 2: Feature Drift & Data Drift")
print("=" * 60)

# %%
# à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸·à¹‰à¸™à¸à¸²à¸™
print("\nğŸ“Š à¹‚à¸«à¸¥à¸” Breast Cancer Dataset")
print("-" * 40)

cancer = load_breast_cancer()
df_base = pd.DataFrame(cancer.data, columns=cancer.feature_names)
df_base['target'] = cancer.target

# à¹€à¸¥à¸·à¸­à¸à¹€à¸‰à¸à¸²à¸° features à¸«à¸¥à¸±à¸à¹† à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸‡à¹ˆà¸²à¸¢à¸•à¹ˆà¸­à¸à¸²à¸£à¸¨à¸¶à¸à¸©à¸²
selected_features = [
    'mean radius', 'mean texture', 'mean perimeter', 'mean area',
    'mean smoothness', 'mean compactness', 'mean concavity',
    'mean symmetry', 'mean fractal dimension'
]

df_selected = df_base[selected_features + ['target']].copy()

print(f"ğŸ“Œ à¸‚à¸™à¸²à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥: {df_selected.shape}")
print(f"ğŸ“Œ Features à¸—à¸µà¹ˆà¹€à¸¥à¸·à¸­à¸: {len(selected_features)} features")

# %% [markdown]
# ### 2.1.2 à¸ªà¸£à¹‰à¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸¡à¸µ Drift à¹à¸šà¸šà¸•à¹ˆà¸²à¸‡à¹†

# %%
# à¹à¸šà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸›à¹‡à¸™ Reference
reference_data = df_selected.iloc[:400].copy()

print("=" * 60)
print("ğŸ“Š à¸ªà¸£à¹‰à¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸¡à¸µ Drift à¹à¸šà¸šà¸•à¹ˆà¸²à¸‡à¹†")
print("=" * 60)

# %%
# 1. Gradual Drift - à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¹à¸šà¸šà¸„à¹ˆà¸­à¸¢à¹€à¸›à¹‡à¸™à¸„à¹ˆà¸­à¸¢à¹„à¸›
print("\nğŸ”¹ 1. Gradual Drift")
print("-" * 40)

gradual_drift_data = df_selected.iloc[400:].copy()

# à¹€à¸à¸´à¹ˆà¸¡à¸„à¹ˆà¸²à¸—à¸µà¸¥à¸°à¸™à¹‰à¸­à¸¢à¹ƒà¸«à¹‰à¸à¸±à¸š features
np.random.seed(42)
drift_factor = 0.1  # 10% shift

for col in selected_features[:5]:  # drift 5 features à¹à¸£à¸
    original_std = gradual_drift_data[col].std()
    gradual_drift_data[col] = gradual_drift_data[col] + (drift_factor * original_std)

print(f"ğŸ“Œ à¸ªà¸£à¹‰à¸²à¸‡ Gradual Drift à¹ƒà¸™ 5 features")
print(f"ğŸ“Œ Drift factor: {drift_factor:.0%}")

# %%
# 2. Sudden Drift - à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¹à¸šà¸šà¸à¸°à¸—à¸±à¸™à¸«à¸±à¸™
print("\nğŸ”¹ 2. Sudden Drift")
print("-" * 40)

sudden_drift_data = df_selected.iloc[400:].copy()

# à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸„à¹ˆà¸²à¹à¸šà¸šà¸à¸°à¸—à¸±à¸™à¸«à¸±à¸™
for col in ['mean radius', 'mean area']:
    sudden_drift_data[col] = sudden_drift_data[col] * 1.5  # à¹€à¸à¸´à¹ˆà¸¡ 50%

print(f"ğŸ“Œ à¸ªà¸£à¹‰à¸²à¸‡ Sudden Drift à¹ƒà¸™ 'mean radius' à¹à¸¥à¸° 'mean area'")
print(f"ğŸ“Œ à¹€à¸à¸´à¹ˆà¸¡à¸„à¹ˆà¸² 50%")

# %%
# 3. Seasonal Drift - à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸•à¸²à¸¡à¸¤à¸”à¸¹à¸à¸²à¸¥
print("\nğŸ”¹ 3. Seasonal Drift (Simulated)")
print("-" * 40)

seasonal_drift_data = df_selected.iloc[400:].copy()

# à¸ˆà¸³à¸¥à¸­à¸‡ seasonal pattern à¸”à¹‰à¸§à¸¢ sine wave
n_samples = len(seasonal_drift_data)
seasonal_factor = np.sin(np.linspace(0, 2*np.pi, n_samples))

for col in ['mean texture', 'mean smoothness']:
    original_std = seasonal_drift_data[col].std()
    seasonal_drift_data[col] = seasonal_drift_data[col] + (seasonal_factor * original_std * 0.3)

print(f"ğŸ“Œ à¸ªà¸£à¹‰à¸²à¸‡ Seasonal Drift à¹ƒà¸™ 'mean texture' à¹à¸¥à¸° 'mean smoothness'")

# %%
# 4. Incremental Drift - à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¹à¸šà¸šà¸ªà¸°à¸ªà¸¡
print("\nğŸ”¹ 4. Incremental Drift")
print("-" * 40)

incremental_drift_data = df_selected.iloc[400:].copy()

# à¸ªà¸£à¹‰à¸²à¸‡ incremental drift - à¸„à¹ˆà¸²à¹€à¸à¸´à¹ˆà¸¡à¸‚à¸¶à¹‰à¸™à¹€à¸£à¸·à¹ˆà¸­à¸¢à¹† à¸•à¸²à¸¡à¸¥à¸³à¸”à¸±à¸š
n_samples = len(incremental_drift_data)
increment = np.linspace(0, 1, n_samples)

for col in ['mean compactness', 'mean concavity']:
    original_std = incremental_drift_data[col].std()
    incremental_drift_data.loc[:, col] = incremental_drift_data[col].values + (increment * original_std * 0.5)

print(f"ğŸ“Œ à¸ªà¸£à¹‰à¸²à¸‡ Incremental Drift à¹ƒà¸™ 'mean compactness' à¹à¸¥à¸° 'mean concavity'")

# %% [markdown]
# ### 2.1.3 à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š Dataset-level Drift

# %%
# à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š Drift à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸°à¸›à¸£à¸°à¹€à¸ à¸—
print("=" * 60)
print("ğŸ“Š à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š Dataset-level Drift")
print("=" * 60)

# Column Mapping
column_mapping = ColumnMapping(
    target='target',
    numerical_features=selected_features
)

# à¸ªà¸£à¹‰à¸²à¸‡à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š drift
def detect_dataset_drift(reference, current, name, column_mapping):
    """à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š dataset-level drift"""
    report = Report(metrics=[DataDriftPreset()])
    report.run(reference_data=reference, current_data=current, column_mapping=column_mapping)
    results = report.as_dict()

    drift_info = results['metrics'][0]['result']
    return {
        'name': name,
        'dataset_drift': drift_info['dataset_drift'],
        'drift_share': drift_info['share_of_drifted_columns'],
        'n_drifted': drift_info['number_of_drifted_columns']
    }

# %%
# à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š drift à¸—à¸¸à¸à¸›à¸£à¸°à¹€à¸ à¸—
drift_types = [
    ('Gradual Drift', gradual_drift_data),
    ('Sudden Drift', sudden_drift_data),
    ('Seasonal Drift', seasonal_drift_data),
    ('Incremental Drift', incremental_drift_data),
]

print("\nğŸ“‹ à¸ªà¸£à¸¸à¸›à¸œà¸¥à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š Dataset Drift:")
print("-" * 60)
print(f"{'Drift Type':<20} {'Detected':<12} {'Drift Share':<15} {'N Drifted'}")
print("-" * 60)

drift_results = []
for name, data in drift_types:
    result = detect_dataset_drift(reference_data, data, name, column_mapping)
    drift_results.append(result)
    detected = "âœ… Yes" if result['dataset_drift'] else "âŒ No"
    print(f"{result['name']:<20} {detected:<12} {result['drift_share']:.1%}{'':>10} {result['n_drifted']}")

# %% [markdown]
# ### ğŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸” LAB 2.1
#
# 1. à¸¥à¸­à¸‡à¸›à¸£à¸±à¸š drift_factor à¹ƒà¸«à¹‰à¸¡à¸²à¸à¸‚à¸¶à¹‰à¸™/à¸™à¹‰à¸­à¸¢à¸¥à¸‡ à¹à¸¥à¸°à¸ªà¸±à¸‡à¹€à¸à¸•à¸œà¸¥
# 2. à¸ªà¸£à¹‰à¸²à¸‡ drift à¹à¸šà¸šà¹ƒà¸«à¸¡à¹ˆà¸—à¸µà¹ˆà¸£à¸§à¸¡ gradual + sudden drift
# 3. à¸—à¸”à¸¥à¸­à¸‡à¸à¸±à¸š dataset à¸­à¸·à¹ˆà¸™à¹à¸¥à¸°à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸œà¸¥

# %%
# à¸à¸·à¹‰à¸™à¸—à¸µà¹ˆà¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸³à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”
# TODO: à¹€à¸‚à¸µà¸¢à¸™à¹‚à¸„à¹‰à¸”à¸‚à¸­à¸‡à¸„à¸¸à¸“à¸—à¸µà¹ˆà¸™à¸µà¹ˆ




# %% [markdown]
# ---
# # LAB 2.2: Feature Drift Detection
#
# ## à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ
# - à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š Drift à¹ƒà¸™à¸£à¸°à¸”à¸±à¸š Feature à¹à¸•à¹ˆà¸¥à¸°à¸•à¸±à¸§
# - à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸§à¹ˆà¸² Feature à¹ƒà¸”à¸¡à¸µ Drift
# - à¸ªà¸£à¹‰à¸²à¸‡ Feature-level Drift Report

# %% [markdown]
# ### 2.2.1 à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š Drift à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸° Feature

# %%
# à¸ªà¸£à¹‰à¸²à¸‡ Feature Drift Report
print("=" * 60)
print("ğŸ“Š Feature-level Drift Detection")
print("=" * 60)

# à¹ƒà¸Šà¹‰ Sudden Drift data à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¹€à¸«à¹‡à¸™à¸œà¸¥à¸Šà¸±à¸”à¹€à¸ˆà¸™
feature_drift_report = Report(metrics=[
    DataDriftPreset()
])

feature_drift_report.run(
    reference_data=reference_data,
    current_data=sudden_drift_data,
    column_mapping=column_mapping
)

print("âœ… à¸ªà¸£à¹‰à¸²à¸‡ Feature Drift Report à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

# %%
# à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ Drift à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸° Feature
feature_results = feature_drift_report.as_dict()

print("\nğŸ“‹ Feature-level Drift Analysis:")
print("-" * 70)
print(f"{'Feature':<25} {'Drift Detected':<15} {'Drift Score':<15} {'Stat Test'}")
print("-" * 70)

drift_by_columns = feature_results['metrics'][0]['result']['drift_by_columns']

for feature, info in drift_by_columns.items():
    if feature != 'target':
        detected = "âœ… Yes" if info['drift_detected'] else "âŒ No"
        score = f"{info['drift_score']:.4f}"
        test = info['stattest_name']
        print(f"{feature:<25} {detected:<15} {score:<15} {test}")

# %%
# à¸šà¸±à¸™à¸—à¸¶à¸ Report
feature_drift_report.save_html("report_feature_drift.html")
print("\nğŸ’¾ à¸šà¸±à¸™à¸—à¸¶à¸ Report à¹€à¸›à¹‡à¸™à¹„à¸Ÿà¸¥à¹Œ 'report_feature_drift.html' à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

# %% [markdown]
# ### 2.2.2 à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š Drift à¹à¸šà¸šà¹€à¸ˆà¸²à¸°à¸ˆà¸‡ Feature

# %%
# à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š Drift à¹€à¸‰à¸à¸²à¸° Feature à¸—à¸µà¹ˆà¸ªà¸™à¹ƒà¸ˆ
print("=" * 60)
print("ğŸ“Š Single Feature Drift Detection")
print("=" * 60)

# à¸ªà¸£à¹‰à¸²à¸‡ Report à¸ªà¸³à¸«à¸£à¸±à¸š features à¹€à¸‰à¸à¸²à¸°
single_feature_report = Report(metrics=[
    ColumnDriftMetric(column_name='mean radius'),
    ColumnDriftMetric(column_name='mean area'),
    ColumnDriftMetric(column_name='mean texture'),
])

single_feature_report.run(
    reference_data=reference_data,
    current_data=sudden_drift_data,
    column_mapping=column_mapping
)

# à¹à¸ªà¸”à¸‡à¸œà¸¥
single_results = single_feature_report.as_dict()

print("\nğŸ“‹ Single Feature Drift Results:")
print("-" * 50)

for metric in single_results['metrics']:
    result = metric['result']
    feature = result['column_name']
    detected = "âœ… Yes" if result['drift_detected'] else "âŒ No"
    score = result['drift_score']
    print(f"ğŸ“Œ {feature}: Drift={detected}, Score={score:.4f}")

# %% [markdown]
# ### 2.2.3 à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š Distribution à¸à¹ˆà¸­à¸™-à¸«à¸¥à¸±à¸‡ Drift

# %%
# à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ Distribution à¸‚à¸­à¸‡ Feature à¸—à¸µà¹ˆà¸¡à¸µ Drift
print("=" * 60)
print("ğŸ“Š Distribution Comparison")
print("=" * 60)

# à¸ªà¸£à¹‰à¸²à¸‡ Report à¹à¸ªà¸”à¸‡ distribution
distribution_report = Report(metrics=[
    ColumnSummaryMetric(column_name='mean radius'),
    ColumnSummaryMetric(column_name='mean area'),
    ColumnValueRangeMetric(column_name='mean radius'),
    ColumnValueRangeMetric(column_name='mean area'),
])

distribution_report.run(
    reference_data=reference_data,
    current_data=sudden_drift_data,
    column_mapping=column_mapping
)

dist_results = distribution_report.as_dict()

print("\nğŸ“‹ Distribution Statistics Comparison:")
print("-" * 70)

for metric in dist_results['metrics']:
    if 'ColumnSummaryMetric' in metric['metric']:
        result = metric['result']
        col = result['column_name']
        ref = result['reference_characteristics']
        cur = result['current_characteristics']

        print(f"\nğŸ”¹ {col}:")
        print(f"   Reference: mean={ref['mean']:.2f}, std={ref['std']:.2f}, min={ref['min']:.2f}, max={ref['max']:.2f}")
        print(f"   Current:   mean={cur['mean']:.2f}, std={cur['std']:.2f}, min={cur['min']:.2f}, max={cur['max']:.2f}")

# %%
# à¸šà¸±à¸™à¸—à¸¶à¸ Distribution Report
distribution_report.save_html("report_distribution_comparison.html")
print("\nğŸ’¾ à¸šà¸±à¸™à¸—à¸¶à¸ Report à¹€à¸›à¹‡à¸™à¹„à¸Ÿà¸¥à¹Œ 'report_distribution_comparison.html' à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

# %% [markdown]
# ### 2.2.4 à¸ªà¸£à¹‰à¸²à¸‡ Feature Drift Test Suite

# %%
# Test Suite à¸ªà¸³à¸«à¸£à¸±à¸š Feature Drift
print("=" * 60)
print("ğŸ§ª Feature Drift Test Suite")
print("=" * 60)

feature_drift_test = TestSuite(tests=[
    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š drift à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸° feature
    TestColumnDrift(column_name='mean radius'),
    TestColumnDrift(column_name='mean area'),
    TestColumnDrift(column_name='mean texture'),
    TestColumnDrift(column_name='mean perimeter'),
    TestColumnDrift(column_name='mean smoothness'),

    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸ˆà¸³à¸™à¸§à¸™ features à¸—à¸µà¹ˆ drift
    TestShareOfDriftedColumns(lte=0.3),  # à¹„à¸¡à¹ˆà¹€à¸à¸´à¸™ 30%

    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š dataset drift
    TestNumberOfDriftedColumns(lte=3),  # à¹„à¸¡à¹ˆà¹€à¸à¸´à¸™ 3 columns
])

feature_drift_test.run(
    reference_data=reference_data,
    current_data=sudden_drift_data,
    column_mapping=column_mapping
)

# à¹à¸ªà¸”à¸‡à¸œà¸¥
test_results = feature_drift_test.as_dict()

print("\nğŸ“‹ Feature Drift Test Results:")
print("-" * 60)

passed = 0
failed = 0
for test in test_results['tests']:
    status = "âœ… PASS" if test['status'] == 'SUCCESS' else "âŒ FAIL"
    if test['status'] == 'SUCCESS':
        passed += 1
    else:
        failed += 1
    print(f"{status}: {test['name']}")

print(f"\nğŸ“Š Summary: {passed} passed, {failed} failed")

# %%
# à¸šà¸±à¸™à¸—à¸¶à¸ Test Suite
feature_drift_test.save_html("test_suite_feature_drift.html")
print("\nğŸ’¾ à¸šà¸±à¸™à¸—à¸¶à¸ Test Suite à¹€à¸›à¹‡à¸™à¹„à¸Ÿà¸¥à¹Œ 'test_suite_feature_drift.html' à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

# %% [markdown]
# ### ğŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸” LAB 2.2
#
# 1. à¸ªà¸£à¹‰à¸²à¸‡ drift à¹ƒà¸«à¹‰à¸à¸±à¸š features à¸­à¸·à¹ˆà¸™à¹† à¹à¸¥à¸°à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š
# 2. à¸›à¸£à¸±à¸š threshold à¸‚à¸­à¸‡ TestShareOfDriftedColumns à¹à¸¥à¸°à¸ªà¸±à¸‡à¹€à¸à¸•à¸œà¸¥
# 3. à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š distribution à¸‚à¸­à¸‡ features à¸—à¸µà¹ˆ drift vs à¹„à¸¡à¹ˆ drift

# %%
# à¸à¸·à¹‰à¸™à¸—à¸µà¹ˆà¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸³à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”
# TODO: à¹€à¸‚à¸µà¸¢à¸™à¹‚à¸„à¹‰à¸”à¸‚à¸­à¸‡à¸„à¸¸à¸“à¸—à¸µà¹ˆà¸™à¸µà¹ˆ




# %% [markdown]
# ---
# # LAB 2.3: Drift Detection Methods
#
# ## à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ
# - à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆ Statistical Tests à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š Drift
# - à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š methods à¸•à¹ˆà¸²à¸‡à¹†
# - à¹€à¸¥à¸·à¸­à¸ method à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡à¸à¸±à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥

# %% [markdown]
# ### 2.3.1 Statistical Tests à¸ªà¸³à¸«à¸£à¸±à¸š Drift Detection
#
# **Evidently à¸£à¸­à¸‡à¸£à¸±à¸š Statistical Tests à¸«à¸¥à¸²à¸¢à¹à¸šà¸š:**
#
# | Test | à¹ƒà¸Šà¹‰à¸à¸±à¸š | à¸¥à¸±à¸à¸©à¸“à¸° |
# |------|--------|--------|
# | **Kolmogorov-Smirnov (KS)** | Numerical | à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š CDF |
# | **Wasserstein Distance** | Numerical | Earth Mover's Distance |
# | **Jensen-Shannon Divergence** | Both | Information-theoretic |
# | **Chi-Square** | Categorical | Frequency comparison |
# | **Z-test** | Numerical | Mean comparison |
# | **Population Stability Index (PSI)** | Both | Banking/Credit risk |

# %%
# Import stattest options
from evidently.calculations.stattests import StatTest

print("=" * 60)
print("ğŸ“Š Statistical Tests à¸ªà¸³à¸«à¸£à¸±à¸š Drift Detection")
print("=" * 60)

# à¹à¸ªà¸”à¸‡ Statistical Tests à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¹„à¸”à¹‰
available_tests = [
    ('ks', 'Kolmogorov-Smirnov', 'numerical'),
    ('wasserstein', 'Wasserstein Distance', 'numerical'),
    ('jensenshannon', 'Jensen-Shannon Divergence', 'both'),
    ('psi', 'Population Stability Index', 'both'),
    ('kl_div', 'Kullback-Leibler Divergence', 'both'),
    ('chisquare', 'Chi-Square', 'categorical'),
    ('z', 'Z-test', 'numerical'),
    ('t_test', 'T-test', 'numerical'),
]

print("\nğŸ“‹ Available Statistical Tests:")
print("-" * 60)
print(f"{'Test ID':<15} {'Name':<30} {'Data Type'}")
print("-" * 60)
for test_id, name, dtype in available_tests:
    print(f"{test_id:<15} {name:<30} {dtype}")

# %% [markdown]
# ### 2.3.2 à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š Statistical Tests

# %%
# à¸—à¸”à¸ªà¸­à¸š methods à¸•à¹ˆà¸²à¸‡à¹† à¸à¸±à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™
print("=" * 60)
print("ğŸ“Š à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š Statistical Tests")
print("=" * 60)

# à¹€à¸¥à¸·à¸­à¸ feature à¸—à¸µà¹ˆà¸ˆà¸°à¸—à¸”à¸ªà¸­à¸š
test_feature = 'mean radius'

# à¸ªà¸£à¹‰à¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸¡à¸µ drift à¸£à¸°à¸”à¸±à¸šà¸•à¹ˆà¸²à¸‡à¹†
np.random.seed(42)
original_values = reference_data[test_feature].values

# Mild drift (5% shift)
mild_drift = sudden_drift_data.copy()
mild_drift[test_feature] = original_values[:len(mild_drift)] * 1.05

# Moderate drift (15% shift)
moderate_drift = sudden_drift_data.copy()
moderate_drift[test_feature] = original_values[:len(moderate_drift)] * 1.15

# Severe drift (30% shift)
severe_drift = sudden_drift_data.copy()
severe_drift[test_feature] = original_values[:len(severe_drift)] * 1.30

print(f"ğŸ“Œ Testing feature: {test_feature}")
print(f"ğŸ“Œ Mild drift: 5% shift")
print(f"ğŸ“Œ Moderate drift: 15% shift")
print(f"ğŸ“Œ Severe drift: 30% shift")

# %%
# à¸—à¸”à¸ªà¸­à¸šà¹à¸•à¹ˆà¸¥à¸° method
stat_tests = ['ks', 'wasserstein', 'jensenshannon', 'psi']
drift_levels = [
    ('No Drift', reference_data.iloc[200:]),
    ('Mild (5%)', mild_drift),
    ('Moderate (15%)', moderate_drift),
    ('Severe (30%)', severe_drift),
]

print("\nğŸ“‹ Comparison Results:")
print("-" * 80)
print(f"{'Test':<15} {'No Drift':<15} {'Mild (5%)':<15} {'Moderate (15%)':<15} {'Severe (30%)':<15}")
print("-" * 80)

for stat_test in stat_tests:
    results = []
    for level_name, data in drift_levels:
        try:
            report = Report(metrics=[
                ColumnDriftMetric(column_name=test_feature, stattest=stat_test)
            ])
            report.run(
                reference_data=reference_data,
                current_data=data,
                column_mapping=column_mapping
            )
            result = report.as_dict()
            drift_score = result['metrics'][0]['result']['drift_score']
            detected = result['metrics'][0]['result']['drift_detected']
            mark = "âš ï¸" if detected else "âœ“"
            results.append(f"{drift_score:.4f} {mark}")
        except Exception as e:
            results.append("N/A")

    print(f"{stat_test:<15} {results[0]:<15} {results[1]:<15} {results[2]:<15} {results[3]:<15}")

# %% [markdown]
# ### 2.3.3 à¸à¸³à¸«à¸™à¸” Custom Statistical Test

# %%
# à¹ƒà¸Šà¹‰ Statistical Test à¸—à¸µà¹ˆà¸à¸³à¸«à¸™à¸”à¹€à¸­à¸‡
print("=" * 60)
print("ğŸ“Š Custom Statistical Test Configuration")
print("=" * 60)

# à¸ªà¸£à¹‰à¸²à¸‡ Report à¸”à¹‰à¸§à¸¢ custom stattest
custom_stattest_report = Report(metrics=[
    # à¹ƒà¸Šà¹‰ KS test à¸à¸±à¸š threshold à¸—à¸µà¹ˆà¸à¸³à¸«à¸™à¸”à¹€à¸­à¸‡
    ColumnDriftMetric(
        column_name='mean radius',
        stattest='ks',
        stattest_threshold=0.1  # à¸à¸³à¸«à¸™à¸” threshold à¹€à¸­à¸‡
    ),
    # à¹ƒà¸Šà¹‰ Wasserstein distance
    ColumnDriftMetric(
        column_name='mean area',
        stattest='wasserstein',
        stattest_threshold=0.1
    ),
    # à¹ƒà¸Šà¹‰ PSI
    ColumnDriftMetric(
        column_name='mean texture',
        stattest='psi',
        stattest_threshold=0.2
    ),
])

custom_stattest_report.run(
    reference_data=reference_data,
    current_data=sudden_drift_data,
    column_mapping=column_mapping
)

# à¹à¸ªà¸”à¸‡à¸œà¸¥
custom_results = custom_stattest_report.as_dict()

print("\nğŸ“‹ Custom Statistical Test Results:")
print("-" * 70)

for metric in custom_results['metrics']:
    result = metric['result']
    col = result['column_name']
    test = result['stattest_name']
    threshold = result['stattest_threshold']
    score = result['drift_score']
    detected = "âœ… Drift" if result['drift_detected'] else "âŒ No Drift"

    print(f"ğŸ“Œ {col}:")
    print(f"   Test: {test}, Threshold: {threshold}, Score: {score:.4f}")
    print(f"   Result: {detected}")
    print()

# %%
# à¸šà¸±à¸™à¸—à¸¶à¸ Report
custom_stattest_report.save_html("report_custom_stattest.html")
print("ğŸ’¾ à¸šà¸±à¸™à¸—à¸¶à¸ Report à¹€à¸›à¹‡à¸™à¹„à¸Ÿà¸¥à¹Œ 'report_custom_stattest.html' à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

# %% [markdown]
# ### 2.3.4 à¹€à¸¥à¸·à¸­à¸ Method à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡

# %%
# à¸„à¸³à¹à¸™à¸°à¸™à¸³à¹ƒà¸™à¸à¸²à¸£à¹€à¸¥à¸·à¸­à¸ Statistical Test
print("=" * 60)
print("ğŸ“š à¸„à¸³à¹à¸™à¸°à¸™à¸³à¹ƒà¸™à¸à¸²à¸£à¹€à¸¥à¸·à¸­à¸ Statistical Test")
print("=" * 60)

recommendations = """
ğŸ“Œ Kolmogorov-Smirnov (ks):
   - à¹€à¸«à¸¡à¸²à¸°à¸à¸±à¸š: Numerical data à¸—à¸±à¹ˆà¸§à¹„à¸›
   - à¸‚à¹‰à¸­à¸”à¸µ: à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸ªà¸¡à¸¡à¸•à¸´ distribution, sensitive à¸•à¹ˆà¸­ shape changes
   - à¸‚à¹‰à¸­à¹€à¸ªà¸µà¸¢: à¸­à¸²à¸ˆà¹„à¸¡à¹ˆ sensitive à¸à¸±à¸š tail differences

ğŸ“Œ Wasserstein Distance:
   - à¹€à¸«à¸¡à¸²à¸°à¸à¸±à¸š: à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸§à¸±à¸” "à¸£à¸°à¸¢à¸°à¸—à¸²à¸‡" à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ distributions
   - à¸‚à¹‰à¸­à¸”à¸µ: Interpretable, à¹„à¸¡à¹ˆà¸¡à¸µà¸›à¸±à¸à¸«à¸²à¸à¸±à¸š zero probabilities
   - à¸‚à¹‰à¸­à¹€à¸ªà¸µà¸¢: à¸­à¸²à¸ˆ sensitive à¸à¸±à¸š outliers

ğŸ“Œ Jensen-Shannon Divergence:
   - à¹€à¸«à¸¡à¸²à¸°à¸à¸±à¸š: Probability distributions
   - à¸‚à¹‰à¸­à¸”à¸µ: Symmetric, bounded (0-1)
   - à¸‚à¹‰à¸­à¹€à¸ªà¸µà¸¢: à¸•à¹‰à¸­à¸‡ discretize continuous data

ğŸ“Œ Population Stability Index (PSI):
   - à¹€à¸«à¸¡à¸²à¸°à¸à¸±à¸š: Credit scoring, Risk management
   - à¸‚à¹‰à¸­à¸”à¸µ: Industry standard, interpretable thresholds
   - à¸‚à¹‰à¸­à¹€à¸ªà¸µà¸¢: Sensitive to bin selection

ğŸ“Œ Chi-Square:
   - à¹€à¸«à¸¡à¸²à¸°à¸à¸±à¸š: Categorical data
   - à¸‚à¹‰à¸­à¸”à¸µ: Well-understood, works with frequencies
   - à¸‚à¹‰à¸­à¹€à¸ªà¸µà¸¢: Requires sufficient sample size per category

ğŸ“‹ General Guidelines:
   PSI < 0.1: No drift
   PSI 0.1-0.2: Slight drift (monitor)
   PSI > 0.2: Significant drift (action needed)
"""

print(recommendations)

# %% [markdown]
# ### 2.3.5 Test Suite à¸”à¹‰à¸§à¸¢ Multiple Methods

# %%
# à¸ªà¸£à¹‰à¸²à¸‡ Test Suite à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸«à¸¥à¸²à¸¢ methods
print("=" * 60)
print("ğŸ§ª Multi-Method Test Suite")
print("=" * 60)

multi_method_test = TestSuite(tests=[
    # à¹ƒà¸Šà¹‰ KS test
    TestColumnDrift(column_name='mean radius', stattest='ks'),

    # à¹ƒà¸Šà¹‰ PSI
    TestColumnDrift(column_name='mean area', stattest='psi'),

    # à¹ƒà¸Šà¹‰ Wasserstein
    TestColumnDrift(column_name='mean texture', stattest='wasserstein'),

    # Overall dataset drift
    TestShareOfDriftedColumns(lte=0.5),
])

multi_method_test.run(
    reference_data=reference_data,
    current_data=sudden_drift_data,
    column_mapping=column_mapping
)

# à¹à¸ªà¸”à¸‡à¸œà¸¥
multi_results = multi_method_test.as_dict()

print("\nğŸ“‹ Multi-Method Test Results:")
print("-" * 60)

for test in multi_results['tests']:
    status = "âœ… PASS" if test['status'] == 'SUCCESS' else "âŒ FAIL"
    print(f"{status}: {test['name']}")

# %%
# à¸šà¸±à¸™à¸—à¸¶à¸ Test Suite
multi_method_test.save_html("test_suite_multi_method.html")
print("\nğŸ’¾ à¸šà¸±à¸™à¸—à¸¶à¸ Test Suite à¹€à¸›à¹‡à¸™à¹„à¸Ÿà¸¥à¹Œ 'test_suite_multi_method.html' à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

# %% [markdown]
# ### ğŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸” LAB 2.3
#
# 1. à¸—à¸”à¸¥à¸­à¸‡à¹ƒà¸Šà¹‰ statistical tests à¸­à¸·à¹ˆà¸™à¹† à¸—à¸µà¹ˆà¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹ƒà¸Šà¹‰
# 2. à¸›à¸£à¸±à¸š threshold à¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸° test à¹à¸¥à¸°à¸ªà¸±à¸‡à¹€à¸à¸•à¸œà¸¥à¸à¸£à¸°à¸—à¸š
# 3. à¸ªà¸£à¹‰à¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ categorical à¹à¸¥à¸°à¹ƒà¸Šà¹‰ Chi-Square test

# %%
# à¸à¸·à¹‰à¸™à¸—à¸µà¹ˆà¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸³à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”
# TODO: à¹€à¸‚à¸µà¸¢à¸™à¹‚à¸„à¹‰à¸”à¸‚à¸­à¸‡à¸„à¸¸à¸“à¸—à¸µà¹ˆà¸™à¸µà¹ˆ




# %% [markdown]
# ---
# # LAB 2.4: Handling and Mitigating Drift
#
# ## à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ
# - à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¸à¸¥à¸¢à¸¸à¸—à¸˜à¹Œà¹ƒà¸™à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£à¸à¸±à¸š Drift
# - à¸ªà¸£à¹‰à¸²à¸‡ Monitoring Pipeline
# - Implement Drift Alert System

# %% [markdown]
# ### 2.4.1 à¸à¸¥à¸¢à¸¸à¸—à¸˜à¹Œà¹ƒà¸™à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£à¸à¸±à¸š Drift
#
# **à¹€à¸¡à¸·à¹ˆà¸­à¸•à¸£à¸§à¸ˆà¸à¸š Drift à¸ªà¸²à¸¡à¸²à¸£à¸–à¸”à¸³à¹€à¸™à¸´à¸™à¸à¸²à¸£à¹„à¸”à¹‰à¸«à¸¥à¸²à¸¢à¸§à¸´à¸˜à¸µ:**
#
# 1. **Retrain Model**: Train à¹‚à¸¡à¹€à¸”à¸¥à¹ƒà¸«à¸¡à¹ˆà¸”à¹‰à¸§à¸¢à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸¥à¹ˆà¸²à¸ªà¸¸à¸”
# 2. **Update Reference Data**: à¸­à¸±à¸à¹€à¸”à¸— baseline data
# 3. **Feature Engineering**: à¸›à¸£à¸±à¸šà¸›à¸£à¸¸à¸‡ features
# 4. **Ensemble Methods**: à¹ƒà¸Šà¹‰à¸«à¸¥à¸²à¸¢à¹‚à¸¡à¹€à¸”à¸¥à¸£à¹ˆà¸§à¸¡à¸à¸±à¸™
# 5. **Online Learning**: à¸­à¸±à¸à¹€à¸”à¸—à¹‚à¸¡à¹€à¸”à¸¥à¹à¸šà¸š incremental

# %%
# à¸ªà¸£à¹‰à¸²à¸‡à¸£à¸°à¸šà¸š Drift Monitoring Pipeline
print("=" * 60)
print("ğŸ“Š Drift Monitoring Pipeline")
print("=" * 60)

class DriftMonitor:
    """Class à¸ªà¸³à¸«à¸£à¸±à¸š monitoring drift à¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸›à¹‡à¸™à¸£à¸°à¸šà¸š"""

    def __init__(self, reference_data, column_mapping, thresholds=None):
        self.reference_data = reference_data
        self.column_mapping = column_mapping
        self.thresholds = thresholds or {
            'dataset_drift_share': 0.3,
            'feature_drift_pvalue': 0.05,
            'psi_threshold': 0.2,
        }
        self.history = []

    def check_drift(self, current_data, batch_id=None):
        """à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š drift à¹à¸¥à¸°à¸šà¸±à¸™à¸—à¸¶à¸à¸œà¸¥"""
        # Dataset-level drift
        dataset_report = Report(metrics=[DataDriftPreset()])
        dataset_report.run(
            reference_data=self.reference_data,
            current_data=current_data,
            column_mapping=self.column_mapping
        )
        dataset_results = dataset_report.as_dict()
        drift_info = dataset_results['metrics'][0]['result']

        # à¸ªà¸£à¹‰à¸²à¸‡ result object
        result = {
            'batch_id': batch_id,
            'timestamp': pd.Timestamp.now(),
            'dataset_drift': drift_info['dataset_drift'],
            'drift_share': drift_info['share_of_drifted_columns'],
            'n_drifted_columns': drift_info['number_of_drifted_columns'],
            'drifted_features': [],
            'alerts': []
        }

        # à¸«à¸² features à¸—à¸µà¹ˆ drift
        for feature, info in drift_info['drift_by_columns'].items():
            if info['drift_detected']:
                result['drifted_features'].append({
                    'feature': feature,
                    'drift_score': info['drift_score'],
                    'stattest': info['stattest_name']
                })

        # à¸ªà¸£à¹‰à¸²à¸‡ alerts
        result['alerts'] = self._generate_alerts(result)

        # à¸šà¸±à¸™à¸—à¸¶à¸ history
        self.history.append(result)

        return result

    def _generate_alerts(self, result):
        """à¸ªà¸£à¹‰à¸²à¸‡ alerts à¸•à¸²à¸¡ thresholds"""
        alerts = []

        if result['dataset_drift']:
            alerts.append({
                'level': 'CRITICAL',
                'type': 'DATASET_DRIFT',
                'message': f"ğŸš¨ Dataset drift detected! {result['drift_share']:.1%} of features drifted"
            })

        if result['drift_share'] > self.thresholds['dataset_drift_share']:
            alerts.append({
                'level': 'HIGH',
                'type': 'HIGH_DRIFT_SHARE',
                'message': f"âš ï¸ High drift share: {result['drift_share']:.1%} (threshold: {self.thresholds['dataset_drift_share']:.1%})"
            })

        return alerts

    def get_summary(self):
        """à¸ªà¸£à¸¸à¸›à¸œà¸¥ monitoring"""
        if not self.history:
            return "No monitoring data available"

        total_checks = len(self.history)
        drift_detected = sum(1 for h in self.history if h['dataset_drift'])

        summary = {
            'total_checks': total_checks,
            'drift_detected_count': drift_detected,
            'drift_rate': drift_detected / total_checks if total_checks > 0 else 0,
            'most_drifted_features': self._get_most_drifted_features()
        }

        return summary

    def _get_most_drifted_features(self):
        """à¸«à¸² features à¸—à¸µà¹ˆ drift à¸šà¹ˆà¸­à¸¢à¸—à¸µà¹ˆà¸ªà¸¸à¸”"""
        feature_counts = {}
        for h in self.history:
            for f in h['drifted_features']:
                feature = f['feature']
                feature_counts[feature] = feature_counts.get(feature, 0) + 1

        return sorted(feature_counts.items(), key=lambda x: x[1], reverse=True)[:5]


print("âœ… à¸ªà¸£à¹‰à¸²à¸‡ DriftMonitor class à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

# %%
# à¸—à¸”à¸ªà¸­à¸š Drift Monitor
print("\n" + "=" * 60)
print("ğŸ” à¸—à¸”à¸ªà¸­à¸š Drift Monitor")
print("=" * 60)

# à¸ªà¸£à¹‰à¸²à¸‡ monitor
monitor = DriftMonitor(
    reference_data=reference_data,
    column_mapping=column_mapping
)

# à¸ˆà¸³à¸¥à¸­à¸‡à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š batches à¸«à¸¥à¸²à¸¢à¹† à¸£à¸­à¸š
batches = [
    ('batch_001', reference_data.iloc[200:]),  # No drift
    ('batch_002', gradual_drift_data),          # Gradual drift
    ('batch_003', sudden_drift_data),           # Sudden drift
    ('batch_004', seasonal_drift_data),         # Seasonal drift
]

print("\nğŸ“‹ Monitoring Results:")
print("-" * 70)

for batch_id, data in batches:
    result = monitor.check_drift(data, batch_id=batch_id)
    drift_status = "ğŸš¨ DRIFT" if result['dataset_drift'] else "âœ… OK"
    print(f"\n{batch_id}: {drift_status}")
    print(f"   Drift Share: {result['drift_share']:.1%}")
    print(f"   Drifted Features: {result['n_drifted_columns']}")

    if result['alerts']:
        for alert in result['alerts']:
            print(f"   [{alert['level']}] {alert['message']}")

# %%
# à¹à¸ªà¸”à¸‡ Summary
print("\n" + "=" * 60)
print("ğŸ“Š Monitoring Summary")
print("=" * 60)

summary = monitor.get_summary()

print(f"\nğŸ“Œ Total Checks: {summary['total_checks']}")
print(f"ğŸ“Œ Drift Detected: {summary['drift_detected_count']} times")
print(f"ğŸ“Œ Drift Rate: {summary['drift_rate']:.1%}")

print("\nğŸ“Œ Most Frequently Drifted Features:")
for feature, count in summary['most_drifted_features']:
    print(f"   - {feature}: {count} times")

# %% [markdown]
# ### 2.4.2 à¸ªà¸£à¹‰à¸²à¸‡ Drift Response Actions

# %%
# à¸ªà¸£à¹‰à¸²à¸‡à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸š response actions
print("=" * 60)
print("ğŸ“Š Drift Response Actions")
print("=" * 60)

def recommend_actions(drift_result, model_performance=None):
    """à¹à¸™à¸°à¸™à¸³ actions à¸•à¸²à¸¡à¸œà¸¥ drift"""
    actions = []

    drift_share = drift_result['drift_share']
    n_drifted = drift_result['n_drifted_columns']

    # à¸à¸³à¸«à¸™à¸” actions à¸•à¸²à¸¡à¸£à¸°à¸”à¸±à¸š drift
    if drift_share < 0.1:
        actions.append({
            'priority': 'LOW',
            'action': 'MONITOR',
            'description': 'Continue monitoring, no immediate action required'
        })

    elif drift_share < 0.3:
        actions.append({
            'priority': 'MEDIUM',
            'action': 'INVESTIGATE',
            'description': 'Investigate drifted features and assess impact'
        })
        actions.append({
            'priority': 'MEDIUM',
            'action': 'UPDATE_REFERENCE',
            'description': 'Consider updating reference data window'
        })

    else:
        actions.append({
            'priority': 'HIGH',
            'action': 'RETRAIN',
            'description': 'Retrain model with recent data'
        })
        actions.append({
            'priority': 'HIGH',
            'action': 'ALERT_STAKEHOLDERS',
            'description': 'Notify data science team and stakeholders'
        })

    # à¸–à¹‰à¸²à¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ performance
    if model_performance and model_performance.get('accuracy_drop', 0) > 0.05:
        actions.append({
            'priority': 'CRITICAL',
            'action': 'IMMEDIATE_RETRAIN',
            'description': f"Model accuracy dropped by {model_performance['accuracy_drop']:.1%}"
        })

    return actions

# %%
# à¸—à¸”à¸ªà¸­à¸š action recommendations
print("\nğŸ“‹ Action Recommendations for Each Batch:")
print("-" * 70)

for batch_id, data in batches:
    result = monitor.history[batches.index((batch_id, data))]
    actions = recommend_actions(result)

    print(f"\nğŸ”¹ {batch_id} (Drift Share: {result['drift_share']:.1%}):")
    for action in actions:
        print(f"   [{action['priority']}] {action['action']}: {action['description']}")

# %% [markdown]
# ### 2.4.3 à¸ªà¸£à¹‰à¸²à¸‡ Comprehensive Monitoring Report

# %%
# à¸ªà¸£à¹‰à¸²à¸‡ Comprehensive Report
print("=" * 60)
print("ğŸ“Š Comprehensive Drift Monitoring Report")
print("=" * 60)

# à¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ sudden drift à¸ªà¸³à¸«à¸£à¸±à¸š demo
comprehensive_monitor_report = Report(metrics=[
    # Dataset overview
    DatasetSummaryMetric(),

    # Data Drift
    DataDriftPreset(),

    # Data Quality
    DatasetMissingValuesMetric(),
    DatasetDuplicatedRowsMetric(),

    # Feature-level details
    ColumnSummaryMetric(column_name='mean radius'),
    ColumnSummaryMetric(column_name='mean area'),
    ColumnDriftMetric(column_name='mean radius'),
    ColumnDriftMetric(column_name='mean area'),
])

comprehensive_monitor_report.run(
    reference_data=reference_data,
    current_data=sudden_drift_data,
    column_mapping=column_mapping
)

print("âœ… à¸ªà¸£à¹‰à¸²à¸‡ Comprehensive Report à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

# %%
# à¸šà¸±à¸™à¸—à¸¶à¸ Comprehensive Report
comprehensive_monitor_report.save_html("report_comprehensive_monitoring.html")
print("\nğŸ’¾ à¸šà¸±à¸™à¸—à¸¶à¸ Report à¹€à¸›à¹‡à¸™à¹„à¸Ÿà¸¥à¹Œ 'report_comprehensive_monitoring.html' à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

# %% [markdown]
# ### 2.4.4 Automated Drift Detection Pipeline

# %%
# à¸ªà¸£à¹‰à¸²à¸‡ Automated Pipeline
print("=" * 60)
print("ğŸ“Š Automated Drift Detection Pipeline")
print("=" * 60)

def run_drift_pipeline(reference_data, current_data, column_mapping,
                       thresholds=None, save_report=True, report_name=None):
    """
    à¸£à¸±à¸™ drift detection pipeline à¹à¸šà¸šà¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´

    Returns:
    - dict: à¸œà¸¥à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š drift à¹à¸¥à¸° recommendations
    """
    if thresholds is None:
        thresholds = {
            'drift_share': 0.3,
            'psi': 0.2,
        }

    results = {
        'status': 'OK',
        'drift_detected': False,
        'metrics': {},
        'alerts': [],
        'recommendations': []
    }

    # 1. à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Data Quality
    quality_report = Report(metrics=[
        DatasetMissingValuesMetric(),
        DatasetDuplicatedRowsMetric()
    ])
    quality_report.run(current_data=current_data, reference_data=reference_data,
                       column_mapping=column_mapping)
    quality_results = quality_report.as_dict()

    missing_share = quality_results['metrics'][0]['result']['current']['share_of_missing_values']
    dup_share = quality_results['metrics'][1]['result']['current']['share_of_duplicated_rows']

    results['metrics']['missing_values_share'] = missing_share
    results['metrics']['duplicates_share'] = dup_share

    # 2. à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Data Drift
    drift_report = Report(metrics=[DataDriftPreset()])
    drift_report.run(reference_data=reference_data, current_data=current_data,
                     column_mapping=column_mapping)
    drift_results = drift_report.as_dict()

    drift_info = drift_results['metrics'][0]['result']
    results['metrics']['drift_share'] = drift_info['share_of_drifted_columns']
    results['metrics']['n_drifted_columns'] = drift_info['number_of_drifted_columns']
    results['drift_detected'] = drift_info['dataset_drift']

    # 3. à¸ªà¸£à¹‰à¸²à¸‡ Alerts
    if results['drift_detected']:
        results['status'] = 'WARNING'
        results['alerts'].append({
            'level': 'HIGH',
            'message': f"Dataset drift detected: {drift_info['share_of_drifted_columns']:.1%} features drifted"
        })

    if missing_share > 0.05:
        results['alerts'].append({
            'level': 'MEDIUM',
            'message': f"High missing values: {missing_share:.1%}"
        })

    # 4. à¸ªà¸£à¹‰à¸²à¸‡ Recommendations
    if drift_info['share_of_drifted_columns'] > thresholds['drift_share']:
        results['status'] = 'CRITICAL'
        results['recommendations'].append("Retrain model with recent data")
        results['recommendations'].append("Update reference dataset")
    elif drift_info['share_of_drifted_columns'] > 0.1:
        results['recommendations'].append("Monitor closely")
        results['recommendations'].append("Investigate drifted features")

    # 5. à¸šà¸±à¸™à¸—à¸¶à¸ Report (optional)
    if save_report:
        filename = report_name or f"pipeline_report_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.html"
        comprehensive_report = Report(metrics=[
            DatasetSummaryMetric(),
            DataDriftPreset(),
            DatasetMissingValuesMetric(),
        ])
        comprehensive_report.run(reference_data=reference_data, current_data=current_data,
                                column_mapping=column_mapping)
        comprehensive_report.save_html(filename)
        results['report_file'] = filename

    return results

# %%
# à¸—à¸”à¸ªà¸­à¸š Pipeline
print("\nğŸ”„ Running Automated Pipeline...")
print("-" * 60)

pipeline_result = run_drift_pipeline(
    reference_data=reference_data,
    current_data=sudden_drift_data,
    column_mapping=column_mapping,
    report_name="report_pipeline_output.html"
)

print(f"\nğŸ“‹ Pipeline Results:")
print(f"   Status: {pipeline_result['status']}")
print(f"   Drift Detected: {pipeline_result['drift_detected']}")
print(f"\nğŸ“Š Metrics:")
for key, value in pipeline_result['metrics'].items():
    if isinstance(value, float):
        print(f"   {key}: {value:.4f}")
    else:
        print(f"   {key}: {value}")

print(f"\nâš ï¸ Alerts:")
for alert in pipeline_result['alerts']:
    print(f"   [{alert['level']}] {alert['message']}")

print(f"\nğŸ’¡ Recommendations:")
for rec in pipeline_result['recommendations']:
    print(f"   - {rec}")

print(f"\nğŸ“ Report saved: {pipeline_result.get('report_file', 'N/A')}")

# %% [markdown]
# ### ğŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸” LAB 2.4
#
# 1. à¸›à¸£à¸±à¸šà¸›à¸£à¸¸à¸‡ DriftMonitor class à¹ƒà¸«à¹‰à¹€à¸à¹‡à¸š history à¸¥à¸‡ file
# 2. à¸ªà¸£à¹‰à¸²à¸‡à¸£à¸°à¸šà¸š notification (email, Slack) à¹€à¸¡à¸·à¹ˆà¸­à¸•à¸£à¸§à¸ˆà¸à¸š drift
# 3. Implement online learning approach à¹€à¸¡à¸·à¹ˆà¸­à¸•à¸£à¸§à¸ˆà¸à¸š gradual drift
# 4. à¸ªà¸£à¹‰à¸²à¸‡ dashboard à¸ªà¸³à¸«à¸£à¸±à¸š monitoring à¸”à¹‰à¸§à¸¢ Streamlit à¸«à¸£à¸·à¸­ Dash

# %%
# à¸à¸·à¹‰à¸™à¸—à¸µà¹ˆà¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸³à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”
# TODO: à¹€à¸‚à¸µà¸¢à¸™à¹‚à¸„à¹‰à¸”à¸‚à¸­à¸‡à¸„à¸¸à¸“à¸—à¸µà¹ˆà¸™à¸µà¹ˆ




# %% [markdown]
# ---
# # à¸ªà¸£à¸¸à¸› Section 2
#
# ## à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¹„à¸”à¹‰à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰
#
# ### LAB 2.1: Understanding Data Drift
# - à¸›à¸£à¸°à¹€à¸ à¸—à¸‚à¸­à¸‡ Data Drift (Gradual, Sudden, Seasonal, Incremental)
# - à¸ªà¸£à¹‰à¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸³à¸¥à¸­à¸‡à¸—à¸µà¹ˆà¸¡à¸µ Drift à¹à¸šà¸šà¸•à¹ˆà¸²à¸‡à¹†
# - à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š Dataset-level Drift
#
# ### LAB 2.2: Feature Drift Detection
# - à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š Drift à¹ƒà¸™à¸£à¸°à¸”à¸±à¸š Feature
# - à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š Distribution à¸à¹ˆà¸­à¸™-à¸«à¸¥à¸±à¸‡ Drift
# - à¸ªà¸£à¹‰à¸²à¸‡ Feature Drift Test Suite
#
# ### LAB 2.3: Drift Detection Methods
# - Statistical Tests à¸•à¹ˆà¸²à¸‡à¹† (KS, Wasserstein, PSI, Chi-Square)
# - à¹€à¸¥à¸·à¸­à¸ method à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡à¸à¸±à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥
# - à¸à¸³à¸«à¸™à¸” Custom Statistical Test
#
# ### LAB 2.4: Handling and Mitigating Drift
# - à¸à¸¥à¸¢à¸¸à¸—à¸˜à¹Œà¸ˆà¸±à¸”à¸à¸²à¸£à¸à¸±à¸š Drift
# - à¸ªà¸£à¹‰à¸²à¸‡ Drift Monitoring Pipeline
# - Automated Drift Detection

# %% [markdown]
# ## Best Practices à¸ªà¸³à¸«à¸£à¸±à¸š Drift Management
#
# 1. **Monitor à¸ªà¸¡à¹ˆà¸³à¹€à¸ªà¸¡à¸­**: à¸•à¸±à¹‰à¸‡ schedule à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š (daily, weekly)
# 2. **à¸à¸³à¸«à¸™à¸” Threshold à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡**: à¸›à¸£à¸±à¸šà¸•à¸²à¸¡ business context
# 3. **à¹€à¸à¹‡à¸š Historical Data**: à¹€à¸à¸·à¹ˆà¸­à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ trend à¹à¸¥à¸° pattern
# 4. **Automate Response**: à¸ªà¸£à¹‰à¸²à¸‡à¸£à¸°à¸šà¸š auto-retrain à¹€à¸¡à¸·à¹ˆà¸­à¸ˆà¸³à¹€à¸›à¹‡à¸™
# 5. **Document Everything**: à¸šà¸±à¸™à¸—à¸¶à¸à¹€à¸«à¸•à¸¸à¸à¸²à¸£à¸“à¹Œà¹à¸¥à¸° actions à¸—à¸µà¹ˆà¸—à¸³

# %%
# à¸ªà¸£à¸¸à¸› files à¸—à¸µà¹ˆà¸ªà¸£à¹‰à¸²à¸‡à¸ˆà¸²à¸ Section 2
print("=" * 60)
print("ğŸ“ Files à¸—à¸µà¹ˆà¸ªà¸£à¹‰à¸²à¸‡à¸ˆà¸²à¸ Section 2")
print("=" * 60)
print("""
1. report_feature_drift.html - Feature Drift Report
2. report_distribution_comparison.html - Distribution Comparison Report
3. test_suite_feature_drift.html - Feature Drift Test Suite
4. report_custom_stattest.html - Custom Statistical Test Report
5. test_suite_multi_method.html - Multi-Method Test Suite
6. report_comprehensive_monitoring.html - Comprehensive Monitoring Report
7. report_pipeline_output.html - Pipeline Output Report
""")
print("âœ… Lab Section 2 à¹€à¸ªà¸£à¹‡à¸ˆà¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œ!")
