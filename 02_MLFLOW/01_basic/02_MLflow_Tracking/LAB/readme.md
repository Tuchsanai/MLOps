
---

## ‚öôÔ∏è Pre-requisite: ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏° Lab

### üìã ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ

‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏° Lab ‡∏ô‡∏µ‡πâ ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ MLflow Server ‡∏£‡∏±‡∏ô‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà `http://127.0.0.1:8080`

### üîç ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö MLflow Server

‡πÄ‡∏õ‡∏¥‡∏î Browser ‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏õ‡∏ó‡∏µ‡πà: [http://127.0.0.1:8080](http://127.0.0.1:8080)

![MLflow UI](./img/1.png)

---



## üöÄ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Lab Environment

### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Lab

```bash
# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå Lab ‡πÅ‡∏¢‡∏Å‡∏à‡∏≤‡∏Å mlflowserver-lab
mkdir -p mlflow-tracking-lab

# ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå
cd mlflow-tracking-lab
```

### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏™‡∏£‡πâ‡∏≤‡∏á Virtual Environment

```bash
# ‡∏™‡∏£‡πâ‡∏≤‡∏á Virtual Environment
python -m venv .venv

# ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Virtual Environment
source .venv/bin/activate

# ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó pip
python -m pip install --upgrade pip
```

### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Dependencies

```bash
# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á MLflow ‡πÅ‡∏•‡∏∞ Libraries ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
pip install mlflow scikit-learn pandas numpy matplotlib seaborn
```

### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 4: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á

```bash
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô MLflow
mlflow --version

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Python packages
pip list | grep -E "mlflow|scikit-learn|pandas"
```

### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 5: ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Tracking URI

```bash
# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Environment Variable ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö MLflow Server
export MLFLOW_TRACKING_URI=http://127.0.0.1:8080
```

> üí° **Tip**: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ‡πÉ‡∏ô `.bashrc` ‡∏´‡∏£‡∏∑‡∏≠ `.zshrc` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á

---

## üóÇÔ∏è ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå Lab

```
mlflow-tracking-lab/
‚îú‚îÄ‚îÄ README.md                    # ‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ
‚îú‚îÄ‚îÄ .venv/                       # Virtual Environment
‚îú‚îÄ‚îÄ experiments/                 # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏î‡∏•‡∏≠‡∏á
‚îÇ   ‚îú‚îÄ‚îÄ lab1_basic_tracking.py
‚îÇ   ‚îú‚îÄ‚îÄ lab2_training_loop.py
‚îÇ   ‚îú‚îÄ‚îÄ lab3_sklearn_autolog.py
‚îÇ   ‚îú‚îÄ‚îÄ lab4_hyperparameter.py
‚îÇ   ‚îú‚îÄ‚îÄ lab5_custom_artifacts.py
‚îÇ   ‚îî‚îÄ‚îÄ lab6_query_runs.py
‚îî‚îÄ‚îÄ outputs/                     # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏Å‡πá‡∏ö output ‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
```

‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå:

```bash
mkdir -p experiments outputs
```

---

## üìù Lab 1: Basic Tracking

### üéØ ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå
- ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ `mlflow.start_run()`
- ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Parameters, Metrics ‡πÅ‡∏•‡∏∞ Artifacts
- ‡∏î‡∏π‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏ô MLflow UI

### üìñ ‡∏ó‡∏§‡∏©‡∏é‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á

‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô MLflow ‡∏°‡∏µ 3 ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏Å:

```
1. ‡πÄ‡∏£‡∏¥‡πà‡∏° Run      ‚Üí  2. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•  ‚Üí  3. ‡∏à‡∏ö Run
   start_run()       log_param()         end_run()
                     log_metric()        (‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ with)
                     log_artifact()
```

### üíª ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ó‡∏î‡∏•‡∏≠‡∏á

‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå `experiments/lab1_basic_tracking.py`:

```python
"""
Lab 1: Basic MLflow Tracking
============================
‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Parameters, Metrics ‡πÅ‡∏•‡∏∞ Artifacts ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
"""

import mlflow
import os

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Tracking URI (‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö MLflow Server)
mlflow.set_tracking_uri("http://127.0.0.1:8080")

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Experiment
# ‡∏ñ‡πâ‡∏≤ Experiment ‡∏ô‡∏µ‡πâ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ ‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
mlflow.set_experiment("lab1-basic-tracking")

print("=" * 50)
print("Lab 1: Basic MLflow Tracking")
print("=" * 50)

# ‡πÄ‡∏£‡∏¥‡πà‡∏° Run ‡πÉ‡∏´‡∏°‡πà
# ‡πÉ‡∏ä‡πâ with statement ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏õ‡∏¥‡∏î Run ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
with mlflow.start_run(run_name="my-first-run"):
    
    # ‡∏î‡∏π Run ID ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
    run_id = mlflow.active_run().info.run_id
    print(f"\nüìå Run ID: {run_id}")
    
    # -------------------------------------------------
    # 1. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Parameters (‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏î‡∏•‡∏≠‡∏á)
    # -------------------------------------------------
    print("\n1Ô∏è‚É£ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Parameters...")
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ó‡∏µ‡∏•‡∏∞‡∏Ñ‡πà‡∏≤
    mlflow.log_param("model_type", "RandomForest")
    mlflow.log_param("n_estimators", 100)
    mlflow.log_param("max_depth", 10)
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡πà‡∏≤‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô
    mlflow.log_params({
        "learning_rate": 0.01,
        "random_state": 42
    })
    
    print("   ‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Parameters ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
    
    # -------------------------------------------------
    # 2. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Metrics (‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ß‡∏±‡∏î‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á)
    # -------------------------------------------------
    print("\n2Ô∏è‚É£ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Metrics...")
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Metrics ‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
    mlflow.log_metric("accuracy", 0.92)
    mlflow.log_metric("precision", 0.89)
    mlflow.log_metric("recall", 0.94)
    mlflow.log_metric("f1_score", 0.91)
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡πà‡∏≤‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô
    mlflow.log_metrics({
        "train_loss": 0.15,
        "val_loss": 0.22
    })
    
    print("   ‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Metrics ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
    
    # -------------------------------------------------
    # 3. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Artifacts (‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á)
    # -------------------------------------------------
    print("\n3Ô∏è‚É£ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Artifacts...")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô Artifact
    os.makedirs("outputs", exist_ok=True)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
    with open("outputs/model_info.txt", "w") as f:
        f.write("Model: RandomForest\n")
        f.write("Version: 1.0\n")
        f.write("Accuracy: 0.92\n")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå JSON
    import json
    config = {
        "model_type": "RandomForest",
        "hyperparameters": {
            "n_estimators": 100,
            "max_depth": 10
        }
    }
    with open("outputs/config.json", "w") as f:
        json.dump(config, f, indent=2)
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß
    mlflow.log_artifact("outputs/model_info.txt")
    mlflow.log_artifact("outputs/config.json")
    
    print("   ‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Artifacts ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
    
    # -------------------------------------------------
    # 4. ‡πÄ‡∏û‡∏¥‡πà‡∏° Tags (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤)
    # -------------------------------------------------
    print("\n4Ô∏è‚É£ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Tags...")
    
    mlflow.set_tag("developer", "student")
    mlflow.set_tag("experiment_type", "baseline")
    mlflow.set_tag("dataset", "iris")
    
    print("   ‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Tags ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")

print("\n" + "=" * 50)
print("üéâ Lab 1 ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")
print("=" * 50)
print(f"\nüìä ‡∏î‡∏π‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà: http://127.0.0.1:8080")
print(f"   ‚Üí ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Experiment: lab1-basic-tracking")
print(f"   ‚Üí ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏ó‡∏µ‡πà Run: my-first-run")
```

### ‚ñ∂Ô∏è ‡∏ß‡∏¥‡∏ò‡∏µ‡∏£‡∏±‡∏ô

```bash
cd mlflow-tracking-lab
source .venv/bin/activate
python experiments/lab1_basic_tracking.py
```

### ‚úÖ ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á

1. ‡πÄ‡∏õ‡∏¥‡∏î MLflow UI ‡∏ó‡∏µ‡πà http://127.0.0.1:8080
2. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Experiment "lab1-basic-tracking"
3. ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏ó‡∏µ‡πà Run "my-first-run"
4. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö:
   - **Parameters**: model_type, n_estimators, max_depth, etc.
   - **Metrics**: accuracy, precision, recall, f1_score, etc.
   - **Artifacts**: model_info.txt, config.json
   - **Tags**: developer, experiment_type, dataset

### üìù ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î Lab 1

1. ‡πÄ‡∏û‡∏¥‡πà‡∏° Parameter ‡πÉ‡∏´‡∏°‡πà‡∏ä‡∏∑‡πà‡∏≠ `min_samples_split` ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô 5
2. ‡πÄ‡∏û‡∏¥‡πà‡∏° Metric ‡πÉ‡∏´‡∏°‡πà‡∏ä‡∏∑‡πà‡∏≠ `auc_roc` ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô 0.95
3. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå `notes.md` ‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô Artifact
4. ‡πÄ‡∏û‡∏¥‡πà‡∏° Tag ‡∏ä‡∏∑‡πà‡∏≠ `version` ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô "v1.0"

---

## üìù Lab 2: Training Loop Tracking

### üéØ ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå
- ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Metrics ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á Training Loop
- ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ `step` parameter ‡πÉ‡∏ô `log_metric()`
- ‡∏î‡∏π Loss Curve ‡πÉ‡∏ô MLflow UI

### üìñ ‡∏ó‡∏§‡∏©‡∏é‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á

‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Metrics ‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤:

```python
# step ‡∏Ñ‡∏∑‡∏≠‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å (‡πÄ‡∏ä‡πà‡∏ô epoch number)
mlflow.log_metric("loss", value, step=epoch)

# MLflow ‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢ step
```

```
Loss Curve ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÑ‡∏î‡πâ:

    Loss
    1.0 ‚î§‚óè
        ‚îÇ ‚ï≤
    0.8 ‚î§  ‚óè
        ‚îÇ   ‚ï≤
    0.6 ‚î§    ‚óè
        ‚îÇ     ‚ï≤
    0.4 ‚î§      ‚óè
        ‚îÇ       ‚ï≤‚óè
    0.2 ‚î§         ‚ï≤‚óè‚óè
        ‚îÇ            ‚ï≤‚óè‚óè‚óè
    0.0 ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        0  2  4  6  8  10  Epoch
```

### üíª ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ó‡∏î‡∏•‡∏≠‡∏á

‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå `experiments/lab2_training_loop.py`:

```python
"""
Lab 2: Training Loop Tracking
=============================
‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Metrics ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£ Training
"""

import mlflow
import numpy as np
import matplotlib.pyplot as plt
import os

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ MLflow
mlflow.set_tracking_uri("http://127.0.0.1:8080")
mlflow.set_experiment("lab2-training-loop")

print("=" * 50)
print("Lab 2: Training Loop Tracking")
print("=" * 50)

# -------------------------------------------------
# ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Å‡∏≤‡∏£ Training Model
# -------------------------------------------------
def simulate_training(epochs, initial_loss=1.0, learning_rate=0.1):
    """
    ‡∏à‡∏≥‡∏•‡∏≠‡∏á Loss ‡∏ó‡∏µ‡πà‡∏•‡∏î‡∏•‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£ Training
    """
    losses = []
    val_losses = []
    
    for epoch in range(epochs):
        # ‡∏à‡∏≥‡∏•‡∏≠‡∏á Training Loss (‡∏•‡∏î‡∏•‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢‡πÜ)
        train_loss = initial_loss * np.exp(-learning_rate * epoch)
        train_loss += np.random.normal(0, 0.02)  # ‡πÄ‡∏û‡∏¥‡πà‡∏° noise ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
        train_loss = max(0.01, train_loss)  # ‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏ï‡∏¥‡∏î‡∏•‡∏ö
        
        # ‡∏à‡∏≥‡∏•‡∏≠‡∏á Validation Loss (‡∏•‡∏î‡∏•‡∏á‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤ Train)
        val_loss = initial_loss * np.exp(-learning_rate * 0.8 * epoch)
        val_loss += np.random.normal(0, 0.03)
        val_loss = max(0.02, val_loss)
        
        losses.append(train_loss)
        val_losses.append(val_loss)
    
    return losses, val_losses

# Parameters
EPOCHS = 50
LEARNING_RATE = 0.1
INITIAL_LOSS = 1.0

# ‡πÄ‡∏£‡∏¥‡πà‡∏° Run
with mlflow.start_run(run_name="training-simulation"):
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Parameters
    print("\nüìã ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Parameters...")
    mlflow.log_params({
        "epochs": EPOCHS,
        "learning_rate": LEARNING_RATE,
        "initial_loss": INITIAL_LOSS,
        "optimizer": "SGD",
        "batch_size": 32
    })
    
    # ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Å‡∏≤‡∏£ Training
    print(f"\nüèÉ ‡πÄ‡∏£‡∏¥‡πà‡∏° Training ‡∏à‡∏≥‡∏•‡∏≠‡∏á {EPOCHS} epochs...")
    train_losses, val_losses = simulate_training(
        EPOCHS, INITIAL_LOSS, LEARNING_RATE
    )
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Metrics ‡∏ó‡∏∏‡∏Å Epoch
    print("\nüìä ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Metrics...")
    for epoch in range(EPOCHS):
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Loss ‡∏û‡∏£‡πâ‡∏≠‡∏° step
        mlflow.log_metric("train_loss", train_losses[epoch], step=epoch)
        mlflow.log_metric("val_loss", val_losses[epoch], step=epoch)
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Accuracy ‡∏à‡∏≥‡∏•‡∏≠‡∏á (‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢‡πÜ)
        train_acc = 0.5 + 0.45 * (1 - np.exp(-0.1 * epoch))
        val_acc = 0.5 + 0.40 * (1 - np.exp(-0.1 * epoch))
        
        mlflow.log_metric("train_accuracy", train_acc, step=epoch)
        mlflow.log_metric("val_accuracy", val_acc, step=epoch)
        
        # ‡πÅ‡∏™‡∏î‡∏á Progress ‡∏ó‡∏∏‡∏Å 10 epochs
        if (epoch + 1) % 10 == 0:
            print(f"   Epoch {epoch+1}/{EPOCHS}: "
                  f"train_loss={train_losses[epoch]:.4f}, "
                  f"val_loss={val_losses[epoch]:.4f}")
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Final Metrics
    mlflow.log_metrics({
        "final_train_loss": train_losses[-1],
        "final_val_loss": val_losses[-1],
        "final_train_accuracy": train_acc,
        "final_val_accuracy": val_acc,
        "best_val_loss": min(val_losses),
        "best_epoch": val_losses.index(min(val_losses))
    })
    
    # -------------------------------------------------
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü Loss Curve ‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô Artifact
    # -------------------------------------------------
    print("\nüìà ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü Loss Curve...")
    os.makedirs("outputs", exist_ok=True)
    
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # ‡∏Å‡∏£‡∏≤‡∏ü Loss
    axes[0].plot(train_losses, label='Training Loss', color='blue')
    axes[0].plot(val_losses, label='Validation Loss', color='orange')
    axes[0].set_xlabel('Epoch')
    axes[0].set_ylabel('Loss')
    axes[0].set_title('Loss Curve')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)
    
    # ‡∏Å‡∏£‡∏≤‡∏ü Accuracy
    train_accs = [0.5 + 0.45 * (1 - np.exp(-0.1 * e)) for e in range(EPOCHS)]
    val_accs = [0.5 + 0.40 * (1 - np.exp(-0.1 * e)) for e in range(EPOCHS)]
    
    axes[1].plot(train_accs, label='Training Accuracy', color='blue')
    axes[1].plot(val_accs, label='Validation Accuracy', color='orange')
    axes[1].set_xlabel('Epoch')
    axes[1].set_ylabel('Accuracy')
    axes[1].set_title('Accuracy Curve')
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig("outputs/training_curves.png", dpi=150)
    plt.close()
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏õ‡πá‡∏ô Artifact
    mlflow.log_artifact("outputs/training_curves.png")
    print("   ‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏£‡∏≤‡∏ü training_curves.png")

print("\n" + "=" * 50)
print("üéâ Lab 2 ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")
print("=" * 50)
print(f"\nüìä ‡∏î‡∏π‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà: http://127.0.0.1:8080")
print(f"   ‚Üí ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Experiment: lab2-training-loop")
print(f"   ‚Üí ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏ó‡∏µ‡πà Run ‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏õ‡∏ó‡∏µ‡πà tab 'Charts'")
print(f"   ‚Üí ‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô Loss Curve ‡πÅ‡∏•‡∏∞ Accuracy Curve")
```

### ‚ñ∂Ô∏è ‡∏ß‡∏¥‡∏ò‡∏µ‡∏£‡∏±‡∏ô

```bash
python experiments/lab2_training_loop.py
```

### ‚úÖ ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á

1. ‡πÄ‡∏õ‡∏¥‡∏î MLflow UI
2. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Experiment "lab2-training-loop"
3. ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏ó‡∏µ‡πà Run ‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏õ‡∏ó‡∏µ‡πà tab **"Charts"**
4. ‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô‡∏Å‡∏£‡∏≤‡∏ü:
   - train_loss ‡πÅ‡∏•‡∏∞ val_loss ‡∏•‡∏î‡∏•‡∏á‡∏ï‡∏≤‡∏° epoch
   - train_accuracy ‡πÅ‡∏•‡∏∞ val_accuracy ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡∏≤‡∏° epoch

### üìù ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î Lab 2

1. ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô `EPOCHS` ‡πÄ‡∏õ‡πá‡∏ô 100 ‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà
2. ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô `LEARNING_RATE` ‡πÄ‡∏õ‡πá‡∏ô 0.05 ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•
3. ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å `learning_rate_decay` ‡∏ó‡∏∏‡∏Å 10 epochs
4. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Train vs Val Loss ‡πÉ‡∏ô‡πÅ‡∏ô‡∏ß‡∏ï‡∏±‡πâ‡∏á

---

## üìù Lab 3: Scikit-learn Autolog

### üéØ ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå
- ‡πÉ‡∏ä‡πâ `mlflow.sklearn.autolog()` 
- ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
- ‡∏î‡∏π Model ‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏ô MLflow UI

### üìñ ‡∏ó‡∏§‡∏©‡∏é‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á

**Autolog** ‡∏Ñ‡∏∑‡∏≠‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏Ç‡∏≠‡∏á MLflow ‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    mlflow.sklearn.autolog()                     ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥:                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Parameters  ‚îÇ  ‚îÇ   Metrics   ‚îÇ  ‚îÇ       Artifacts         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ                         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ All model ‚îÇ  ‚îÇ ‚Ä¢ accuracy  ‚îÇ  ‚îÇ ‚Ä¢ Trained model         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   params    ‚îÇ  ‚îÇ ‚Ä¢ f1_score  ‚îÇ  ‚îÇ ‚Ä¢ Feature names         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Fit time  ‚îÇ  ‚îÇ ‚Ä¢ precision ‚îÇ  ‚îÇ ‚Ä¢ Confusion matrix      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ ‚Ä¢ recall    ‚îÇ  ‚îÇ ‚Ä¢ Training data stats   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Frameworks:                                             ‚îÇ
‚îÇ  sklearn, pytorch, tensorflow, keras, xgboost, lightgbm, ...   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### üíª ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ó‡∏î‡∏•‡∏≠‡∏á

‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå `experiments/lab3_sklearn_autolog.py`:

```python
"""
Lab 3: Scikit-learn Autolog
===========================
‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ mlflow.sklearn.autolog()
"""

import mlflow
import mlflow.sklearn
from sklearn.datasets import load_iris, load_wine
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import warnings
warnings.filterwarnings('ignore')

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ MLflow
mlflow.set_tracking_uri("http://127.0.0.1:8080")
mlflow.set_experiment("lab3-sklearn-autolog")

print("=" * 50)
print("Lab 3: Scikit-learn Autolog")
print("=" * 50)

# -------------------------------------------------
# Part 1: ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏Å‡∏±‡∏ö Iris Dataset
# -------------------------------------------------
print("\nüìä Part 1: Iris Dataset with RandomForest")
print("-" * 40)

# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
iris = load_iris()
X_train, X_test, y_train, y_test = train_test_split(
    iris.data, iris.target, test_size=0.2, random_state=42
)

# ‡πÄ‡∏õ‡∏¥‡∏î Autolog
mlflow.sklearn.autolog(
    log_input_examples=True,
    log_model_signatures=True,
    log_models=True
)

# Training - MLflow ‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥!
with mlflow.start_run(run_name="iris-randomforest"):
    print("\nüå≤ Training RandomForest...")
    
    rf_model = RandomForestClassifier(
        n_estimators=100,
        max_depth=5,
        random_state=42
    )
    rf_model.fit(X_train, y_train)
    
    predictions = model.predict(X_test)
    accuracy = accuracy_score(y_test, predictions)
    
    mlflow.log_metric("test_accuracy", accuracy)
    mlflow.set_tag("dataset", "iris")
    mlflow.set_tag("model_type", "RandomForest")
    
    print(f"   ‚úÖ Test Accuracy: {accuracy:.4f}")

# -------------------------------------------------
# Part 2: ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏Å‡∏±‡∏ö Wine Dataset
# -------------------------------------------------
print("\nüìä Part 2: Wine Dataset with LogisticRegression")
print("-" * 40)

wine = load_wine()
X_train, X_test, y_train, y_test = train_test_split(
    wine.data, wine.target, test_size=0.2, random_state=42
)

with mlflow.start_run(run_name="wine-logistic"):
    print("\nüìà Training Logistic Regression...")
    
    lr_model = LogisticRegression(max_iter=1000, C=1.0, random_state=42)
    lr_model.fit(X_train, y_train)
    
    predictions = lr_model.predict(X_test)
    accuracy = accuracy_score(y_test, predictions)
    
    mlflow.log_metric("test_accuracy", accuracy)
    mlflow.set_tag("dataset", "wine")
    mlflow.set_tag("model_type", "LogisticRegression")
    
    print(f"   ‚úÖ Test Accuracy: {accuracy:.4f}")

# -------------------------------------------------
# Part 3: ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏´‡∏•‡∏≤‡∏¢ Models
# -------------------------------------------------
print("\nüìä Part 3: Model Comparison on Iris")
print("-" * 40)

X_train, X_test, y_train, y_test = train_test_split(
    iris.data, iris.target, test_size=0.2, random_state=42
)

from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier

models = [
    ("DecisionTree", DecisionTreeClassifier(max_depth=5, random_state=42)),
    ("SVM", SVC(kernel='rbf', random_state=42)),
    ("KNN", KNeighborsClassifier(n_neighbors=5))
]

for model_name, model in models:
    with mlflow.start_run(run_name=f"iris-{model_name.lower()}"):
        print(f"\nüîÑ Training {model_name}...")
        
        model.fit(X_train, y_train)
        predictions = model.predict(X_test)
        accuracy = accuracy_score(y_test, predictions)
        
        mlflow.log_metric("test_accuracy", accuracy)
        mlflow.set_tag("dataset", "iris")
        mlflow.set_tag("model_type", model_name)
        
        print(f"   ‚úÖ {model_name} Accuracy: {accuracy:.4f}")

mlflow.sklearn.autolog(disable=True)

print("\n" + "=" * 50)
print("üéâ Lab 3 ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")
print("=" * 50)
print(f"\nüìä ‡∏î‡∏π‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà: http://127.0.0.1:8080")
print(f"   ‚Üí ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Experiment: lab3-sklearn-autolog")
print(f"   ‚Üí ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Runs ‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡∏ï‡∏¥‡πä‡∏Å‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏•‡∏≤‡∏¢ Runs")
print(f"   ‚Üí ‡∏Ñ‡∏•‡∏¥‡∏Å 'Compare' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö")
```

### ‚ñ∂Ô∏è ‡∏ß‡∏¥‡∏ò‡∏µ‡∏£‡∏±‡∏ô

```bash
python experiments/lab3_sklearn_autolog.py
```

### ‚úÖ ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á

1. ‡πÄ‡∏õ‡∏¥‡∏î MLflow UI
2. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Experiment "lab3-sklearn-autolog"
3. ‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô 5 Runs ‡∏û‡∏£‡πâ‡∏≠‡∏° Parameters ‡πÅ‡∏•‡∏∞ Metrics ‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥

### üìù ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î Lab 3

1. ‡πÄ‡∏û‡∏¥‡πà‡∏° Model ‡πÉ‡∏´‡∏°‡πà: `GradientBoostingClassifier`
2. ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏Å‡∏±‡∏ö `load_digits()` dataset
3. ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö 3 Models ‡πÅ‡∏•‡∏∞‡∏´‡∏≤ Model ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î

---

## üìù Lab 4: Hyperparameter Comparison

### üéØ ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå
- ‡∏ó‡∏î‡∏•‡∏≠‡∏á Hyperparameter ‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡πà‡∏≤
- ‡πÉ‡∏ä‡πâ MLflow UI ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•

### üíª ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ó‡∏î‡∏•‡∏≠‡∏á

‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå `experiments/lab4_hyperparameter.py`:

```python
"""
Lab 4: Hyperparameter Comparison
================================
‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á Hyperparameters ‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡πà‡∏≤‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•
"""

import mlflow
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import warnings
warnings.filterwarnings('ignore')

mlflow.set_tracking_uri("http://127.0.0.1:8080")
mlflow.set_experiment("lab4-hyperparameter-tuning")

print("=" * 50)
print("Lab 4: Hyperparameter Comparison")
print("=" * 50)

# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
data = load_breast_cancer()
X_train, X_test, y_train, y_test = train_test_split(
    data.data, data.target, test_size=0.2, random_state=42
)

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Hyperparameter Search Space
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 5, 10, None],
    'min_samples_split': [2, 5, 10]
}

total_experiments = (len(param_grid['n_estimators']) * 
                    len(param_grid['max_depth']) * 
                    len(param_grid['min_samples_split']))

print(f"\nüìã Total experiments: {total_experiments}")

best_accuracy = 0
best_params = None
experiment_count = 0

for n_est in param_grid['n_estimators']:
    for max_d in param_grid['max_depth']:
        for min_split in param_grid['min_samples_split']:
            experiment_count += 1
            
            max_d_str = str(max_d) if max_d is not None else "None"
            run_name = f"rf_nest{n_est}_depth{max_d_str}_split{min_split}"
            
            with mlflow.start_run(run_name=run_name):
                mlflow.log_params({
                    "n_estimators": n_est,
                    "max_depth": max_d if max_d is not None else "unlimited",
                    "min_samples_split": min_split,
                    "random_state": 42
                })
                
                model = RandomForestClassifier(
                    n_estimators=n_est,
                    max_depth=max_d,
                    min_samples_split=min_split,
                    random_state=42,
                    n_jobs=-1
                )
                model.fit(X_train, y_train)
                
                predictions = model.predict(X_test)
                
                accuracy = accuracy_score(y_test, predictions)
                precision = precision_score(y_test, predictions)
                recall = recall_score(y_test, predictions)
                f1 = f1_score(y_test, predictions)
                
                cv_scores = cross_val_score(model, X_train, y_train, cv=5)
                
                mlflow.log_metrics({
                    "accuracy": accuracy,
                    "precision": precision,
                    "recall": recall,
                    "f1_score": f1,
                    "cv_mean": cv_scores.mean(),
                    "cv_std": cv_scores.std()
                })
                
                if accuracy > best_accuracy:
                    best_accuracy = accuracy
                    best_params = {
                        "n_estimators": n_est,
                        "max_depth": max_d,
                        "min_samples_split": min_split
                    }
                    mlflow.set_tag("is_best", "true")
                else:
                    mlflow.set_tag("is_best", "false")
                
                print(f"   [{experiment_count}/{total_experiments}] "
                      f"{run_name}: accuracy={accuracy:.4f}")

print("\n" + "=" * 50)
print(f"üèÜ Best Accuracy: {best_accuracy:.4f}")
print(f"   Best Params: {best_params}")
print("=" * 50)
```

### ‚ñ∂Ô∏è ‡∏ß‡∏¥‡∏ò‡∏µ‡∏£‡∏±‡∏ô

```bash
python experiments/lab4_hyperparameter.py
```

---

## üìù Lab 5: Custom Artifacts

### üéØ ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå
- ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Confusion Matrix
- ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Feature Importance
- ‡∏™‡∏£‡πâ‡∏≤‡∏á Custom Visualizations

### üíª ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ó‡∏î‡∏•‡∏≠‡∏á

‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå `experiments/lab5_custom_artifacts.py`:

```python
"""
Lab 5: Custom Artifacts
=======================
‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Custom Artifacts
"""

import mlflow
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    accuracy_score, confusion_matrix, classification_report,
    roc_curve, auc
)
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import json
import os
import warnings
warnings.filterwarnings('ignore')

mlflow.set_tracking_uri("http://127.0.0.1:8080")
mlflow.set_experiment("lab5-custom-artifacts")

os.makedirs("outputs", exist_ok=True)

data = load_breast_cancer()
X_train, X_test, y_train, y_test = train_test_split(
    data.data, data.target, test_size=0.2, random_state=42
)

with mlflow.start_run(run_name="detailed-analysis"):
    
    params = {"n_estimators": 100, "max_depth": 10, "random_state": 42}
    mlflow.log_params(params)
    
    model = RandomForestClassifier(**params, n_jobs=-1)
    model.fit(X_train, y_train)
    
    predictions = model.predict(X_test)
    predictions_proba = model.predict_proba(X_test)[:, 1]
    
    accuracy = accuracy_score(y_test, predictions)
    mlflow.log_metric("accuracy", accuracy)
    
    # 1. Confusion Matrix
    cm = confusion_matrix(y_test, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['Malignant', 'Benign'],
                yticklabels=['Malignant', 'Benign'])
    plt.title('Confusion Matrix')
    plt.ylabel('Actual')
    plt.xlabel('Predicted')
    plt.savefig("outputs/confusion_matrix.png", dpi=150)
    plt.close()
    mlflow.log_artifact("outputs/confusion_matrix.png")
    
    # 2. ROC Curve
    fpr, tpr, _ = roc_curve(y_test, predictions_proba)
    roc_auc = auc(fpr, tpr)
    
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='darkorange', lw=2,
             label=f'ROC curve (AUC = {roc_auc:.4f})')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve')
    plt.legend()
    plt.savefig("outputs/roc_curve.png", dpi=150)
    plt.close()
    mlflow.log_metric("roc_auc", roc_auc)
    mlflow.log_artifact("outputs/roc_curve.png")
    
    # 3. Feature Importance
    feature_importance = pd.DataFrame({
        'feature': data.feature_names,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    feature_importance.to_csv("outputs/feature_importance.csv", index=False)
    mlflow.log_artifact("outputs/feature_importance.csv")
    
    plt.figure(figsize=(10, 8))
    top_features = feature_importance.head(15)
    plt.barh(range(len(top_features)), top_features['importance'])
    plt.yticks(range(len(top_features)), top_features['feature'])
    plt.xlabel('Importance')
    plt.title('Top 15 Feature Importance')
    plt.gca().invert_yaxis()
    plt.savefig("outputs/feature_importance.png", dpi=150)
    plt.close()
    mlflow.log_artifact("outputs/feature_importance.png")
    
    print(f"‚úÖ Accuracy: {accuracy:.4f}")
    print(f"‚úÖ ROC AUC: {roc_auc:.4f}")

print("\nüéâ Lab 5 ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")
print("üìä ‡∏î‡∏π Artifacts ‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà MLflow UI ‚Üí Artifacts tab")
```

### ‚ñ∂Ô∏è ‡∏ß‡∏¥‡∏ò‡∏µ‡∏£‡∏±‡∏ô

```bash
python experiments/lab5_custom_artifacts.py
```

---

## üìù Lab 6: Query & Search Runs

### üéØ ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå
- ‡πÉ‡∏ä‡πâ MLflow API ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ Runs
- ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Runs ‡∏î‡πâ‡∏ß‡∏¢ Python

### üíª ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ó‡∏î‡∏•‡∏≠‡∏á

‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå `experiments/lab6_query_runs.py`:

```python
"""
Lab 6: Query & Search Runs
==========================
‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ MLflow API ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Runs
"""

import mlflow
from mlflow.tracking import MlflowClient
import pandas as pd

mlflow.set_tracking_uri("http://127.0.0.1:8080")

print("=" * 50)
print("Lab 6: Query & Search Runs")
print("=" * 50)

client = MlflowClient()

# 1. List Experiments
print("\nüìã 1. List All Experiments")
experiments = client.search_experiments()
for exp in experiments:
    print(f"   ID: {exp.experiment_id} | Name: {exp.name}")

# 2. Get Experiment by Name
print("\nüîç 2. Get Experiment by Name")
exp_name = "lab4-hyperparameter-tuning"
experiment = client.get_experiment_by_name(exp_name)

if experiment:
    exp_id = experiment.experiment_id
    print(f"   Found: {experiment.name} (ID: {exp_id})")
    
    # 3. Search Runs
    print("\nüîé 3. Search Runs with accuracy > 0.95")
    runs_high_acc = mlflow.search_runs(
        experiment_ids=[exp_id],
        filter_string="metrics.accuracy > 0.95",
        order_by=["metrics.accuracy DESC"]
    )
    print(f"   ‡∏û‡∏ö {len(runs_high_acc)} runs")
    
    # 4. Top 5 Runs
    print("\nüìä 4. Top 5 Runs by Accuracy")
    top_runs = mlflow.search_runs(
        experiment_ids=[exp_id],
        order_by=["metrics.accuracy DESC"],
        max_results=5
    )
    
    if len(top_runs) > 0:
        cols = ['run_id', 'params.n_estimators', 'metrics.accuracy']
        available = [c for c in cols if c in top_runs.columns]
        print(top_runs[available].to_string(index=False))
    
    # 5. Statistics
    print("\nüìà 5. Accuracy Statistics")
    all_runs = mlflow.search_runs(experiment_ids=[exp_id])
    if 'metrics.accuracy' in all_runs.columns:
        print(f"   Mean: {all_runs['metrics.accuracy'].mean():.4f}")
        print(f"   Max:  {all_runs['metrics.accuracy'].max():.4f}")
        print(f"   Min:  {all_runs['metrics.accuracy'].min():.4f}")
else:
    print(f"   ‚ùå Experiment '{exp_name}' not found. ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏±‡∏ô Lab 4 ‡∏Å‡πà‡∏≠‡∏ô")

print("\nüéâ Lab 6 ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")
```

### ‚ñ∂Ô∏è ‡∏ß‡∏¥‡∏ò‡∏µ‡∏£‡∏±‡∏ô

```bash
python experiments/lab6_query_runs.py
```

---

## üìö ‡∏™‡∏£‡∏∏‡∏õ

### üéØ ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ

| Lab | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ | ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ |
|-----|--------|----------------|
| 1 | Basic Tracking | log_param, log_metric, log_artifact |
| 2 | Training Loop | ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Metrics ‡∏ï‡∏≤‡∏° step/epoch |
| 3 | Sklearn Autolog | autolog() ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ |
| 4 | Hyperparameter | Grid Search + ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏• |
| 5 | Custom Artifacts | Confusion Matrix, ROC, Feature Importance |
| 6 | Query Runs | ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Runs ‡∏î‡πâ‡∏ß‡∏¢ API |

### üìå ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏à‡∏≥

```python
# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Server
mlflow.set_tracking_uri("http://127.0.0.1:8080")

# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Experiment
mlflow.set_experiment("my-experiment")

# ‡πÄ‡∏£‡∏¥‡πà‡∏° Run
with mlflow.start_run(run_name="my-run"):
    mlflow.log_param("key", value)
    mlflow.log_metric("accuracy", 0.95)
    mlflow.log_metric("loss", 0.1, step=epoch)
    mlflow.log_artifact("file.png")
    mlflow.set_tag("key", "value")

# Autolog
mlflow.sklearn.autolog()

# ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ Runs
runs = mlflow.search_runs(
    experiment_ids=["1"],
    filter_string="metrics.accuracy > 0.9"
)
```

### üîó ‡πÅ‡∏´‡∏•‡πà‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°

- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [MLflow Tracking Guide](https://mlflow.org/docs/latest/tracking.html)
- [MLflow Python API](https://mlflow.org/docs/latest/python_api/index.html)

---

## ‚ùì FAQ - ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢

### Q1: ‡∏ó‡∏≥‡πÑ‡∏° MLflow UI ‡πÑ‡∏°‡πà‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•?
**A:** ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ MLflow Server ‡∏£‡∏±‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà:
```bash
cd ../mlflowserver-lab
source .venv/bin/activate
mlflow server --host 127.0.0.1 --port 8080 \
  --backend-store-uri sqlite:///mlruns_db/mlflow.db \
  --artifacts-destination ./mlartifacts --serve-artifacts
```

### Q2: Error "MLFLOW_TRACKING_URI not set"
**A:** ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Environment Variable:
```bash
export MLFLOW_TRACKING_URI=http://127.0.0.1:8080
```

### Q3: Artifacts ‡πÑ‡∏°‡πà‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô UI
**A:** ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Server ‡∏£‡∏±‡∏ô‡∏î‡πâ‡∏ß‡∏¢ `--serve-artifacts` flag

---

## üèÅ Checklist ‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á Lab

- [ ] ‡∏£‡∏±‡∏ô Lab 1-6 ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
- [ ] ‡∏î‡∏π‡∏ú‡∏•‡πÉ‡∏ô MLflow UI ‡πÑ‡∏î‡πâ
- [ ] ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á Parameters, Metrics, Artifacts
- [ ] ‡∏ó‡∏≥‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡∏ó‡πâ‡∏≤‡∏¢ Lab ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 2 ‡∏Ç‡πâ‡∏≠‡∏ï‡πà‡∏≠ Lab

---

**üéâ ‡∏Ç‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏ô‡∏∏‡∏Å‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ MLflow Tracking!**