# %% [markdown]
# # üß™ Lab: MLflow Prompt Management with Gemini API
#
# ## ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå (Objectives)
# 1. ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ **MLflow Prompt Registry** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Prompt ‡πÅ‡∏ö‡∏ö‡∏°‡∏µ Version Control
# 2. ‡πÉ‡∏ä‡πâ `mlflow.genai.register_prompt` ‡πÅ‡∏•‡∏∞ `mlflow.genai.load_prompt` ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î Prompt
# 3. ‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ **Reflection Pattern** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á Prompt ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
# 4. ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û Prompt ‡πÅ‡∏ï‡πà‡∏•‡∏∞ Version ‡∏ú‡πà‡∏≤‡∏ô MLflow
#
# ## ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° (Prerequisites)
# - Python 3.9+
# - MLflow Server ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà `http://127.0.0.1:5000`
# - Gemini API Key
#
# ## ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Lab
# | ‡∏™‡πà‡∏ß‡∏ô | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ | ‡πÄ‡∏ß‡∏•‡∏≤‡πÇ‡∏î‡∏¢‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì |
# |------|--------|---------------|
# | Part 1 | Setup & Helper Functions | 10 ‡∏ô‡∏≤‡∏ó‡∏µ |
# | Part 2 | MLflow Prompt Registry ‚Äî Register & Load | 20 ‡∏ô‡∏≤‡∏ó‡∏µ |
# | Part 3 | Prompt Testing & Evaluation | 20 ‡∏ô‡∏≤‡∏ó‡∏µ |
# | Part 4 | Reflection-based Prompt Optimization | 30 ‡∏ô‡∏≤‡∏ó‡∏µ |
# | Part 5 | Full Optimization Loop & Comparison | 20 ‡∏ô‡∏≤‡∏ó‡∏µ |

# %% [markdown]
# ---
# # Part 1: Setup & Helper Functions
# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Library ‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Helper Functions ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏ï‡∏•‡∏≠‡∏î‡∏ó‡∏±‡πâ‡∏á Lab

# %%
# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Library ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
# !pip install mlflow google-genai

# %%
# Import Libraries
import mlflow
import mlflow.genai
import json
import time
from typing import Dict, List
from google import genai
from google.genai import types

print(f"MLflow version: {mlflow.__version__}")

# %% [markdown]
# ## 1.1 ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤ API Key ‡πÅ‡∏•‡∏∞‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Gemini

# %%
# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î API Key ‡πÅ‡∏•‡∏∞ Model
API_KEY = "AIzaSyB5irEioOc2skZ_aaLy9qDGo9sAAmLc5_k"  # <<<< ‡πÉ‡∏™‡πà API Key ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà
MODEL_NAME = "gemini-2.0-flash"

# ‡∏™‡∏£‡πâ‡∏≤‡∏á Client
client = genai.Client(api_key=API_KEY)

print("‚úÖ Gemini Client ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")

# %% [markdown]
# ## 1.2 ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ MLflow Server
#
# > ‚ö†Ô∏è ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤ MLflow Server ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡∏π‡πà ‡πÇ‡∏î‡∏¢‡∏£‡∏±‡∏ô `mlflow server` ‡πÉ‡∏ô Terminal ‡∏Å‡πà‡∏≠‡∏ô

# %%
# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î MLflow Tracking URI
MLFLOW_TRACKING_URI = "http://127.0.0.1:5000"

# ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ MLflow Server
mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)

print(f"‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ MLflow Server ‡∏ó‡∏µ‡πà: {MLFLOW_TRACKING_URI}")
print(f"   Tracking URI: {mlflow.get_tracking_uri()}")

# %% [markdown]
# ## 1.3 Helper Functions
#
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏ï‡∏•‡∏≠‡∏î‡∏ó‡∏±‡πâ‡∏á Lab:
# - `call_gemini()` ‚Äî ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Gemini API
# - `print_section()` ‚Äî ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏°

# %%
# === Helper Functions ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏ï‡∏•‡∏≠‡∏î‡∏ó‡∏±‡πâ‡∏á Lab ===

def call_gemini(prompt: str, temperature: float = 0.0, max_tokens: int = 2048) -> str:
    """Helper function ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Gemini API"""
    response = client.models.generate_content(
        model=MODEL_NAME,
        contents=prompt,
        config=types.GenerateContentConfig(
            temperature=temperature,
            max_output_tokens=max_tokens,
        )
    )
    return response.text


def print_section(title: str, content: str, emoji: str = "üîπ"):
    """Helper function ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏°"""
    print(f"\n{emoji} {title}")
    print("‚îÄ" * 50)
    print(content)
    print("‚îÄ" * 50)


# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Gemini API
test_response = call_gemini("‡∏ï‡∏≠‡∏ö‡∏™‡∏±‡πâ‡∏ô‡πÜ: 1+1 ‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏£?")
print_section("‡∏ó‡∏î‡∏™‡∏≠‡∏ö Gemini API", test_response, "üß™")

# %% [markdown]
# ---
# # Part 2: MLflow Prompt Registry ‚Äî Register & Load
#
# MLflow Prompt Registry ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Prompt ‡πÑ‡∏î‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô **Version Control**:
# - **Register**: ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Prompt ‡∏û‡∏£‡πâ‡∏≠‡∏° version
# - **Load**: ‡πÇ‡∏´‡∏•‡∏î Prompt ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡πÉ‡∏ä‡πâ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏ó‡∏ô‡∏Ñ‡πà‡∏≤‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ (template variables)
#
# ### ‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏´‡∏•‡∏±‡∏Å
# ```
# Prompt v1 ‚Üí Register ‚Üí MLflow Registry
#                              ‚Üì
#                         Load & Use ‚Üí ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
#                              ‚Üì
#                         Evaluate ‚Üí ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á ‚Üí Prompt v2 ‚Üí Register...
# ```

# %% [markdown]
# ## 2.1 Register Prompt ‚Äî ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Prompt ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏£‡∏Å
#
# ‡πÉ‡∏ä‡πâ `mlflow.genai.register_prompt()` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Prompt Template ‡∏•‡∏á‡πÉ‡∏ô MLflow Registry
#
# **Parameters ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:**
# - `name` ‚Äî ‡∏ä‡∏∑‡πà‡∏≠ Prompt (‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á)
# - `template` ‚Äî ‡∏ï‡∏±‡∏ß Prompt Template ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ `{{ variable }}` ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£
# - `commit_message` ‚Äî ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô Git commit message)

# %%

# %%
# === Lab 2.1: Register Prompt v1 ‚Äî Sentiment Analysis ===

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Prompt Template ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Sentiment Analysis
PROMPT_NAME = "sentiment_classifier"

PROMPT_TEMPLATE_V1 = """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå sentiment ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ

‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {{ text }}

‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡πÄ‡∏î‡∏µ‡∏¢‡∏ß: positive, negative, ‡∏´‡∏£‡∏∑‡∏≠ neutral"""

# ‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô Prompt v1
prompt_v1 = mlflow.genai.register_prompt(
    name=PROMPT_NAME,
    template=PROMPT_TEMPLATE_V1,
    commit_message="v1: Basic sentiment classifier - simple instruction"
)



# %%
print(f"‚úÖ ‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô Prompt ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
print(f"   Name: {prompt_v1.name}")
print(f"   Version: {prompt_v1.version}")
print(f"   Template:\n{prompt_v1.template}")

# %% [markdown]
# ## 2.2 Load Prompt ‚Äî ‡πÇ‡∏´‡∏•‡∏î Prompt ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
#
# ‡πÉ‡∏ä‡πâ `mlflow.genai.load_prompt()` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÇ‡∏´‡∏•‡∏î Prompt ‡∏à‡∏≤‡∏Å Registry
# ‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏ó‡∏ô‡∏Ñ‡πà‡∏≤‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏î‡πâ‡∏ß‡∏¢ `.format()` method
#
# **‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö URI**: `prompts:/<prompt_name>/<version>`
# - `prompts:/sentiment_classifier/1` ‚Äî ‡πÇ‡∏´‡∏•‡∏î version 1
# - `prompts:/sentiment_classifier/latest` ‚Äî ‡πÇ‡∏´‡∏•‡∏î version ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î

# %%
# === Lab 2.2: Load Prompt ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á ===

# ‡πÇ‡∏´‡∏•‡∏î Prompt ‡∏à‡∏≤‡∏Å Registry
loaded_prompt = mlflow.genai.load_prompt(f"prompts:/{PROMPT_NAME}/1")

print(f"üìã Prompt ‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡∏°‡∏≤:")
print(f"   Version: {loaded_prompt.version}")
print(f"   Template: {loaded_prompt.template}")

# %%
# ‡πÅ‡∏ó‡∏ô‡∏Ñ‡πà‡∏≤‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Gemini API
test_texts = [
    "‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏£‡πâ‡∏≤‡∏ô‡∏ô‡∏µ‡πâ‡∏≠‡∏£‡πà‡∏≠‡∏¢‡∏°‡∏≤‡∏Å‡πÜ ‡πÄ‡∏•‡∏¢ ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏î‡∏µ‡∏™‡∏∏‡∏î‡πÜ",
    "‡∏ú‡∏¥‡∏î‡∏´‡∏ß‡∏±‡∏á‡∏°‡∏≤‡∏Å ‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏õ‡∏Å",
    "‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏ù‡∏ô‡∏ï‡∏Å‡∏ï‡∏≠‡∏ô‡∏ö‡πà‡∏≤‡∏¢"
]

print("üîç ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Prompt v1 ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:\n")

for text in test_texts:
    # ‡πÅ‡∏ó‡∏ô‡∏Ñ‡πà‡∏≤ {{ text }} ‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏£‡∏¥‡∏á
    filled_prompt = loaded_prompt.format(text=text)
    result = call_gemini(filled_prompt)
    print(f"  üìù ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {text}")
    print(f"  üè∑Ô∏è  ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå: {result.strip()}")
    print()

# %% [markdown]
# ## 2.3 Register Prompt v2 ‚Äî ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á Prompt
#
# ‡∏•‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á Prompt ‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô ‡πÅ‡∏•‡πâ‡∏ß Register ‡πÄ‡∏õ‡πá‡∏ô Version ‡πÉ‡∏´‡∏°‡πà

# %%
# === Lab 2.3: Register Prompt v2 ‚Äî Improved Version ===

PROMPT_TEMPLATE_V2 = """‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å (Sentiment Analyst) ‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢

## ‡∏Å‡∏é‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå:
- **positive**: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏∂‡∏á‡∏û‡∏≠‡πÉ‡∏à ‡∏ä‡∏∑‡πà‡∏ô‡∏ä‡∏° ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
- **negative**: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏°‡πà‡∏û‡∏≠‡πÉ‡∏à ‡∏ú‡∏¥‡∏î‡∏´‡∏ß‡∏±‡∏á ‡∏ö‡πà‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏ö
- **neutral**: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏•‡∏≤‡∏á ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡πÄ‡∏ó‡πá‡∏à‡∏à‡∏£‡∏¥‡∏á ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô

## ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå:
{{ text }}

## ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö (‡∏ï‡∏≠‡∏ö‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Ñ‡∏≥‡πÄ‡∏î‡∏µ‡∏¢‡∏ß: positive, negative, ‡∏´‡∏£‡∏∑‡∏≠ neutral):"""

# Register ‡πÄ‡∏õ‡πá‡∏ô Version ‡πÉ‡∏´‡∏°‡πà (‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏î‡∏¥‡∏° ‚Üí MLflow ‡∏™‡∏£‡πâ‡∏≤‡∏á version ‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)
prompt_v2 = mlflow.genai.register_prompt(
    name=PROMPT_NAME,
    template=PROMPT_TEMPLATE_V2,
    commit_message="v2: Added role, rules, and structured format"
)

print(f"‚úÖ ‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô Prompt v2 ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
print(f"   Name: {prompt_v2.name}")
print(f"   Version: {prompt_v2.version}")

# %% [markdown]
# ## 2.4 ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Prompt v1 vs v2
#
# ‡πÇ‡∏´‡∏•‡∏î Prompt ‡∏ó‡∏±‡πâ‡∏á 2 version ‡∏°‡∏≤‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö

# %%
# === Lab 2.4: ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö 2 Versions ===

prompt_v1_loaded = mlflow.genai.load_prompt(f"prompts:/{PROMPT_NAME}/1")
prompt_v2_loaded = mlflow.genai.load_prompt(f"prompts:/{PROMPT_NAME}/2")

print("üìä ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Prompt 2 Versions:\n")
print(f"{'='*60}")
print(f"Version 1 (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß: {len(prompt_v1_loaded.template)} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£):")
print(f"{'‚îÄ'*60}")
print(prompt_v1_loaded.template)
print(f"\n{'='*60}")
print(f"Version 2 (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß: {len(prompt_v2_loaded.template)} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£):")
print(f"{'‚îÄ'*60}")
print(prompt_v2_loaded.template)

# %% [markdown]
# ---
# # Part 3: Prompt Testing & Evaluation
#
# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö (Test Dataset) ‡πÅ‡∏•‡∏∞‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Evaluate
# ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏±‡∏î‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á Prompt ‡πÅ‡∏ï‡πà‡∏•‡∏∞ Version ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö

# %% [markdown]
# ## 3.1 ‡∏™‡∏£‡πâ‡∏≤‡∏á Test Dataset
#
# ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á (Ground Truth) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏±‡∏î Accuracy

# %%
# === Lab 3.1: Test Dataset ===

TEST_DATA = [
    # === ‡∏õ‡∏£‡∏∞‡∏ä‡∏î / Sarcasm ===
    {"text": "‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡∏£‡∏≠‡∏Ç‡∏≠‡∏á 3 ‡∏≠‡∏≤‡∏ó‡∏¥‡∏ï‡∏¢‡πå ‡πÑ‡∏î‡πâ‡∏Ç‡∏≠‡∏á‡∏°‡∏≤‡∏ä‡∏≥‡∏£‡∏∏‡∏î ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÇ‡∏•‡∏Å‡∏à‡∏£‡∏¥‡∏á‡πÜ", "expected": "negative"},
    {"text": "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏ú‡∏¥‡∏î‡πÉ‡∏´‡πâ‡∏ñ‡∏∂‡∏á 2 ‡∏£‡∏≠‡∏ö ‡πÉ‡∏™‡πà‡πÉ‡∏à‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡∏ô‡∏∞‡∏Ñ‡∏∞", "expected": "negative"},
    {"text": "‡∏£‡∏≤‡∏Ñ‡∏≤‡πÅ‡∏Ñ‡πà‡∏ô‡∏µ‡πâ‡πÄ‡∏≠‡∏á ‡∏ñ‡∏π‡∏Å‡∏à‡∏±‡∏á ‡πÅ‡∏Ñ‡πà‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏•‡∏∞‡∏´‡∏°‡∏∑‡πà‡∏ô‡∏™‡∏≠‡∏á‡∏´‡∏°‡∏∑‡πà‡∏ô ‡πÉ‡∏Ñ‡∏£‡πÜ ‡∏Å‡πá‡∏ã‡∏∑‡πâ‡∏≠‡πÑ‡∏î‡πâ", "expected": "negative"},
    {"text": "‡∏î‡∏µ‡∏Ñ‡πà‡∏∞ ‡∏î‡∏µ‡∏°‡∏≤‡∏Å‡∏Ñ‡πà‡∏∞ ‡∏î‡∏µ‡∏à‡∏ô‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏∞‡∏û‡∏π‡∏î‡∏¢‡∏±‡∏á‡πÑ‡∏á‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏∞ üôÇ", "expected": "negative"},
    
    # === ‡∏ö‡∏ß‡∏Å‡∏ó‡∏µ‡πà‡∏î‡∏π‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏•‡∏ö / Positive disguised as negative ===
    {"text": "‡πÅ‡∏û‡∏á‡∏à‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏≤‡∏¢ ‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ñ‡∏∏‡πâ‡∏°‡∏ó‡∏∏‡∏Å‡∏ö‡∏≤‡∏ó", "expected": "positive"},
    {"text": "‡πÄ‡∏Å‡∏•‡∏µ‡∏¢‡∏î‡∏£‡πâ‡∏≤‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏•‡∏¢ ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏°‡∏≤‡∏ó‡∏µ‡πÑ‡∏£‡∏Å‡πá‡πÉ‡∏ä‡πâ‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏¢‡∏≠‡∏∞ ‡∏≠‡∏£‡πà‡∏≠‡∏¢‡∏ó‡∏∏‡∏Å‡πÄ‡∏°‡∏ô‡∏π", "expected": "positive"},

    # === ‡∏•‡∏ö‡∏ó‡∏µ‡πà‡∏î‡∏π‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ö‡∏ß‡∏Å / Negative disguised as positive ===
    {"text": "‡∏ö‡∏£‡∏£‡∏à‡∏∏‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏°‡∏°‡∏≤‡∏Å‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏≤‡∏¢‡∏Ç‡πâ‡∏≤‡∏á‡πÉ‡∏ô‡πÄ‡∏ô‡πà‡∏≤‡∏´‡∏°‡∏î‡πÄ‡∏•‡∏¢", "expected": "negative"},
    {"text": "‡πÄ‡∏°‡∏ô‡∏π‡πÄ‡∏¢‡∏≠‡∏∞‡∏î‡∏µ‡∏à‡∏±‡∏á ‡πÅ‡∏ï‡πà‡∏™‡∏±‡πà‡∏á‡∏≠‡∏∞‡πÑ‡∏£‡∏Å‡πá‡∏´‡∏°‡∏î ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÅ‡∏ï‡πà‡∏ô‡πâ‡∏≥‡πÄ‡∏õ‡∏•‡πà‡∏≤", "expected": "negative"},
    {"text": "‡∏£‡πâ‡∏≤‡∏ô‡∏î‡∏±‡∏á‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡∏Ñ‡πà‡∏∞ ‡∏î‡∏±‡∏á‡∏à‡∏ô‡∏Ñ‡∏¥‡∏ß‡∏¢‡∏≤‡∏ß 3 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á ‡πÅ‡∏ï‡πà‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤‡∏°‡∏≤‡∏Å", "expected": "negative"},

    # === ‡∏Å‡∏•‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏π‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ö‡∏ß‡∏Å / Neutral disguised as positive ===
    {"text": "‡∏£‡πâ‡∏≤‡∏ô‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡∏£‡∏≤‡∏á‡∏ß‡∏±‡∏•‡∏£‡πâ‡∏≤‡∏ô‡∏¢‡∏≠‡∏î‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏õ‡∏µ 2561", "expected": "neutral"},
    {"text": "‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏ß‡πà‡∏≤‡∏≠‡∏£‡πà‡∏≠‡∏¢‡∏°‡∏≤‡∏Å ‡πÉ‡∏´‡πâ 4.8 ‡∏î‡∏≤‡∏ß‡∏ö‡∏ô Google", "expected": "neutral"},
    {"text": "‡πÄ‡∏ä‡∏ü‡πÄ‡∏Ñ‡∏¢‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏£‡πâ‡∏≤‡∏ô‡∏°‡∏¥‡∏ä‡∏•‡∏¥‡∏ô‡∏™‡∏ï‡∏≤‡∏£‡πå‡πÉ‡∏ô‡∏ù‡∏£‡∏±‡πà‡∏á‡πÄ‡∏®‡∏™‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô", "expected": "neutral"},
    {"text": "‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ï‡∏±‡∏ß‡∏ô‡∏µ‡πâ‡∏Ç‡∏≤‡∏¢‡∏î‡∏µ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö 1 ‡∏ö‡∏ô‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏•‡πâ‡∏ß", "expected": "neutral"},
    {"text": "‡∏£‡πâ‡∏≤‡∏ô‡πÄ‡∏õ‡∏¥‡∏î‡∏™‡∏≤‡∏Ç‡∏≤‡πÉ‡∏´‡∏°‡πà 5 ‡∏™‡∏≤‡∏Ç‡∏≤‡πÉ‡∏ô‡∏õ‡∏µ‡∏ô‡∏µ‡πâ ‡∏£‡∏ß‡∏°‡πÄ‡∏õ‡πá‡∏ô 20 ‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏±‡πà‡∏ß‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®", "expected": "neutral"},

    # === ‡∏Å‡∏•‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏π‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏•‡∏ö / Neutral disguised as negative ===
    {"text": "‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏´‡∏°‡∏î‡∏™‡∏ï‡πá‡∏≠‡∏Å‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß ‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡∏ß‡∏≤‡∏á‡∏Ç‡∏≤‡∏¢‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå‡∏´‡∏ô‡πâ‡∏≤", "expected": "neutral"},
    {"text": "‡∏£‡πâ‡∏≤‡∏ô‡∏õ‡∏¥‡∏î‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 1-15 ‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°", "expected": "neutral"},
    {"text": "‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢‡∏£‡πâ‡∏≤‡∏ô‡πÑ‡∏°‡πà‡∏£‡∏±‡∏ö‡∏Ñ‡∏∑‡∏ô‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏á 7 ‡∏ß‡∏±‡∏ô", "expected": "neutral"},
    {"text": "‡∏Ñ‡πà‡∏≤‡∏™‡πà‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô 50 ‡∏ö‡∏≤‡∏ó ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏≤‡∏°‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å ‡∏Å‡∏¥‡πÇ‡∏•‡∏Å‡∏£‡∏±‡∏°‡∏•‡∏∞ 15 ‡∏ö‡∏≤‡∏ó", "expected": "neutral"}, 

]

    
print(f"üìä Test Dataset: {len(TEST_DATA)} ‡∏Ç‡πâ‡∏≠")
print(f"   Positive: {sum(1 for d in TEST_DATA if d['expected'] == 'positive')} ‡∏Ç‡πâ‡∏≠")
print(f"   Negative: {sum(1 for d in TEST_DATA if d['expected'] == 'negative')} ‡∏Ç‡πâ‡∏≠")
print(f"   Neutral:  {sum(1 for d in TEST_DATA if d['expected'] == 'neutral')} ‡∏Ç‡πâ‡∏≠")

# %% [markdown]
# ## 3.2 ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Evaluate
#
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö Prompt ‡∏Å‡∏±‡∏ö Test Dataset ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
# ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Accuracy ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå

# %%
# === Lab 3.2: Evaluation Function ===

def evaluate_prompt(prompt_template: str, test_data: List[Dict], version_label: str = "") -> Dict:
    """
    ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô Prompt ‡∏Å‡∏±‡∏ö‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö
    
    Parameters:
        prompt_template: Prompt template ‡∏ó‡∏µ‡πà‡∏°‡∏µ {{ text }}
        test_data: ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö [{text, expected}, ...]
        version_label: ‡∏ä‡∏∑‡πà‡∏≠ version ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
        
    Returns:
        Dict ‡∏ó‡∏µ‡πà‡∏°‡∏µ accuracy, results, correct, total
    """
    results = []
    correct = 0
    total = len(test_data)
    
    print(f"\nüß™ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Prompt {version_label}")
    print("‚îÄ" * 60)
    
    for i, item in enumerate(test_data):
        # ‡πÅ‡∏ó‡∏ô‡∏Ñ‡πà‡∏≤ {{ text }}
        filled = prompt_template.replace("{{ text }}", item["text"])
        
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Gemini
        response = call_gemini(filled).strip().lower()
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö ‚Äî ‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞ label ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á
        predicted = "unknown"
        for label in ["positive", "negative", "neutral"]:
            if label in response:
                predicted = label
                break
        
        is_correct = predicted == item["expected"]
        if is_correct:
            correct += 1
        
        result = {
            "text": item["text"],
            "expected": item["expected"],
            "predicted": predicted,
            "raw_response": response,
            "correct": "‚úÖ" if is_correct else "‚ùå"
        }
        results.append(result)
        
        print(f"  {result['correct']} [{i+1}/{total}] Expected: {item['expected']:8s} | "
              f"Predicted: {predicted:8s} | {item['text'][:30]}...")
        
        time.sleep(1.5)  # ‡∏´‡∏ô‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏¥‡∏ô Rate Limit
    
    accuracy = (correct / total) * 100
    
    print(f"\nüìä ‡∏ú‡∏•‡∏£‡∏ß‡∏°: Accuracy = {accuracy:.1f}% ({correct}/{total})")
    
    return {
        "accuracy": accuracy,
        "correct": correct,
        "total": total,
        "results": results
    }

# %% [markdown]
# ## 3.3 ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Prompt v1 ‡πÅ‡∏•‡∏∞ v2

# %%
# === Lab 3.3: ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Prompt v1 ===

prompt_v1_loaded = mlflow.genai.load_prompt(f"prompts:/{PROMPT_NAME}/1")
eval_v1 = evaluate_prompt(prompt_v1_loaded.template, TEST_DATA, version_label="v1")

# %%
# === ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Prompt v2 ===

prompt_v2_loaded = mlflow.genai.load_prompt(f"prompts:/{PROMPT_NAME}/2")
eval_v2 = evaluate_prompt(prompt_v2_loaded.template, TEST_DATA, version_label="v2")

# %%
# === ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö ===

print("\n" + "=" * 60)
print("üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Prompt v1 vs v2")
print("=" * 60)
print(f"  Prompt v1: Accuracy = {eval_v1['accuracy']:.1f}% ({eval_v1['correct']}/{eval_v1['total']})")
print(f"  Prompt v2: Accuracy = {eval_v2['accuracy']:.1f}% ({eval_v2['correct']}/{eval_v2['total']})")
improvement = eval_v2['accuracy'] - eval_v1['accuracy']
if improvement > 0:
    print(f"  üìà v2 ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ v1: +{improvement:.1f}%")
elif improvement < 0:
    print(f"  üìâ v1 ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ v2: {improvement:.1f}%")
else:
    print(f"  ‚û°Ô∏è  ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô")

# %% [markdown]
# ---
# # Part 4: Reflection-based Prompt Optimization
#
# ‡πÉ‡∏ä‡πâ **Reflection Pattern** ‡πÉ‡∏´‡πâ LLM ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏∏‡∏î‡∏≠‡πà‡∏≠‡∏ô‡∏Ç‡∏≠‡∏á Prompt ‡πÅ‡∏•‡πâ‡∏ß‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤
#
# ### Reflection Loop:
# ```
# Prompt v_n ‚Üí ‡∏ó‡∏î‡∏™‡∏≠‡∏ö ‚Üí ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î ‚Üí ‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt ‡πÉ‡∏´‡∏°‡πà ‚Üí Prompt v_n+1 ‚Üí ‡∏ó‡∏î‡∏™‡∏≠‡∏ö ‚Üí ...
# ```

# %% [markdown]
# ## 4.1 Reflection for Prompt Optimization
#
# ‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå Reflection Pattern ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö **‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏à‡∏£‡∏¥‡∏á** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ LLM
# ‡πÄ‡∏´‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏™‡∏ô‡∏≠ Prompt ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏à‡∏∏‡∏î
#
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏∞:
# 1. ‡∏£‡∏±‡∏ö Prompt ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö
# 2. ‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ Gemini ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏∏‡∏î‡∏≠‡πà‡∏≠‡∏ô‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏ï‡∏≠‡∏ö‡∏ú‡∏¥‡∏î
# 3. ‡πÉ‡∏´‡πâ Gemini ‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô

# %%
# === Lab 4.2: Prompt Optimization with Reflection ===

def optimize_prompt_with_reflection(
    current_template: str,
    eval_results: Dict,
    version_label: str = ""
) -> str:
    """
    ‡πÉ‡∏ä‡πâ Reflection ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á Prompt ‡∏à‡∏≤‡∏Å‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö
    
    Parameters:
        current_template: Prompt template ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
        eval_results: ‡∏ú‡∏•‡∏à‡∏≤‡∏Å evaluate_prompt()
        version_label: ‡∏ä‡∏∑‡πà‡∏≠ version ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
    
    Returns:
        Prompt template ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÅ‡∏•‡πâ‡∏ß
    """
    accuracy = eval_results["accuracy"]
    correct = eval_results["correct"]
    total = eval_results["total"]
    results = eval_results["results"]
    
    # ‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏ï‡∏≠‡∏ö‡∏ú‡∏¥‡∏î
    wrong_answers = [r for r in results if r['correct'] == '‚ùå']
    
    if not wrong_answers:
        print("‚úÖ Prompt ‡πÑ‡∏î‡πâ 100% ‡πÅ‡∏•‡πâ‡∏ß ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á!")
        return current_template
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Reflection Prompt
    reflection_request = f"""‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô Prompt Engineering

## Prompt ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô:
{current_template}

## ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö:
- Accuracy: {accuracy:.1f}% ({correct}/{total})
- ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î: {total - correct} ‡∏Ç‡πâ‡∏≠

## ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏ï‡∏≠‡∏ö‡∏ú‡∏¥‡∏î:
{json.dumps(wrong_answers, ensure_ascii=False, indent=2)}

## ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á:
1. **‡∏à‡∏∏‡∏î‡∏≠‡πà‡∏≠‡∏ô‡∏Ç‡∏≠‡∏á Prompt ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô** ‚Äî ‡∏≠‡∏∞‡πÑ‡∏£‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏ú‡∏¥‡∏î?
2. **Prompt ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÅ‡∏•‡πâ‡∏ß** ‚Äî ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ {{{{ text }}}}
   ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡πÄ‡∏î‡∏µ‡∏¢‡∏ß: positive, negative, ‡∏´‡∏£‡∏∑‡∏≠ neutral
3. **‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á** ‚Äî ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ß‡πà‡∏≤‡πÅ‡∏Å‡πâ‡∏≠‡∏∞‡πÑ‡∏£ ‡∏ó‡∏≥‡πÑ‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤

‚ö†Ô∏è ‡∏™‡πà‡∏ß‡∏ô Prompt ‡πÉ‡∏´‡∏°‡πà ‡πÉ‡∏´‡πâ‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ [NEW_PROMPT_START] ‡πÅ‡∏•‡∏∞‡∏à‡∏ö‡∏î‡πâ‡∏ß‡∏¢ [NEW_PROMPT_END]"""
    
    print_section(f"üîç Reflection Analysis ({version_label})", 
                  f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå {len(wrong_answers)} ‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏ï‡∏≠‡∏ö‡∏ú‡∏¥‡∏î...", "ü§î")
    
    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Gemini ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt ‡πÉ‡∏´‡∏°‡πà
    reflection_response = call_gemini(reflection_request, temperature=0.3, max_tokens=4096)
    print_section("Reflection Result", reflection_response, "üí°")
    
    # ‡∏î‡∏∂‡∏á Prompt ‡πÉ‡∏´‡∏°‡πà‡∏à‡∏≤‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    new_prompt = extract_new_prompt(reflection_response)
    
    if new_prompt:
        print_section("New Prompt Extracted", new_prompt, "üÜï")
    else:
        print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á Prompt ‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏î‡πâ ‡πÉ‡∏ä‡πâ Prompt ‡πÄ‡∏î‡∏¥‡∏°")
        new_prompt = current_template
    
    return new_prompt


def extract_new_prompt(response: str) -> str:
    """‡∏î‡∏∂‡∏á Prompt ‡πÉ‡∏´‡∏°‡πà‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á [NEW_PROMPT_START] ‡πÅ‡∏•‡∏∞ [NEW_PROMPT_END]"""
    start_marker = "[NEW_PROMPT_START]"
    end_marker = "[NEW_PROMPT_END]"
    
    if start_marker in response and end_marker in response:
        start_idx = response.index(start_marker) + len(start_marker)
        end_idx = response.index(end_marker)
        return response[start_idx:end_idx].strip()
    
    return None

# %% [markdown]
# ## 4.3 ‡∏ó‡∏î‡∏•‡∏≠‡∏á Optimize Prompt v2
#
# ‡∏ô‡∏≥‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö Prompt v2 ‡∏°‡∏≤‡πÉ‡∏´‡πâ Reflection ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt v3

# %%
# === Lab 4.3: Optimize v2 ‚Üí v3 ===
# ‡πÉ‡∏ä‡πâ‡∏ú‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö v2 ‡∏à‡∏≤‡∏Å Part 3
new_template_v3 = optimize_prompt_with_reflection(current_template=prompt_v2_loaded.template,eval_results=eval_v2,version_label="v2 ‚Üí v3")

# %%
print(new_template_v3)

# %% [markdown]
# ## 4.4 Register ‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö Prompt v3

# %%
# === Lab 4.4: Register v3 ===

prompt_v3 = mlflow.genai.register_prompt(
    name=PROMPT_NAME,
    template=new_template_v3,
    commit_message="v3: Reflection-optimized from v2 test results")


print(f"‚úÖ ‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô Prompt v3 ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! (Version: {prompt_v3.version})")


# %%
# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Prompt v3
prompt_v3_loaded = mlflow.genai.load_prompt(f"prompts:/{PROMPT_NAME}/3")
eval_v3 = evaluate_prompt(prompt_v3_loaded.template, TEST_DATA, version_label="v3")

# %% [markdown]
# ---
# # Part 5: Full Optimization Loop & Comparison
#
# ‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô **Optimization Loop** ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏ã‡πâ‡∏≥‡πÑ‡∏î‡πâ:
# 1. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Prompt ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
# 2. ‡∏ñ‡πâ‡∏≤ Accuracy ‡πÑ‡∏°‡πà‡∏ñ‡∏∂‡∏á‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ‚Üí Reflection ‚Üí ‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt ‡πÉ‡∏´‡∏°‡πà
# 3. Register Version ‡πÉ‡∏´‡∏°‡πà ‚Üí ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
# 4. ‡∏ó‡∏≥‡∏ã‡πâ‡∏≥‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏ñ‡∏∂‡∏á‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏£‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≠‡∏ö

# %%
# === Lab 5: Full Optimization Loop ===

def prompt_optimization_loop(
    prompt_name: str,
    initial_template: str,
    test_data: List[Dict],
    target_accuracy: float = 100.0,
    max_iterations: int = 3
) -> Dict:
    """
    Optimization Loop: ‡∏ó‡∏î‡∏™‡∏≠‡∏ö ‚Üí Reflect ‚Üí ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á ‚Üí ‡∏ó‡∏î‡∏™‡∏≠‡∏ö ‚Üí ...
    
    Parameters:
        prompt_name: ‡∏ä‡∏∑‡πà‡∏≠ Prompt ‡πÉ‡∏ô MLflow Registry
        initial_template: Prompt template ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
        test_data: ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö
        target_accuracy: ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ Accuracy (%)
        max_iterations: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≠‡∏ö‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
    
    Returns:
        Dict ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏ó‡∏∏‡∏Å iteration
    """
    history = []
    current_template = initial_template
    
    print("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏° Prompt Optimization Loop")
    print(f"   ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢: Accuracy >= {target_accuracy}%")
    print(f"   ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≠‡∏ö‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î: {max_iterations}")
    print("=" * 60)
    
    for iteration in range(1, max_iterations + 1):
        print(f"\n{'='*60}")
        print(f"üîÑ Iteration {iteration}/{max_iterations}")
        print(f"{'='*60}")
        
        # Step 1: Evaluate
        eval_result = evaluate_prompt(
            current_template, test_data, 
            version_label=f"Iter-{iteration}"
        )
        
        history.append({
            "iteration": iteration,
            "accuracy": eval_result["accuracy"],
            "correct": eval_result["correct"],
            "total": eval_result["total"],
            "template": current_template
        })
        
        # Step 2: Check target
        if eval_result["accuracy"] >= target_accuracy:
            print(f"\nüéâ ‡∏ñ‡∏∂‡∏á‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡πÅ‡∏•‡πâ‡∏ß! Accuracy = {eval_result['accuracy']:.1f}%")
            break
        
        # Step 3: Reflect & Optimize
        print(f"\nüîç ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ñ‡∏∂‡∏á‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ({eval_result['accuracy']:.1f}% < {target_accuracy}%)")
        print(f"   ‡∏Å‡∏≥‡∏•‡∏±‡∏á Reflect ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á...")
        
        new_template = optimize_prompt_with_reflection(
            current_template, eval_result,
            version_label=f"Iter-{iteration}"
        )
        
        # Step 4: Register ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á
        if new_template != current_template:
            registered = mlflow.genai.register_prompt(
                name=prompt_name,
                template=new_template,
                commit_message=f"Optimization iteration {iteration}: "
                             f"Accuracy {eval_result['accuracy']:.1f}% ‚Üí improving"
            )
            print(f"   ‚úÖ Registered new version: {registered.version}")
            current_template = new_template
        else:
            print("   ‚ö†Ô∏è Prompt ‡πÑ‡∏°‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á ‡∏´‡∏¢‡∏∏‡∏î Loop")
            break
    
    # === ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏• ===
    print(f"\n{'='*60}")
    print("üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏• Optimization Loop")
    print(f"{'='*60}")
    for h in history:
        bar = "‚ñà" * int(h["accuracy"] / 5)
        print(f"  Iter {h['iteration']}: {bar} {h['accuracy']:.1f}% ({h['correct']}/{h['total']})")
    
    if len(history) > 1:
        improvement = history[-1]["accuracy"] - history[0]["accuracy"]
        print(f"\n  üìà ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏£‡∏ß‡∏°: {'+' if improvement >= 0 else ''}{improvement:.1f}%")
    
    return {
        "history": history,
        "final_template": current_template,
        "iterations": len(history)
    }

# %% [markdown]
# ## 5.1 ‡∏£‡∏±‡∏ô Optimization Loop
#
# ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å Prompt v1 (Basic) ‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏ö‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥

# %%
# === Lab 5.1: Run Full Optimization ===

# ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å Prompt v1 (‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)
starting_prompt = mlflow.genai.load_prompt(f"prompts:/{PROMPT_NAME}/1")

optimization_result = prompt_optimization_loop(
    prompt_name=PROMPT_NAME,
    initial_template=starting_prompt.template,
    test_data=TEST_DATA,
    target_accuracy=100.0,
    max_iterations=3
)

# %%

# %% [markdown]
# ## 5.2 ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏∏‡∏Å Version ‡∏û‡∏£‡πâ‡∏≠‡∏° MLflow Tracking

# %%
# === Lab 5.2: Log ‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏á MLflow ===

mlflow.set_experiment("prompt_optimization_lab")

with mlflow.start_run(run_name="prompt_versions_comparison"):
    # Log ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏ï‡πà‡∏•‡∏∞ iteration
    for h in optimization_result["history"]:
        mlflow.log_metric(f"accuracy_iter_{h['iteration']}", h["accuracy"])
        mlflow.log_metric(f"correct_iter_{h['iteration']}", h["correct"])
    
    # Log ‡∏Ñ‡πà‡∏≤‡∏™‡∏£‡∏∏‡∏õ
    mlflow.log_metric("final_accuracy", optimization_result["history"][-1]["accuracy"])
    mlflow.log_metric("total_iterations", optimization_result["iterations"])
    
    if len(optimization_result["history"]) > 1:
        improvement = (optimization_result["history"][-1]["accuracy"] 
                      - optimization_result["history"][0]["accuracy"])
        mlflow.log_metric("total_improvement", improvement)
    
    # Log Prompt template ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
    mlflow.log_param("final_prompt_template", optimization_result["final_template"][:250])
    mlflow.log_param("prompt_name", PROMPT_NAME)
    mlflow.log_param("model_name", MODEL_NAME)
    mlflow.log_param("test_data_size", len(TEST_DATA))
    
    print("‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏•‡∏á MLflow ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢!")
    print(f"   Experiment: prompt_optimization_lab")
    print(f"   ‡∏î‡∏π‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà: {MLFLOW_TRACKING_URI}")

# %% [markdown]
# ## 5.3 ‡∏î‡∏π Prompt ‡∏ó‡∏∏‡∏Å Version ‡πÉ‡∏ô Registry

# %%
# === Lab 5.3: ‡πÅ‡∏™‡∏î‡∏á Prompt ‡∏ó‡∏∏‡∏Å Version ===

print(f"üìã Prompt Versions ‡πÉ‡∏ô Registry: '{PROMPT_NAME}'\n")

version = 1
while True:
    try:
        p = mlflow.genai.load_prompt(f"prompts:/{PROMPT_NAME}/{version}")
        print(f"{'='*60}")
        print(f"üìå Version {version}")
        print(f"{'‚îÄ'*60}")
        print(p.template[:200] + ("..." if len(p.template) > 200 else ""))
        print()
        version += 1
    except Exception:
        break

print(f"‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {version - 1} versions")

# %% [markdown]
# ---
# # üéØ ‡∏™‡∏£‡∏∏‡∏õ Lab
#
# ## ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ:
# 1. **MLflow Prompt Registry** ‚Äî ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Prompt ‡πÅ‡∏ö‡∏ö‡∏°‡∏µ Version Control
#    - `mlflow.genai.register_prompt()` ‚Üí ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Prompt ‡∏û‡∏£‡πâ‡∏≠‡∏° commit message
#    - `mlflow.genai.load_prompt()` ‚Üí ‡πÇ‡∏´‡∏•‡∏î Prompt ‡∏ï‡∏≤‡∏° version
#    - `.format()` ‚Üí ‡πÅ‡∏ó‡∏ô‡∏Ñ‡πà‡∏≤‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÉ‡∏ô template
#
# 2. **Prompt Evaluation** ‚Äî ‡∏ß‡∏±‡∏î‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö
#    - ‡∏™‡∏£‡πâ‡∏≤‡∏á Test Dataset ‡∏û‡∏£‡πâ‡∏≠‡∏° Ground Truth
#    - ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Accuracy ‡πÅ‡∏¢‡∏Å‡∏£‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠
#
# 3. **Reflection Pattern** ‚Äî ‡πÉ‡∏ä‡πâ LLM ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á
#    - Generate ‚Üí Reflect ‚Üí Improve
#    - ‡∏ô‡∏≥‡∏ú‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏à‡∏£‡∏¥‡∏á‡∏°‡∏≤‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏∏‡∏î‡∏≠‡πà‡∏≠‡∏ô
#
# 4. **Optimization Loop** ‚Äî ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
#    - Test ‚Üí Reflect ‚Üí Optimize ‚Üí Register ‚Üí Test ‚Üí ...
#    - ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏ú‡∏•‡∏ú‡πà‡∏≤‡∏ô MLflow Tracking
#
# ## ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°:
# - ‡∏•‡∏≠‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡∏¢‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô (‡πÄ‡∏ä‡πà‡∏ô ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏™‡∏µ, ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏≥‡∏Å‡∏ß‡∏°)
# - ‡∏õ‡∏£‡∏±‡∏ö `temperature` ‡πÉ‡∏ô Reflection ‡πÉ‡∏´‡πâ‡∏™‡∏π‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ Prompt ‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢
# - ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• Gemini ‡∏ï‡πà‡∏≤‡∏á‡πÜ (‡πÄ‡∏ä‡πà‡∏ô flash vs pro)
