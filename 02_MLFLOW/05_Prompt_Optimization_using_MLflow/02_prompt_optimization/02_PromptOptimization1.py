# %% [markdown]
# # üöÄ LAB: Prompt Optimization using MLflow with Google Gemini
#
# **‡∏ß‡∏¥‡∏ä‡∏≤:** Machine Learning Operations (MLOps)  
# **‡πÄ‡∏ß‡∏•‡∏≤:** 2-3 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á  
# **‡∏£‡∏∞‡∏î‡∏±‡∏ö:** Intermediate
#
# ---
#
# ## **‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏Ç‡∏≠‡∏á Lab (Overview)**
#
# ‡πÉ‡∏ô Lab ‡∏ô‡∏µ‡πâ ‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏à‡∏∞‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ **‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á Prompt (Prompt Optimization)** ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö
# ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ **MLflow** ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° (Track) ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å Prompt ‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á **Google Gemini API**
#
# ### üéØ ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á Track Prompt?
#
# ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö LLM (Large Language Model) ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô Prompt ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
# ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏≤‡∏Å ‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° Prompt ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ:
#
# 1. **‡∏ó‡∏≥‡∏ã‡πâ‡∏≥‡πÑ‡∏î‡πâ (Reproducible)** - ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡πÉ‡∏ä‡πâ Prompt ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÑ‡∏î‡πâ
# 2. **‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÑ‡∏î‡πâ (Comparable)** - ‡πÄ‡∏´‡πá‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å Prompt ‡∏ï‡πà‡∏≤‡∏á‡πÜ
# 3. **‡∏ß‡∏±‡∏î‡∏ú‡∏•‡πÑ‡∏î‡πâ (Measurable)** - ‡∏°‡∏µ Metrics ‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û
# 4. **‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡∏°‡πÑ‡∏î‡πâ (Collaborative)** - ‡πÅ‡∏ä‡∏£‡πå‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡∏°‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢
#
# ---

# %% [markdown]
# ## **‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ (Learning Objectives)**
#
# ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ô‡∏µ‡πâ ‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ:
#
# ### ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à (Remember & Understand)
# 1. **‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢** ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á Google Gemini API ‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÑ‡∏î‡πâ
# 2. **‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢** ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á Prompt Engineering ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á Prompt ‡πÑ‡∏î‡πâ
# 3. **‡∏£‡∏∞‡∏ö‡∏∏** ‡∏≠‡∏á‡∏Ñ‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á Prompt ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ
#
# ### ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ (Apply)
# 4. **‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô** Prompt ‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏£‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡πÑ‡∏õ‡∏¢‡∏±‡∏á Gemini API ‡πÑ‡∏î‡πâ
# 5. **‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô** MLflow ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å (log) ‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° (track) ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á Prompt ‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÑ‡∏î‡πâ
# 6. **‡∏Å‡∏≥‡∏´‡∏ô‡∏î** Parameters ‡πÅ‡∏•‡∏∞ Metrics ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô Prompt ‡πÑ‡∏î‡πâ
#
# ### ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏• (Analyze & Evaluate)
# 7. **‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö** ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å Prompt ‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏ú‡πà‡∏≤‡∏ô MLflow UI ‡πÑ‡∏î‡πâ
# 8. **‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå** Metrics ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á Prompt ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÅ‡∏ö‡∏ö‡πÑ‡∏î‡πâ
# 9. **‡πÄ‡∏•‡∏∑‡∏≠‡∏Å** Prompt ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏õ‡∏£‡∏∞‡∏à‡∏±‡∏Å‡∏©‡πå‡πÑ‡∏î‡πâ
#
# ---

# %% [markdown]
# ## **‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏ó‡∏§‡∏©‡∏é‡∏µ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô (Theoretical Foundation)**
#
# ### 1.1 Prompt Engineering ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?
#
# **Prompt Engineering** ‡∏Ñ‡∏∑‡∏≠‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡πÅ‡∏•‡∏∞‡∏®‡∏¥‡∏•‡∏õ‡πå‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á (Prompt) 
# ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏≤‡∏Å Large Language Model (LLM)
#
# ```
# ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
# ‚îÇ                    Prompt Engineering Flow                  ‚îÇ
# ‚îÇ                                                             ‚îÇ
# ‚îÇ   [Input Prompt] ‚îÄ‚îÄ‚ñ∫ [LLM Processing] ‚îÄ‚îÄ‚ñ∫ [Output Response] ‚îÇ
# ‚îÇ        ‚îÇ                    ‚îÇ                    ‚îÇ          ‚îÇ
# ‚îÇ        ‚ñº                    ‚ñº                    ‚ñº          ‚îÇ
# ‚îÇ   "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå..."     Model Inference      "‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå..." ‚îÇ
# ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
# ```
#
# ### 1.2 ‡∏≠‡∏á‡∏Ñ‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á Prompt ‡∏ó‡∏µ‡πà‡∏î‡∏µ
#
# | ‡∏≠‡∏á‡∏Ñ‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á |
# |-----------|---------|---------|
# | **Context** | ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á | "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô..." |
# | **Instruction** | ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô | "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ..." |
# | **Input Data** | ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• | "‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ Q1: 1M, Q2: 1.2M..." |
# | **Output Format** | ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ | "‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö JSON..." |
# | **Constraints** | ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç | "‡∏ï‡∏≠‡∏ö‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 100 ‡∏Ñ‡∏≥..." |
#
# ### 1.3 MLflow ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Prompt Tracking
#
# **MLflow** ‡πÄ‡∏õ‡πá‡∏ô Platform ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Machine Learning Lifecycle
# ‡∏ã‡∏∂‡πà‡∏á‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ô‡∏≥‡∏°‡∏≤‡πÉ‡∏ä‡πâ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° Prompt Experiments ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û:
#
# ```
# ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
# ‚îÇ                     MLflow Components                       ‚îÇ
# ‚îÇ                                                             ‚îÇ
# ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
# ‚îÇ  ‚îÇ   Tracking   ‚îÇ  ‚îÇ   Projects   ‚îÇ  ‚îÇ    Models    ‚îÇ      ‚îÇ
# ‚îÇ  ‚îÇ  (Logging)   ‚îÇ  ‚îÇ (Packaging)  ‚îÇ  ‚îÇ  (Registry)  ‚îÇ      ‚îÇ
# ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
# ‚îÇ         ‚îÇ                                                   ‚îÇ
# ‚îÇ         ‚ñº                                                   ‚îÇ
# ‚îÇ  ‚Ä¢ Parameters (prompt_template, temperature)                ‚îÇ
# ‚îÇ  ‚Ä¢ Metrics (response_time, token_count, quality_score)      ‚îÇ
# ‚îÇ  ‚Ä¢ Artifacts (prompts.txt, responses.json)                  ‚îÇ
# ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
# ```
#
# ---

# %% [markdown]
# ## **‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏° (Setup)**
#
# ### 2.1 ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Library ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
#
# **‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:** ‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ `google-genai` ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô package ‡πÉ‡∏´‡∏°‡πà‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
# ‡πÅ‡∏ó‡∏ô `google-generativeai` ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å deprecated ‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß

# %%
# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Libraries ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
# ‡∏£‡∏±‡∏ô‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÅ‡∏•‡πâ‡∏ß Restart Kernel

# !pip install mlflow google-genai python-dotenv

# %% [markdown]
# ### 2.2 Import Libraries

# %%
# Import Libraries ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
import mlflow
from google import genai
from google.genai import types
import time
import json
import os
from datetime import datetime
from typing import Dict, Any, List, Optional

# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
import re

print("‚úÖ Import Libraries ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
print(f"üì¶ MLflow Version: {mlflow.__version__}")

# %% [markdown]
# ### 2.3 Configuration Setup
#
# **‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:** ‡∏Å‡πà‡∏≠‡∏ô‡∏£‡∏±‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API Key ‡∏Ç‡∏≠‡∏á Google Gemini
#
# ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠ API Key:
# 1. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà https://aistudio.google.com/app/apikey
# 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á API Key ‡πÉ‡∏´‡∏°‡πà
# 3. ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å API Key ‡∏°‡∏≤‡πÉ‡∏™‡πà‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ `GOOGLE_API_KEY`

# %%
# ===========================================
# ‚öôÔ∏è CONFIGURATION - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡πà‡∏≤‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
# ===========================================

# Google Gemini API Key
# ‚ö†Ô∏è ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÄ‡∏õ‡πá‡∏ô API Key ‡∏Ç‡∏≠‡∏á‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÄ‡∏≠‡∏á
GOOGLE_API_KEY = "YOUR_API_KEY_HERE"

# MLflow Configuration
MLFLOW_TRACKING_URI = "http://localhost:5000"
EXPERIMENT_NAME = "prompt-optimization-lab"

# Model Configuration
MODEL_NAME = "gemini-2.0-flash"

print("‚úÖ Configuration ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")

# %% [markdown]
# ### 2.4 Initialize Services
#
# ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Google Gemini API ‡πÅ‡∏•‡∏∞ MLflow Server
#
# **‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô google-genai package ‡πÉ‡∏´‡∏°‡πà:**
# - ‡πÉ‡∏ä‡πâ `genai.Client()` ‡πÅ‡∏ó‡∏ô `genai.configure()`
# - API ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô object-oriented ‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô

# %%
# ‡∏™‡∏£‡πâ‡∏≤‡∏á Gemini Client (‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏´‡∏°‡πà)
client = genai.Client(api_key=GOOGLE_API_KEY)

# ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ MLflow Server
mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Experiment
mlflow.set_experiment(EXPERIMENT_NAME)

# ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Experiment
experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)
print(f"‚úÖ MLflow Experiment: {experiment.name}")
print(f"üìÅ Experiment ID: {experiment.experiment_id}")
print(f"üîó MLflow UI: {MLFLOW_TRACKING_URI}")

# %% [markdown]
# ### 2.5 ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Gemini API

# %%
# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Gemini API (‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏´‡∏°‡πà)
test_response = client.models.generate_content(
    model=MODEL_NAME,
    contents="‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ ‡∏ö‡∏≠‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏´‡∏ô‡πà‡∏≠‡∏¢"
)

print("‚úÖ ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Gemini API ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
print(f"üìù Response: {test_response.text[:200]}...")

# %% [markdown]
# ---
# ## **‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 3: Helper Functions ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á**
#
# ### 3.1 ‡∏ó‡∏§‡∏©‡∏é‡∏µ: Metrics ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô Prompt
#
# ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á Prompt ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ß‡∏±‡∏î‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ Metrics:
#
# | Metric | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ | ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì |
# |--------|---------|---------|
# | **Response Time** | ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö | end_time - start_time |
# | **Token Count** | ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Token ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ | len(response.text.split()) * 1.3 (‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì) |
# | **Response Length** | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö | len(response.text) |
# | **Completeness** | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô | ‡∏°‡∏µ element ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà |
# | **Format Compliance** | ‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏° Format ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà | JSON valid? ‡∏°‡∏µ header? |

# %%
def call_gemini_with_tracking(
    prompt: str,
    gemini_client: genai.Client,
    model_name: str = MODEL_NAME,
    temperature: float = 0.7,
    max_output_tokens: int = 1024
) -> Dict[str, Any]:
    """
    ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ Gemini API ‡πÅ‡∏•‡∏∞‡πÄ‡∏Å‡πá‡∏ö Metrics ‡∏ï‡πà‡∏≤‡∏á‡πÜ
    
    Parameters:
    -----------
    prompt : str
        Prompt ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á
    gemini_client : genai.Client
        Client instance ‡∏Ç‡∏≠‡∏á Gemini
    model_name : str
        ‡∏ä‡∏∑‡πà‡∏≠ Model ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ
    temperature : float
        ‡∏Ñ‡πà‡∏≤ Temperature (0.0 - 1.0)
    max_output_tokens : int
        ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Token ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á Output
    
    Returns:
    --------
    dict : ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏û‡∏£‡πâ‡∏≠‡∏° Metrics
    """
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Generation Config
    config = types.GenerateContentConfig(
        temperature=temperature,
        max_output_tokens=max_output_tokens
    )
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
    start_time = time.time()
    
    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API (‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏´‡∏°‡πà)
    response = gemini_client.models.generate_content(
        model=model_name,
        contents=prompt,
        config=config
    )
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î
    end_time = time.time()
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Metrics
    response_time = end_time - start_time
    response_text = response.text
    response_length = len(response_text)
    word_count = len(response_text.split())
    estimated_tokens = int(word_count * 1.3)  # ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏Å‡∏≤‡∏£
    
    return {
        "response_text": response_text,
        "response_time": round(response_time, 3),
        "response_length": response_length,
        "word_count": word_count,
        "estimated_tokens": estimated_tokens,
        "timestamp": datetime.now().isoformat()
    }

print("‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á Function call_gemini_with_tracking ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")

# %%
def calculate_quality_metrics(
    response_text: str,
    expected_elements: List[str] = None,
    expected_format: str = None
) -> Dict[str, float]:
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Quality Metrics ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Response
    
    Parameters:
    -----------
    response_text : str
        ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏à‡∏≤‡∏Å Model
    expected_elements : list, optional
        ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Keywords ‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏°‡∏µ‡πÉ‡∏ô Response
    expected_format : str, optional
        ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á ('json', 'markdown', 'bullet_points')
    
    Returns:
    --------
    dict : Quality Metrics
    """
    metrics = {}
    
    # 1. Element Coverage Score (0-1)
    if expected_elements:
        found_count = sum(
            1 for elem in expected_elements 
            if elem.lower() in response_text.lower()
        )
        metrics["element_coverage"] = round(
            found_count / len(expected_elements), 2
        )
    
    # 2. Format Compliance Score (0-1)
    if expected_format:
        if expected_format == "json":
            try:
                json.loads(response_text)
                metrics["format_compliance"] = 1.0
            except:
                # ‡∏•‡∏≠‡∏á‡∏´‡∏≤ JSON ‡πÉ‡∏ô response
                json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
                if json_match:
                    try:
                        json.loads(json_match.group())
                        metrics["format_compliance"] = 0.8
                    except:
                        metrics["format_compliance"] = 0.0
                else:
                    metrics["format_compliance"] = 0.0
                    
        elif expected_format == "markdown":
            has_headers = bool(re.search(r'^#+\s', response_text, re.MULTILINE))
            has_formatting = any(x in response_text for x in ['**', '*', '`', '```'])
            metrics["format_compliance"] = (has_headers * 0.5) + (has_formatting * 0.5)
            
        elif expected_format == "bullet_points":
            bullet_count = len(re.findall(r'^[\-\*\‚Ä¢]\s', response_text, re.MULTILINE))
            metrics["format_compliance"] = min(1.0, bullet_count / 5)  # ‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á 5+ bullets
    
    # 3. Readability Score (based on sentence structure)
    sentences = re.split(r'[.!?]', response_text)
    sentences = [s.strip() for s in sentences if s.strip()]
    if sentences:
        avg_sentence_length = sum(len(s.split()) for s in sentences) / len(sentences)
        # Optimal: 15-20 words per sentence
        if 10 <= avg_sentence_length <= 25:
            metrics["readability_score"] = 1.0
        elif 5 <= avg_sentence_length <= 35:
            metrics["readability_score"] = 0.7
        else:
            metrics["readability_score"] = 0.4
    
    return metrics

print("‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á Function calculate_quality_metrics ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")

# %% [markdown]
# ---
# ## **‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 4: ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏ó‡∏µ‡πà 1 - Basic Prompt Comparison**
#
# ### 4.1 ‡∏ó‡∏§‡∏©‡∏é‡∏µ: Zero-shot vs Few-shot Prompting
#
# ```
# ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
# ‚îÇ                    Prompting Strategies                        ‚îÇ
# ‚îÇ                                                                ‚îÇ
# ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
# ‚îÇ  ‚îÇ   Zero-shot     ‚îÇ  ‚îÇ    One-shot     ‚îÇ  ‚îÇ    Few-shot     ‚îÇ‚îÇ
# ‚îÇ  ‚îÇ  (‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á) ‚îÇ  ‚îÇ (1 ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á)    ‚îÇ  ‚îÇ (‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á) ‚îÇ‚îÇ
# ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
# ‚îÇ         ‚îÇ                     ‚îÇ                     ‚îÇ          ‚îÇ
# ‚îÇ         ‚ñº                     ‚ñº                     ‚ñº          ‚îÇ
# ‚îÇ   "‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà:       "‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:            "‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 1:...   ‚îÇ
# ‚îÇ    ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏µ‡πâ"        '‡∏î‡∏µ‡∏°‡∏≤‡∏Å' ‚Üí ‡∏ö‡∏ß‡∏Å          ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 2:...   ‚îÇ
# ‚îÇ                       ‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà:..."        ‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà:..."  ‚îÇ
# ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
# ```
#
# **‡∏Ç‡πâ‡∏≠‡∏î‡∏µ-‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢:**
#
# | Strategy | ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ | ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢ |
# |----------|------|--------|
# | Zero-shot | ‡∏á‡πà‡∏≤‡∏¢, ‡πÄ‡∏£‡πá‡∏ß, ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î Token | ‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à Task |
# | Few-shot | ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Å‡∏ß‡πà‡∏≤, ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à Context | ‡πÉ‡∏ä‡πâ Token ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ |

# %% [markdown]
# ### 4.2 ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Task: Sentiment Analysis
#
# ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å (Sentiment Analysis)

# %%
# ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Sentiment Analysis
test_reviews = [
    "‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏î‡∏µ‡∏°‡∏≤‡∏Å ‡∏™‡πà‡∏á‡πÄ‡∏£‡πá‡∏ß ‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡πÉ‡∏à‡∏Ñ‡∏£‡∏±‡∏ö ‡∏à‡∏∞‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡∏ã‡∏∑‡πâ‡∏≠‡∏≠‡∏µ‡∏Å",
    "‡πÅ‡∏¢‡πà‡∏°‡∏≤‡∏Å ‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏õ‡∏Å ‡∏£‡∏≠‡∏ô‡∏≤‡∏ô‡∏°‡∏≤‡∏Å ‡πÑ‡∏°‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥",
    "‡∏û‡∏≠‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ñ‡∏π‡∏Å ‡πÅ‡∏ï‡πà‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Å‡πá‡∏á‡∏±‡πâ‡∏ô‡πÜ",
    "‡∏ä‡∏≠‡∏ö‡∏°‡∏≤‡∏Å‡∏Ñ‡πà‡∏∞ ‡∏™‡∏µ‡∏™‡∏ß‡∏¢ ‡πÉ‡∏™‡πà‡∏™‡∏ö‡∏≤‡∏¢ ‡∏Ñ‡∏∏‡πâ‡∏°‡∏£‡∏≤‡∏Ñ‡∏≤",
    "‡∏ú‡∏¥‡∏î‡∏´‡∏ß‡∏±‡∏á‡∏°‡∏≤‡∏Å ‡∏™‡∏±‡πà‡∏á‡πÑ‡∏ã‡∏™‡πå L ‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô M ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏£‡πâ‡∏≤‡∏ô‡∏Å‡πá‡πÑ‡∏°‡πà‡∏ï‡∏≠‡∏ö"
]

# Expected Labels ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô
expected_sentiments = ["positive", "negative", "neutral", "positive", "negative"]

print("üìã ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö:")
for i, review in enumerate(test_reviews):
    print(f"  {i+1}. {review[:50]}... ‚Üí {expected_sentiments[i]}")

# %% [markdown]
# ### 4.3 Prompt Variations
#
# ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á 3 ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Prompt ‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô:

# %%
# Prompt 1: Zero-shot Simple
prompt_zero_shot = """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:

‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: "{text}"

‡∏ï‡∏≠‡∏ö‡πÄ‡∏û‡∏µ‡∏¢‡∏á: positive, negative, ‡∏´‡∏£‡∏∑‡∏≠ neutral"""

# Prompt 2: Zero-shot with Context
prompt_zero_shot_context = """‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤

‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏Ç‡∏≠‡∏á‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:
- positive: ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏≠‡πÉ‡∏à ‡∏ä‡∏∑‡πà‡∏ô‡∏ä‡∏° ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
- negative: ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏°‡πà‡∏û‡∏≠‡πÉ‡∏à ‡∏ï‡∏≥‡∏´‡∏ô‡∏¥ ‡πÑ‡∏°‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥  
- neutral: ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á‡∏ö‡∏ß‡∏Å‡πÅ‡∏•‡∏∞‡∏•‡∏ö

‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: "{text}"

‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡πÄ‡∏î‡∏µ‡∏¢‡∏ß: positive, negative, ‡∏´‡∏£‡∏∑‡∏≠ neutral"""

# Prompt 3: Few-shot with Examples
prompt_few_shot = """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏à‡∏≤‡∏Å‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:
1. "‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏™‡∏ß‡∏¢‡∏°‡∏≤‡∏Å ‡∏ä‡∏≠‡∏ö‡πÄ‡∏•‡∏¢" ‚Üí positive
2. "‡∏´‡πà‡∏ß‡∏¢‡πÅ‡∏ï‡∏Å ‡πÑ‡∏°‡πà‡∏ã‡∏∑‡πâ‡∏≠‡∏≠‡∏µ‡∏Å‡πÅ‡∏•‡πâ‡∏ß" ‚Üí negative
3. "‡∏Å‡πá‡πÇ‡∏≠‡πÄ‡∏Ñ‡∏ô‡∏∞ ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÅ‡∏¢‡πà‡πÅ‡∏ï‡πà‡∏Å‡πá‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏°‡∏≤‡∏Å" ‚Üí neutral

‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: "{text}"

‡∏ï‡∏≠‡∏ö:"""

# ‡πÄ‡∏Å‡πá‡∏ö Prompts ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô Dictionary
prompt_variations = {
    "zero_shot_simple": prompt_zero_shot,
    "zero_shot_context": prompt_zero_shot_context,
    "few_shot": prompt_few_shot
}

print("üìù ‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt Variations ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
for name in prompt_variations.keys():
    print(f"  ‚Ä¢ {name}")

# %% [markdown]
# ### 4.4 ‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏î‡πâ‡∏ß‡∏¢ MLflow

# %%
def run_sentiment_experiment(
    prompt_name: str,
    prompt_template: str,
    test_texts: List[str],
    expected_labels: List[str],
    gemini_client: genai.Client,
    model_name: str = MODEL_NAME,
    temperature: float = 0.3
) -> Dict[str, Any]:
    """
    ‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á Sentiment Analysis ‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢ MLflow
    """
    
    # ‡πÄ‡∏£‡∏¥‡πà‡∏° MLflow Run
    with mlflow.start_run(run_name=f"sentiment_{prompt_name}"):
        
        # Log Parameters
        mlflow.log_param("prompt_name", prompt_name)
        mlflow.log_param("prompt_template", prompt_template[:500])  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß
        mlflow.log_param("temperature", temperature)
        mlflow.log_param("model", model_name)
        mlflow.log_param("num_samples", len(test_texts))
        
        # ‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        results = []
        total_time = 0
        correct_count = 0
        
        print(f"\nüîÑ Running: {prompt_name}")
        print("-" * 50)
        
        for i, (text, expected) in enumerate(zip(test_texts, expected_labels)):
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt
            full_prompt = prompt_template.format(text=text)
            
            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API
            response_data = call_gemini_with_tracking(
                full_prompt,
                gemini_client,
                model_name=model_name,
                temperature=temperature,
                max_output_tokens=50
            )
            
            # ‡∏î‡∏∂‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            predicted = response_data["response_text"].strip().lower()
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
            is_correct = expected.lower() in predicted
            if is_correct:
                correct_count += 1
            
            # ‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            results.append({
                "input": text[:50] + "...",
                "expected": expected,
                "predicted": predicted[:20],
                "correct": is_correct,
                "response_time": response_data["response_time"]
            })
            
            total_time += response_data["response_time"]
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
            status = "‚úÖ" if is_correct else "‚ùå"
            print(f"  {i+1}. {status} Expected: {expected}, Got: {predicted[:15]}")
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Metrics ‡∏£‡∏ß‡∏°
        accuracy = correct_count / len(test_texts)
        avg_response_time = total_time / len(test_texts)
        
        # Log Metrics
        mlflow.log_metric("accuracy", round(accuracy, 3))
        mlflow.log_metric("avg_response_time", round(avg_response_time, 3))
        mlflow.log_metric("total_time", round(total_time, 3))
        mlflow.log_metric("correct_count", correct_count)
        
        # Log Artifacts (‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå)
        results_filename = f"results_{prompt_name}.json"
        with open(results_filename, "w", encoding="utf-8") as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        mlflow.log_artifact(results_filename)
        os.remove(results_filename)  # ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå temp
        
        print("-" * 50)
        print(f"üìä Results: Accuracy = {accuracy:.1%}, Avg Time = {avg_response_time:.2f}s")
        
        return {
            "prompt_name": prompt_name,
            "accuracy": accuracy,
            "avg_response_time": avg_response_time,
            "results": results
        }

print("‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á Function run_sentiment_experiment ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")

# %% [markdown]
# ### 4.5 ‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î

# %%
# ‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å Prompt Variation
experiment_results = []

for prompt_name, prompt_template in prompt_variations.items():
    result = run_sentiment_experiment(
        prompt_name=prompt_name,
        prompt_template=prompt_template,
        test_texts=test_reviews,
        expected_labels=expected_sentiments,
        gemini_client=client,
        model_name=MODEL_NAME,
        temperature=0.3
    )
    experiment_results.append(result)
    
    # ‡∏´‡∏¢‡∏∏‡∏î‡∏û‡∏±‡∏Å‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å Rate Limit
    time.sleep(1)

print("\n" + "=" * 50)
print("üèÜ ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á:")
print("=" * 50)

# %% [markdown]
# ### 4.6 ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå

# %%
# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö
print("\nüìä Comparison Table:")
print("-" * 60)
print(f"{'Prompt Name':<25} {'Accuracy':<12} {'Avg Time (s)':<12}")
print("-" * 60)

best_accuracy = 0
best_prompt = ""

for result in experiment_results:
    accuracy_pct = f"{result['accuracy']:.1%}"
    print(f"{result['prompt_name']:<25} {accuracy_pct:<12} {result['avg_response_time']:<12.3f}")
    
    if result['accuracy'] > best_accuracy:
        best_accuracy = result['accuracy']
        best_prompt = result['prompt_name']

print("-" * 60)
print(f"\nü•á Best Prompt: {best_prompt} (Accuracy: {best_accuracy:.1%})")

# %% [markdown]
# ### üîç ‡πÑ‡∏õ‡∏î‡∏π‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏ô MLflow UI
#
# ‡πÄ‡∏õ‡∏¥‡∏î Browser ‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏õ‡∏ó‡∏µ‡πà: **http://localhost:5000**
#
# 1. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Experiment: `prompt-optimization-lab`
# 2. ‡∏î‡∏π Runs ‡∏ó‡∏±‡πâ‡∏á 3 ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Metrics
# 3. ‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° "Compare" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÅ‡∏ö‡∏ö side-by-side
#
# ---

# %% [markdown]
# ## **‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 5: ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏ó‡∏µ‡πà 2 - Temperature Optimization**
#
# ### 5.1 ‡∏ó‡∏§‡∏©‡∏é‡∏µ: Temperature Parameter
#
# **Temperature** ‡∏Ñ‡∏∑‡∏≠ Parameter ‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏Ñ‡∏ß‡∏≤‡∏° "‡∏™‡∏∏‡πà‡∏°" ‡∏Ç‡∏≠‡∏á Output:
#
# ```
# ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
# ‚îÇ                  Temperature Effect                         ‚îÇ
# ‚îÇ                                                             ‚îÇ
# ‚îÇ   Temperature = 0.0          Temperature = 1.0              ‚îÇ
# ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
# ‚îÇ   ‚îÇ  Deterministic  ‚îÇ        ‚îÇ    Creative     ‚îÇ           ‚îÇ
# ‚îÇ   ‚îÇ   Consistent    ‚îÇ   ‚îÄ‚îÄ‚ñ∫  ‚îÇ    Diverse      ‚îÇ           ‚îÇ
# ‚îÇ   ‚îÇ   Predictable   ‚îÇ        ‚îÇ   Unpredictable ‚îÇ           ‚îÇ
# ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
# ‚îÇ                                                             ‚îÇ
# ‚îÇ   Use cases:                 Use cases:                     ‚îÇ
# ‚îÇ   ‚Ä¢ Classification          ‚Ä¢ Creative writing              ‚îÇ
# ‚îÇ   ‚Ä¢ Extraction              ‚Ä¢ Brainstorming                 ‚îÇ
# ‚îÇ   ‚Ä¢ Summarization           ‚Ä¢ Story generation              ‚îÇ
# ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
# ```
#
# | Temperature | ‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞ Output | ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô |
# |-------------|--------------|------------|
# | 0.0 - 0.3 | ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ ‡∏Ñ‡∏á‡∏ó‡∏µ‡πà | Classification, Extraction |
# | 0.4 - 0.7 | ‡∏™‡∏°‡∏î‡∏∏‡∏• | General Q&A, Summarization |
# | 0.8 - 1.0 | ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå ‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ | Creative Writing |

# %%
# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Task: Creative Text Generation
creative_prompt = """‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ü‡∏©‡∏ì‡∏≤‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡πÅ‡∏ü‡∏ä‡∏∑‡πà‡∏≠ "Morning Brew"
- ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß 2-3 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ
- ‡πÄ‡∏ô‡πâ‡∏ô‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏Å‡∏≤‡∏®‡∏≠‡∏ö‡∏≠‡∏∏‡πà‡∏ô ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡πÅ‡∏ü‡∏£‡∏™‡πÄ‡∏Ç‡πâ‡∏°
- ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏î‡∏π‡∏î‡πÉ‡∏à‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤"""

# Temperature values ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö
temperatures = [0.1, 0.5, 0.7, 0.9]

print("üéØ Task: Creative Text Generation")
print(f"üìù Prompt: {creative_prompt[:100]}...")

# %% [markdown]
# ### 5.2 ‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á Temperature

# %%
def run_temperature_experiment(
    prompt: str,
    temperatures: List[float],
    gemini_client: genai.Client,
    model_name: str = MODEL_NAME,
    runs_per_temp: int = 3
) -> List[Dict]:
    """
    ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏Ç‡∏≠‡∏á Temperature ‡∏ï‡πà‡∏≠ Output
    """
    all_results = []
    
    for temp in temperatures:
        print(f"\nüå°Ô∏è Testing Temperature = {temp}")
        print("-" * 50)
        
        with mlflow.start_run(run_name=f"temp_{temp}"):
            
            # Log Parameters
            mlflow.log_param("temperature", temp)
            mlflow.log_param("prompt", prompt[:300])
            mlflow.log_param("runs_per_temp", runs_per_temp)
            
            responses = []
            total_time = 0
            
            for run_num in range(runs_per_temp):
                # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API
                response_data = call_gemini_with_tracking(
                    prompt,
                    gemini_client,
                    model_name=model_name,
                    temperature=temp,
                    max_output_tokens=200
                )
                
                responses.append(response_data["response_text"])
                total_time += response_data["response_time"]
                
                print(f"  Run {run_num + 1}: {response_data['response_text'][:80]}...")
                
                # ‡∏´‡∏¢‡∏∏‡∏î‡∏û‡∏±‡∏Å‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
                time.sleep(0.5)
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Diversity Score (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á Output)
            # ‡πÉ‡∏ä‡πâ Jaccard Similarity
            def jaccard_similarity(text1, text2):
                set1 = set(text1.lower().split())
                set2 = set(text2.lower().split())
                intersection = len(set1.intersection(set2))
                union = len(set1.union(set2))
                return intersection / union if union > 0 else 0
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
            similarities = []
            for i in range(len(responses)):
                for j in range(i + 1, len(responses)):
                    sim = jaccard_similarity(responses[i], responses[j])
                    similarities.append(sim)
            
            avg_similarity = sum(similarities) / len(similarities) if similarities else 1
            diversity_score = 1 - avg_similarity  # Diversity = 1 - Similarity
            
            # Log Metrics
            mlflow.log_metric("diversity_score", round(diversity_score, 3))
            mlflow.log_metric("avg_response_time", round(total_time / runs_per_temp, 3))
            mlflow.log_metric("avg_similarity", round(avg_similarity, 3))
            
            # ‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            result = {
                "temperature": temp,
                "diversity_score": round(diversity_score, 3),
                "avg_similarity": round(avg_similarity, 3),
                "responses": responses
            }
            all_results.append(result)
            
            print(f"  üìä Diversity Score: {diversity_score:.3f}")
    
    return all_results

# ‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á
temp_results = run_temperature_experiment(
    prompt=creative_prompt,
    temperatures=temperatures,
    gemini_client=client,
    model_name=MODEL_NAME,
    runs_per_temp=3
)

# %% [markdown]
# ### 5.3 ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á Temperature

# %%
print("\n" + "=" * 60)
print("üìä Temperature Experiment Results")
print("=" * 60)
print(f"{'Temperature':<15} {'Diversity Score':<18} {'Avg Similarity':<15}")
print("-" * 60)

for result in temp_results:
    print(f"{result['temperature']:<15} {result['diversity_score']:<18.3f} {result['avg_similarity']:<15.3f}")

print("-" * 60)
print("\nüí° Insights:")
print("  ‚Ä¢ Low Temperature (0.1-0.3): Output ‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥")
print("  ‚Ä¢ High Temperature (0.7-0.9): Output ‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå")

# %% [markdown]
# ---
# ## **‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 6: ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏ó‡∏µ‡πà 3 - System Prompt Optimization**
#
# ### 6.1 ‡∏ó‡∏§‡∏©‡∏é‡∏µ: Role-based Prompting
#
# ‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏´‡∏ô‡∏î Role ‡πÉ‡∏´‡πâ‡∏Å‡∏±‡∏ö LLM ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏™‡πÑ‡∏ï‡∏•‡πå‡πÅ‡∏•‡∏∞‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ:
#
# ```
# ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
# ‚îÇ                    Role-based Prompting                     ‚îÇ
# ‚îÇ                                                             ‚îÇ
# ‚îÇ   "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô..."                              ‚îÇ
# ‚îÇ                ‚îÇ                                            ‚îÇ
# ‚îÇ                ‚ñº                                            ‚îÇ
# ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
# ‚îÇ   ‚îÇ  ‚Ä¢ Expert Vocabulary                                 ‚îÇ  ‚îÇ
# ‚îÇ   ‚îÇ  ‚Ä¢ Domain-specific Knowledge                        ‚îÇ  ‚îÇ
# ‚îÇ   ‚îÇ  ‚Ä¢ Professional Tone                                ‚îÇ  ‚îÇ
# ‚îÇ   ‚îÇ  ‚Ä¢ Relevant Examples                                ‚îÇ  ‚îÇ
# ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
# ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
# ```

# %%
# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Task: Technical Explanation
task_question = "‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ß‡πà‡∏≤ Machine Learning ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£"

# System Prompts ‡∏ï‡πà‡∏≤‡∏á‡πÜ
system_prompts = {
    "no_role": {
        "description": "‡πÑ‡∏°‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î Role",
        "prompt": f"{task_question}\n\n‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡πÉ‡∏ô 3-4 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ"
    },
    "teacher": {
        "description": "‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏£‡∏π‡∏™‡∏≠‡∏ô‡πÄ‡∏î‡πá‡∏Å",
        "prompt": f"""‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏£‡∏π‡∏™‡∏≠‡∏ô‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏¢‡∏≤‡∏Å‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢
‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏î‡πá‡∏Å‡∏≠‡∏≤‡∏¢‡∏∏ 10 ‡∏Ç‡∏ß‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÑ‡∏î‡πâ

{task_question}

‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡πÉ‡∏ô 3-4 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ ‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏î‡πá‡∏Å‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÑ‡∏î‡πâ"""
    },
    "professor": {
        "description": "‡πÄ‡∏õ‡πá‡∏ô‡∏®‡∏≤‡∏™‡∏ï‡∏£‡∏≤‡∏à‡∏≤‡∏£‡∏¢‡πå",
        "prompt": f"""‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏®‡∏≤‡∏™‡∏ï‡∏£‡∏≤‡∏à‡∏≤‡∏£‡∏¢‡πå‡∏î‡πâ‡∏≤‡∏ô Computer Science ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô AI
‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏≤‡∏á‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥

{task_question}

‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡πÉ‡∏ô 3-4 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ ‡πÄ‡∏ô‡πâ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ"""
    },
    "entrepreneur": {
        "description": "‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡∏±‡∏Å‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à",
        "prompt": f"""‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô CEO ‡∏Ç‡∏≠‡∏á‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó Tech Startup ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
‡πÄ‡∏ô‡πâ‡∏ô‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á

{task_question}

‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡πÉ‡∏ô 3-4 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ ‡πÄ‡∏ô‡πâ‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏ó‡∏≤‡∏á‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à"""
    }
}

print("üé≠ System Prompts ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö:")
for name, config in system_prompts.items():
    print(f"  ‚Ä¢ {name}: {config['description']}")

# %% [markdown]
# ### 6.2 ‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á System Prompts

# %%
def run_system_prompt_experiment(
    system_prompts: Dict[str, Dict],
    gemini_client: genai.Client,
    model_name: str = MODEL_NAME,
    temperature: float = 0.5
) -> List[Dict]:
    """
    ‡∏ó‡∏î‡∏™‡∏≠‡∏ö System Prompts ‡∏ï‡πà‡∏≤‡∏á‡πÜ
    """
    results = []
    
    for role_name, config in system_prompts.items():
        print(f"\nüé≠ Testing Role: {role_name} - {config['description']}")
        print("-" * 50)
        
        with mlflow.start_run(run_name=f"role_{role_name}"):
            
            # Log Parameters
            mlflow.log_param("role_name", role_name)
            mlflow.log_param("role_description", config["description"])
            mlflow.log_param("prompt", config["prompt"][:300])
            mlflow.log_param("temperature", temperature)
            
            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API
            response_data = call_gemini_with_tracking(
                config["prompt"],
                gemini_client,
                model_name=model_name,
                temperature=temperature,
                max_output_tokens=300
            )
            
            response_text = response_data["response_text"]
            
            # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Response
            word_count = len(response_text.split())
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            technical_terms = ["algorithm", "data", "model", "training", "neural", 
                            "‡∏≠‡∏±‡∏•‡∏Å‡∏≠‡∏£‡∏¥‡∏ó‡∏∂‡∏°", "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", "‡πÇ‡∏°‡πÄ‡∏î‡∏•", "‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ", "‡∏ù‡∏∂‡∏Å"]
            technical_count = sum(1 for term in technical_terms 
                                if term.lower() in response_text.lower())
            
            # Log Metrics
            mlflow.log_metric("response_time", response_data["response_time"])
            mlflow.log_metric("word_count", word_count)
            mlflow.log_metric("technical_terms_count", technical_count)
            mlflow.log_metric("response_length", response_data["response_length"])
            
            # Log Response as Artifact
            response_filename = f"response_{role_name}.txt"
            with open(response_filename, "w", encoding="utf-8") as f:
                f.write(f"Role: {config['description']}\n")
                f.write(f"Prompt:\n{config['prompt']}\n\n")
                f.write(f"Response:\n{response_text}")
            mlflow.log_artifact(response_filename)
            os.remove(response_filename)
            
            print(f"üìù Response:\n{response_text}\n")
            print(f"üìä Word Count: {word_count}, Technical Terms: {technical_count}")
            
            results.append({
                "role_name": role_name,
                "description": config["description"],
                "response": response_text,
                "word_count": word_count,
                "technical_count": technical_count,
                "response_time": response_data["response_time"]
            })
        
        time.sleep(1)
    
    return results

# ‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á
role_results = run_system_prompt_experiment(
    system_prompts=system_prompts,
    gemini_client=client,
    model_name=MODEL_NAME,
    temperature=0.5
)

# %% [markdown]
# ### 6.3 ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á System Prompts

# %%
print("\n" + "=" * 70)
print("üìä System Prompt Experiment Results")
print("=" * 70)
print(f"{'Role':<15} {'Description':<20} {'Words':<10} {'Tech Terms':<12} {'Time(s)':<10}")
print("-" * 70)

for result in role_results:
    print(f"{result['role_name']:<15} {result['description']:<20} "
          f"{result['word_count']:<10} {result['technical_count']:<12} "
          f"{result['response_time']:<10.3f}")

print("-" * 70)
print("\nüí° Insights:")
print("  ‚Ä¢ Teacher Role: ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏á‡πà‡∏≤‡∏¢ ‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÑ‡∏î‡πâ")
print("  ‚Ä¢ Professor Role: ‡πÉ‡∏ä‡πâ‡∏®‡∏±‡∏û‡∏ó‡πå‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏ä‡∏¥‡∏á‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£")
print("  ‚Ä¢ Entrepreneur Role: ‡πÄ‡∏ô‡πâ‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á")

# %% [markdown]
# ---
# ## **‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 7: ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏ó‡∏µ‡πà 4 - Output Format Optimization**
#
# ### 7.1 ‡∏ó‡∏§‡∏©‡∏é‡∏µ: Output Format Control
#
# ‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Output ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ó‡∏±‡∏ô‡∏ó‡∏µ:
#
# ```
# ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
# ‚îÇ                   Output Format Types                       ‚îÇ
# ‚îÇ                                                             ‚îÇ
# ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
# ‚îÇ  ‚îÇ Plain   ‚îÇ  ‚îÇ  JSON   ‚îÇ  ‚îÇMarkdown ‚îÇ  ‚îÇ  Table  ‚îÇ        ‚îÇ
# ‚îÇ  ‚îÇ  Text   ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ         ‚îÇ        ‚îÇ
# ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
# ‚îÇ       ‚îÇ            ‚îÇ            ‚îÇ            ‚îÇ              ‚îÇ
# ‚îÇ       ‚ñº            ‚ñº            ‚ñº            ‚ñº              ‚îÇ
# ‚îÇ   "‡∏™‡∏£‡∏∏‡∏õ..."    {"title":    "# ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠    | Col1 | Col2 |  ‚îÇ
# ‚îÇ                "xxx"}      **bold**"    |------|------|   ‚îÇ
# ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
# ```

# %%
# Task: Product Analysis
product_info = """
‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤: iPhone 15 Pro Max
‡∏£‡∏≤‡∏Ñ‡∏≤: 48,900 ‡∏ö‡∏≤‡∏ó
‡∏à‡∏∏‡∏î‡πÄ‡∏î‡πà‡∏ô: ‡∏ä‡∏¥‡∏õ A17 Pro, ‡∏Å‡∏•‡πâ‡∏≠‡∏á 48MP, USB-C, Titanium Design
‡∏à‡∏∏‡∏î‡∏î‡πâ‡∏≠‡∏¢: ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏™‡∏π‡∏á, ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
"""

# Output Format Prompts
format_prompts = {
    "plain_text": {
        "description": "‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤",
        "prompt": f"""‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:
{product_info}

‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° 3-4 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ"""
    },
    
    "json_format": {
        "description": "JSON Format",
        "prompt": f"""‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:
{product_info}

‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON format ‡∏ï‡∏≤‡∏°‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ô‡∏µ‡πâ:
{{
  "product_name": "...",
  "price": "...",
  "pros": ["...", "..."],
  "cons": ["...", "..."],
  "recommendation": "...",
  "rating": 1-5
}}

‡∏ï‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞ JSON ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏∑‡πà‡∏ô"""
    },
    
    "markdown_format": {
        "description": "Markdown Format",
        "prompt": f"""‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:
{product_info}

‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏õ‡πá‡∏ô Markdown format ‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:
## [‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤]
**‡∏£‡∏≤‡∏Ñ‡∏≤:** ...
### ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ
- ...
### ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢
- ...
### ‡∏™‡∏£‡∏∏‡∏õ
..."""
    },
    
    "bullet_points": {
        "description": "Bullet Points",
        "prompt": f"""‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:
{product_info}

‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏õ‡πá‡∏ô bullet points:
‚Ä¢ ‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤: ...
‚Ä¢ ‡∏£‡∏≤‡∏Ñ‡∏≤: ...
‚Ä¢ ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ: ...
‚Ä¢ ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢: ...
‚Ä¢ ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: ..."""
    }
}

print("üìã Output Formats ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö:")
for name, config in format_prompts.items():
    print(f"  ‚Ä¢ {name}: {config['description']}")

# %% [markdown]
# ### 7.2 ‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á Output Format

# %%
def run_format_experiment(
    format_prompts: Dict[str, Dict],
    gemini_client: genai.Client,
    model_name: str = MODEL_NAME,
    temperature: float = 0.3
) -> List[Dict]:
    """
    ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Output Formats ‡∏ï‡πà‡∏≤‡∏á‡πÜ
    """
    results = []
    
    for format_name, config in format_prompts.items():
        print(f"\nüìÑ Testing Format: {format_name} - {config['description']}")
        print("-" * 50)
        
        with mlflow.start_run(run_name=f"format_{format_name}"):
            
            # Log Parameters
            mlflow.log_param("format_name", format_name)
            mlflow.log_param("format_description", config["description"])
            mlflow.log_param("temperature", temperature)
            
            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API
            response_data = call_gemini_with_tracking(
                config["prompt"],
                gemini_client,
                model_name=model_name,
                temperature=temperature,
                max_output_tokens=500
            )
            
            response_text = response_data["response_text"]
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Quality Metrics
            expected_format = format_name.replace("_format", "").replace("_points", "_points")
            if format_name == "json_format":
                expected_format = "json"
            elif format_name == "markdown_format":
                expected_format = "markdown"
            elif format_name == "bullet_points":
                expected_format = "bullet_points"
            else:
                expected_format = None
            
            quality_metrics = calculate_quality_metrics(
                response_text,
                expected_elements=["iPhone", "48,900", "A17", "‡∏Å‡∏•‡πâ‡∏≠‡∏á"],
                expected_format=expected_format
            )
            
            # Log Metrics
            mlflow.log_metric("response_time", response_data["response_time"])
            mlflow.log_metric("response_length", response_data["response_length"])
            
            for metric_name, metric_value in quality_metrics.items():
                mlflow.log_metric(metric_name, metric_value)
            
            print(f"üìù Response:\n{response_text[:300]}...\n")
            print(f"üìä Quality Metrics: {quality_metrics}")
            
            results.append({
                "format_name": format_name,
                "description": config["description"],
                "response": response_text,
                "response_time": response_data["response_time"],
                **quality_metrics
            })
        
        time.sleep(1)
    
    return results

# ‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á
format_results = run_format_experiment(
    format_prompts=format_prompts,
    gemini_client=client,
    model_name=MODEL_NAME,
    temperature=0.3
)

# %% [markdown]
# ### 7.3 ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á Output Format

# %%
print("\n" + "=" * 80)
print("üìä Output Format Experiment Results")
print("=" * 80)
print(f"{'Format':<18} {'Description':<18} {'Time(s)':<10} {'Coverage':<12} {'Format OK':<12}")
print("-" * 80)

for result in format_results:
    coverage = result.get('element_coverage', 'N/A')
    format_ok = result.get('format_compliance', 'N/A')
    
    if isinstance(coverage, float):
        coverage = f"{coverage:.2f}"
    if isinstance(format_ok, float):
        format_ok = f"{format_ok:.2f}"
    
    print(f"{result['format_name']:<18} {result['description']:<18} "
          f"{result['response_time']:<10.3f} {coverage:<12} {format_ok:<12}")

print("-" * 80)

# %% [markdown]
# ---
# ## **‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 8: ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏ó‡∏µ‡πà 5 - Chain-of-Thought Prompting**
#
# ### 8.1 ‡∏ó‡∏§‡∏©‡∏é‡∏µ: Chain-of-Thought (CoT)
#
# **Chain-of-Thought** ‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ Model ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏¥‡∏î‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:
#
# ```
# ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
# ‚îÇ              Chain-of-Thought Prompting                     ‚îÇ
# ‚îÇ                                                             ‚îÇ
# ‚îÇ   Direct Answer          vs    Chain-of-Thought             ‚îÇ
# ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
# ‚îÇ   ‚îÇ Q: 15+27=?    ‚îÇ           ‚îÇ Q: 15+27=?    ‚îÇ            ‚îÇ
# ‚îÇ   ‚îÇ               ‚îÇ           ‚îÇ               ‚îÇ            ‚îÇ
# ‚îÇ   ‚îÇ A: 42         ‚îÇ           ‚îÇ A: Let me     ‚îÇ            ‚îÇ
# ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ think step    ‚îÇ            ‚îÇ
# ‚îÇ                               ‚îÇ by step...    ‚îÇ            ‚îÇ
# ‚îÇ                               ‚îÇ 15+27         ‚îÇ            ‚îÇ
# ‚îÇ                               ‚îÇ = 15+20+7     ‚îÇ            ‚îÇ
# ‚îÇ                               ‚îÇ = 35+7        ‚îÇ            ‚îÇ
# ‚îÇ                               ‚îÇ = 42          ‚îÇ            ‚îÇ
# ‚îÇ                               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
# ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
# ```
#
# **‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏Ç‡∏≠‡∏á CoT:**
# - ‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì
# - ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö
# - ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô

# %%
# Task: Math Word Problem
math_problems = [
    {
        "question": "‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤‡∏Ç‡∏≤‡∏¢‡πÄ‡∏™‡∏∑‡πâ‡∏≠‡∏ú‡πâ‡∏≤‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ï‡∏±‡∏ß‡∏•‡∏∞ 250 ‡∏ö‡∏≤‡∏ó ‡∏ñ‡πâ‡∏≤‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ã‡∏∑‡πâ‡∏≠ 3 ‡∏ï‡∏±‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏õ‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏î 10% ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏Ñ‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠‡πÄ‡∏™‡∏∑‡πâ‡∏≠ 5 ‡∏ï‡∏±‡∏ß ‡∏ï‡πâ‡∏≠‡∏á‡∏à‡πà‡∏≤‡∏¢‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà?",
        "answer": 1125
    },
    {
        "question": "‡∏£‡∏ñ‡πÑ‡∏ü‡∏Ç‡∏ö‡∏ß‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ A ‡πÄ‡∏ß‡∏•‡∏≤ 9:00 ‡∏ô. ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß 60 ‡∏Å‡∏°./‡∏ä‡∏°. ‡∏≠‡∏µ‡∏Å 30 ‡∏ô‡∏≤‡∏ó‡∏µ‡∏ï‡πà‡∏≠‡∏°‡∏≤ ‡∏£‡∏ñ‡πÑ‡∏ü‡∏≠‡∏µ‡∏Å‡∏Ç‡∏ö‡∏ß‡∏ô‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ B ‡∏ã‡∏∂‡πà‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏´‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å A 150 ‡∏Å‡∏°. ‡∏°‡∏∏‡πà‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏°‡∏≤‡∏´‡∏≤‡∏Å‡∏±‡∏ô ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß 90 ‡∏Å‡∏°./‡∏ä‡∏°. ‡∏£‡∏ñ‡∏™‡∏≠‡∏á‡∏Ç‡∏ö‡∏ß‡∏ô‡∏à‡∏∞‡∏û‡∏ö‡∏Å‡∏±‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏î?",
        "answer": "10:00"
    },
    {
        "question": "‡∏°‡∏µ‡πÄ‡∏á‡∏¥‡∏ô 1,000 ‡∏ö‡∏≤‡∏ó ‡∏ù‡∏≤‡∏Å‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡πÑ‡∏î‡πâ‡∏î‡∏≠‡∏Å‡πÄ‡∏ö‡∏µ‡πâ‡∏¢ 3% ‡∏ï‡πà‡∏≠‡∏õ‡∏µ ‡∏ñ‡πâ‡∏≤‡∏ù‡∏≤‡∏Å‡∏Ñ‡∏£‡∏ö 2 ‡∏õ‡∏µ (‡∏Ñ‡∏¥‡∏î‡∏î‡∏≠‡∏Å‡πÄ‡∏ö‡∏µ‡πâ‡∏¢‡∏ó‡∏ö‡∏ï‡πâ‡∏ô) ‡∏à‡∏∞‡πÑ‡∏î‡πâ‡πÄ‡∏á‡∏¥‡∏ô‡∏£‡∏ß‡∏°‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà?",
        "answer": 1060.9
    }
]

# Prompt Variants
cot_prompts = {
    "direct": {
        "description": "‡∏ï‡∏≠‡∏ö‡∏ï‡∏£‡∏á‡πÜ",
        "template": """‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:

{question}

‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô"""
    },
    
    "cot_basic": {
        "description": "CoT ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô",
        "template": """‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ ‡πÇ‡∏î‡∏¢‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏¥‡∏î:

{question}

‡∏Ñ‡∏¥‡∏î‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô ‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢"""
    },
    
    "cot_structured": {
        "description": "CoT ‡πÅ‡∏ö‡∏ö‡∏°‡∏µ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á",
        "template": """‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:

{question}

1. ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ: [‡∏£‡∏∞‡∏ö‡∏∏‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç]
2. ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏´‡∏≤: [‡∏£‡∏∞‡∏ö‡∏∏‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°]
3. ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ: [‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô]
4. ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì: [‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì]
5. ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: [‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ß‡∏•‡∏≤]"""
    }
}

print("üìê Math Problems ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö:")
for i, prob in enumerate(math_problems):
    print(f"  {i+1}. {prob['question'][:50]}...")

# %% [markdown]
# ### 8.2 ‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á Chain-of-Thought

# %%
def run_cot_experiment(
    problems: List[Dict],
    cot_prompts: Dict[str, Dict],
    gemini_client: genai.Client,
    model_name: str = MODEL_NAME,
    temperature: float = 0.2
) -> Dict[str, List]:
    """
    ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Chain-of-Thought Prompting
    """
    all_results = {}
    
    for prompt_name, prompt_config in cot_prompts.items():
        print(f"\nüß† Testing: {prompt_name} - {prompt_config['description']}")
        print("=" * 60)
        
        results = []
        correct_count = 0
        
        with mlflow.start_run(run_name=f"cot_{prompt_name}"):
            
            # Log Parameters
            mlflow.log_param("cot_type", prompt_name)
            mlflow.log_param("description", prompt_config["description"])
            mlflow.log_param("temperature", temperature)
            mlflow.log_param("num_problems", len(problems))
            
            for i, problem in enumerate(problems):
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á Full Prompt
                full_prompt = prompt_config["template"].format(
                    question=problem["question"]
                )
                
                # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API
                response_data = call_gemini_with_tracking(
                    full_prompt,
                    gemini_client,
                    model_name=model_name,
                    temperature=temperature,
                    max_output_tokens=500
                )
                
                response_text = response_data["response_text"]
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á (‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏á‡πà‡∏≤‡∏¢)
                expected = str(problem["answer"])
                is_correct = expected in response_text
                if is_correct:
                    correct_count += 1
                
                status = "‚úÖ" if is_correct else "‚ùå"
                print(f"\n  Problem {i+1}: {status}")
                print(f"  Expected: {expected}")
                print(f"  Response: {response_text[:200]}...")
                
                results.append({
                    "problem_num": i + 1,
                    "expected": expected,
                    "response": response_text,
                    "correct": is_correct,
                    "response_time": response_data["response_time"]
                })
                
                time.sleep(0.5)
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Accuracy
            accuracy = correct_count / len(problems)
            avg_time = sum(r["response_time"] for r in results) / len(results)
            
            # Log Metrics
            mlflow.log_metric("accuracy", round(accuracy, 3))
            mlflow.log_metric("correct_count", correct_count)
            mlflow.log_metric("avg_response_time", round(avg_time, 3))
            
            print(f"\nüìä {prompt_name}: Accuracy = {accuracy:.1%}")
            
            all_results[prompt_name] = {
                "accuracy": accuracy,
                "correct_count": correct_count,
                "avg_time": avg_time,
                "results": results
            }
    
    return all_results

# ‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á
cot_results = run_cot_experiment(
    problems=math_problems,
    cot_prompts=cot_prompts,
    gemini_client=client,
    model_name=MODEL_NAME,
    temperature=0.2
)

# %% [markdown]
# ### 8.3 ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á CoT

# %%
print("\n" + "=" * 60)
print("üìä Chain-of-Thought Experiment Results")
print("=" * 60)
print(f"{'Method':<20} {'Accuracy':<15} {'Correct':<12} {'Avg Time(s)':<12}")
print("-" * 60)

for method_name, result in cot_results.items():
    print(f"{method_name:<20} {result['accuracy']:.1%}{'':<10} "
          f"{result['correct_count']}/{len(math_problems):<9} "
          f"{result['avg_time']:.3f}")

print("-" * 60)
print("\nüí° Insights:")
print("  ‚Ä¢ Direct prompting ‡∏≠‡∏≤‡∏à‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô")
print("  ‚Ä¢ CoT ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ Model ‡∏Ñ‡∏¥‡∏î‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö")
print("  ‚Ä¢ Structured CoT ‡∏ä‡πà‡∏ß‡∏¢‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ‡∏î‡∏µ")

# %% [markdown]
# ---
# ## **‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 9: Best Practices ‡πÅ‡∏•‡∏∞ Tips**
#
# ### 9.1 ‡∏™‡∏£‡∏∏‡∏õ Best Practices ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Prompt Optimization
#
# ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ:
#
# | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ | Best Practice |
# |-------|--------------|
# | **Clarity** | ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô Prompt ‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡∏£‡∏∞‡∏ö‡∏∏‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ |
# | **Context** | ‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÅ‡∏•‡∏∞ Role ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° |
# | **Examples** | ‡πÉ‡∏ä‡πâ Few-shot ‡πÄ‡∏°‡∏∑‡πà‡∏≠ Task ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô |
# | **Format** | ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Output Format ‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô |
# | **Temperature** | ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ ‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå |
# | **CoT** | ‡πÉ‡∏ä‡πâ Chain-of-Thought ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏• |

# %%
# ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å MLflow
experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)
runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])

print("üìä ‡∏™‡∏£‡∏∏‡∏õ Runs ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô Experiment:")
print("-" * 80)
print(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Runs ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(runs)}")

if not runs.empty:
    # ‡πÅ‡∏™‡∏î‡∏á Columns ‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
    important_cols = ['run_id', 'status', 'start_time']
    metric_cols = [col for col in runs.columns if col.startswith('metrics.')]
    param_cols = [col for col in runs.columns if col.startswith('params.')]
    
    print(f"\nMetrics ‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å: {[col.replace('metrics.', '') for col in metric_cols[:5]]}")
    print(f"Parameters ‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å: {[col.replace('params.', '') for col in param_cols[:5]]}")

print("-" * 80)
print(f"\nüîó ‡πÄ‡∏õ‡∏¥‡∏î MLflow UI ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î: {MLFLOW_TRACKING_URI}")

# %% [markdown]
# ### 9.2 Prompt Template Library
#
# ‡∏™‡∏£‡πâ‡∏≤‡∏á Library ‡∏Ç‡∏≠‡∏á Prompt Templates ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ã‡πâ‡∏≥‡πÑ‡∏î‡πâ:

# %%
# Prompt Template Library
PROMPT_LIBRARY = {
    "sentiment_analysis": {
        "description": "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°",
        "template": """‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å

‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:
- positive: ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏≠‡πÉ‡∏à ‡∏ä‡∏∑‡πà‡∏ô‡∏ä‡∏°
- negative: ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏°‡πà‡∏û‡∏≠‡πÉ‡∏à ‡∏ï‡∏≥‡∏´‡∏ô‡∏¥
- neutral: ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô

‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: "{text}"

‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON: {{"sentiment": "...", "confidence": 0.0-1.0, "reason": "..."}}""",
        "recommended_temp": 0.3
    },
    
    "summarization": {
        "description": "‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤",
        "template": """‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö:

{content}

‡∏™‡∏£‡∏∏‡∏õ:
- ‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å: [1-2 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ]
- ‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏£‡∏≠‡∏á: [bullet points]
- ‡∏Ç‡πâ‡∏≠‡∏™‡∏£‡∏∏‡∏õ: [1 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ]""",
        "recommended_temp": 0.5
    },
    
    "code_explanation": {
        "description": "‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ Code",
        "template": """‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÄ‡∏°‡∏≠‡∏£‡πå‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç

‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ Code ‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:
```
{code}
```

‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:
1. ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏±‡∏Å: ...
2. ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£: ...
3. Input/Output: ...
4. ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á: ...""",
        "recommended_temp": 0.3
    },
    
    "creative_writing": {
        "description": "‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå",
        "template": """‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡∏±‡∏Å‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏°‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û

‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô {content_type} ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö: {topic}

‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î:
- ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß: {length}
- ‡πÇ‡∏ó‡∏ô: {tone}
- ‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢: {audience}""",
        "recommended_temp": 0.8
    }
}

print("üìö Prompt Template Library:")
print("-" * 50)
for name, config in PROMPT_LIBRARY.items():
    print(f"‚Ä¢ {name}: {config['description']}")
    print(f"  Temperature ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: {config['recommended_temp']}")
print("-" * 50)

# %% [markdown]
# ---
# ## **‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 10: ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î (Exercises)**
#
# ### Exercise 1: Custom Sentiment Prompt
# ‡πÉ‡∏´‡πâ‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt ‡πÉ‡∏´‡∏°‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Sentiment Analysis
# ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞ Emoji

# %%
# TODO: Exercise 1 - ‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Emoji
# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Input: "‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏î‡∏µ‡∏°‡∏≤‡∏Å üòçüëç ‡∏£‡∏±‡∏Å‡πÄ‡∏•‡∏¢"

exercise1_prompt = """
# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç Prompt ‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Emoji
# Hint: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏° Emoji

YOUR_PROMPT_HERE = '''
...
'''
"""

# %% [markdown]
# ### Exercise 2: Temperature Experiment
# ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏´‡∏≤ Temperature ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Task ‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ

# %%
# TODO: Exercise 2 - ‡∏´‡∏≤ Temperature ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
# Task: ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ö‡∏ó‡∏Å‡∏ß‡∏µ‡∏™‡∏±‡πâ‡∏ô‡πÜ

exercise2_task = """
1. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ö‡∏ó‡∏Å‡∏ß‡∏µ
2. ‡∏ó‡∏î‡∏•‡∏≠‡∏á Temperature: 0.3, 0.5, 0.7, 0.9, 1.0
3. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏î‡πâ‡∏ß‡∏¢ MLflow
4. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Temperature ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
"""

# %% [markdown]
# ### Exercise 3: Chain-of-Thought for Your Domain
# ‡∏™‡∏£‡πâ‡∏≤‡∏á CoT Prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÉ‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤‡∏Ç‡∏≠‡∏á‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤

# %%
# TODO: Exercise 3 - ‡∏™‡∏£‡πâ‡∏≤‡∏á CoT Prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏≤‡∏á
# ‡πÄ‡∏ä‡πà‡∏ô: ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏á‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô, ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢‡πÇ‡∏£‡∏Ñ, ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Code Bug

exercise3_template = """
# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á CoT Prompt

YOUR_COT_PROMPT = '''
‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô [‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó]

‡∏õ‡∏±‡∏ç‡∏´‡∏≤: {problem}

‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå:
1. [‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1]: ...
2. [‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2]: ...
3. [‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3]: ...

‡∏™‡∏£‡∏∏‡∏õ: ...
'''
"""

# %% [markdown]
# ---
# ## **‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 11: ‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏•‡∏∞‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô (Summary)**
#
# ### Key Takeaways
#
# 1. **Prompt Engineering ‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡πÅ‡∏•‡∏∞‡∏®‡∏¥‡∏•‡∏õ‡πå** - ‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏ß‡∏±‡∏î‡∏ú‡∏•‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö
#
# 2. **MLflow ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á Prompt ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö** - ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Parameters, Metrics, ‡πÅ‡∏•‡∏∞ Artifacts
#
# 3. **‡∏≠‡∏á‡∏Ñ‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á Prompt:**
#    - Context/Role
#    - Clear Instructions
#    - Examples (Few-shot)
#    - Output Format
#    - Constraints
#
# 4. **Temperature ‡∏°‡∏µ‡∏ú‡∏•‡∏ï‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢** - ‡∏ï‡πà‡∏≥ = ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥, ‡∏™‡∏π‡∏á = ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå
#
# 5. **Chain-of-Thought ‡∏ä‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•** - ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö Math, Logic, Analysis
#
# ### Next Steps
#
# - ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏Å‡∏±‡∏ö Task ‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
# - ‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt Library ‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß
# - ‡πÉ‡∏ä‡πâ MLflow ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á
# - ‡πÅ‡∏ä‡∏£‡πå‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡∏°

# %%
print("=" * 60)
print("üéâ ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏î‡πâ‡∏ß‡∏¢! ‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô Lab ‡πÅ‡∏•‡πâ‡∏ß")
print("=" * 60)
print("\nüìå ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ:")
print("  ‚úÖ ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Google Gemini API (google-genai package ‡πÉ‡∏´‡∏°‡πà)")
print("  ‚úÖ ‡∏Å‡∏≤‡∏£ Track Experiments ‡∏î‡πâ‡∏ß‡∏¢ MLflow")
print("  ‚úÖ Prompt Engineering Techniques")
print("  ‚úÖ ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Prompts")
print("\nüîó Resources:")
print(f"  ‚Ä¢ MLflow UI: {MLFLOW_TRACKING_URI}")
print("  ‚Ä¢ Google AI Studio: https://aistudio.google.com")
print("  ‚Ä¢ MLflow Docs: https://mlflow.org/docs")
print("  ‚Ä¢ Google GenAI Docs: https://ai.google.dev/gemini-api/docs")
print("\nüë®‚Äçüè´ ‡∏≠‡∏¢‡πà‡∏≤‡∏•‡∏∑‡∏°‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏ô MLflow UI!")

# %% [markdown]
# ---
# ## **Appendix: Troubleshooting**
#
# ### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç
#
# | ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ | ‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏ | ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ |
# |-------|-------|-------|
# | API Key Invalid | API Key ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á | ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á Key ‡πÉ‡∏´‡∏°‡πà |
# | Rate Limit | ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API ‡∏ñ‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ | ‡πÄ‡∏û‡∏¥‡πà‡∏° time.sleep() |
# | MLflow Connection Error | Server ‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô | ‡∏£‡∏±‡∏ô `mlflow server` ‡∏Å‡πà‡∏≠‡∏ô |
# | Empty Response | Prompt ‡πÑ‡∏°‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô | ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á Prompt |
# | JSON Parse Error | Output ‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô JSON | ‡πÉ‡∏ä‡πâ Prompt ‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏°‡∏á‡∏ß‡∏î‡∏Å‡∏ß‡πà‡∏≤ |
# | Import Error (google.generativeai) | ‡πÉ‡∏ä‡πâ package ‡πÄ‡∏Å‡πà‡∏≤ | ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô google-genai |
#
# ### ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡πà‡∏≠‡∏¢
#
# ```bash
# # ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á package ‡πÉ‡∏´‡∏°‡πà
# pip install google-genai
#
# # ‡πÄ‡∏£‡∏¥‡πà‡∏° MLflow Server
# mlflow server --host 0.0.0.0 --port 5000
#
# # ‡∏î‡∏π Experiments ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
# mlflow experiments search
#
# # Export Results
# mlflow experiments csv -e "prompt-optimization-lab"
# ```
#
# ### ‡∏Å‡∏≤‡∏£ Migrate ‡∏à‡∏≤‡∏Å google-generativeai (‡πÄ‡∏Å‡πà‡∏≤) ‡πÑ‡∏õ google-genai (‡πÉ‡∏´‡∏°‡πà)
#
# ```python
# # ‡πÄ‡∏Å‡πà‡∏≤ (Deprecated)
# import google.generativeai as genai
# genai.configure(api_key="...")
# model = genai.GenerativeModel("gemini-1.5-flash")
# response = model.generate_content("Hello")
#
# # ‡πÉ‡∏´‡∏°‡πà (Recommended)
# from google import genai
# from google.genai import types
# client = genai.Client(api_key="...")
# response = client.models.generate_content(
#     model="gemini-2.0-flash",
#     contents="Hello",
#     config=types.GenerateContentConfig(temperature=0.7)
# )
# ```

# %% [markdown]
# ---
# **End of Lab**
#
# üìß ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏™‡∏á‡∏™‡∏±‡∏¢ ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏™‡∏≠‡∏ô‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà [‡∏≠‡∏µ‡πÄ‡∏°‡∏•/‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏≤‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠]
