# %% [markdown]
# # üöÄ Lab: Deploy MLflow Model as a Local Inference Server
#
# **‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ (Learning Objectives)**
#
# ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏à‡∏ö Lab ‡∏ô‡∏µ‡πâ ‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏à‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ:
# 1. ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏Ç‡∏≠‡∏á MLflow Model Serving ‡πÅ‡∏•‡∏∞ Model Registry
# 2. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å (Log) ‡πÇ‡∏°‡πÄ‡∏î‡∏• Scikit-learn ‡πÅ‡∏•‡∏∞ PyTorch ‡∏•‡∏á‡πÉ‡∏ô MLflow
# 3. Deploy ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏õ‡πá‡∏ô REST API Server ‡∏ö‡∏ô Local Machine
# 4. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ú‡πà‡∏≤‡∏ô HTTP Request
# 5. ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Deploy ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á Scikit-learn ‡πÅ‡∏•‡∏∞ PyTorch
#
# **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ (Prerequisites)**
# - Python Programming
# - Machine Learning ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
# - REST API ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
# - Docker (‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô ‡πÅ‡∏ï‡πà‡∏à‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô)

# %% [markdown]
# ---
# ## üìö Part 1: ‡∏ó‡∏§‡∏©‡∏é‡∏µ‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô (Theory & Concepts)
# ---

# %% [markdown]
# ### 1.1 MLflow Model ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?
#
# **MLflow Model** ‡πÄ‡∏õ‡πá‡∏ô format ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ package ‡πÇ‡∏°‡πÄ‡∏î‡∏• Machine Learning 
# ‡∏ó‡∏µ‡πà‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ deploy ‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ platform
#
# ```
# ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
# ‚îÇ                     MLflow Model Format                      ‚îÇ
# ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
# ‚îÇ  üìÅ model/                                                   ‚îÇ
# ‚îÇ  ‚îú‚îÄ‚îÄ üìÑ MLmodel          (metadata & flavors)               ‚îÇ
# ‚îÇ  ‚îú‚îÄ‚îÄ üìÑ conda.yaml       (dependencies)                     ‚îÇ
# ‚îÇ  ‚îú‚îÄ‚îÄ üìÑ requirements.txt (pip dependencies)                 ‚îÇ
# ‚îÇ  ‚îú‚îÄ‚îÄ üìÑ python_env.yaml  (python version)                   ‚îÇ
# ‚îÇ  ‚îî‚îÄ‚îÄ üì¶ model.pkl / model.pt (serialized model)             ‚îÇ
# ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
# ```
#
# **MLmodel file** ‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå YAML ‡∏ó‡∏µ‡πà‡∏ö‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:
# - **Flavors**: ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏à‡∏≤‡∏Å framework ‡πÉ‡∏î (sklearn, pytorch, tensorflow, etc.)
# - **Signature**: Input/Output schema ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•
# - **Input Example**: ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á input ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö

# %% [markdown]
# ### 1.2 Model Serving Architecture
#
# ```
#                           MLflow Model Serving Architecture
#
#     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
#     ‚îÇ              ‚îÇ  HTTP   ‚îÇ                      ‚îÇ  Load   ‚îÇ              ‚îÇ
#     ‚îÇ   Client     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   MLflow Serving     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ    Model     ‚îÇ
#     ‚îÇ  (Request)   ‚îÇ         ‚îÇ   (REST API Server)  ‚îÇ         ‚îÇ  (Artifact)  ‚îÇ
#     ‚îÇ              ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ                      ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ              ‚îÇ
#     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  JSON   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò Predict ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
#                               
#     üì± curl / Python         üñ•Ô∏è Port 5001              üì¶ MLflow Model
#        requests                  /invocations              Format
# ```
#
# **‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô:**
# 1. Client ‡∏™‡πà‡∏á HTTP POST request ‡∏û‡∏£‡πâ‡∏≠‡∏° input data (JSON format)
# 2. MLflow Serving ‡∏£‡∏±‡∏ö request ‡πÅ‡∏•‡∏∞ parse input
# 3. ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ predict
# 4. ‡∏™‡πà‡∏á prediction ‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON response

# %% [markdown]
# ### 1.3 Model Flavor ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?
#
# **Flavor** ‡∏Ñ‡∏∑‡∏≠ convention ‡∏ó‡∏µ‡πà‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ñ‡∏π‡∏Å serialize ‡πÅ‡∏•‡∏∞ deserialize ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£
#
# | Flavor | Framework | ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô |
# |--------|-----------|-----------|
# | `sklearn` | Scikit-learn | Classification, Regression |
# | `pytorch` | PyTorch | Deep Learning |
# | `tensorflow` | TensorFlow/Keras | Deep Learning |
# | `xgboost` | XGBoost | Gradient Boosting |
# | `pyfunc` | Any Python | Custom models |
#
# **‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ Flavor?**
# - ‡πÅ‡∏ï‡πà‡∏•‡∏∞ framework ‡∏°‡∏µ‡∏ß‡∏¥‡∏ò‡∏µ save/load ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô
# - Flavor ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ MLflow ‡∏£‡∏π‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÅ‡∏ö‡∏ö
# - ‡∏ó‡∏≥‡πÉ‡∏´‡πâ deployment ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô

# %% [markdown]
# ### 1.4 REST API Endpoints
#
# ‡πÄ‡∏°‡∏∑‡πà‡∏≠ deploy ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ `mlflow models serve` ‡∏à‡∏∞‡πÑ‡∏î‡πâ endpoints ‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:
#
# | Endpoint | Method | Description |
# |----------|--------|-------------|
# | `/invocations` | POST | ‡∏™‡πà‡∏á data ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥ prediction |
# | `/ping` | GET | Health check |
# | `/health` | GET | Health check (alternative) |
# | `/version` | GET | MLflow version |
#
# **Input Format ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö /invocations:**
#
# ```json
# // Format 1: dataframe_split (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)
# {
#     "dataframe_split": {
#         "columns": ["feature1", "feature2"],
#         "data": [[1.0, 2.0], [3.0, 4.0]]
#     }
# }
#
# // Format 2: dataframe_records
# {
#     "dataframe_records": [
#         {"feature1": 1.0, "feature2": 2.0},
#         {"feature1": 3.0, "feature2": 4.0}
#     ]
# }
#
# // Format 3: instances (TensorFlow style)
# {
#     "instances": [[1.0, 2.0], [3.0, 4.0]]
# }
# ```

# %% [markdown]
# ---
# ## üîß Part 2: Environment Setup
# ---

# %% [markdown]
# ### 2.1 ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Dependencies
#
# ‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ô‡∏µ‡πâ‡πÉ‡∏ô terminal ‡∏´‡∏£‡∏∑‡∏≠ notebook cell:

# %%
# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á packages ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
# #!pip install mlflow scikit-learn torch pandas numpy requests

# %% [markdown]
# ### 2.2 Import Libraries

# %%
# Standard libraries
import os
import json
import time
import subprocess
import warnings
import yaml  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡πà‡∏≤‡∏ô MLmodel file
warnings.filterwarnings('ignore')

# Data manipulation
import numpy as np
import pandas as pd

# Machine Learning
from sklearn.datasets import load_iris, load_wine
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# Deep Learning
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset

# MLflow
import mlflow
import mlflow.sklearn
import mlflow.pytorch
from mlflow.tracking import MlflowClient
from mlflow.models import infer_signature

# HTTP requests
import requests

print("‚úÖ All libraries imported successfully!")
print(f"üì¶ MLflow version: {mlflow.__version__}")
print(f"üì¶ PyTorch version: {torch.__version__}")

# %% [markdown]
# ### 2.3 Setup MLflow Tracking Server
#
# **‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:** ‡∏Å‡πà‡∏≠‡∏ô‡∏£‡∏±‡∏ô Lab ‡∏ô‡∏µ‡πâ ‡∏ï‡πâ‡∏≠‡∏á setup MLflow Tracking Server ‡∏Å‡πà‡∏≠‡∏ô
#
# #### Step 1: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Lab
# ```bash
# # 2.1 ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ü‡∏•‡πå Lab
# mkdir -p /home/student/workspace/mlflowserver-lab
#
# # 2.2 ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå
# cd /home/student/workspace/mlflowserver-lab
#
# # 2.3 ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
# mkdir -p /home/student/workspace/mlflowserver-lab/mlruns_db
# mkdir -p /home/student/workspace/mlflowserver-lab/mlartifacts
# ```
#
# #### Step 2: Start MLflow Server
# ```bash
# # 2.4 ‡πÄ‡∏õ‡∏¥‡∏î Server ‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å IP
# nohup mlflow server \
#   --host 0.0.0.0 --port 5000 \
#   --backend-store-uri sqlite:////home/student/workspace/mlflowserver-lab/mlruns_db/mlflow.db \
#   --artifacts-destination /home/student/workspace/mlflowserver-lab/mlartifacts \
#   --serve-artifacts > mlflow.log 2>&1 &
# ```
#
# #### ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Server
# ```bash
# # ‡∏î‡∏π log
# tail -f mlflow.log
#
# # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö process
# ps aux | grep mlflow
#
# # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠
# curl http://127.0.0.1:5000/health
# ```
#
# **Architecture:**
# ```
# /home/student/workspace/mlflowserver-lab/
# ‚îú‚îÄ‚îÄ mlruns_db/
# ‚îÇ   ‚îî‚îÄ‚îÄ mlflow.db          <- Backend Store (SQLite)
# ‚îú‚îÄ‚îÄ mlartifacts/           <- Artifact Store
# ‚îÇ   ‚îî‚îÄ‚îÄ {experiment_id}/
# ‚îÇ       ‚îî‚îÄ‚îÄ {run_id}/
# ‚îÇ           ‚îî‚îÄ‚îÄ artifacts/
# ‚îî‚îÄ‚îÄ mlflow.log             <- Server Log
#
# ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      HTTP       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
# ‚îÇ   Jupyter Lab   ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îÇ  MLflow Tracking    ‚îÇ
# ‚îÇ   (Client)      ‚îÇ   Port 5000     ‚îÇ  Server             ‚îÇ
# ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
#                                              ‚îÇ
#                               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
#                               ‚ñº                              ‚ñº
#                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
#                     ‚îÇ  Backend Store  ‚îÇ           ‚îÇ  Artifact Store ‚îÇ
#                     ‚îÇ  (SQLite DB)    ‚îÇ           ‚îÇ  (Local Files)  ‚îÇ
#                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
# ```

# %%
# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î MLflow Configuration
MLFLOW_TRACKING_URI = "http://127.0.0.1:5000"
EXPERIMENT_NAME = "Model_Deployment_Lab"

# Paths (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á)
LAB_BASE_PATH = "/home/student/workspace/mlflowserver-lab"
MLRUNS_DB_PATH = f"{LAB_BASE_PATH}/mlruns_db"
ARTIFACTS_PATH = f"{LAB_BASE_PATH}/mlartifacts"

# ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ MLflow Server
mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)

# ‡∏™‡∏£‡πâ‡∏≤‡∏á MlflowClient ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö interact ‡∏Å‡∏±‡∏ö server
client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ experiment
mlflow.set_experiment(EXPERIMENT_NAME)

print(f"üìç MLflow Tracking URI: {MLFLOW_TRACKING_URI}")
print(f"üìÅ Lab Base Path: {LAB_BASE_PATH}")
print(f"üìÅ Artifacts Path: {ARTIFACTS_PATH}")
print(f"üî¨ Experiment: {EXPERIMENT_NAME}")

# %%
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ MLflow Server
print("üîç ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ MLflow Server...")
print("-" * 50)

try:
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠
    response = requests.get(f"{MLFLOW_TRACKING_URI}/health", timeout=5)
    if response.status_code == 200:
        print("‚úÖ MLflow Server is running!")
    
    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• experiment
    experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)
    if experiment:
        print(f"üìå Experiment ID: {experiment.experiment_id}")
        print(f"üìÅ Artifact Location: {experiment.artifact_location}")
    else:
        print(f"üìù Creating new experiment: {EXPERIMENT_NAME}")
        
    # ‡πÅ‡∏™‡∏î‡∏á experiments ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    print(f"\nüìã Available Experiments:")
    experiments = client.search_experiments()
    for exp in experiments:
        print(f"   - {exp.name} (ID: {exp.experiment_id})")
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå
    print(f"\nüìÅ Directory Structure:")
    if os.path.exists(LAB_BASE_PATH):
        print(f"   ‚úÖ {LAB_BASE_PATH}")
        if os.path.exists(MLRUNS_DB_PATH):
            print(f"   ‚úÖ {MLRUNS_DB_PATH}")
        if os.path.exists(ARTIFACTS_PATH):
            print(f"   ‚úÖ {ARTIFACTS_PATH}")
    else:
        print(f"   ‚ö†Ô∏è Lab directory not found: {LAB_BASE_PATH}")
        
except requests.exceptions.ConnectionError:
    print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ MLflow Server ‡πÑ‡∏î‡πâ!")
    print("üí° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤ start MLflow Server ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á:")
    print()
    print("   # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå")
    print("   mkdir -p /home/student/workspace/mlflowserver-lab/mlruns_db")
    print("   mkdir -p /home/student/workspace/mlflowserver-lab/mlartifacts")
    print()
    print("   # Start Server")
    print("   cd /home/student/workspace/mlflowserver-lab")
    print("   nohup mlflow server \\")
    print("     --host 0.0.0.0 --port 5000 \\")
    print("     --backend-store-uri sqlite:////home/student/workspace/mlflowserver-lab/mlruns_db/mlflow.db \\")
    print("     --artifacts-destination /home/student/workspace/mlflowserver-lab/mlartifacts \\")
    print("     --serve-artifacts > mlflow.log 2>&1 &")
except Exception as e:
    print(f"‚ö†Ô∏è Error: {e}")

# %% [markdown]
# ### 2.4 Helper Functions ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ Model Path
#
# ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ MLflow Server ‡∏Å‡∏±‡∏ö `--serve-artifacts` artifacts ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á:
#
# ```
# /home/student/workspace/mlflowserver-lab/
# ‚îî‚îÄ‚îÄ mlartifacts/
#     ‚îî‚îÄ‚îÄ {experiment_id}/
#         ‚îî‚îÄ‚îÄ {run_id}/
#             ‚îî‚îÄ‚îÄ artifacts/
#                 ‚îî‚îÄ‚îÄ {artifact_path}/
#                     ‚îú‚îÄ‚îÄ MLmodel
#                     ‚îú‚îÄ‚îÄ model.pkl (sklearn)
#                     ‚îî‚îÄ‚îÄ data/ (pytorch)
# ```

# %%
def get_experiment_id(experiment_name: str) -> str:
    """‡∏î‡∏∂‡∏á experiment ID ‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠ experiment"""
    experiment = mlflow.get_experiment_by_name(experiment_name)
    if experiment:
        return experiment.experiment_id
    return None


def get_artifact_base_path() -> str:
    """‡∏î‡∏∂‡∏á artifact base path ‡∏à‡∏≤‡∏Å experiment"""
    return ARTIFACTS_PATH


def find_model_path_by_run_id(run_id: str, artifact_path: str = "sklearn_model") -> str:
    """
    ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ model path ‡∏à‡∏≤‡∏Å run_id
    
    Args:
        run_id: MLflow Run ID
        artifact_path: Path ‡∏Ç‡∏≠‡∏á artifact ‡∏ó‡∏µ‡πà log ‡πÑ‡∏ß‡πâ
    
    Returns:
        Full path ‡∏´‡∏£‡∏∑‡∏≠ Model URI
    """
    return f"runs:/{run_id}/{artifact_path}"


def find_model_path_local(experiment_id: str, run_id: str, artifact_name: str = "sklearn_model") -> str:
    """
    ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ model path ‡∏à‡∏≤‡∏Å local artifacts folder
    
    Args:
        experiment_id: Experiment ID
        run_id: Run ID
        artifact_name: ‡∏ä‡∏∑‡πà‡∏≠ artifact (sklearn_model, pytorch_model, etc.)
    
    Returns:
        Local path ‡πÑ‡∏õ‡∏¢‡∏±‡∏á model
    """
    model_path = f"{ARTIFACTS_PATH}/{experiment_id}/{run_id}/artifacts/{artifact_name}"
    if os.path.exists(model_path):
        return model_path
    return None


def find_models_by_flavor_from_server(experiment_name: str, flavor: str = "sklearn") -> list:
    """
    ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ models ‡∏à‡∏≤‡∏Å MLflow Server ‡∏ï‡∏≤‡∏° flavor
    
    Args:
        experiment_name: ‡∏ä‡∏∑‡πà‡∏≠ experiment
        flavor: MLflow flavor ("sklearn", "pytorch", etc.)
    
    Returns:
        List ‡∏Ç‡∏≠‡∏á model info
    """
    experiment = mlflow.get_experiment_by_name(experiment_name)
    if not experiment:
        return []
    
    # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ runs ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô experiment
    runs = client.search_runs(
        experiment_ids=[experiment.experiment_id],
        order_by=["start_time DESC"]
    )
    
    found_models = []
    for run in runs:
        run_id = run.info.run_id
        
        # ‡∏•‡∏≠‡∏á‡πÇ‡∏´‡∏•‡∏î model info
        try:
            # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î artifact paths ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ
            possible_paths = [
                f"runs:/{run_id}/sklearn_model",
                f"runs:/{run_id}/pytorch_model",
                f"runs:/{run_id}/model"
            ]
            
            for model_uri in possible_paths:
                try:
                    model_info = mlflow.models.get_model_info(model_uri)
                    if flavor in model_info.flavors:
                        # ‡∏´‡∏≤ local path ‡∏î‡πâ‡∏ß‡∏¢
                        artifact_name = model_uri.split("/")[-1]
                        local_path = find_model_path_local(
                            experiment.experiment_id, 
                            run_id, 
                            artifact_name
                        )
                        
                        found_models.append({
                            'run_id': run_id,
                            'run_name': run.info.run_name,
                            'model_uri': model_uri,
                            'local_path': local_path,
                            'flavors': list(model_info.flavors.keys()),
                            'status': run.info.status
                        })
                        break
                except:
                    continue
        except Exception as e:
            continue
    
    return found_models


def find_models_by_flavor_local(experiment_id: str, flavor: str = "sklearn") -> list:
    """
    ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ models ‡∏à‡∏≤‡∏Å local artifacts folder ‡∏ï‡∏≤‡∏° flavor
    
    Args:
        experiment_id: Experiment ID
        flavor: MLflow flavor ("sklearn", "pytorch", etc.)
    
    Returns:
        List ‡∏Ç‡∏≠‡∏á model info
    """
    experiment_path = f"{ARTIFACTS_PATH}/{experiment_id}"
    found_models = []
    
    if not os.path.exists(experiment_path):
        print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå: {experiment_path}")
        return found_models
    
    # ‡∏ß‡∏ô‡∏´‡∏≤ run folders
    for run_id in os.listdir(experiment_path):
        run_path = f"{experiment_path}/{run_id}"
        if not os.path.isdir(run_path):
            continue
            
        artifacts_path = f"{run_path}/artifacts"
        if not os.path.exists(artifacts_path):
            continue
        
        # ‡∏ß‡∏ô‡∏´‡∏≤ artifact folders (sklearn_model, pytorch_model, etc.)
        for artifact_name in os.listdir(artifacts_path):
            model_path = f"{artifacts_path}/{artifact_name}"
            mlmodel_file = f"{model_path}/MLmodel"
            
            if os.path.exists(mlmodel_file):
                with open(mlmodel_file, 'r') as f:
                    mlmodel = yaml.safe_load(f)
                
                if 'flavors' in mlmodel and flavor in mlmodel['flavors']:
                    found_models.append({
                        'run_id': run_id,
                        'artifact_name': artifact_name,
                        'local_path': model_path,
                        'model_uri': f"runs:/{run_id}/{artifact_name}",
                        'flavors': list(mlmodel['flavors'].keys())
                    })
    
    return found_models


def list_registered_models():
    """‡πÅ‡∏™‡∏î‡∏á registered models ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
    try:
        registered_models = client.search_registered_models()
        return registered_models
    except Exception as e:
        print(f"‚ö†Ô∏è Error: {e}")
        return []


print("‚úÖ Helper functions defined successfully!")

# %% [markdown]
# ---
# ## üå≤ Part 3: Scikit-learn Model Deployment
# ---

# %% [markdown]
# ### 3.1 ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Iris Dataset
#
# **Iris Dataset** ‡πÄ‡∏õ‡πá‡∏ô dataset ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ Classification
# - 150 samples
# - 4 features: sepal length, sepal width, petal length, petal width
# - 3 classes: setosa, versicolor, virginica

# %%
# Load Iris dataset
iris = load_iris()
X = pd.DataFrame(iris.data, columns=iris.feature_names)
y = iris.target

# ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô
print("üìä Dataset Info:")
print(f"   Shape: {X.shape}")
print(f"   Features: {list(X.columns)}")
print(f"   Classes: {list(iris.target_names)}")
print()
print("üìã Sample data:")
X.head()

# %%
# ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"‚úÇÔ∏è Train set: {X_train.shape[0]} samples")
print(f"‚úÇÔ∏è Test set: {X_test.shape[0]} samples")

# %% [markdown]
# ### 3.2 Train ‡πÅ‡∏•‡∏∞ Log Scikit-learn Model
#
# **‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£ Log Model:**
# 1. ‡πÄ‡∏£‡∏¥‡πà‡∏° MLflow run
# 2. Train model
# 3. Log parameters, metrics
# 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á signature ‡πÅ‡∏•‡∏∞ input example
# 5. Log model ‡∏î‡πâ‡∏ß‡∏¢ `mlflow.sklearn.log_model()`

# %%
# Train ‡πÅ‡∏•‡∏∞ Log RandomForest model
with mlflow.start_run(run_name="sklearn_randomforest") as run:
    
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î hyperparameters
    n_estimators = 100
    max_depth = 5
    random_state = 42
    
    # Log parameters
    mlflow.log_param("n_estimators", n_estimators)
    mlflow.log_param("max_depth", max_depth)
    mlflow.log_param("random_state", random_state)
    mlflow.log_param("model_type", "RandomForestClassifier")
    
    # Train model
    model = RandomForestClassifier(
        n_estimators=n_estimators,
        max_depth=max_depth,
        random_state=random_state
    )
    model.fit(X_train, y_train)
    
    # Evaluate
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    
    # Log metrics
    mlflow.log_metric("accuracy", accuracy)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á signature (‡∏ö‡∏≠‡∏Å input/output schema)
    signature = infer_signature(X_train, model.predict(X_train))
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á input example ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö
    input_example = X_train.head(3)
    
    # Log model ‡∏û‡∏£‡πâ‡∏≠‡∏° signature ‡πÅ‡∏•‡∏∞ input example
    model_info = mlflow.sklearn.log_model(
        sk_model=model,
        artifact_path="sklearn_model",
        signature=signature,
        input_example=input_example,
        registered_model_name="iris_classifier_sklearn"  # Register model ‡∏î‡πâ‡∏ß‡∏¢
    )
    
    # ‡πÄ‡∏Å‡πá‡∏ö run_id ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ deploy
    sklearn_run_id = run.info.run_id
    
    # ============================================
    # FIX: ‡πÉ‡∏ä‡πâ runs:/ URI ‡πÅ‡∏ó‡∏ô models:/ URI
    # ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ runs:/ URI ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏Å‡∏ß‡πà‡∏≤
    # ============================================
    sklearn_model_uri = f"runs:/{sklearn_run_id}/sklearn_model"
    
    print("=" * 60)
    print("‚úÖ Scikit-learn Model Logged Successfully!")
    print("=" * 60)
    print(f"üìå Run ID: {sklearn_run_id}")
    print(f"üì¶ Model URI (runs:/): {sklearn_model_uri}")
    print(f"üì¶ Model URI (models:/): models:/iris_classifier_sklearn/1")
    print(f"üìä Accuracy: {accuracy:.4f}")
    print()
    print("üìã Model Signature:")
    print(signature)

# %% [markdown]
# ### 3.3 ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Model Artifacts
#
# ‡∏î‡∏π‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà MLflow ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô:

# %%
# ‡πÅ‡∏™‡∏î‡∏á model URI
print(f"üì¶ Model URI: {sklearn_model_uri}")
print()

# Load ‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö model info
model_info = mlflow.models.get_model_info(sklearn_model_uri)
print("üìã Model Info:")
print(f"   Flavors: {list(model_info.flavors.keys())}")
print(f"   Run ID: {model_info.run_id}")
print()

# ‡πÅ‡∏™‡∏î‡∏á MLmodel file content
print("üìÑ MLmodel file content:")

# ============================================
# FIX: ‡πÉ‡∏ä‡πâ runs:/ URI ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö download_artifacts
# ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ models:/ URI ‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏¥‡∏î error
# ============================================
try:
    # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: ‡πÉ‡∏ä‡πâ runs:/ URI (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)
    mlmodel_path = mlflow.artifacts.download_artifacts(sklearn_model_uri + "/MLmodel")
    with open(mlmodel_path, 'r') as f:
        print(f.read())
except Exception as e:
    print(f"‚ö†Ô∏è Method 1 (runs:/ URI) failed: {e}")
    
    # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: ‡πÉ‡∏ä‡πâ local path ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
    try:
        experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)
        local_mlmodel_path = f"{ARTIFACTS_PATH}/{experiment.experiment_id}/{sklearn_run_id}/artifacts/sklearn_model/MLmodel"
        
        if os.path.exists(local_mlmodel_path):
            print(f"\nüìÅ Using local path: {local_mlmodel_path}")
            with open(local_mlmodel_path, 'r') as f:
                print(f.read())
        else:
            print(f"‚ö†Ô∏è Local path not found: {local_mlmodel_path}")
            
            # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 3: ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å model_info ‡πÅ‡∏ó‡∏ô
            print("\nüìã Alternative: Showing MLmodel info from API:")
            print(f"   Model URI: {model_info.model_uri}")
            print(f"   Flavors: {model_info.flavors}")
            if model_info.signature:
                print(f"   Signature Inputs: {model_info.signature.inputs}")
                print(f"   Signature Outputs: {model_info.signature.outputs}")
    except Exception as e2:
        print(f"‚ö†Ô∏è Method 2 (local path) also failed: {e2}")
        print("\nüìã Showing available model info:")
        print(f"   Run ID: {sklearn_run_id}")
        print(f"   Flavors: {list(model_info.flavors.keys())}")

# %% [markdown]
# ### 3.4 Test Model Locally (‡∏Å‡πà‡∏≠‡∏ô Deploy)
#
# ‡∏°‡∏µ 2 ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ load model ‡∏à‡∏≤‡∏Å MLflow Server:
# 1. **‡∏à‡∏≤‡∏Å Model URI** - ‡πÉ‡∏ä‡πâ `runs:/<run_id>/<artifact_path>`
# 2. **‡∏à‡∏≤‡∏Å Registered Model** - ‡πÉ‡∏ä‡πâ `models:/<model_name>/<version>`

# %%
# ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: Load model ‡∏à‡∏≤‡∏Å Model URI (runs:/)
print("üß™ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: Load ‡∏à‡∏≤‡∏Å Model URI (runs:/)")
print("-" * 50)
print(f"üì¶ Model URI: {sklearn_model_uri}")

loaded_model_uri = mlflow.sklearn.load_model(sklearn_model_uri)

test_data = X_test.head(5)
predictions = loaded_model_uri.predict(test_data)

for i, (idx, row) in enumerate(test_data.iterrows()):
    pred_class = iris.target_names[predictions[i]]
    actual_class = iris.target_names[y_test.iloc[i]]
    status = "‚úÖ" if predictions[i] == y_test.iloc[i] else "‚ùå"
    print(f"   Sample {i+1}: Predicted={pred_class}, Actual={actual_class} {status}")

# %%
# ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: Load model ‡∏à‡∏≤‡∏Å Registered Model Name
print("\nüß™ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: Load ‡∏à‡∏≤‡∏Å Registered Model (models:/)")
print("-" * 50)

registered_model_uri = "models:/iris_classifier_sklearn/1"
print(f"üì¶ Registered Model URI: {registered_model_uri}")

try:
    loaded_registered_model = mlflow.sklearn.load_model(registered_model_uri)
    print(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î Model ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {type(loaded_registered_model)}")
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
    predictions = loaded_registered_model.predict(X_test[:5])
    print(f"\nüîÆ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ 5 ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏£‡∏Å:")
    print(f"   Predictions: {predictions}")
    print(f"   Actual:      {y_test[:5].values}")
except Exception as e:
    print(f"‚ö†Ô∏è Error loading registered model: {e}")
    print("üí° Model ‡∏≠‡∏≤‡∏à‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ register ‡∏´‡∏£‡∏∑‡∏≠ version ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
    print(f"üí° ‡πÉ‡∏ä‡πâ runs:/ URI ‡πÅ‡∏ó‡∏ô: {sklearn_model_uri}")

# %%
# ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ sklearn models ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å MLflow Server
print("\nüìã ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ Sklearn Models ‡∏à‡∏≤‡∏Å MLflow Server:")
print("-" * 50)

sklearn_models = find_models_by_flavor_from_server(EXPERIMENT_NAME, flavor="sklearn")
for i, model in enumerate(sklearn_models, 1):
    print(f"   {i}. Run: {model['run_name']} ({model['run_id'][:8]}...)")
    print(f"      URI: {model['model_uri']}")
    if model.get('local_path'):
        print(f"      Local: {model['local_path']}")
    print(f"      Flavors: {model['flavors']}")
    print(f"      Status: {model['status']}")

# %%
# ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ sklearn models ‡∏à‡∏≤‡∏Å local artifacts folder
print("\nüìã ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ Sklearn Models ‡∏à‡∏≤‡∏Å Local Artifacts:")
print("-" * 50)

experiment_id = get_experiment_id(EXPERIMENT_NAME)
if experiment_id:
    local_sklearn_models = find_models_by_flavor_local(experiment_id, flavor="sklearn")
    for i, model in enumerate(local_sklearn_models, 1):
        print(f"   {i}. Run ID: {model['run_id'][:8]}...")
        print(f"      Local Path: {model['local_path']}")
        print(f"      Model URI: {model['model_uri']}")
        print(f"      Flavors: {model['flavors']}")

# %% [markdown]
# ### 3.5 Deploy Scikit-learn Model as REST API
#
# **‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Deploy:**
#
# ```bash
# mlflow models serve -m <model_uri> -p <port> --no-conda
# ```
#
# **Parameters:**
# - `-m`: Model URI (runs:/<run_id>/model ‡∏´‡∏£‡∏∑‡∏≠ models:/<name>/<version>)
# - `-p`: Port number
# - `--no-conda`: ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ conda environment (‡πÉ‡∏ä‡πâ current environment)
# - `--host`: Host address (default: 127.0.0.1)

# %%
# ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á deploy
print("üöÄ Deploy Scikit-learn Model")
print("=" * 60)
print()
print("üìã ‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ô‡∏µ‡πâ‡πÉ‡∏ô Terminal ‡πÅ‡∏¢‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏´‡∏≤‡∏Å:")
print()
print("# ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: ‡πÉ‡∏ä‡πâ runs:/ URI (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)")
print(f'mlflow models serve -m "{sklearn_model_uri}" -p 5001 --no-conda')
print()
print("# ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: ‡πÉ‡∏ä‡πâ registered model name")
print('mlflow models serve -m "models:/iris_classifier_sklearn/1" -p 5001 --no-conda')
print()
print("=" * 60)
print("‚è≥ ‡∏£‡∏≠‡πÉ‡∏´‡πâ server start ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢‡∏£‡∏±‡∏ô cell ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ...")
print("   (‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° 'Listening at: http://127.0.0.1:5001')")

# %% [markdown]
# ### 3.6 ‡∏ó‡∏î‡∏™‡∏≠‡∏ö REST API (Scikit-learn)
#
# **‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å server start ‡πÅ‡∏•‡πâ‡∏ß** ‡∏£‡∏±‡∏ô cell ‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö:

# %%
def test_sklearn_api(port=5001):
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö REST API ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Scikit-learn model"""
    
    base_url = f"http://127.0.0.1:{port}"
    
    # Test 1: Health check
    print("üîç Test 1: Health Check")
    print("-" * 40)
    try:
        response = requests.get(f"{base_url}/health", timeout=5)
        print(f"   Status: {response.status_code}")
        print(f"   Response: {response.text}")
    except requests.exceptions.ConnectionError:
        print("   ‚ùå Connection failed! Make sure server is running.")
        return
    
    # Test 2: Prediction with dataframe_split format
    print()
    print("üîç Test 2: Prediction (dataframe_split format)")
    print("-" * 40)
    
    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° test data
    test_samples = X_test.head(3).values.tolist()
    
    payload = {
        "dataframe_split": {
            "columns": list(X.columns),
            "data": test_samples
        }
    }
    
    print(f"   üì§ Request payload:")
    print(f"      {json.dumps(payload, indent=6)}")
    
    response = requests.post(
        f"{base_url}/invocations",
        headers={"Content-Type": "application/json"},
        json=payload
    )
    
    print()
    print(f"   üì• Response:")
    print(f"      Status: {response.status_code}")
    print(f"      Predictions: {response.json()}")
    
    # ‡πÅ‡∏õ‡∏•‡∏á predictions ‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠ class
    predictions = response.json()['predictions']
    print()
    print("   üìä Prediction Results:")
    for i, pred in enumerate(predictions):
        print(f"      Sample {i+1}: {iris.target_names[pred]}")
    
    # Test 3: Prediction with instances format
    print()
    print("üîç Test 3: Prediction (instances format)")
    print("-" * 40)
    
    payload_instances = {
        "instances": test_samples
    }
    
    response = requests.post(
        f"{base_url}/invocations",
        headers={"Content-Type": "application/json"},
        json=payload_instances
    )
    
    print(f"   üì• Response: {response.json()}")
    
    print()
    print("‚úÖ All API tests completed!")

# ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ function ‡∏ó‡∏î‡∏™‡∏≠‡∏ö
# ‚ö†Ô∏è Uncomment ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å start server ‡πÅ‡∏•‡πâ‡∏ß
# test_sklearn_api(5001)

# %% [markdown]
# ### 3.7 ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ curl command
#
# ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ curl ‡πÉ‡∏ô terminal ‡πÑ‡∏î‡πâ:
#
# ```bash
# # Health check
# curl http://127.0.0.1:5001/health
#
# # Prediction
# curl -X POST http://127.0.0.1:5001/invocations \
#      -H "Content-Type: application/json" \
#      -d '{"dataframe_split": {"columns": ["sepal length (cm)", "sepal width (cm)", "petal length (cm)", "petal width (cm)"], "data": [[5.1, 3.5, 1.4, 0.2]]}}'
# ```

# %% [markdown]
# ---
# ## üî• Part 4: PyTorch Model Deployment
# ---

# %% [markdown]
# ### 4.1 ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Wine Dataset
#
# **Wine Dataset** ‡πÄ‡∏õ‡πá‡∏ô dataset ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö classification
# - 178 samples
# - 13 features (chemical analysis)
# - 3 classes (wine types)

# %%
# Load Wine dataset
wine = load_wine()
X_wine = pd.DataFrame(wine.data, columns=wine.feature_names)
y_wine = wine.target

# Normalize features (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Neural Network)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_wine_scaled = scaler.fit_transform(X_wine)

print("üìä Wine Dataset Info:")
print(f"   Shape: {X_wine.shape}")
print(f"   Features: {len(wine.feature_names)} features")
print(f"   Classes: {list(wine.target_names)}")
print()
print("üìã Sample features:")
print(f"   {wine.feature_names[:5]}...")

# %%
# ‡πÅ‡∏ö‡πà‡∏á train/test
X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(
    X_wine_scaled, y_wine, test_size=0.2, random_state=42, stratify=y_wine
)

# ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô PyTorch tensors
X_train_tensor = torch.FloatTensor(X_train_wine)
y_train_tensor = torch.LongTensor(y_train_wine)
X_test_tensor = torch.FloatTensor(X_test_wine)
y_test_tensor = torch.LongTensor(y_test_wine)

# ‡∏™‡∏£‡πâ‡∏≤‡∏á DataLoader
train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)

print(f"‚úÇÔ∏è Train set: {X_train_tensor.shape[0]} samples")
print(f"‚úÇÔ∏è Test set: {X_test_tensor.shape[0]} samples")
print(f"üì¶ Tensor shapes: X={X_train_tensor.shape}, y={y_train_tensor.shape}")

# %% [markdown]
# ### 4.2 ‡∏™‡∏£‡πâ‡∏≤‡∏á Neural Network Model
#
# **‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Network:**
# ```
# Input (13 features)
#     ‚Üì
# Linear(13, 64) + ReLU + Dropout(0.3)
#     ‚Üì
# Linear(64, 32) + ReLU + Dropout(0.3)
#     ‚Üì
# Linear(32, 3) ‚Üí Output (3 classes)
# ```

# %%
class WineClassifier(nn.Module):
    """Neural Network ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Wine Classification"""
    
    def __init__(self, input_dim=13, hidden1=64, hidden2=32, output_dim=3):
        super(WineClassifier, self).__init__()
        
        self.network = nn.Sequential(
            nn.Linear(input_dim, hidden1),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden1, hidden2),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden2, output_dim)
        )
    
    def forward(self, x):
        return self.network(x)

# ‡∏™‡∏£‡πâ‡∏≤‡∏á model instance
pytorch_model = WineClassifier()
print("üèóÔ∏è Model Architecture:")
print(pytorch_model)
print()
print(f"üìä Total parameters: {sum(p.numel() for p in pytorch_model.parameters()):,}")

# %% [markdown]
# ### 4.3 Train PyTorch Model

# %%
def train_pytorch_model(model, train_loader, X_test, y_test, epochs=100, lr=0.001):
    """Train PyTorch model ‡πÅ‡∏•‡∏∞ return metrics"""
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)
    
    history = {'loss': [], 'accuracy': []}
    
    model.train()
    for epoch in range(epochs):
        epoch_loss = 0
        for batch_X, batch_y in train_loader:
            optimizer.zero_grad()
            outputs = model(batch_X)
            loss = criterion(outputs, batch_y)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()
        
        # Evaluate
        model.eval()
        with torch.no_grad():
            test_outputs = model(X_test)
            _, predicted = torch.max(test_outputs, 1)
            accuracy = (predicted == y_test).sum().item() / len(y_test)
        model.train()
        
        history['loss'].append(epoch_loss / len(train_loader))
        history['accuracy'].append(accuracy)
        
        if (epoch + 1) % 20 == 0:
            print(f"   Epoch [{epoch+1}/{epochs}] Loss: {epoch_loss/len(train_loader):.4f}, Acc: {accuracy:.4f}")
    
    return history

# Train model
print("üèãÔ∏è Training PyTorch Model...")
print("-" * 40)
history = train_pytorch_model(
    pytorch_model, train_loader, 
    X_test_tensor, y_test_tensor,
    epochs=100, lr=0.001
)

print("-" * 40)
print(f"‚úÖ Training completed! Final accuracy: {history['accuracy'][-1]:.4f}")

# %% [markdown]
# ### 4.4 Log PyTorch Model to MLflow
#
# **‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å Scikit-learn:**
# - ‡πÉ‡∏ä‡πâ `mlflow.pytorch.log_model()` ‡πÅ‡∏ó‡∏ô `mlflow.sklearn.log_model()`
# - ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏ input signature ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
# - ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ log ‡πÄ‡∏õ‡πá‡∏ô scripted model ‡∏´‡∏£‡∏∑‡∏≠ regular model

# %%
# Log PyTorch model to MLflow
with mlflow.start_run(run_name="pytorch_wine_classifier") as run:
    
    # Log parameters
    mlflow.log_param("model_type", "Neural Network")
    mlflow.log_param("hidden1", 64)
    mlflow.log_param("hidden2", 32)
    mlflow.log_param("epochs", 100)
    mlflow.log_param("learning_rate", 0.001)
    mlflow.log_param("optimizer", "Adam")
    
    # Log metrics
    mlflow.log_metric("final_accuracy", history['accuracy'][-1])
    mlflow.log_metric("final_loss", history['loss'][-1])
    
    # Log training history
    for i, (loss, acc) in enumerate(zip(history['loss'], history['accuracy'])):
        mlflow.log_metric("train_loss", loss, step=i)
        mlflow.log_metric("train_accuracy", acc, step=i)
    
    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° input example
    input_example = X_test_tensor[:3].numpy()
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á signature
    # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PyTorch ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ numpy array ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ infer signature
    pytorch_model.eval()
    with torch.no_grad():
        sample_output = pytorch_model(X_test_tensor[:3]).numpy()
    
    signature = infer_signature(input_example, sample_output)
    
    # Log model
    model_info = mlflow.pytorch.log_model(
        pytorch_model=pytorch_model,
        artifact_path="pytorch_model",
        signature=signature,
        input_example=input_example,
        registered_model_name="wine_classifier_pytorch"
    )
    
    pytorch_run_id = run.info.run_id
    
    # ============================================
    # FIX: ‡πÉ‡∏ä‡πâ runs:/ URI ‡πÅ‡∏ó‡∏ô models:/ URI
    # ============================================
    pytorch_model_uri = f"runs:/{pytorch_run_id}/pytorch_model"
    
    print("=" * 60)
    print("‚úÖ PyTorch Model Logged Successfully!")
    print("=" * 60)
    print(f"üìå Run ID: {pytorch_run_id}")
    print(f"üì¶ Model URI (runs:/): {pytorch_model_uri}")
    print(f"üì¶ Model URI (models:/): models:/wine_classifier_pytorch/1")
    print(f"üìä Final Accuracy: {history['accuracy'][-1]:.4f}")
    print()
    print("üìã Model Signature:")
    print(signature)

# %% [markdown]
# ### 4.5 Test PyTorch Model Locally
#
# ‡πÄ‡∏ä‡πà‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö Scikit-learn ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ load PyTorch model ‡∏à‡∏≤‡∏Å MLflow Server ‡πÑ‡∏î‡πâ:

# %%
# ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: Load ‡∏à‡∏≤‡∏Å Model URI
print("üß™ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: Load PyTorch Model ‡∏à‡∏≤‡∏Å Model URI (runs:/)")
print("-" * 50)
print(f"üì¶ Model URI: {pytorch_model_uri}")

loaded_pytorch_model = mlflow.pytorch.load_model(pytorch_model_uri)
loaded_pytorch_model.eval()

with torch.no_grad():
    test_input = X_test_tensor[:5]
    outputs = loaded_pytorch_model(test_input)
    _, predictions = torch.max(outputs, 1)

for i in range(5):
    pred_class = wine.target_names[predictions[i]]
    actual_class = wine.target_names[y_test_tensor[i]]
    status = "‚úÖ" if predictions[i] == y_test_tensor[i] else "‚ùå"
    print(f"   Sample {i+1}: Predicted={pred_class}, Actual={actual_class} {status}")

# %%
# ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: Load ‡∏à‡∏≤‡∏Å Registered Model
print("\nüß™ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: Load PyTorch Model ‡∏à‡∏≤‡∏Å Registered Model (models:/)")
print("-" * 50)

registered_pytorch_uri = "models:/wine_classifier_pytorch/1"
print(f"üì¶ Registered Model URI: {registered_pytorch_uri}")

try:
    loaded_pt_registered = mlflow.pytorch.load_model(registered_pytorch_uri)
    loaded_pt_registered.eval()
    print(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î Model ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {type(loaded_pt_registered)}")
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
    with torch.no_grad():
        test_input = X_test_tensor[:5]
        outputs = loaded_pt_registered(test_input)
        _, predictions = torch.max(outputs, 1)
    
    print(f"\nüîÆ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ 5 ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏£‡∏Å:")
    print(f"   Predictions: {predictions.numpy()}")
    print(f"   Actual:      {y_test_tensor[:5].numpy()}")
except Exception as e:
    print(f"‚ö†Ô∏è Error loading registered model: {e}")
    print("üí° Model ‡∏≠‡∏≤‡∏à‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ register ‡∏´‡∏£‡∏∑‡∏≠ version ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
    print(f"üí° ‡πÉ‡∏ä‡πâ runs:/ URI ‡πÅ‡∏ó‡∏ô: {pytorch_model_uri}")

# %%
# ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ pytorch models ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å MLflow Server
print("\nüìã ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ PyTorch Models ‡∏à‡∏≤‡∏Å MLflow Server:")
print("-" * 50)

pytorch_models = find_models_by_flavor_from_server(EXPERIMENT_NAME, flavor="pytorch")
for i, model in enumerate(pytorch_models, 1):
    print(f"   {i}. Run: {model['run_name']} ({model['run_id'][:8]}...)")
    print(f"      URI: {model['model_uri']}")
    if model.get('local_path'):
        print(f"      Local: {model['local_path']}")
    print(f"      Flavors: {model['flavors']}")
    print(f"      Status: {model['status']}")

# %%
# ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ pytorch models ‡∏à‡∏≤‡∏Å local artifacts folder
print("\nüìã ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ PyTorch Models ‡∏à‡∏≤‡∏Å Local Artifacts:")
print("-" * 50)

experiment_id = get_experiment_id(EXPERIMENT_NAME)
if experiment_id:
    local_pytorch_models = find_models_by_flavor_local(experiment_id, flavor="pytorch")
    for i, model in enumerate(local_pytorch_models, 1):
        print(f"   {i}. Run ID: {model['run_id'][:8]}...")
        print(f"      Local Path: {model['local_path']}")
        print(f"      Model URI: {model['model_uri']}")
        print(f"      Flavors: {model['flavors']}")

# %% [markdown]
# ### 4.6 Deploy PyTorch Model as REST API
#
# **‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:** PyTorch model ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ pyfunc flavor ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ serve

# %%
print("üöÄ Deploy PyTorch Model")
print("=" * 60)
print()
print("üìã ‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ô‡∏µ‡πâ‡πÉ‡∏ô Terminal ‡πÅ‡∏¢‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏´‡∏≤‡∏Å:")
print()
print("# ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: ‡πÉ‡∏ä‡πâ runs:/ URI (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)")
print(f'mlflow models serve -m "{pytorch_model_uri}" -p 5002 --no-conda')
print()
print("# ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: ‡πÉ‡∏ä‡πâ registered model name")
print('mlflow models serve -m "models:/wine_classifier_pytorch/1" -p 5002 --no-conda')
print()
print("=" * 60)
print("‚è≥ ‡∏£‡∏≠‡πÉ‡∏´‡πâ server start ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢‡∏£‡∏±‡∏ô cell ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ...")

# %% [markdown]
# ### 4.7 ‡∏ó‡∏î‡∏™‡∏≠‡∏ö REST API (PyTorch)

# %%
def test_pytorch_api(port=5002):
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö REST API ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PyTorch model"""
    
    base_url = f"http://127.0.0.1:{port}"
    
    # Test 1: Health check
    print("üîç Test 1: Health Check")
    print("-" * 40)
    try:
        response = requests.get(f"{base_url}/health", timeout=5)
        print(f"   Status: {response.status_code}")
    except requests.exceptions.ConnectionError:
        print("   ‚ùå Connection failed! Make sure server is running.")
        return
    
    # Test 2: Prediction
    print()
    print("üîç Test 2: Prediction")
    print("-" * 40)
    
    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° test data (‡πÉ‡∏ä‡πâ scaled data)
    test_samples = X_test_wine[:3].tolist()
    
    payload = {
        "instances": test_samples
    }
    
    print(f"   üì§ Sending {len(test_samples)} samples...")
    
    response = requests.post(
        f"{base_url}/invocations",
        headers={"Content-Type": "application/json"},
        json=payload
    )
    
    print(f"   üì• Response Status: {response.status_code}")
    
    if response.status_code == 200:
        result = response.json()
        print(f"   üìä Raw output shape: {len(result['predictions'])} x {len(result['predictions'][0])}")
        
        # ‡πÅ‡∏õ‡∏•‡∏á logits ‡πÄ‡∏õ‡πá‡∏ô class predictions
        predictions = np.argmax(result['predictions'], axis=1)
        print()
        print("   üìä Prediction Results:")
        for i, pred in enumerate(predictions):
            actual = y_test_wine[i]
            status = "‚úÖ" if pred == actual else "‚ùå"
            print(f"      Sample {i+1}: {wine.target_names[pred]} (actual: {wine.target_names[actual]}) {status}")
    else:
        print(f"   ‚ùå Error: {response.text}")
    
    print()
    print("‚úÖ PyTorch API test completed!")

# ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ function ‡∏ó‡∏î‡∏™‡∏≠‡∏ö
# ‚ö†Ô∏è Uncomment ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å start server ‡πÅ‡∏•‡πâ‡∏ß
# test_pytorch_api(5002)

# %% [markdown]
# ---
# ## üìä Part 5: Load Models ‡∏à‡∏≤‡∏Å MLflow Server (Session Restart)
# ---

# %% [markdown]
# ### 5.1 ‡πÄ‡∏°‡∏∑‡πà‡∏≠ Restart Session
#
# ‡πÄ‡∏°‡∏∑‡πà‡∏≠ restart Jupyter session ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ load model ‡∏à‡∏≤‡∏Å MLflow Server ‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ:
#
# **‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: ‡πÉ‡∏ä‡πâ Run ID (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)**
# ```python
# model_uri = f"runs:/{run_id}/sklearn_model"
# model = mlflow.sklearn.load_model(model_uri)
# ```
#
# **‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: ‡πÉ‡∏ä‡πâ Registered Model Name**
# ```python
# model_uri = "models:/iris_classifier_sklearn/1"
# model = mlflow.sklearn.load_model(model_uri)
# ```
#
# **‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 3: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏≤‡∏Å MLflow Server**
# ```python
# models = find_models_by_flavor_from_server(experiment_name, "sklearn")
# model = mlflow.sklearn.load_model(models[0]['model_uri'])
# ```

# %%
# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: Reconnect ‡πÅ‡∏•‡∏∞ Load model ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å restart session
print("üîÑ Reconnect to MLflow Server After Session Restart")
print("=" * 60)

# Step 1: Reconnect to MLflow Server
MLFLOW_TRACKING_URI = "http://127.0.0.1:5000"
EXPERIMENT_NAME = "Model_Deployment_Lab"
LAB_BASE_PATH = "/home/student/workspace/mlflowserver-lab"
ARTIFACTS_PATH = f"{LAB_BASE_PATH}/mlartifacts"

mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)

print(f"üìç Connected to: {MLFLOW_TRACKING_URI}")
print(f"üìÅ Artifacts Path: {ARTIFACTS_PATH}")

# Step 2: ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• experiment
experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)
if experiment:
    print(f"üìå Experiment ID: {experiment.experiment_id}")
    
    # Step 3: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ runs ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
    print("\nüìã Recent Runs:")
    runs = client.search_runs(
        experiment_ids=[experiment.experiment_id],
        order_by=["start_time DESC"],
        max_results=5
    )
    
    for run in runs:
        print(f"   - {run.info.run_name} ({run.info.run_id[:8]}...)")
        print(f"     Status: {run.info.status}")
        print(f"     Started: {run.info.start_time}")
else:
    print("‚ö†Ô∏è Experiment not found. Please run training cells first.")

# %%
# ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏•‡∏∞ load sklearn model
print("\nüì• Loading Scikit-learn Model from Server...")
print("-" * 50)

sklearn_models = find_models_by_flavor_from_server(EXPERIMENT_NAME, flavor="sklearn")

if sklearn_models:
    # ‡πÉ‡∏ä‡πâ model ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
    latest_sklearn = sklearn_models[0]
    print(f"üì¶ Found: {latest_sklearn['run_name']}")
    print(f"   URI: {latest_sklearn['model_uri']}")
    
    sklearn_model_reloaded = mlflow.sklearn.load_model(latest_sklearn['model_uri'])
    print(f"‚úÖ Loaded: {type(sklearn_model_reloaded).__name__}")
else:
    print("‚ö†Ô∏è No sklearn models found")

# %%
# ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏•‡∏∞ load pytorch model
print("\nüì• Loading PyTorch Model from Server...")
print("-" * 50)

pytorch_models = find_models_by_flavor_from_server(EXPERIMENT_NAME, flavor="pytorch")

if pytorch_models:
    # ‡πÉ‡∏ä‡πâ model ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
    latest_pytorch = pytorch_models[0]
    print(f"üì¶ Found: {latest_pytorch['run_name']}")
    print(f"   URI: {latest_pytorch['model_uri']}")
    
    pytorch_model_reloaded = mlflow.pytorch.load_model(latest_pytorch['model_uri'])
    pytorch_model_reloaded.eval()
    print(f"‚úÖ Loaded: {type(pytorch_model_reloaded).__name__}")
else:
    print("‚ö†Ô∏è No pytorch models found")

# %% [markdown]
# ### 5.2 ‡πÅ‡∏™‡∏î‡∏á Registered Models
#
# ‡∏î‡∏π models ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà register ‡πÑ‡∏ß‡πâ‡πÉ‡∏ô Model Registry:

# %%
print("üìã Registered Models in Model Registry:")
print("=" * 60)

registered_models = list_registered_models()

if registered_models:
    for rm in registered_models:
        print(f"\nüì¶ {rm.name}")
        # ‡∏î‡∏∂‡∏á versions
        versions = client.search_model_versions(f"name='{rm.name}'")
        for v in versions:
            print(f"   Version {v.version}: {v.current_stage}")
            print(f"   Run ID: {v.run_id[:8]}...")
            print(f"   URI: models:/{rm.name}/{v.version}")
else:
    print("   No registered models found")

# %% [markdown]
# ### 5.3 Deploy Commands ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Models ‡∏à‡∏≤‡∏Å Server

# %%
print("üöÄ Deploy Commands")
print("=" * 60)

experiment_id = get_experiment_id(EXPERIMENT_NAME)

# Sklearn
sklearn_models = find_models_by_flavor_from_server(EXPERIMENT_NAME, flavor="sklearn")
if sklearn_models:
    print("\nüìã Deploy Scikit-learn Model:")
    print()
    print("   # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: Using Run URI (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ - ‡∏ú‡πà‡∏≤‡∏ô MLflow Server)")
    print(f'   mlflow models serve -m "{sklearn_models[0]["model_uri"]}" -p 5001 --no-conda')
    print()
    print("   # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: Using Registered Model")
    print('   mlflow models serve -m "models:/iris_classifier_sklearn/1" -p 5001 --no-conda')
    
    if sklearn_models[0].get('local_path'):
        print()
        print("   # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 3: Using Local Path (Direct)")
        print(f'   mlflow models serve -m "{sklearn_models[0]["local_path"]}" -p 5001 --no-conda')

# PyTorch
pytorch_models = find_models_by_flavor_from_server(EXPERIMENT_NAME, flavor="pytorch")
if pytorch_models:
    print("\nüìã Deploy PyTorch Model:")
    print()
    print("   # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: Using Run URI (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ - ‡∏ú‡πà‡∏≤‡∏ô MLflow Server)")
    print(f'   mlflow models serve -m "{pytorch_models[0]["model_uri"]}" -p 5002 --no-conda')
    print()
    print("   # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: Using Registered Model")
    print('   mlflow models serve -m "models:/wine_classifier_pytorch/1" -p 5002 --no-conda')
    
    if pytorch_models[0].get('local_path'):
        print()
        print("   # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 3: Using Local Path (Direct)")
        print(f'   mlflow models serve -m "{pytorch_models[0]["local_path"]}" -p 5002 --no-conda')

print()
print("=" * 60)
print("üí° Tips:")
print("   - ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1 (runs:/) ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏Å‡∏ß‡πà‡∏≤")
print("   - ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2 (models:/) ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ model registered ‡∏Å‡πà‡∏≠‡∏ô")
print("   - ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 3 ‡πÉ‡∏ä‡πâ local path ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ Server")
print(f"   - Artifacts ‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà: {ARTIFACTS_PATH}")

# %% [markdown]
# ---
# ## üìä Part 6: ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ
# ---

# %% [markdown]
# ### 6.1 ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Scikit-learn vs PyTorch Deployment
#
# | Feature | Scikit-learn | PyTorch |
# |---------|--------------|---------|
# | **Log Function** | `mlflow.sklearn.log_model()` | `mlflow.pytorch.log_model()` |
# | **Model Format** | pickle (.pkl) | PyTorch state dict |
# | **Flavor** | sklearn, pyfunc | pytorch, pyfunc |
# | **Input Format** | DataFrame, numpy | Tensor, numpy |
# | **Output** | Direct predictions | Logits (need argmax) |
# | **Preprocessing** | Built into model | May need separate |
# | **Serve Command** | Same | Same |

# %% [markdown]
# ### 6.2 ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Model URI Formats
#
# | URI Format | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á | ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö | ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏ |
# |------------|---------|-----------|----------|
# | `runs:/` | `runs:/{run_id}/sklearn_model` | load_model, download_artifacts | **‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥** - ‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î |
# | `models:/` | `models:/iris_classifier/1` | load_model | ‡∏ï‡πâ‡∏≠‡∏á register model ‡∏Å‡πà‡∏≠‡∏ô |
# | Local path | `/path/to/model` | load_model, serve | ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ Server |

# %% [markdown]
# ### 6.3 ‡∏™‡∏£‡∏∏‡∏õ Model URIs ‡πÅ‡∏•‡∏∞ Paths
#
# ‡∏£‡∏±‡∏ô cell ‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π Model URIs ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î:

# %%
print("üìã Summary of Logged Models")
print("=" * 60)

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ variables ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
try:
    print()
    print("üå≤ Scikit-learn Model (Iris Classification):")
    print(f"   Run ID: {sklearn_run_id}")
    print(f"   Model URI (runs:/): {sklearn_model_uri}")
    print(f"   Registered Name: iris_classifier_sklearn")
    print(f"   Registered URI: models:/iris_classifier_sklearn/1")
except NameError:
    print("‚ö†Ô∏è Sklearn model variables not found. Run training cells first.")

try:
    print()
    print("üî• PyTorch Model (Wine Classification):")
    print(f"   Run ID: {pytorch_run_id}")
    print(f"   Model URI (runs:/): {pytorch_model_uri}")
    print(f"   Registered Name: wine_classifier_pytorch")
    print(f"   Registered URI: models:/wine_classifier_pytorch/1")
except NameError:
    print("‚ö†Ô∏è PyTorch model variables not found. Run training cells first.")

print()
print("=" * 60)
print("üìÅ File Locations:")
print(f"   Lab Base: {LAB_BASE_PATH}")
print(f"   Artifacts: {ARTIFACTS_PATH}")
print(f"   Database: {MLRUNS_DB_PATH}/mlflow.db")

print()
print("=" * 60)
print("üöÄ Deploy Commands:")
print()
print("# Using Run URI (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥):")
try:
    print(f'mlflow models serve -m "{sklearn_model_uri}" -p 5001 --no-conda')
    print(f'mlflow models serve -m "{pytorch_model_uri}" -p 5002 --no-conda')
except NameError:
    print("# Run training cells first to get model URIs")
print()
print("# Using Registered Model:")
print('mlflow models serve -m "models:/iris_classifier_sklearn/1" -p 5001 --no-conda')
print('mlflow models serve -m "models:/wine_classifier_pytorch/1" -p 5002 --no-conda')
print()
print("=" * 60)
print("üåê MLflow UI: http://127.0.0.1:5000")

# %% [markdown]
# ### 6.4 Best Practices ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Production
#
# **1. ‡πÉ‡∏ä‡πâ `runs:/` URI ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö download_artifacts:**
# ```python
# # ‚úÖ ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ - ‡πÉ‡∏ä‡πâ runs:/ URI
# mlmodel_path = mlflow.artifacts.download_artifacts(f"runs:/{run_id}/model/MLmodel")
#
# # ‚ö†Ô∏è ‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ - ‡πÉ‡∏ä‡πâ models:/ URI
# mlmodel_path = mlflow.artifacts.download_artifacts(f"models:/my_model/1/MLmodel")
# ```
#
# **2. ‡πÉ‡∏ä‡πâ Model Signature ‡πÄ‡∏™‡∏°‡∏≠:**
# ```python
# signature = infer_signature(X_train, model.predict(X_train))
# mlflow.sklearn.log_model(model, "model", signature=signature)
# ```
#
# **3. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Input Example:**
# - ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏ó‡∏î‡∏™‡∏≠‡∏ö model ‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢
# - ‡πÄ‡∏õ‡πá‡∏ô documentation ‡πÉ‡∏´‡πâ‡∏Ñ‡∏ô‡∏≠‡∏∑‡πà‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à input format
#
# **4. ‡πÉ‡∏ä‡πâ Model Registry:**
# - Version control ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö models
# - Stage transitions (Staging ‚Üí Production)
# - Model lineage tracking
#
# **5. Containerization:**
# ```bash
# # Build Docker image
# mlflow models build-docker -m "runs:/{run_id}/model" -n my_model_image
#
# # Run container
# docker run -p 5001:8080 my_model_image
# ```
#
# **6. Environment Management:**
# - ‡πÉ‡∏ä‡πâ conda.yaml ‡∏´‡∏£‡∏∑‡∏≠ requirements.txt
# - Pin dependency versions
# - Test ‡πÉ‡∏ô isolated environment

# %% [markdown]
# ---
# ## üéØ Part 7: ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î (Exercises)
# ---

# %% [markdown]
# ### Exercise 1: Deploy Logistic Regression Model
#
# **Task:** Train ‡πÅ‡∏•‡∏∞ Deploy Logistic Regression model ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Iris dataset
#
# **Steps:**
# 1. Train LogisticRegression model
# 2. Log ‡∏•‡∏á MLflow ‡∏û‡∏£‡πâ‡∏≠‡∏° signature
# 3. Deploy ‡πÄ‡∏õ‡πá‡∏ô REST API ‡∏ö‡∏ô port 5003
# 4. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ requests

# %%
# TODO: ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô code ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà
# Hint: ‡πÉ‡∏ä‡πâ LogisticRegression() ‡∏à‡∏≤‡∏Å sklearn.linear_model

# Your code here:
# ...

# %% [markdown]
# ### Exercise 2: Custom PyTorch Model
#
# **Task:** ‡∏™‡∏£‡πâ‡∏≤‡∏á Neural Network ‡∏ó‡∏µ‡πà‡∏°‡∏µ architecture ‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
#
# **Requirements:**
# - ‡πÄ‡∏û‡∏¥‡πà‡∏° layer ‡πÄ‡∏õ‡πá‡∏ô 4 hidden layers
# - ‡πÉ‡∏ä‡πâ BatchNormalization
# - Log ‡∏•‡∏á MLflow ‡πÅ‡∏•‡∏∞ deploy

# %%
# TODO: ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô code ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà

# Your code here:
# ...

# %% [markdown]
# ### Exercise 3: Batch Prediction API
#
# **Task:** ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô function ‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á batch prediction ‡πÑ‡∏õ‡∏¢‡∏±‡∏á API
#
# **Requirements:**
# - ‡∏£‡∏±‡∏ö DataFrame ‡πÄ‡∏õ‡πá‡∏ô input
# - ‡∏™‡πà‡∏á request ‡πÑ‡∏õ API
# - Return predictions ‡∏û‡∏£‡πâ‡∏≠‡∏° class names

# %%
def batch_predict(df, api_url, class_names):
    """
    ‡∏™‡πà‡∏á batch prediction ‡πÑ‡∏õ‡∏¢‡∏±‡∏á MLflow serving API
    
    Args:
        df: pandas DataFrame ‡∏ó‡∏µ‡πà‡∏°‡∏µ features
        api_url: URL ‡∏Ç‡∏≠‡∏á API (e.g., "http://127.0.0.1:5001/invocations")
        class_names: list ‡∏Ç‡∏≠‡∏á‡∏ä‡∏∑‡πà‡∏≠ classes
    
    Returns:
        DataFrame ‡∏û‡∏£‡πâ‡∏≠‡∏° predictions
    """
    # TODO: Implement this function
    pass

# Test your function:
# result = batch_predict(X_test.head(10), "http://127.0.0.1:5001/invocations", iris.target_names)
# print(result)

# %% [markdown]
# ---
# ## üìö Part 8: References ‡πÅ‡∏•‡∏∞‡πÅ‡∏´‡∏•‡πà‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
# ---
#
# **Official Documentation:**
# - [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
# - [MLflow Models](https://mlflow.org/docs/latest/models.html)
# - [MLflow Model Serving](https://mlflow.org/docs/latest/deployment/index.html)
#
# **Tutorials:**
# - [MLflow Quickstart](https://mlflow.org/docs/latest/getting-started/index.html)
# - [Deploy Models with MLflow](https://mlflow.org/docs/latest/deployment/deploy-model-locally.html)
#
# **Advanced Topics:**
# - Docker deployment
# - Kubernetes deployment
# - Cloud deployment (AWS SageMaker, Azure ML, GCP)
# - Model monitoring ‡πÅ‡∏•‡∏∞ A/B testing

# %% [markdown]
# ---
# ## ‚úÖ Checklist ‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á‡∏á‡∏≤‡∏ô
#
# - [ ] ‡∏£‡∏±‡∏ô notebook ‡∏à‡∏ô‡∏à‡∏ö‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏°‡∏µ error
# - [ ] Log models ‡∏ó‡∏±‡πâ‡∏á Scikit-learn ‡πÅ‡∏•‡∏∞ PyTorch ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
# - [ ] Deploy ‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö REST API ‡πÑ‡∏î‡πâ
# - [ ] ‡∏ó‡∏≥‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 1 ‡∏Ç‡πâ‡∏≠
# - [ ] ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á sklearn ‡πÅ‡∏•‡∏∞ pytorch deployment
#
# ---
#
# **üéâ ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏î‡πâ‡∏ß‡∏¢! ‡∏Ñ‡∏∏‡∏ì‡∏à‡∏ö Lab ‡∏ô‡∏µ‡πâ‡πÅ‡∏•‡πâ‡∏ß!**
#
# ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ:
# - Log ‡πÅ‡∏•‡∏∞ Deploy ML models ‡∏î‡πâ‡∏ß‡∏¢ MLflow
# - ‡∏™‡∏£‡πâ‡∏≤‡∏á REST API ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö model inference
# - ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à Model Signature ‡πÅ‡∏•‡∏∞ Input Format
# - ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏≤‡∏£ deploy ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á frameworks ‡∏ï‡πà‡∏≤‡∏á‡πÜ
