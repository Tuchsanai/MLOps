# üìù ‡∏Å‡∏≤‡∏£‡∏ö‡πâ‡∏≤‡∏ô: MLflow Model Registry

**‡∏ß‡∏¥‡∏ä‡∏≤:** Machine Learning Operations (MLOps)  
**‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠:** MLflow Model Registry

---

## üìã ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ

1. ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ö‡πâ‡∏≤‡∏ô‡πÉ‡∏ô Jupyter Notebook ‡∏´‡∏£‡∏∑‡∏≠ Python script
2. MLflow Server ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏±‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà `http://127.0.0.1:5000`
3. ‡πÉ‡∏™‡πà‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏• ‡πÅ‡∏•‡∏∞‡∏£‡∏´‡∏±‡∏™‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á

### üì§ ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ TA ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö
- ‡πÑ‡∏ü‡∏•‡πå code (.ipynb ‡∏´‡∏£‡∏∑‡∏≠ .py) ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô
- Screenshot ‡∏´‡∏ô‡πâ‡∏≤ MLflow UI ‡πÅ‡∏™‡∏î‡∏á Registered Model ‡πÅ‡∏•‡∏∞ Versions
- ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö accuracy ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ Model Version

---

## üìö ‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà 1: Wine Quality Classification Model Registry

### üéØ ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå
‡∏ù‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ MLflow Model Registry ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Wine Quality ‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£ train ‡∏´‡∏•‡∏≤‡∏¢ models, ‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤ Registry, ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ versions ‡πÅ‡∏•‡∏∞ aliases

### üìñ ‡πÇ‡∏à‡∏ó‡∏¢‡πå

‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÑ‡∏ß‡∏ô‡πå (Wine Quality Classification) ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ MLflow Model Registry ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏•‡∏≤‡∏¢‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô

**‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥:**

1. **Train Model 3 Versions**
   - Version 1: `DecisionTreeClassifier` (baseline)
   - Version 2: `RandomForestClassifier` (n_estimators=100)
   - Version 3: `GradientBoostingClassifier` (n_estimators=100)
   
2. **‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô Models ‡πÄ‡∏Ç‡πâ‡∏≤ Registry**
   - ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠ Registered Model: `wine-quality-classifier`
   - ‡πÄ‡∏û‡∏¥‡πà‡∏° Description ‡∏ó‡∏µ‡πà‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
   - ‡πÄ‡∏û‡∏¥‡πà‡∏° Tags ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Registered Model: `task`, `dataset`, `team`
   - ‡πÄ‡∏û‡∏¥‡πà‡∏° Tags ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ Version: `model_type`, `status`

3. **‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Aliases**
   - ‡∏Å‡∏≥‡∏´‡∏ô‡∏î `baseline` alias ‡πÉ‡∏´‡πâ Version 1
   - ‡∏Å‡∏≥‡∏´‡∏ô‡∏î `staging` alias ‡πÉ‡∏´‡πâ Version ‡∏ó‡∏µ‡πà‡∏°‡∏µ accuracy ‡∏™‡∏π‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö 2
   - ‡∏Å‡∏≥‡∏´‡∏ô‡∏î `champion` alias ‡πÉ‡∏´‡πâ Version ‡∏ó‡∏µ‡πà‡∏°‡∏µ accuracy ‡∏™‡∏π‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î

4. **‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö Models**
   - ‡πÇ‡∏´‡∏•‡∏î champion model ‡∏à‡∏≤‡∏Å Registry
   - ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• test set 10 ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
   - ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• predictions ‡πÅ‡∏•‡∏∞ actual values

### üîß Code ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô

```python
# === ‡∏Å‡∏≤‡∏£‡∏ö‡πâ‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà 1: Wine Quality Classification ===
# ‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•: _______________
# ‡∏£‡∏´‡∏±‡∏™‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤: _______________

import mlflow
from mlflow.tracking import MlflowClient
from sklearn.datasets import load_wine
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, f1_score
from mlflow.models import infer_signature
import numpy as np

# === Setup ===
MLFLOW_TRACKING_URI = "http://127.0.0.1:5000"
mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
client = MlflowClient()

# === ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Wine Quality ===
wine = load_wine()
X_train, X_test, y_train, y_test = train_test_split(
    wine.data, wine.target, test_size=0.2, random_state=42
)

print(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Wine Quality ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
print(f"üìä Training samples: {len(X_train)}")
print(f"üìä Test samples: {len(X_test)}")
print(f"üìä Features: {wine.feature_names}")
print(f"üìä Classes: {wine.target_names}")

# === ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏∑‡πà‡∏≠ Registered Model ===
MODEL_NAME = "wine-quality-classifier"

# === ‡∏™‡∏£‡πâ‡∏≤‡∏á Experiment ===
mlflow.set_experiment("wine-quality-homework")

# TODO: ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô code ‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ
# 1. Train ‡πÅ‡∏•‡∏∞‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô Model Version 1 (DecisionTree)
# 2. Train ‡πÅ‡∏•‡∏∞‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô Model Version 2 (RandomForest)
# 3. Train ‡πÅ‡∏•‡∏∞‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô Model Version 3 (GradientBoosting)
# 4. ‡πÄ‡∏û‡∏¥‡πà‡∏° Description ‡πÅ‡∏•‡∏∞ Tags
# 5. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Aliases
# 6. ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö Champion Model

```

---

## üìö ‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà 2: PyTorch MNIST Digit Classifier with Model Registry

### üéØ ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå
‡∏ù‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ MLflow Model Registry ‡∏Å‡∏±‡∏ö PyTorch Neural Network ‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£ train ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç MNIST ‡∏´‡∏•‡∏≤‡∏¢‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ú‡πà‡∏≤‡∏ô Registry

### üìñ ‡πÇ‡∏à‡∏ó‡∏¢‡πå

‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏•‡∏≤‡∏¢‡∏°‡∏∑‡∏≠‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô (MNIST Digit Classification) ‡∏î‡πâ‡∏ß‡∏¢ PyTorch ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ MLflow Model Registry ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÇ‡∏°‡πÄ‡∏î‡∏•

**‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥:**

1. **‡∏™‡∏£‡πâ‡∏≤‡∏á Neural Network Architecture**
   - ‡∏™‡∏£‡πâ‡∏≤‡∏á class `DigitClassifier` ‡∏ó‡∏µ‡πà‡∏™‡∏∑‡∏ö‡∏ó‡∏≠‡∏î‡∏à‡∏≤‡∏Å `nn.Module`
   - ‡∏£‡∏±‡∏ö parameter `hidden_size` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ç‡∏ô‡∏≤‡∏î hidden layer
   - Input: 64 features (8x8 image flattened)
   - Output: 10 classes (digits 0-9)

2. **Train Model 2 Versions**
   - Version 1: `hidden_size=32`, `epochs=50` (baseline)
   - Version 2: `hidden_size=64`, `epochs=100` (improved)
   - ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å parameters, metrics (accuracy, loss)
   - ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å training loss ‡∏ó‡∏∏‡∏Å 10 epochs

3. **‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Models**
   - ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠ Registered Model: `mnist-digit-classifier`
   - ‡πÄ‡∏û‡∏¥‡πà‡∏° Description ‡πÅ‡∏•‡∏∞ Tags ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
   - ‡∏Å‡∏≥‡∏´‡∏ô‡∏î `baseline` alias ‡πÉ‡∏´‡πâ Version 1
   - ‡∏Å‡∏≥‡∏´‡∏ô‡∏î `champion` alias ‡πÉ‡∏´‡πâ Version ‡∏ó‡∏µ‡πà‡∏°‡∏µ accuracy ‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤

4. **‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Models**
   - ‡πÇ‡∏´‡∏•‡∏î‡∏ó‡∏±‡πâ‡∏á baseline ‡πÅ‡∏•‡∏∞ champion models
   - ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö accuracy ‡∏Ç‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á 2 versions
   - ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• predictions ‡∏Ç‡∏≠‡∏á champion model ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 5 ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á

### üîß Code ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô

```python
# === ‡∏Å‡∏≤‡∏£‡∏ö‡πâ‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà 2: PyTorch MNIST Digit Classifier ===
# ‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•: _______________
# ‡∏£‡∏´‡∏±‡∏™‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤: _______________

import mlflow
from mlflow.tracking import MlflowClient
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from mlflow.models import infer_signature
import torch
import torch.nn as nn
import numpy as np

# === Setup ===
MLFLOW_TRACKING_URI = "http://127.0.0.1:5000"
mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
client = MlflowClient()

# === ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• MNIST Digits (8x8) ===
digits = load_digits()
X = digits.data.astype('float32')  # (1797, 64)
y = digits.target  # 0-9

# Normalize
X = X / 16.0  # Max value is 16

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• MNIST Digits ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
print(f"üìä Training samples: {len(X_train)}")
print(f"üìä Test samples: {len(X_test)}")
print(f"üìä Input shape: {X_train.shape[1]} features (8x8 image flattened)")
print(f"üìä Classes: 0-9 (10 digits)")

# === ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏∑‡πà‡∏≠ Registered Model ===
MODEL_NAME = "mnist-digit-classifier"

# === ‡∏™‡∏£‡πâ‡∏≤‡∏á Experiment ===
mlflow.set_experiment("mnist-digit-homework")

# TODO: ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô code ‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ
# 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á class DigitClassifier(nn.Module)
# 2. Train ‡πÅ‡∏•‡∏∞‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô Model Version 1 (hidden_size=32)
# 3. Train ‡πÅ‡∏•‡∏∞‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô Model Version 2 (hidden_size=64)
# 4. ‡πÄ‡∏û‡∏¥‡πà‡∏° Description, Tags ‡πÅ‡∏•‡∏∞ Aliases
# 5. ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Models

# === ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Neural Network Structure ===
class DigitClassifier(nn.Module):
    def __init__(self, input_size=64, hidden_size=32, num_classes=10):
        super(DigitClassifier, self).__init__()
        # TODO: ‡∏Å‡∏≥‡∏´‡∏ô‡∏î layers
        # Hint: ‡πÉ‡∏ä‡πâ nn.Linear, nn.ReLU
        # self.fc1 = nn.Linear(input_size, hidden_size)
        # self.relu = nn.ReLU()
        # self.fc2 = nn.Linear(hidden_size, num_classes)
        pass
    
    def forward(self, x):
        # TODO: ‡∏Å‡∏≥‡∏´‡∏ô‡∏î forward pass
        # out = self.fc1(x)
        # out = self.relu(out)
        # out = self.fc2(out)
        # return out
        pass

# === ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Model ‡πÅ‡∏•‡∏∞ Train ===
# model_v1 = DigitClassifier(hidden_size=16)  # TODO: ‡πÅ‡∏Å‡πâ hidden_size ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏°‡πÇ‡∏à‡∏ó‡∏¢‡πå
# loss_history = train_pytorch_model(model_v1, X_train, y_train, epochs=30, learning_rate=0.01)  # TODO: ‡πÅ‡∏Å‡πâ epochs ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏°‡πÇ‡∏à‡∏ó‡∏¢‡πå

# === Helper Function ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Training ===
def train_pytorch_model(model, X_train, y_train, epochs=50, learning_rate=0.01):
    """
    Train PyTorch model ‡πÅ‡∏•‡∏∞ return loss history
    """
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
    
    X_tensor = torch.FloatTensor(X_train)
    y_tensor = torch.LongTensor(y_train)
    
    loss_history = []
    
    for epoch in range(epochs):
        # Forward pass
        outputs = model(X_tensor)
        loss = criterion(outputs, y_tensor)
        
        # Backward pass
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å loss ‡∏ó‡∏∏‡∏Å 10 epochs
        if (epoch + 1) % 10 == 0:
            loss_history.append((epoch + 1, loss.item()))
            print(f"   Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}")
    
    return loss_history

# === Helper Function ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Evaluation ===
def evaluate_pytorch_model(model, X_test, y_test):
    """
    Evaluate PyTorch model ‡πÅ‡∏•‡∏∞ return accuracy
    """
    model.eval()
    with torch.no_grad():
        X_tensor = torch.FloatTensor(X_test)
        outputs = model(X_tensor)
        _, predicted = torch.max(outputs.data, 1)
        accuracy = (predicted.numpy() == y_test).sum() / len(y_test)
    return accuracy, predicted.numpy()

```

---

## üí° ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°

### ‡∏Å‡∏≤‡∏£ Log Model ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô
```python
mlflow.sklearn.log_model(
    sk_model=model,
    artifact_path="model",
    signature=signature,
    registered_model_name="model-name"  # ‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
)
```

### ‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏° Description ‡πÅ‡∏•‡∏∞ Tags
```python
client.update_registered_model(name="model-name", description="...")
client.set_registered_model_tag("model-name", "key", "value")
client.update_model_version(name="model-name", version="1", description="...")
client.set_model_version_tag("model-name", "1", "key", "value")
```

### ‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏´‡∏ô‡∏î Aliases
```python
client.set_registered_model_alias(name="model-name", alias="champion", version="1")
```

### ‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î Model ‡∏à‡∏≤‡∏Å Alias
```python
model = mlflow.sklearn.load_model(f"models:/model-name@champion")
# ‡∏´‡∏£‡∏∑‡∏≠
model = mlflow.pytorch.load_model(f"models:/model-name@champion")
```



---

**üîó MLflow Server URL:** http://127.0.0.1:5000

**‡∏Ç‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏ä‡∏Ñ‡∏î‡∏µ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ö‡πâ‡∏≤‡∏ô! üéì**