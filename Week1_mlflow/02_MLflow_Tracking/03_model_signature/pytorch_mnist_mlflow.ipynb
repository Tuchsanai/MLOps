{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c2f6cdb",
   "metadata": {},
   "source": [
    "\n",
    "# PyTorch CNN + MLflow (MNIST) — End‑to‑End Demo\n",
    "\n",
    "This notebook trains a simple CNN on MNIST, logs metrics and the model to **MLflow** (with an **input/output signature**), and then loads the logged model back via `mlflow.pyfunc` for inference.\n",
    "\n",
    "> **Tracking URI:** `http://127.0.0.1:8080` (adjust if your MLflow server runs elsewhere).  \n",
    "> If your MLflow **Model Registry** is not configured, the notebook will **gracefully fall back** to logging without registering the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ad17d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ## 0) Install (if needed)\n",
    "# If you're running in a fresh environment, uncomment and run:\n",
    "# !pip install torch torchvision mlflow numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e30d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from mlflow.models import infer_signature\n",
    "import numpy as np\n",
    "\n",
    "# Reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Point to your MLflow Tracking Server\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "print(\"MLflow Tracking URI ->\", mlflow.get_tracking_uri())\n",
    "\n",
    "# (Optional) Choose/declare an experiment name for clarity\n",
    "mlflow.set_experiment(\"MNIST_CNN_MLflow_Demo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd246a5",
   "metadata": {},
   "source": [
    "## 1) Define a simple CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe868bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))  # (N, 32, 14, 14)\n",
    "        x = self.pool(self.relu(self.conv2(x)))  # (N, 64, 7, 7)\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfc5aee",
   "metadata": {},
   "source": [
    "## 2) Data preparation (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177211b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "def prepare_data(batch_size=64):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    \n",
    "    train_dataset = datasets.MNIST(\n",
    "        root='./data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    test_dataset = datasets.MNIST(\n",
    "        root='./data',\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07eabea0",
   "metadata": {},
   "source": [
    "## 3) Training & Evaluation helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a600bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "def train_model(model, train_loader, criterion, optimizer, device, epochs=2, log_every=100):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if (i + 1) % log_every == 0:\n",
    "                avg_loss = running_loss / log_every\n",
    "                print(f'Epoch [{epoch+1}/{epochs}], Step [{i+1}], Loss: {avg_loss:.4f}')\n",
    "                # Log iterative loss to MLflow\n",
    "                mlflow.log_metric(\"train_loss\", avg_loss, step=epoch * len(train_loader) + i + 1)\n",
    "                running_loss = 0.0\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100.0 * correct / total\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a4faf7",
   "metadata": {},
   "source": [
    "## 4) Train, Log to MLflow (with Signature), and Reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b18c7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "def main():\n",
    "    # Device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Data\n",
    "    print(\"Preparing data...\")\n",
    "    train_loader, test_loader = prepare_data(batch_size=64)\n",
    "    \n",
    "    with mlflow.start_run(run_name=\"pytorch_image_classification\"):\n",
    "        # Hyperparameters\n",
    "        lr = 1e-3\n",
    "        epochs = 2\n",
    "        num_classes = 10\n",
    "        \n",
    "        # Log parameters\n",
    "        mlflow.log_param(\"learning_rate\", lr)\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.log_param(\"model_type\", \"SimpleCNN\")\n",
    "        mlflow.log_param(\"optimizer\", \"Adam\")\n",
    "        \n",
    "        # Model / loss / optimizer\n",
    "        model = SimpleCNN(num_classes=num_classes).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "        # Train\n",
    "        print(\"Training model...\")\n",
    "        train_model(model, train_loader, criterion, optimizer, device, epochs=epochs, log_every=100)\n",
    "        \n",
    "        # Evaluate\n",
    "        print(\"Evaluating model...\")\n",
    "        accuracy = evaluate_model(model, test_loader, device)\n",
    "        print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "        mlflow.log_metric(\"test_accuracy\", accuracy)\n",
    "        \n",
    "        # Signature: create a single-sample input and corresponding output\n",
    "        sample_batch = next(iter(test_loader))\n",
    "        sample_input = sample_batch[0][:1].numpy()  # shape (1, 1, 28, 28)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            sample_output = model(torch.tensor(sample_input).to(device))\n",
    "            sample_output = sample_output.cpu().numpy()  # shape (1, 10)\n",
    "        \n",
    "        signature = infer_signature(sample_input, sample_output)\n",
    "        \n",
    "        # Try to register; if registry not configured, fall back to plain log\n",
    "        print(\"Logging model to MLflow...\")\n",
    "        model_info = None\n",
    "        try:\n",
    "            model_info = mlflow.pytorch.log_model(\n",
    "                pytorch_model=model,\n",
    "                artifact_path=\"model\",\n",
    "                signature=signature,\n",
    "                input_example=sample_input,\n",
    "                registered_model_name=\"pytorch_mnist_classifier\"\n",
    "            )\n",
    "            print(\"✔ Model logged and registered as 'pytorch_mnist_classifier'.\")\n",
    "        except Exception as e:\n",
    "            print(\"⚠ Registry not available or other issue:\", e)\n",
    "            print(\"→ Falling back to logging without registration...\")\n",
    "            model_info = mlflow.pytorch.log_model(\n",
    "                pytorch_model=model,\n",
    "                artifact_path=\"model\",\n",
    "                signature=signature,\n",
    "                input_example=sample_input\n",
    "            )\n",
    "            print(\"✔ Model logged (unregistered).\")\n",
    "        \n",
    "        run_id = mlflow.active_run().info.run_id\n",
    "        print(f\"Run ID: {run_id}\")\n",
    "        print(f\"Model URI: {model_info.model_uri}\")\n",
    "        \n",
    "        # Test loading via PyFunc\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"Testing model loading...\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "        \n",
    "        test_input = sample_input\n",
    "        prediction = loaded_model.predict(test_input)  # (1, 10)\n",
    "        \n",
    "        print(f\"Test input shape: {test_input.shape}\")\n",
    "        print(f\"Prediction shape: {prediction.shape}\")\n",
    "        print(f\"Predicted class: {int(np.argmax(prediction[0]))}\")\n",
    "        print(f\"Prediction logits (first 5): {prediction[0][:5]}\")\n",
    "        \n",
    "        print(\"\\n✓ Model successfully logged and loaded!\")\n",
    "        print(f\"✓ MLflow UI: {mlflow.get_tracking_uri()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c08741",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Tips & Troubleshooting\n",
    "\n",
    "- **Model Registry not configured?**  \n",
    "  If your MLflow server does not have a backend store/registry set up, the registration step will fail; this notebook automatically falls back to logging the model without registering it.\n",
    "\n",
    "- **Can't reach MLflow at `http://127.0.0.1:8080`?**  \n",
    "  Make sure your MLflow server is running, e.g.:\n",
    "  ```bash\n",
    "  pkill -f \"mlflow server\" || true\n",
    "  mlflow server --host 127.0.0.1 --port 8080 --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns\n",
    "  ```\n",
    "\n",
    "- **GPU not available?**  \n",
    "  The code will automatically run on CPU. Training MNIST still finishes quickly.\n",
    "\n",
    "- **Dataset download blocked?**  \n",
    "  Ensure your environment has internet access to download MNIST on first run. Subsequent runs will use cached data in `./data`.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
