services:
  mlflow:
    image: ghcr.io/mlflow/mlflow:v3.8.1
    container_name: mlflow-server
    volumes:
      - ./mlflow-data/mlruns:/mlflow/mlruns
      - ./mlflow-data/mlartifacts:/mlflow/mlartifacts
    command: >
      mlflow server
      --host 0.0.0.0
      --port 8080
      --backend-store-uri sqlite:////mlflow/mlruns/mlflow.db
      --default-artifact-root /mlflow/mlartifacts
    restart: unless-stopped
    networks:
      - mlops-network

  mlflow-proxy:
    image: nginx:alpine
    container_name: mlflow-proxy
    ports:
      - "8080:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - mlflow
    restart: unless-stopped
    networks:
      - mlops-network

  mlops:
    image: tuchsanai/mlops_2568_2:latest
    container_name: mlops-container
    ports:
      - "8888:8888"
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow-proxy:80
    command: >
      bash -c "
        cd /home/student/workspace &&
        git clone -b dev https://github.com/Tuchsanai/MLOps.git || true &&
        jupyter lab --ip=0.0.0.0 --port=8888 --no-browser --IdentityProvider.token=mlops
      "
    restart: unless-stopped
    depends_on:
      - mlflow-proxy
    networks:
      - mlops-network

networks:
  mlops-network:
    driver: bridge