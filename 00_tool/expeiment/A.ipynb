{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d3e7a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "response = {\n",
    "  \"id\": \"msg_01SQxKnt4JPv29XtmxdFrby8\",\n",
    "  \"type\": \"message\",\n",
    "  \"role\": \"assistant\",\n",
    "  \"model\": \"claude-opus-4-5-20251101\",\n",
    "  \"content\": [\n",
    "    {\n",
    "      \"type\": \"text\",\n",
    "      \"text\": \"# ğŸ“š Data Drift Detection: Complete Guide for MLOps\\n\\n## à¸ªà¸²à¸£à¸šà¸±à¸\\n1. [à¸šà¸—à¸™à¸³: à¸—à¸³à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆ Data Drift](#à¸šà¸—à¸™à¸³-à¸—à¸³à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆ-data-drift)\\n2. [LAB 1: Understanding Data Drift Concepts](#lab-1-understanding-data-drift-concepts)\\n3. [LAB 2: Feature Drift Detection](#lab-2-feature-drift-detection)\\n4. [LAB 3: Multivariate Drift Analysis](#lab-3-multivariate-drift-analysis)\\n5. [LAB 4: Drift Detection in Production Simulation](#lab-4-drift-detection-in-production-simulation)\\n6. [LAB 5: Custom Metrics & Drift Thresholds](#lab-5-custom-metrics--drift-thresholds)\\n7. [LAB 6: End-to-End Monitoring Pipeline](#lab-6-end-to-end-monitoring-pipeline)\\n8. [à¸ªà¸£à¸¸à¸›à¹à¸¥à¸° Best Practices](#à¸ªà¸£à¸¸à¸›à¹à¸¥à¸°-best-practices)\\n\\n---\\n\\n## à¸šà¸—à¸™à¸³: à¸—à¸³à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆ Data Drift\\n\\n### Data Drift à¸„à¸·à¸­à¸­à¸°à¹„à¸£?\\n\\n**Data Drift** (à¸«à¸£à¸·à¸­ Dataset Shift) à¸„à¸·à¸­à¸›à¸£à¸²à¸à¸à¸à¸²à¸£à¸“à¹Œà¸—à¸µà¹ˆà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¸£à¸°à¸šà¸š production à¸¡à¸µà¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¹„à¸›à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰ train à¹‚à¸¡à¹€à¸”à¸¥ à¸‹à¸¶à¹ˆà¸‡à¹€à¸›à¹‡à¸™à¸«à¸™à¸¶à¹ˆà¸‡à¹ƒà¸™à¸ªà¸²à¹€à¸«à¸•à¸¸à¸«à¸¥à¸±à¸à¸—à¸µà¹ˆà¸—à¸³à¹ƒà¸«à¹‰ ML Model à¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸à¸¥à¸”à¸¥à¸‡à¹€à¸¡à¸·à¹ˆà¸­à¹€à¸§à¸¥à¸²à¸œà¹ˆà¸²à¸™à¹„à¸›\\n\\n```\\nTraining Time                    Production Time\\n     â”‚                                â”‚\\n     â–¼                                â–¼\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\\nâ”‚ Training    â”‚               â”‚ Production  â”‚\\nâ”‚ Data        â”‚â”€â”€â”€â”€ Drift â”€â”€â”€â–¶â”‚ Data        â”‚\\nâ”‚ P(X,Y)_trainâ”‚               â”‚ P(X,Y)_prod â”‚\\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n     â”‚                                â”‚\\n     â–¼                                â–¼\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\\nâ”‚ Good Model  â”‚               â”‚ Degraded    â”‚\\nâ”‚ Performance â”‚               â”‚ Performance â”‚\\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n```\\n\\n### à¸—à¸³à¹„à¸¡ Drift Detection à¸–à¸¶à¸‡à¸ªà¸³à¸„à¸±à¸?\\n\\n1. **Model Degradation**: à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸µà¹ˆ train à¸”à¹‰à¸§à¸¢à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸à¹ˆà¸²à¸­à¸²à¸ˆà¸—à¸³à¸™à¸²à¸¢à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¸à¸±à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¸¡à¹ˆ\\n2. **Business Impact**: à¸à¸²à¸£à¸•à¸±à¸”à¸ªà¸´à¸™à¹ƒà¸ˆà¸œà¸´à¸”à¸à¸¥à¸²à¸”à¸ªà¹ˆà¸‡à¸œà¸¥à¸•à¹ˆà¸­à¸˜à¸¸à¸£à¸à¸´à¸ˆà¹‚à¸”à¸¢à¸•à¸£à¸‡\\n3. **Regulatory Compliance**: à¸«à¸¥à¸²à¸¢à¸­à¸¸à¸•à¸ªà¸²à¸«à¸à¸£à¸£à¸¡à¸•à¹‰à¸­à¸‡à¸à¸²à¸£ monitoring à¸­à¸¢à¹ˆà¸²à¸‡à¸•à¹ˆà¸­à¹€à¸™à¸·à¹ˆà¸­à¸‡\\n4. **Resource Optimization**: à¸£à¸¹à¹‰à¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡ retrain à¸Šà¹ˆà¸§à¸¢à¸›à¸£à¸°à¸«à¸¢à¸±à¸”à¸—à¸£à¸±à¸à¸¢à¸²à¸à¸£\\n\\n---\\n\\n## LAB 1: Understanding Data Drift Concepts\\n\\n### ğŸ¯ à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ\\n- à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸„à¸§à¸²à¸¡à¹à¸•à¸à¸•à¹ˆà¸²à¸‡à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ Covariate Shift à¹à¸¥à¸° Concept Drift\\n- à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰ Statistical tests à¸ªà¸³à¸«à¸£à¸±à¸š drift detection\\n- à¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸¥à¸·à¸­à¸ drift detection method à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡\\n\\n### à¸—à¸¤à¸©à¸à¸µ: à¸›à¸£à¸°à¹€à¸ à¸—à¸‚à¸­à¸‡ Data Drift\\n\\n#### 1. Covariate Shift (Feature Drift)\\n\\n**à¸™à¸´à¸¢à¸²à¸¡**: à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸‚à¸­à¸‡ distribution à¸‚à¸­à¸‡ input features P(X) à¹‚à¸”à¸¢à¸—à¸µà¹ˆà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œ P(Y|X) à¸¢à¸±à¸‡à¸„à¸‡à¹€à¸”à¸´à¸¡\\n\\n```\\nCovariate Shift:\\nâ”œâ”€â”€ P(X)_train â‰  P(X)_prod     â† Distribution à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™\\nâ””â”€â”€ P(Y|X)_train = P(Y|X)_prod  â† Relationship à¸„à¸‡à¹€à¸”à¸´à¸¡\\n```\\n\\n**à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¹ƒà¸™à¸Šà¸µà¸§à¸´à¸•à¸ˆà¸£à¸´à¸‡**:\\n- à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸³à¸™à¸²à¸¢à¸£à¸²à¸„à¸²à¸šà¹‰à¸²à¸™à¸—à¸µà¹ˆ train à¸à¸±à¸šà¸šà¹‰à¸²à¸™à¹ƒà¸™à¹€à¸¡à¸·à¸­à¸‡ à¹à¸•à¹ˆà¸•à¹‰à¸­à¸‡à¸—à¸³à¸™à¸²à¸¢à¸šà¹‰à¸²à¸™à¹ƒà¸™à¸Šà¸™à¸šà¸—\\n- à¹‚à¸¡à¹€à¸”à¸¥à¸­à¸²à¸¢à¸¸à¸¥à¸¹à¸à¸„à¹‰à¸²à¸—à¸µà¹ˆ train à¸à¸±à¸šà¸à¸¥à¸¸à¹ˆà¸¡à¸­à¸²à¸¢à¸¸ 20-40 à¸›à¸µ à¹à¸•à¹ˆ production à¸¡à¸µà¸¥à¸¹à¸à¸„à¹‰à¸²à¸­à¸²à¸¢à¸¸ 40-60 à¸›à¸µ\\n\\n**Code Reference** - à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Covariate Shift:\\n```python\\ndef generate_covariate_shift_data():\\n    # Training data: à¸¥à¸¹à¸à¸„à¹‰à¸²à¸­à¸²à¸¢à¸¸à¸™à¹‰à¸­à¸¢ (20-40)\\n    age_train = np.random.normal(30, 5, n_train)\\n    \\n    # Production data: à¸¥à¸¹à¸à¸„à¹‰à¸²à¸­à¸²à¸¢à¸¸à¸¡à¸²à¸à¸‚à¸¶à¹‰à¸™ (40-60) - Covariate Shift!\\n    age_prod = np.random.normal(50, 5, n_prod)\\n    \\n    # à¸à¸à¸à¸²à¸£à¸‹à¸·à¹‰à¸­à¹€à¸«à¸¡à¸·à¸­à¸™à¹€à¸”à¸´à¸¡ (à¹„à¸¡à¹ˆà¸¡à¸µ Concept Drift)\\n    # P(Y|X) à¸¢à¸±à¸‡à¸„à¸‡à¹€à¸”à¸´à¸¡\\n```\\n\\n#### 2. Concept Drift (Label Drift)\\n\\n**à¸™à¸´à¸¢à¸²à¸¡**: à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸‚à¸­à¸‡à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œà¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ input à¹à¸¥à¸° output P(Y|X)\\n\\n```\\nConcept Drift:\\nâ”œâ”€â”€ P(X) à¸­à¸²à¸ˆà¸„à¸‡à¸—à¸µà¹ˆà¸«à¸£à¸·à¸­à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸à¹‡à¹„à¸”à¹‰\\nâ””â”€â”€ P(Y|X)_train â‰  P(Y|X)_prod  â† Relationship à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™!\\n```\\n\\n**à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¹ƒà¸™à¸Šà¸µà¸§à¸´à¸•à¸ˆà¸£à¸´à¸‡**:\\n- à¸à¸¤à¸•à¸´à¸à¸£à¸£à¸¡à¸à¸²à¸£à¸‹à¸·à¹‰à¸­à¸‚à¸­à¸‡à¸¥à¸¹à¸à¸„à¹‰à¸²à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸«à¸¥à¸±à¸‡ COVID-19\\n- à¸„à¸§à¸²à¸¡à¸«à¸¡à¸²à¸¢à¸‚à¸­à¸‡ \\\"spam email\\\" à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹„à¸›à¸•à¸²à¸¡à¹€à¸§à¸¥à¸²\\n\\n**Code Reference** - à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Concept Drift:\\n```python\\ndef generate_concept_drift_data():\\n    # Training: à¸à¸à¸à¸²à¸£à¸‹à¸·à¹‰à¸­à¹€à¸”à¸´à¸¡ - à¸‹à¸·à¹‰à¸­à¸–à¹‰à¸² income > 45000\\n    purchase_train = (income_train > 45000).astype(int)\\n    \\n    # Production: à¸à¸à¸à¸²à¸£à¸‹à¸·à¹‰à¸­à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ - à¸‹à¸·à¹‰à¸­à¸–à¹‰à¸² income > 55000\\n    # Threshold à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ = Concept Drift!\\n    purchase_prod = (income_prod > 55000).astype(int)\\n```\\n\\n#### à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š Covariate Shift vs Concept Drift\\n\\n| à¸¥à¸±à¸à¸©à¸“à¸° | Covariate Shift | Concept Drift |\\n|--------|-----------------|---------------|\\n| à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ | P(X) | P(Y\\\\|X) |\\n| à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡ | à¸à¸¥à¸¸à¹ˆà¸¡à¸¥à¸¹à¸à¸„à¹‰à¸²à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ | à¸à¸¤à¸•à¸´à¸à¸£à¸£à¸¡à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ |\\n| à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š | à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š feature distributions | à¸•à¹‰à¸­à¸‡à¸¡à¸µ labels à¸«à¸£à¸·à¸­ performance |\\n| à¸§à¸´à¸˜à¸µà¹à¸à¹‰ | Sample weighting, Retrain | Retrain with new data |\\n\\n---\\n\\n### Statistical Tests à¸ªà¸³à¸«à¸£à¸±à¸š Drift Detection\\n\\n#### 1. Kolmogorov-Smirnov (KS) Test\\n\\n**à¸—à¸¤à¸©à¸à¸µ**:\\n- à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š Cumulative Distribution Function (CDF) à¸‚à¸­à¸‡ 2 samples\\n- à¸§à¸±à¸”à¸„à¸§à¸²à¸¡à¹à¸•à¸à¸•à¹ˆà¸²à¸‡à¸ªà¸¹à¸‡à¸ªà¸¸à¸”à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ 2 CDFs\\n\\n```\\nKS Statistic = max|Fâ‚(x) - Fâ‚‚(x)|\\n\\nà¹‚à¸”à¸¢à¸—à¸µà¹ˆ:\\n- Fâ‚(x) = CDF à¸‚à¸­à¸‡ reference data\\n- Fâ‚‚(x) = CDF à¸‚à¸­à¸‡ current data\\n```\\n\\n**à¸à¸²à¸£à¸•à¸µà¸„à¸§à¸²à¸¡**:\\n- KS Statistic: 0-1 (à¸¢à¸´à¹ˆà¸‡à¸ªà¸¹à¸‡ = à¸¢à¸´à¹ˆà¸‡à¹à¸•à¸à¸•à¹ˆà¸²à¸‡)\\n- p-value < 0.05: reject null hypothesis â†’ à¸¡à¸µ drift\\n\\n**à¸‚à¹‰à¸­à¸”à¸µ**:\\n- à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸ªà¸¡à¸¡à¸•à¸´ distribution (non-parametric)\\n- Sensitive à¸•à¹ˆà¸­à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡\\n\\n**à¸‚à¹‰à¸­à¹€à¸ªà¸µà¸¢**:\\n- à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¸à¸±à¸š continuous variables à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™\\n\\n**Code Reference**:\\n```python\\ndef kolmogorov_smirnov_test(data1, data2, feature_name=\\\"feature\\\"):\\n    statistic, p_value = stats.ks_2samp(data1, data2)\\n    drift_detected = p_value < 0.05\\n    \\n    return {\\n        'statistic': statistic,\\n        'p_value': p_value,\\n        'drift_detected': drift_detected\\n    }\\n```\\n\\n#### 2. Population Stability Index (PSI)\\n\\n**à¸—à¸¤à¸©à¸à¸µ**:\\n- à¸§à¸±à¸”à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸‚à¸­à¸‡ distribution à¹‚à¸”à¸¢à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š proportions à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸° bin\\n- à¸™à¸´à¸¢à¸¡à¹ƒà¸Šà¹‰à¹ƒà¸™ credit scoring à¹à¸¥à¸° financial models\\n\\n**à¸ªà¸¹à¸•à¸£**:\\n```\\nPSI = Î£ (Actual% - Expected%) Ã— ln(Actual% / Expected%)\\n\\nà¹‚à¸”à¸¢à¸—à¸µà¹ˆ:\\n- Expected% = proportion à¹ƒà¸™ reference data\\n- Actual% = proportion à¹ƒà¸™ current data\\n```\\n\\n**à¸à¸²à¸£à¸•à¸µà¸„à¸§à¸²à¸¡ PSI**:\\n\\n| à¸„à¹ˆà¸² PSI | à¸„à¸§à¸²à¸¡à¸«à¸¡à¸²à¸¢ | Action |\\n|---------|----------|--------|\\n| < 0.1 | à¹„à¸¡à¹ˆà¸¡à¸µà¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸ªà¸³à¸„à¸±à¸ | à¸›à¸à¸•à¸´ |\\n| 0.1 - 0.25 | à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸›à¸²à¸™à¸à¸¥à¸²à¸‡ | à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹€à¸à¸´à¹ˆà¸¡ |\\n| â‰¥ 0.25 | à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸¡à¸²à¸ | à¸•à¹‰à¸­à¸‡à¸”à¸³à¹€à¸™à¸´à¸™à¸à¸²à¸£ |\\n\\n**Code Reference**:\\n```python\\ndef calculate_psi(expected, actual, bins=10, eps=1e-6):\\n    # à¸ªà¸£à¹‰à¸²à¸‡ bins à¸ˆà¸²à¸ expected data\\n    breakpoints = np.percentile(expected, np.linspace(0, 100, bins + 1))\\n    \\n    # à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸° bin\\n    expected_counts, _ = np.histogram(expected, bins=breakpoints)\\n    actual_counts, _ = np.histogram(actual, bins=breakpoints)\\n    \\n    # à¸„à¸³à¸™à¸§à¸“ proportions\\n    expected_props = expected_counts / len(expected) + eps\\n    actual_props = actual_counts / len(actual) + eps\\n    \\n    # à¸„à¸³à¸™à¸§à¸“ PSI\\n    psi = np.sum((actual_props - expected_props) * np.log(actual_props / expected_props))\\n    return psi\\n```\\n\\n#### 3. Wasserstein Distance (Earth Mover's Distance)\\n\\n**à¸—à¸¤à¸©à¸à¸µ**:\\n- à¸§à¸±à¸” \\\"à¸‡à¸²à¸™\\\" à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰à¹ƒà¸™à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ distribution à¸«à¸™à¸¶à¹ˆà¸‡à¹„à¸›à¹€à¸›à¹‡à¸™à¸­à¸µà¸ distribution\\n- à¸„à¸¥à¹‰à¸²à¸¢à¸à¸±à¸šà¸à¸²à¸£à¸„à¸³à¸™à¸§à¸“à¸•à¹‰à¸™à¸—à¸¸à¸™à¹ƒà¸™à¸à¸²à¸£à¸‚à¸™à¸¢à¹‰à¸²à¸¢à¸”à¸´à¸™\\n\\n```\\nWasserstein Distance = inf âˆ«|Fâ‚â»Â¹(u) - Fâ‚‚â»Â¹(u)| du\\n\\nà¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸ªà¸¡à¸·à¸­à¸™:\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\\nâ”‚   Pile A    â”‚  move   â”‚   Pile B    â”‚\\nâ”‚   (sand)    â”‚ â”€â”€â”€â”€â”€â”€â–¶ â”‚   (sand)    â”‚\\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  cost   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n```\\n\\n**à¸‚à¹‰à¸­à¸”à¸µ**:\\n- à¸„à¸³à¸™à¸¶à¸‡à¸–à¸¶à¸‡ distance à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ bins\\n- Sensitive à¸•à¹ˆà¸­ shift à¹ƒà¸™à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡\\n\\n**Code Reference**:\\n```python\\ndef wasserstein_distance_test(data1, data2, feature_name=\\\"feature\\\"):\\n    distance = stats.wasserstein_distance(data1, data2)\\n    \\n    # Normalize à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰ standard deviation\\n    std_ref = np.std(data1)\\n    normalized_distance = distance / std_ref if std_ref > 0 else distance\\n    \\n    return {\\n        'distance': distance,\\n        'normalized_distance': normalized_distance\\n    }\\n```\\n\\n### à¸à¸²à¸£à¹€à¸¥à¸·à¸­à¸ Drift Detection Method\\n\\n```\\nDecision Tree:\\n\\n1. Data Type?\\n   â”œâ”€â”€ Continuous â†’ à¹„à¸›à¸‚à¹‰à¸­ 2\\n   â””â”€â”€ Categorical â†’ Chi-squared à¸«à¸£à¸·à¸­ PSI\\n\\n2. à¸•à¹‰à¸­à¸‡à¸à¸²à¸£ Statistical Significance?\\n   â”œâ”€â”€ à¹ƒà¸Šà¹ˆ â†’ KS Test\\n   â””â”€â”€ à¹„à¸¡à¹ˆà¸ˆà¸³à¹€à¸›à¹‡à¸™ â†’ PSI à¸«à¸£à¸·à¸­ Wasserstein\\n\\n3. Industry Requirement?\\n   â”œâ”€â”€ Finance/Credit â†’ PSI (regulatory standards)\\n   â””â”€â”€ à¸­à¸·à¹ˆà¸™à¹† â†’ à¹€à¸¥à¸·à¸­à¸à¸•à¸²à¸¡à¸„à¸§à¸²à¸¡à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡\\n\\n4. à¸•à¹‰à¸­à¸‡à¸à¸²à¸£ Sensitivity à¸ªà¸¹à¸‡?\\n   â”œâ”€â”€ à¹ƒà¸Šà¹ˆ â†’ Wasserstein\\n   â””â”€â”€ à¸›à¸à¸•à¸´ â†’ KS à¸«à¸£à¸·à¸­ PSI\\n```\\n\\n---\\n\\n## LAB 2: Feature Drift Detection\\n\\n### ğŸ¯ à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ\\n- à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š drift à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸° feature à¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸›à¹‡à¸™à¸£à¸°à¸šà¸š\\n- à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ numerical vs categorical feature drift\\n- à¸ªà¸£à¹‰à¸²à¸‡ visualization à¸ªà¸³à¸«à¸£à¸±à¸š feature distributions\\n\\n### à¸—à¸¤à¸©à¸à¸µ: Per-Feature Analysis\\n\\nà¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ drift à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸° feature à¸¡à¸µà¸„à¸§à¸²à¸¡à¸ªà¸³à¸„à¸±à¸à¹€à¸à¸£à¸²à¸°:\\n1. à¸Šà¹ˆà¸§à¸¢à¸£à¸°à¸šà¸¸ root cause à¸‚à¸­à¸‡ model performance degradation\\n2. à¸—à¸³à¹ƒà¸«à¹‰à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸§à¹ˆà¸² feature à¹„à¸«à¸™à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸¡à¸²à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸”\\n3. à¸ªà¸²à¸¡à¸²à¸£à¸– prioritize à¸à¸²à¸£à¹à¸à¹‰à¹„à¸‚à¹„à¸”à¹‰\\n\\n### Numerical Features vs Categorical Features\\n\\n#### Numerical Features\\n```\\nMethods à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰:\\nâ”œâ”€â”€ KS Test - compare CDFs\\nâ”œâ”€â”€ PSI - compare bin proportions\\nâ””â”€â”€ Wasserstein - measure distribution distance\\n```\\n\\n#### Categorical Features\\n```\\nMethods à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰:\\nâ”œâ”€â”€ Chi-squared Test - compare frequency distributions\\nâ””â”€â”€ PSI (category-based) - compare category proportions\\n```\\n\\n### Feature Drift Detector Class\\n\\n**Architecture**:\\n```\\nFeatureDriftDetector\\nâ”œâ”€â”€ __init__()\\nâ”‚   â”œâ”€â”€ reference_data\\nâ”‚   â”œâ”€â”€ current_data\\nâ”‚   â”œâ”€â”€ numerical_features\\nâ”‚   â””â”€â”€ categorical_features\\nâ”‚\\nâ”œâ”€â”€ Numerical Methods\\nâ”‚   â”œâ”€â”€ ks_test()\\nâ”‚   â”œâ”€â”€ calculate_psi()\\nâ”‚   â””â”€â”€ wasserstein_test()\\nâ”‚\\nâ”œâ”€â”€ Categorical Methods\\nâ”‚   â”œâ”€â”€ chi_squared_test()\\nâ”‚   â””â”€â”€ categorical_psi()\\nâ”‚\\nâ””â”€â”€ Analysis\\n    â”œâ”€â”€ analyze_numerical_feature()\\n    â”œâ”€â”€ analyze_categorical_feature()\\n    â”œâ”€â”€ analyze_all_features()\\n    â””â”€â”€ get_summary_report()\\n```\\n\\n**Code Reference**:\\n```python\\nclass FeatureDriftDetector:\\n    def __init__(self, reference_data, current_data, \\n                 numerical_features=None, categorical_features=None):\\n        self.reference = reference_data\\n        self.current = current_data\\n        self.numerical_features = numerical_features\\n        self.categorical_features = categorical_features\\n    \\n    def analyze_numerical_feature(self, feature):\\n        results = {\\n            'ks_test': self.ks_test(feature),\\n            'psi': self.calculate_psi(feature),\\n            'wasserstein': self.wasserstein_test(feature)\\n        }\\n        # à¸ªà¸£à¸¸à¸›à¸œà¸¥\\n        ks_drift = results['ks_test']['p_value'] < 0.05\\n        psi_value = results['psi']['psi']\\n        \\n        if psi_value < 0.1:\\n            psi_severity = 'none'\\n        elif psi_value < 0.25:\\n            psi_severity = 'mild'\\n        else:\\n            psi_severity = 'severe'\\n        \\n        results['drift_detected'] = ks_drift or psi_severity != 'none'\\n        return results\\n```\\n\\n### Feature Drift Ranking\\n\\nà¸ˆà¸±à¸”à¸¥à¸³à¸”à¸±à¸š features à¸•à¸²à¸¡à¸„à¸§à¸²à¸¡à¸£à¸¸à¸™à¹à¸£à¸‡à¸‚à¸­à¸‡ drift à¹€à¸à¸·à¹ˆà¸­ prioritization:\\n\\n```\\nRanking Algorithm:\\n1. à¸„à¸³à¸™à¸§à¸“ PSI à¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸¸à¸ features\\n2. à¹€à¸£à¸µà¸¢à¸‡à¸¥à¸³à¸”à¸±à¸šà¸ˆà¸²à¸à¸¡à¸²à¸à¹„à¸›à¸™à¹‰à¸­à¸¢\\n3. à¸à¸³à¸«à¸™à¸” severity level (none/mild/severe)\\n4. Focus à¹à¸à¹‰à¹„à¸‚ features à¸—à¸µà¹ˆà¸¡à¸µ severe drift à¸à¹ˆà¸­à¸™\\n```\\n\\n### Time-based Distribution Analysis\\n\\nà¸à¸²à¸£à¸•à¸´à¸”à¸•à¸²à¸¡ drift à¹€à¸¡à¸·à¹ˆà¸­à¹€à¸§à¸¥à¸²à¸œà¹ˆà¸²à¸™à¹„à¸›:\\n\\n```\\nPeriod 0 (Reference)\\n    â”‚\\n    â–¼\\nPeriod 1 â”€â”€â”€â”€ PSI = 0.02 (none)\\n    â”‚\\n    â–¼\\nPeriod 2 â”€â”€â”€â”€ PSI = 0.08 (none)\\n    â”‚\\n    â–¼\\nPeriod 3 â”€â”€â”€â”€ PSI = 0.15 (mild) âš ï¸\\n    â”‚\\n    â–¼\\nPeriod 4 â”€â”€â”€â”€ PSI = 0.28 (severe) ğŸ”´\\n```\\n\\n---\\n\\n## LAB 3: Multivariate Drift Analysis\\n\\n### ğŸ¯ à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ\\n- à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š drift à¸—à¸µà¹ˆà¹€à¸à¸´à¸”à¸ˆà¸²à¸à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œà¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ features\\n- à¹ƒà¸Šà¹‰ Dataset-level drift detection\\n- à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ Correlation changes\\n\\n### à¸—à¸¤à¸©à¸à¸µ: Multivariate Drift\\n\\n**à¸›à¸±à¸à¸«à¸²**: Univariate methods à¸­à¸²à¸ˆà¸à¸¥à¸²à¸” drift à¸—à¸µà¹ˆà¹€à¸à¸´à¸”à¸ˆà¸²à¸à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸‚à¸­à¸‡à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œà¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ features\\n\\n```\\nà¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡:\\nReference:                    Current:\\n- Age mean = 35              - Age mean = 35      (à¹€à¸«à¸¡à¸·à¸­à¸™à¹€à¸”à¸´à¸¡)\\n- Income mean = 50000        - Income mean = 50000 (à¹€à¸«à¸¡à¸·à¸­à¸™à¹€à¸”à¸´à¸¡)\\n- Corr(Age, Income) = 0.8    - Corr(Age, Income) = 0.1 â† à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™!\\n\\nUnivariate test: à¹„à¸¡à¹ˆà¸à¸š drift\\nMultivariate test: à¸à¸š drift à¹ƒà¸™à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œ\\n```\\n\\n### Methods à¸ªà¸³à¸«à¸£à¸±à¸š Multivariate Drift\\n\\n#### 1. Correlation-based Analysis\\n\\n**à¸—à¸¤à¸©à¸à¸µ**: à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š correlation matrix à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ reference à¹à¸¥à¸° current data\\n\\n**Fisher's Z Transformation** à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š correlations:\\n```\\nZ = arctanh(r)\\n\\nZ-test statistic = (Z_ref - Z_cur) / SE\\nwhere SE = sqrt(1/(nâ‚-3) + 1/(nâ‚‚-3))\\n```\\n\\n**Code Reference**:\\n```python\\ndef correlation_drift_test(ref_df, cur_df, significance_level=0.05):\\n    ref_corr = ref_df.corr()\\n    cur_corr = cur_df.corr()\\n    \\n    for col1, col2 in feature_pairs:\\n        r_ref = ref_corr.loc[col1, col2]\\n        r_cur = cur_corr.loc[col1, col2]\\n        \\n        # Fisher's Z transformation\\n        z_ref = np.arctanh(r_ref)\\n        z_cur = np.arctanh(r_cur)\\n        \\n        # Z-test\\n        se = np.sqrt(1/(n_ref-3) + 1/(n_cur-3))\\n        z_stat = (z_ref - z_cur) / se\\n        p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))\\n```\\n\\n#### 2. PCA-based Analysis\\n\\n**à¸—à¸¤à¸©à¸à¸µ**: à¹ƒà¸Šà¹‰ Principal Component Analysis à¹€à¸à¸·à¹ˆà¸­à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸‚à¸­à¸‡ multivariate structure\\n\\n```\\nPCA Drift Detection:\\nâ”œâ”€â”€ Explained Variance Ratio - variance à¸—à¸µà¹ˆà¹à¸•à¹ˆà¸¥à¸° PC à¸­à¸˜à¸´à¸šà¸²à¸¢à¹„à¸”à¹‰\\nâ”œâ”€â”€ Component Similarity - à¸—à¸´à¸¨à¸—à¸²à¸‡à¸‚à¸­à¸‡ PC à¹€à¸«à¸¡à¸·à¸­à¸™à¹€à¸”à¸´à¸¡à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ\\nâ””â”€â”€ Reconstruction Error - error à¹€à¸¡à¸·à¹ˆà¸­ reconstruct data\\n```\\n\\n**Metrics à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰**:\\n1. **Explained Variance Comparison**: à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸§à¹ˆà¸²à¹à¸•à¹ˆà¸¥à¸° PC à¸­à¸˜à¸´à¸šà¸²à¸¢ variance à¹€à¸—à¹ˆà¸²à¹€à¸”à¸´à¸¡à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ\\n2. **Component Similarity (Cosine Similarity)**: à¸”à¸¹à¸§à¹ˆà¸² PC directions à¹€à¸«à¸¡à¸·à¸­à¸™à¹€à¸”à¸´à¸¡à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ\\n3. **Reconstruction Error**: à¹ƒà¸Šà¹‰ reference PCA à¸à¸±à¸š current data à¹à¸¥à¹‰à¸§à¸”à¸¹ error\\n\\n**Code Reference**:\\n```python\\ndef pca_drift_detection(ref_df, cur_df, n_components=None):\\n    # Standardize\\n    scaler = StandardScaler()\\n    ref_scaled = scaler.fit_transform(ref_df)\\n    cur_scaled = scaler.transform(cur_df)\\n    \\n    # Fit PCA on reference\\n    pca_ref = PCA(n_components=n_components)\\n    pca_ref.fit(ref_scaled)\\n    \\n    # Component similarities (using cosine similarity)\\n    for i in range(n_components):\\n        cos_sim = abs(np.dot(pca_ref.components_[i], pca_cur.components_[i]))\\n        # à¸–à¹‰à¸² cos_sim < 0.9 = structure à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™\\n```\\n\\n#### 3. Mahalanobis Distance\\n\\n**à¸—à¸¤à¸©à¸à¸µ**: à¸§à¸±à¸”à¸§à¹ˆà¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¸¡à¹ˆà¸­à¸¢à¸¹à¹ˆà¸«à¹ˆà¸²à¸‡à¸ˆà¸²à¸ distribution à¸‚à¸­à¸‡ reference data à¹€à¸—à¹ˆà¸²à¹„à¸£ à¹‚à¸”à¸¢à¸„à¸³à¸™à¸¶à¸‡à¸–à¸¶à¸‡ covariance\\n\\n```\\nMahalanobis Distance = âˆš((x - Î¼)áµ€ Î£â»Â¹ (x - Î¼))\\n\\nà¹‚à¸”à¸¢à¸—à¸µà¹ˆ:\\n- x = data point\\n- Î¼ = mean à¸‚à¸­à¸‡ reference\\n- Î£ = covariance matrix à¸‚à¸­à¸‡ reference\\n```\\n\\n**à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™**:\\n1. Fit covariance à¸šà¸™ reference data\\n2. à¸„à¸³à¸™à¸§à¸“ Mahalanobis distance à¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸¸à¸ points\\n3. à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š distribution à¸‚à¸­à¸‡ distances\\n\\n**Code Reference**:\\n```python\\ndef mahalanobis_drift_detection(ref_df, cur_df, threshold_percentile=95):\\n    # Fit covariance on reference\\n    cov = EmpiricalCovariance().fit(ref_scaled)\\n    \\n    # Calculate distances\\n    ref_distances = cov.mahalanobis(ref_scaled)\\n    cur_distances = cov.mahalanobis(cur_scaled)\\n    \\n    # Compare distributions\\n    ks_stat, ks_pval = stats.ks_2samp(ref_distances, cur_distances)\\n    drift_detected = ks_pval < 0.05\\n```\\n\\n### Comprehensive Multivariate Analysis\\n\\n```\\nMultivariateriftDetector\\nâ”œâ”€â”€ Correlation Analysis\\nâ”‚   â””â”€â”€ à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š pairwise correlation changes\\nâ”œâ”€â”€ PCA Analysis\\nâ”‚   â””â”€â”€ à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š structure changes\\nâ”œâ”€â”€ Mahalanobis Analysis\\nâ”‚   â””â”€â”€ à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š distribution shift\\nâ””â”€â”€ Consensus\\n    â””â”€â”€ à¸£à¸§à¸¡à¸œà¸¥à¸ˆà¸²à¸à¸—à¸¸à¸ methods\\n```\\n\\n---\\n\\n## LAB 4: Drift Detection in Production Simulation\\n\\n### ğŸ¯ à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ\\n- à¸ªà¸£à¹‰à¸²à¸‡ simulated data stream à¸—à¸µà¹ˆà¸¡à¸µ drift\\n- à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š sudden vs gradual drift\\n- Implement sliding window monitoring\\n\\n### à¸—à¸¤à¸©à¸à¸µ: Drift Patterns à¹ƒà¸™ Production\\n\\n#### Types of Drift\\n\\n```\\n1. Sudden Drift (Abrupt)\\n   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n               â”‚\\n               â–¼ Drift Point\\n   à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸—à¸±à¸™à¸—à¸µ\\n\\n2. Gradual Drift\\n   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n   à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸Šà¹‰à¸²à¹† à¸•à¸²à¸¡à¹€à¸§à¸¥à¸²\\n\\n3. Incremental Drift\\n   â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€\\n       â”‚   â”‚   â”‚   â”‚\\n   à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹€à¸›à¹‡à¸™à¸‚à¸±à¹‰à¸™à¸šà¸±à¸™à¹„à¸”\\n\\n4. Seasonal/Recurring Drift\\n   â”€â”€â”€â”€â•²â•±â”€â”€â”€â”€â•²â•±â”€â”€â”€â”€â•²â•±â”€â”€â”€â”€\\n   à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸•à¸²à¸¡ pattern à¸‹à¹‰à¸³\\n```\\n\\n**Code Reference** - Data Stream Simulator:\\n```python\\nclass DataStreamSimulator:\\n    def generate_stream(self, n_samples, drift_type='no_drift', drift_params=None):\\n        if drift_type == 'sudden':\\n            # à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸—à¸±à¸™à¸—à¸µà¸—à¸µà¹ˆ drift_point\\n            data[:drift_point] = np.random.normal(base_mean, ...)\\n            data[drift_point:] = np.random.normal(new_mean, ...)\\n            \\n        elif drift_type == 'gradual':\\n            # Linear interpolation\\n            for i in range(n_samples):\\n                if drift_start <= i <= drift_end:\\n                    progress = (i - drift_start) / (drift_end - drift_start)\\n                    current_mean = base_mean + progress * (final_mean - base_mean)\\n```\\n\\n### Sliding Window Drift Detection\\n\\n**à¸«à¸¥à¸±à¸à¸à¸²à¸£**:\\n```\\nTime â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶\\n\\nReference Window          Test Window\\n[â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•]     [â•â•â•â•â•â•â•â•â•]\\n        â–²                      â–²\\n        â”‚                      â”‚\\n   Fixed/Slow moving    Current data\\n```\\n\\n**Architecture**:\\n```\\nSlidingWindowDriftDetector\\nâ”œâ”€â”€ reference_buffer (deque with maxlen)\\nâ”œâ”€â”€ test_buffer (deque with maxlen)\\nâ”œâ”€â”€ update(value)\\nâ”‚   â”œâ”€â”€ Add to buffer\\nâ”‚   â”œâ”€â”€ Check if ready\\nâ”‚   â””â”€â”€ Run drift detection\\nâ”œâ”€â”€ Detection Methods\\nâ”‚   â”œâ”€â”€ KS Test\\nâ”‚   â””â”€â”€ PSI\\nâ””â”€â”€ Output\\n    â”œâ”€â”€ drift_detected\\n    â”œâ”€â”€ metrics\\n    â””â”€â”€ history\\n```\\n\\n**Code Reference**:\\n```python\\nclass SlidingWindowDriftDetector:\\n    def __init__(self, reference_window_size=200, test_window_size=100):\\n        self.reference_buffer = deque(maxlen=reference_window_size)\\n        self.test_buffer = deque(maxlen=test_window_size)\\n    \\n    def update(self, value, timestamp=None):\\n        # à¹€à¸à¸´à¹ˆà¸¡à¸„à¹ˆà¸²à¹ƒà¸™ buffers\\n        if not self.is_initialized:\\n            self.reference_buffer.append(value)\\n            return {'status': 'initializing'}\\n        \\n        self.test_buffer.append(value)\\n        \\n        if len(self.test_buffer) < self.test_window_size:\\n            return {'status': 'collecting'}\\n        \\n        # à¸—à¸³ drift detection\\n        ref_array = np.array(self.reference_buffer)\\n        test_array = np.array(self.test_buffer)\\n        \\n        psi = self.calculate_psi(ref_array, test_array)\\n        drift_detected = psi > self.psi_threshold\\n        \\n        return {\\n            'drift_detected': drift_detected,\\n            'psi': psi\\n        }\\n```\\n\\n### Adaptive Reference Window\\n\\n**à¸›à¸±à¸à¸«à¸²à¸‚à¸­à¸‡ Fixed Reference**:\\n- Gradual drift à¸­à¸²à¸ˆà¸•à¸£à¸§à¸ˆà¹„à¸¡à¹ˆà¹€à¸ˆà¸­ à¹€à¸à¸£à¸²à¸° reference à¹€à¸à¹ˆà¸²à¹€à¸à¸´à¸™à¹„à¸›\\n- à¸•à¹‰à¸­à¸‡ adapt reference à¹€à¸¡à¸·à¹ˆà¸­ detect drift\\n\\n**à¸§à¸´à¸˜à¸µà¹à¸à¹‰**:\\n```python\\nclass AdaptiveDriftDetector:\\n    def adapt_reference(self):\\n        \\\"\\\"\\\"à¸›à¸£à¸±à¸š reference window à¹€à¸¡à¸·à¹ˆà¸­ confirm drift\\\"\\\"\\\"\\n        # à¸œà¸ªà¸¡ old reference à¸à¸±à¸š new data\\n        old_weight = 0.5\\n        \\n        # à¹€à¸à¸´à¹ˆà¸¡à¸šà¸²à¸‡à¸ªà¹ˆà¸§à¸™à¸ˆà¸²à¸ old reference\\n        for val in old_ref[-n_old:]:\\n            self.reference_buffer.append(val)\\n        \\n        # à¹€à¸à¸´à¹ˆà¸¡ new data\\n        for val in new_data:\\n            self.reference_buffer.append(val)\\n```\\n\\n### Page-Hinkley Test\\n\\n**à¸—à¸¤à¸©à¸à¸µ**: Algorithm à¸ªà¸³à¸«à¸£à¸±à¸š detect mean shift à¹ƒà¸™ streaming data\\n\\n```\\nAlgorithm:\\n1. Update running mean: Î¼_t = Î±Â·Î¼_{t-1} + (1-Î±)Â·x_t\\n2. Update cumulative sum: S_t = S_{t-1} + (x_t - Î¼_t - Î´)\\n3. Track min/max of S_t\\n4. Detect if S_t - min(S) > Î» (upward shift)\\n         à¸«à¸£à¸·à¸­ max(S) - S_t > Î» (downward shift)\\n```\\n\\n**Code Reference**:\\n```python\\nclass PageHinkleyDetector:\\n    def update(self, value):\\n        # Update mean (exponential moving average)\\n        self.mean = self.alpha * self.mean + (1 - self.alpha) * value\\n        \\n        # Update cumulative sum\\n        self.sum += value - self.mean - self.delta\\n        \\n        # Update min/max\\n        self.min_sum = min(self.min_sum, self.sum)\\n        self.max_sum = max(self.max_sum, self.sum)\\n        \\n        # Detection\\n        ph_positive = self.sum - self.min_sum  # Upward shift\\n        ph_negative = self.max_sum - self.sum  # Downward shift\\n        \\n        drift_detected = (ph_positive > self.lambda_) or (ph_negative > self.lambda_)\\n```\\n\\n### Comparison of Methods\\n\\n| Method | Pros | Cons | Best For |\\n|--------|------|------|----------|\\n| Sliding Window | Simple, intuitive | Fixed reference | Sudden drift |\\n| Adaptive | Handles gradual drift | More complex | Production |\\n| Page-Hinkley | Low memory, fast | Mean shift only | Real-time |\\n\\n---\\n\\n## LAB 5: Custom Metrics & Drift Thresholds\\n\\n### ğŸ¯ à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ\\n- à¸ªà¸£à¹‰à¸²à¸‡ custom drift metrics\\n- à¸›à¸£à¸±à¸š threshold à¸•à¸²à¸¡ business requirements\\n- Handle false positives/negatives\\n\\n### à¸—à¸¤à¸©à¸à¸µ: Threshold Selection\\n\\n**à¸›à¸±à¸à¸«à¸²**: Default thresholds à¸­à¸²à¸ˆà¹„à¸¡à¹ˆà¹€à¸«à¸¡à¸²à¸°à¸à¸±à¸šà¸—à¸¸à¸ use case\\n\\n```\\nTrade-off:\\n                    Threshold\\n           Low â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ High\\n           \\nSensitivity: High                    Low\\nFalse Positive: High                 Low\\nFalse Negative: Low                  High\\n```\\n\\n### Custom Drift Metrics\\n\\n#### 1. Combined Score\\n```python\\ndef combined_score(reference, current, weights=None):\\n    \\\"\\\"\\\"à¸£à¸§à¸¡à¸«à¸¥à¸²à¸¢ metrics à¹€à¸‚à¹‰à¸²à¸”à¹‰à¸§à¸¢à¸à¸±à¸™\\\"\\\"\\\"\\n    if weights is None:\\n        weights = {\\n            'psi': 0.3,\\n            'wasserstein': 0.3,\\n            'mean_shift': 0.2,\\n            'percentile': 0.2\\n        }\\n    \\n    # Normalize à¹à¸•à¹ˆà¸¥à¸° metric à¹ƒà¸«à¹‰à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸Šà¹ˆà¸§à¸‡ 0-1\\n    psi = min(calculate_psi(reference, current), 1.0)\\n    wasserstein = min(normalized_wasserstein(reference, current) / 3, 1.0)\\n    mean_shift = min(mean_shift_ratio(reference, current) / 3, 1.0)\\n    percentile = min(percentile_shift(reference, current) / 3, 1.0)\\n    \\n    score = (weights['psi'] * psi + \\n             weights['wasserstein'] * wasserstein +\\n             weights['mean_shift'] * mean_shift +\\n             weights['percentile'] * percentile)\\n    \\n    return score\\n```\\n\\n#### 2. Jensen-Shannon Divergence\\n```python\\ndef jensen_shannon_divergence(reference, current, bins=10):\\n    \\\"\\\"\\\"Symmetric version of KL Divergence\\\"\\\"\\\"\\n    # à¸ªà¸£à¹‰à¸²à¸‡ normalized histograms\\n    ref_hist = np.histogram(reference, bins=bins, density=True)[0]\\n    cur_hist = np.histogram(current, bins=bins, density=True)[0]\\n    \\n    # Average distribution\\n    m = 0.5 * (ref_hist + cur_hist)\\n    \\n    # JS Divergence = 0.5 * (KL(P||M) + KL(Q||M))\\n    js = 0.5 * (kl_divergence(ref_hist, m) + kl_divergence(cur_hist, m))\\n    return js\\n```\\n\\n### Threshold Optimization\\n\\n#### F1-based Optimization\\n\\n```python\\ndef find_optimal_threshold(scenarios, metric_func, thresholds, optimize_for='f1'):\\n    \\\"\\\"\\\"à¸«à¸² threshold à¸—à¸µà¹ˆà¹ƒà¸«à¹‰ F1 score à¸ªà¸¹à¸‡à¸ªà¸¸à¸”\\\"\\\"\\\"\\n    results = []\\n    \\n    for t in thresholds:\\n        y_true = [s['has_drift'] for s in scenarios]\\n        y_pred = [metric_func(s['reference'], s['current']) > t for s in scenarios]\\n        \\n        precision = precision_score(y_true, y_pred)\\n        recall = recall_score(y_true, y_pred)\\n        f1 = f1_score(y_true, y_pred)\\n        \\n        results.append({'threshold': t, 'f1': f1})\\n    \\n    # à¸«à¸² optimal\\n    optimal = max(results, key=lambda x: x['f1'])\\n    return optimal\\n```\\n\\n#### Cost-based Optimization\\n\\n**à¸—à¸¤à¸©à¸à¸µ**: à¸›à¸£à¸±à¸š threshold à¸•à¸²à¸¡ cost à¸‚à¸­à¸‡ false positive vs false negative\\n\\n```\\nTotal Cost = FP_count Ã— FP_cost + FN_count Ã— FN_cost\\n\\nScenarios:\\nâ”œâ”€â”€ High FN cost (à¹€à¸Šà¹ˆà¸™ fraud detection)\\nâ”‚   â””â”€â”€ à¹ƒà¸Šà¹‰ Low threshold â†’ detect more, accept false alarms\\nâ”œâ”€â”€ High FP cost (à¹€à¸Šà¹ˆà¸™ expensive retraining)\\nâ”‚   â””â”€â”€ à¹ƒà¸Šà¹‰ High threshold â†’ conservative detection\\nâ””â”€â”€ Balanced cost\\n    â””â”€â”€ Optimize for F1\\n```\\n\\n**Code Reference**:\\n```python\\nclass BusinessDriftThreshold:\\n    def __init__(self, false_positive_cost=1, false_negative_cost=10):\\n        self.fp_cost = false_positive_cost\\n        self.fn_cost = false_negative_cost\\n    \\n    def calculate_total_cost(self, y_true, y_pred):\\n        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n        return fp * self.fp_cost + fn * self.fn_cost\\n    \\n    def find_cost_optimal_threshold(self, scenarios, metric_func, thresholds):\\n        costs = []\\n        for t in thresholds:\\n            y_pred = [metric_func(s['reference'], s['current']) > t \\n                     for s in scenarios]\\n            cost = self.calculate_total_cost(y_true, y_pred)\\n            costs.append({'threshold': t, 'cost': cost})\\n        \\n        optimal = min(costs, key=lambda x: x['cost'])\\n        return optimal\\n```\\n\\n### Handling False Positives/Negatives\\n\\n#### Ensemble Approach\\n```python\\nclass RobustDriftDetector:\\n    \\\"\\\"\\\"à¹ƒà¸Šà¹‰à¸«à¸¥à¸²à¸¢ methods à¸£à¹ˆà¸§à¸¡à¸à¸±à¸™\\\"\\\"\\\"\\n    \\n    def detect(self, reference, current):\\n        all_metrics = self._calculate_all_metrics(reference, current)\\n        \\n        # Majority voting\\n        drift_votes = sum(\\n            1 for m, v in all_metrics.items() \\n            if v > self.thresholds[m]\\n        )\\n        \\n        # à¸•à¹‰à¸­à¸‡ 3/4 methods agree\\n        ensemble_drift = drift_votes >= 3\\n        \\n        return ensemble_drift\\n```\\n\\n#### Confirmation Mechanism\\n```python\\ndef detect_with_confirmation(self, reference, current):\\n    \\\"\\\"\\\"à¸•à¹‰à¸­à¸‡ detect à¸«à¸¥à¸²à¸¢à¸„à¸£à¸±à¹‰à¸‡à¸•à¸´à¸”à¸à¸±à¸™à¸–à¸¶à¸‡à¸¢à¸·à¸™à¸¢à¸±à¸™\\\"\\\"\\\"\\n    \\n    potential_drift = self.primary_metric(reference, current) > threshold\\n    \\n    if potential_drift:\\n        self.consecutive_count += 1\\n    else:\\n        self.consecutive_count = 0\\n    \\n    # Confirmed à¸–à¹‰à¸² detect 3 à¸„à¸£à¸±à¹‰à¸‡à¸•à¸´à¸”à¸à¸±à¸™\\n    confirmed = self.consecutive_count >= 3\\n    return confirmed\\n```\\n\\n### Best Practices à¸ªà¸³à¸«à¸£à¸±à¸š Threshold Setting\\n\\n```\\n1ï¸âƒ£ DOMAIN-SPECIFIC THRESHOLDS\\n   - à¹„à¸¡à¹ˆà¹ƒà¸Šà¹‰ default à¹‚à¸”à¸¢à¹„à¸¡à¹ˆ validate\\n   - à¸—à¸”à¸ªà¸­à¸šà¸à¸±à¸š labeled data\\n   - à¸›à¸£à¸¶à¸à¸©à¸² domain experts\\n\\n2ï¸âƒ£ COST-BASED OPTIMIZATION\\n   - à¸à¸´à¸ˆà¸²à¸£à¸“à¸² cost à¸‚à¸­à¸‡ FP vs FN\\n   - FN à¹à¸à¸‡ â†’ Lower threshold\\n   - FP à¹à¸à¸‡ â†’ Higher threshold\\n\\n3ï¸âƒ£ ENSEMBLE APPROACH\\n   - à¹ƒà¸Šà¹‰à¸«à¸¥à¸²à¸¢ metrics à¸£à¹ˆà¸§à¸¡à¸à¸±à¸™\\n   - Voting mechanism à¸¥à¸” false positives\\n\\n4ï¸âƒ£ CONFIRMATION MECHANISM\\n   - Require consecutive detections\\n   - à¸›à¹‰à¸­à¸‡à¸à¸±à¸™ temporary spikes\\n\\n5ï¸âƒ£ PERIODIC REVIEW\\n   - Review thresholds à¹€à¸›à¹‡à¸™à¸£à¸°à¸¢à¸°\\n   - Business requirements à¸­à¸²à¸ˆà¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™\\n```\\n\\n---\\n\\n## LAB 6: End-to-End Monitoring Pipeline\\n\\n### ğŸ¯ à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ\\n- à¸£à¸§à¸¡à¸—à¸¸à¸ components à¹€à¸‚à¹‰à¸²à¸”à¹‰à¸§à¸¢à¸à¸±à¸™\\n- à¸ªà¸£à¹‰à¸²à¸‡ automated monitoring workflow\\n- Integrate à¸à¸±à¸š MLflow\\n\\n### Architecture Overview\\n\\n```\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\\nâ”‚                 Drift Monitoring Pipeline                    â”‚\\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\\nâ”‚                                                              â”‚\\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚\\nâ”‚  â”‚  Data Source   â”‚â”€â”€â”€â–¶â”‚  Data Buffer   â”‚                   â”‚\\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚\\nâ”‚                                â”‚                             â”‚\\nâ”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚\\nâ”‚                    â”‚   Drift Calculator    â”‚                â”‚\\nâ”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚\\nâ”‚                                â”‚                             â”‚\\nâ”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚\\nâ”‚           â”‚                    â”‚                    â”‚       â”‚\\nâ”‚           â–¼                    â–¼                    â–¼       â”‚\\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\\nâ”‚  â”‚   Alert     â”‚      â”‚   Report    â”‚      â”‚   MLflow    â”‚ â”‚\\nâ”‚  â”‚   Manager   â”‚      â”‚   Generator â”‚      â”‚   Tracker   â”‚ â”‚\\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\\nâ”‚                                                              â”‚\\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n```\\n\\n### Core Components\\n\\n#### 1. Data Classes\\n\\n```python\\nfrom dataclasses import dataclass\\nfrom enum import Enum\\n\\nclass AlertSeverity(Enum):\\n    INFO = \\\"info\\\"\\n    WARNING = \\\"warning\\\"\\n    CRITICAL = \\\"critical\\\"\\n\\nclass DriftType(Enum):\\n    NONE = \\\"none\\\"\\n    MILD = \\\"mild\\\"\\n    MODERATE = \\\"moderate\\\"\\n    SEVERE = \\\"severe\\\"\\n\\n@dataclass\\nclass DriftResult:\\n    timestamp: datetime\\n    feature: str\\n    drift_detected: bool\\n    drift_type: DriftType\\n    psi: float\\n    ks_statistic: float\\n    ks_pvalue: float\\n    reference_mean: float\\n    current_mean: float\\n\\n@dataclass\\nclass Alert:\\n    timestamp: datetime\\n    severity: AlertSeverity\\n    message: str\\n    details: Dict\\n    acknowledged: bool = False\\n```\\n\\n#### 2. Configuration\\n\\n```python\\n@dataclass\\nclass MonitoringConfig:\\n    reference_window_size: int = 1000\\n    current_window_size: int = 200\\n    psi_mild_threshold: float = 0.1\\n    psi_moderate_threshold: float = 0.2\\n    psi_severe_threshold: float = 0.25\\n    ks_significance: float = 0.05\\n    check_interval_seconds: int = 60\\n    alert_cooldown_minutes: int = 30\\n    features_to_monitor: List[str] = field(default_factory=list)\\n```\\n\\n#### 3. Data Buffer\\n\\n```python\\nclass DataBuffer:\\n    \\\"\\\"\\\"Buffer à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸à¹‡à¸š reference à¹à¸¥à¸° current data\\\"\\\"\\\"\\n    \\n    def __init__(self, config: MonitoringConfig):\\n        self.reference_data: Dict[str, deque] = {}\\n        self.current_data: Dict[str, deque] = {}\\n    \\n    def initialize(self, reference_df: pd.DataFrame):\\n        \\\"\\\"\\\"Initialize with reference data\\\"\\\"\\\"\\n        for feature in self.config.features_to_monitor:\\n            self.reference_data[feature] = deque(\\n                reference_df[feature].values,\\n                maxlen=self.config.reference_window_size\\n            )\\n    \\n    def add_data(self, data: Dict[str, float]):\\n        \\\"\\\"\\\"Add new data point\\\"\\\"\\\"\\n        for feature, value in data.items():\\n            self.current_data[feature].append(value)\\n```\\n\\n#### 4. Alert Manager\\n\\n```python\\nclass AlertManager:\\n    \\\"\\\"\\\"à¸ˆà¸±à¸”à¸à¸²à¸£ alerts à¸à¸£à¹‰à¸­à¸¡ cooldown\\\"\\\"\\\"\\n    \\n    def __init__(self, config: MonitoringConfig):\\n        self.alerts: List[Alert] = []\\n        self.last_alert_time: Dict[str, datetime] = {}\\n    \\n    def should_alert(self, feature: str) -> bool:\\n        \\\"\\\"\\\"Check cooldown\\\"\\\"\\\"\\n        if feature not in self.last_alert_time:\\n            return True\\n        elapsed = datetime.now() - self.last_alert_time[feature]\\n        return elapsed > timedelta(minutes=self.config.alert_cooldown_minutes)\\n    \\n    def create_alert(self, drift_result: DriftResult) -> Optional[Alert]:\\n        if not drift_result.drift_detected:\\n            return None\\n        \\n        if not self.should_alert(drift_result.feature):\\n            return None\\n        \\n        # Determine severity\\n        severity = self._determine_severity(drift_result.drift_type)\\n        \\n        alert = Alert(\\n            timestamp=drift_result.timestamp,\\n            severity=severity,\\n            message=f\\\"Drift detected in {drift_result.feature}\\\",\\n            details=drift_result.to_dict()\\n        )\\n        \\n        self.alerts.append(alert)\\n        self.last_alert_time[drift_result.feature] = datetime.now()\\n        \\n        return alert\\n```\\n\\n#### 5. Main Pipeline\\n\\n```python\\nclass DriftMonitoringPipeline:\\n    def __init__(self, config: MonitoringConfig):\\n        self.config = config\\n        self.data_buffer = DataBuffer(config)\\n        self.alert_manager = AlertManager(config)\\n        self.drift_calculator = DriftCalculator()\\n        self.results_history: List[DriftResult] = []\\n    \\n    def initialize(self, reference_data: pd.DataFrame):\\n        self.data_buffer.initialize(reference_data)\\n    \\n    def process_batch(self, batch_data: pd.DataFrame) -> List[DriftResult]:\\n        results = []\\n        \\n        # Add data to buffer\\n        for idx, row in batch_data.iterrows():\\n            self.data_buffer.add_data(row.to_dict())\\n        \\n        # Check if ready\\n        if not self.data_buffer.is_current_ready():\\n            return results\\n        \\n        # Detect drift for each feature\\n        for feature in self.config.features_to_monitor:\\n            result = self._detect_drift_for_feature(feature)\\n            if result:\\n                results.append(result)\\n                \\n                # Create alert if needed\\n                if result.drift_detected:\\n                    self.alert_manager.create_alert(result)\\n        \\n        return results\\n```\\n\\n### Report Generation\\n\\n```python\\nclass ReportGenerator:\\n    def generate_html_report(self, output_path: str):\\n        \\\"\\\"\\\"Generate HTML report\\\"\\\"\\\"\\n        summary = self.pipeline.get_summary_report()\\n        \\n        html_content = f\\\"\\\"\\\"\\n        <html>\\n        <head><title>Drift Monitoring Report</title></head>\\n        <body>\\n            <h1>Drift Monitoring Report</h1>\\n            <p>Generated: {datetime.now()}</p>\\n            \\n            <h2>Summary</h2>\\n            <p>Total Checks: {summary['total_checks']}</p>\\n            <p>Drifts Detected: {summary['total_drifts_detected']}</p>\\n            \\n            <h2>Feature Summary</h2>\\n            <table>\\n                <tr><th>Feature</th><th>PSI</th><th>Status</th></tr>\\n                {self._generate_feature_rows(summary)}\\n            </table>\\n            \\n            <h2>Active Alerts</h2>\\n            {self._generate_alerts_section()}\\n        </body>\\n        </html>\\n        \\\"\\\"\\\"\\n        \\n        with open(output_path, 'w') as f:\\n            f.write(html_content)\\n```\\n\\n### MLflow Integration\\n\\n```python\\nclass MLflowDriftTracker:\\n    def __init__(self, experiment_name: str = \\\"drift_monitoring\\\"):\\n        mlflow.set_experiment(experiment_name)\\n    \\n    def log_drift_result(self, result: DriftResult):\\n        mlflow.log_metric(f\\\"{result.feature}_psi\\\", result.psi)\\n        mlflow.log_metric(f\\\"{result.feature}_drift\\\", 1 if result.drift_detected else 0)\\n        mlflow.log_param(f\\\"{result.feature}_drift_type\\\", result.drift_type.value)\\n    \\n    def log_summary(self, summary: Dict):\\n        mlflow.log_metric(\\\"total_drifts\\\", summary.get('total_drifts_detected', 0))\\n        for feature, data in summary.get('feature_summary', {}).items():\\n            mlflow.log_metric(f\\\"{feature}_drift_rate\\\", data['drift_rate'])\\n    \\n    def log_artifact(self, artifact_path: str):\\n        mlflow.log_artifact(artifact_path)\\n```\\n\\n---\\n\\n## à¸ªà¸£à¸¸à¸›à¹à¸¥à¸° Best Practices\\n\\n### Summary Table\\n\\n| Lab | à¸«à¸±à¸§à¸‚à¹‰à¸­ | Key Concepts |\\n|-----|--------|--------------|\\n| 1 | Understanding Data Drift | Covariate/Concept Shift, KS/PSI/Wasserstein |\\n| 2 | Feature Drift Detection | Per-feature analysis, Numerical vs Categorical |\\n| 3 | Multivariate Drift | Correlation, PCA, Mahalanobis Distance |\\n| 4 | Production Simulation | Streaming, Sliding Window, Page-Hinkley |\\n| 5 | Custom Metrics & Thresholds | Optimization, Cost-based, Ensemble |\\n| 6 | End-to-End Pipeline | Architecture, Alerting, Reporting, MLflow |\\n\\n### Decision Framework\\n\\n```\\nà¹€à¸¡à¸·à¹ˆà¸­à¸à¸š Drift à¸„à¸§à¸£à¸—à¸³à¸­à¸¢à¹ˆà¸²à¸‡à¹„à¸£?\\n\\n1. Assess Severity\\n   â”œâ”€â”€ MILD â†’ Monitor closely\\n   â”œâ”€â”€ MODERATE â†’ Investigate root cause\\n   â””â”€â”€ SEVERE â†’ Immediate action required\\n\\n2. Investigate Root Cause\\n   â”œâ”€â”€ Data collection issue?\\n   â”œâ”€â”€ Upstream data change?\\n   â”œâ”€â”€ Real-world change?\\n   â””â”€â”€ Seasonal pattern?\\n\\n3. Decide Action\\n   â”œâ”€â”€ Retrain model\\n   â”œâ”€â”€ Update feature engineering\\n   â”œâ”€â”€ Adjust thresholds\\n   â””â”€â”€ Business process change\\n```\\n\\n### Production Checklist\\n\\n```\\nâ–¡ Define monitoring strategy\\n  â–¡ Which features to monitor?\\n  â–¡ What thresholds to use?\\n  â–¡ How often to check?\\n\\nâ–¡ Implement detection\\n  â–¡ Choose appropriate methods\\n  â–¡ Handle both numerical and categorical\\n  â–¡ Consider multivariate drift\\n\\nâ–¡ Set up alerting\\n  â–¡ Define severity levels\\n  â–¡ Configure notification channels\\n  â–¡ Set cooldown periods\\n\\nâ–¡ Create reporting\\n  â–¡ Automated dashboards\\n  â–¡ Periodic reports\\n  â–¡ Historical analysis\\n\\nâ–¡ Plan remediation\\n  â–¡ When to retrain?\\n  â–¡ How to validate new model?\\n  â–¡ Rollback procedures\\n```\\n\\n### Final Thoughts\\n\\nà¸à¸²à¸£à¸—à¸³ Drift Detection à¸—à¸µà¹ˆà¸”à¸µà¸•à¹‰à¸­à¸‡:\\n\\n1. **à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆ Business Context**: Drift à¸—à¸µà¹ˆà¸ªà¸³à¸„à¸±à¸à¹ƒà¸™ domain à¸«à¸™à¸¶à¹ˆà¸‡à¸­à¸²à¸ˆà¹„à¸¡à¹ˆà¸ªà¸³à¸„à¸±à¸à¹ƒà¸™ domain à¸­à¸·à¹ˆà¸™\\n\\n2. **à¹ƒà¸Šà¹‰à¸«à¸¥à¸²à¸¢ Methods**: à¹„à¸¡à¹ˆà¸¡à¸µ method à¹ƒà¸”à¸—à¸µà¹ˆà¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œà¹à¸šà¸š à¸„à¸§à¸£à¹ƒà¸Šà¹‰à¸«à¸¥à¸²à¸¢ methods à¸£à¹ˆà¸§à¸¡à¸à¸±à¸™\\n\\n3. **Tune Thresholds**: Default thresholds à¸¡à¸±à¸à¹„à¸¡à¹ˆà¹€à¸«à¸¡à¸²à¸° à¸•à¹‰à¸­à¸‡à¸›à¸£à¸±à¸šà¸•à¸²à¸¡ use case\\n\\n4. **Automate**: à¸à¸²à¸£à¸—à¸³ manual monitoring à¹„à¸¡à¹ˆà¸¢à¸±à¹ˆà¸‡à¸¢à¸·à¸™ à¸•à¹‰à¸­à¸‡à¸¡à¸µ automated pipeline\\n\\n5. **Monitor the Monitor**: à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² monitoring system à¸—à¸³à¸‡à¸²à¸™à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡\\n\\n---\\n\\n## à¹à¸«à¸¥à¹ˆà¸‡à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¹€à¸à¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡\\n\\n- [Evidently AI Documentation](https://docs.evidentlyai.com/)\\n- [NannyML Documentation](https://docs.nannyml.com/)\\n- [Alibi Detect](https://docs.seldon.io/projects/alibi-detect/)\\n- [Great Expectations](https://docs.greatexpectations.io/)\\n\\n---\\n\\n*à¹€à¸­à¸à¸ªà¸²à¸£à¸™à¸µà¹‰à¸ˆà¸±à¸”à¸—à¸³à¹€à¸à¸·à¹ˆà¸­à¸›à¸£à¸°à¸à¸­à¸šà¸à¸²à¸£à¹€à¸£à¸µà¸¢à¸™à¸à¸²à¸£à¸ªà¸­à¸™à¸§à¸´à¸Šà¸² MLOps*\"\n",
    "    }\n",
    "  ],\n",
    " \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77f36907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ğŸ“š Data Drift Detection: Complete Guide for MLOps\n",
      "\n",
      "## à¸ªà¸²à¸£à¸šà¸±à¸\n",
      "1. [à¸šà¸—à¸™à¸³: à¸—à¸³à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆ Data Drift](#à¸šà¸—à¸™à¸³-à¸—à¸³à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆ-data-drift)\n",
      "2. [LAB 1: Understanding Data Drift Concepts](#lab-1-understanding-data-drift-concepts)\n",
      "3. [LAB 2: Feature Drift Detection](#lab-2-feature-drift-detection)\n",
      "4. [LAB 3: Multivariate Drift Analysis](#lab-3-multivariate-drift-analysis)\n",
      "5. [LAB 4: Drift Detection in Production Simulation](#lab-4-drift-detection-in-production-simulation)\n",
      "6. [LAB 5: Custom Metrics & Drift Thresholds](#lab-5-custom-metrics--drift-thresholds)\n",
      "7. [LAB 6: End-to-End Monitoring Pipeline](#lab-6-end-to-end-monitoring-pipeline)\n",
      "8. [à¸ªà¸£à¸¸à¸›à¹à¸¥à¸° Best Practices](#à¸ªà¸£à¸¸à¸›à¹à¸¥à¸°-best-practices)\n",
      "\n",
      "---\n",
      "\n",
      "## à¸šà¸—à¸™à¸³: à¸—à¸³à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆ Data Drift\n",
      "\n",
      "### Data Drift à¸„à¸·à¸­à¸­à¸°à¹„à¸£?\n",
      "\n",
      "**Data Drift** (à¸«à¸£à¸·à¸­ Dataset Shift) à¸„à¸·à¸­à¸›à¸£à¸²à¸à¸à¸à¸²à¸£à¸“à¹Œà¸—à¸µà¹ˆà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¸£à¸°à¸šà¸š production à¸¡à¸µà¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¹„à¸›à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰ train à¹‚à¸¡à¹€à¸”à¸¥ à¸‹à¸¶à¹ˆà¸‡à¹€à¸›à¹‡à¸™à¸«à¸™à¸¶à¹ˆà¸‡à¹ƒà¸™à¸ªà¸²à¹€à¸«à¸•à¸¸à¸«à¸¥à¸±à¸à¸—à¸µà¹ˆà¸—à¸³à¹ƒà¸«à¹‰ ML Model à¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸à¸¥à¸”à¸¥à¸‡à¹€à¸¡à¸·à¹ˆà¸­à¹€à¸§à¸¥à¸²à¸œà¹ˆà¸²à¸™à¹„à¸›\n",
      "\n",
      "```\n",
      "Training Time                    Production Time\n",
      "     â”‚                                â”‚\n",
      "     â–¼                                â–¼\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ Training    â”‚               â”‚ Production  â”‚\n",
      "â”‚ Data        â”‚â”€â”€â”€â”€ Drift â”€â”€â”€â–¶â”‚ Data        â”‚\n",
      "â”‚ P(X,Y)_trainâ”‚               â”‚ P(X,Y)_prod â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "     â”‚                                â”‚\n",
      "     â–¼                                â–¼\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ Good Model  â”‚               â”‚ Degraded    â”‚\n",
      "â”‚ Performance â”‚               â”‚ Performance â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "```\n",
      "\n",
      "### à¸—à¸³à¹„à¸¡ Drift Detection à¸–à¸¶à¸‡à¸ªà¸³à¸„à¸±à¸?\n",
      "\n",
      "1. **Model Degradation**: à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸µà¹ˆ train à¸”à¹‰à¸§à¸¢à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸à¹ˆà¸²à¸­à¸²à¸ˆà¸—à¸³à¸™à¸²à¸¢à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¸à¸±à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¸¡à¹ˆ\n",
      "2. **Business Impact**: à¸à¸²à¸£à¸•à¸±à¸”à¸ªà¸´à¸™à¹ƒà¸ˆà¸œà¸´à¸”à¸à¸¥à¸²à¸”à¸ªà¹ˆà¸‡à¸œà¸¥à¸•à¹ˆà¸­à¸˜à¸¸à¸£à¸à¸´à¸ˆà¹‚à¸”à¸¢à¸•à¸£à¸‡\n",
      "3. **Regulatory Compliance**: à¸«à¸¥à¸²à¸¢à¸­à¸¸à¸•à¸ªà¸²à¸«à¸à¸£à¸£à¸¡à¸•à¹‰à¸­à¸‡à¸à¸²à¸£ monitoring à¸­à¸¢à¹ˆà¸²à¸‡à¸•à¹ˆà¸­à¹€à¸™à¸·à¹ˆà¸­à¸‡\n",
      "4. **Resource Optimization**: à¸£à¸¹à¹‰à¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡ retrain à¸Šà¹ˆà¸§à¸¢à¸›à¸£à¸°à¸«à¸¢à¸±à¸”à¸—à¸£à¸±à¸à¸¢à¸²à¸à¸£\n",
      "\n",
      "---\n",
      "\n",
      "## LAB 1: Understanding Data Drift Concepts\n",
      "\n",
      "### ğŸ¯ à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ\n",
      "- à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸„à¸§à¸²à¸¡à¹à¸•à¸à¸•à¹ˆà¸²à¸‡à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ Covariate Shift à¹à¸¥à¸° Concept Drift\n",
      "- à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰ Statistical tests à¸ªà¸³à¸«à¸£à¸±à¸š drift detection\n",
      "- à¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸¥à¸·à¸­à¸ drift detection method à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡\n",
      "\n",
      "### à¸—à¸¤à¸©à¸à¸µ: à¸›à¸£à¸°à¹€à¸ à¸—à¸‚à¸­à¸‡ Data Drift\n",
      "\n",
      "#### 1. Covariate Shift (Feature Drift)\n",
      "\n",
      "**à¸™à¸´à¸¢à¸²à¸¡**: à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸‚à¸­à¸‡ distribution à¸‚à¸­à¸‡ input features P(X) à¹‚à¸”à¸¢à¸—à¸µà¹ˆà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œ P(Y|X) à¸¢à¸±à¸‡à¸„à¸‡à¹€à¸”à¸´à¸¡\n",
      "\n",
      "```\n",
      "Covariate Shift:\n",
      "â”œâ”€â”€ P(X)_train â‰  P(X)_prod     â† Distribution à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™\n",
      "â””â”€â”€ P(Y|X)_train = P(Y|X)_prod  â† Relationship à¸„à¸‡à¹€à¸”à¸´à¸¡\n",
      "```\n",
      "\n",
      "**à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¹ƒà¸™à¸Šà¸µà¸§à¸´à¸•à¸ˆà¸£à¸´à¸‡**:\n",
      "- à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸³à¸™à¸²à¸¢à¸£à¸²à¸„à¸²à¸šà¹‰à¸²à¸™à¸—à¸µà¹ˆ train à¸à¸±à¸šà¸šà¹‰à¸²à¸™à¹ƒà¸™à¹€à¸¡à¸·à¸­à¸‡ à¹à¸•à¹ˆà¸•à¹‰à¸­à¸‡à¸—à¸³à¸™à¸²à¸¢à¸šà¹‰à¸²à¸™à¹ƒà¸™à¸Šà¸™à¸šà¸—\n",
      "- à¹‚à¸¡à¹€à¸”à¸¥à¸­à¸²à¸¢à¸¸à¸¥à¸¹à¸à¸„à¹‰à¸²à¸—à¸µà¹ˆ train à¸à¸±à¸šà¸à¸¥à¸¸à¹ˆà¸¡à¸­à¸²à¸¢à¸¸ 20-40 à¸›à¸µ à¹à¸•à¹ˆ production à¸¡à¸µà¸¥à¸¹à¸à¸„à¹‰à¸²à¸­à¸²à¸¢à¸¸ 40-60 à¸›à¸µ\n",
      "\n",
      "**Code Reference** - à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Covariate Shift:\n",
      "```python\n",
      "def generate_covariate_shift_data():\n",
      "    # Training data: à¸¥à¸¹à¸à¸„à¹‰à¸²à¸­à¸²à¸¢à¸¸à¸™à¹‰à¸­à¸¢ (20-40)\n",
      "    age_train = np.random.normal(30, 5, n_train)\n",
      "    \n",
      "    # Production data: à¸¥à¸¹à¸à¸„à¹‰à¸²à¸­à¸²à¸¢à¸¸à¸¡à¸²à¸à¸‚à¸¶à¹‰à¸™ (40-60) - Covariate Shift!\n",
      "    age_prod = np.random.normal(50, 5, n_prod)\n",
      "    \n",
      "    # à¸à¸à¸à¸²à¸£à¸‹à¸·à¹‰à¸­à¹€à¸«à¸¡à¸·à¸­à¸™à¹€à¸”à¸´à¸¡ (à¹„à¸¡à¹ˆà¸¡à¸µ Concept Drift)\n",
      "    # P(Y|X) à¸¢à¸±à¸‡à¸„à¸‡à¹€à¸”à¸´à¸¡\n",
      "```\n",
      "\n",
      "#### 2. Concept Drift (Label Drift)\n",
      "\n",
      "**à¸™à¸´à¸¢à¸²à¸¡**: à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸‚à¸­à¸‡à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œà¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ input à¹à¸¥à¸° output P(Y|X)\n",
      "\n",
      "```\n",
      "Concept Drift:\n",
      "â”œâ”€â”€ P(X) à¸­à¸²à¸ˆà¸„à¸‡à¸—à¸µà¹ˆà¸«à¸£à¸·à¸­à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸à¹‡à¹„à¸”à¹‰\n",
      "â””â”€â”€ P(Y|X)_train â‰  P(Y|X)_prod  â† Relationship à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™!\n",
      "```\n",
      "\n",
      "**à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¹ƒà¸™à¸Šà¸µà¸§à¸´à¸•à¸ˆà¸£à¸´à¸‡**:\n",
      "- à¸à¸¤à¸•à¸´à¸à¸£à¸£à¸¡à¸à¸²à¸£à¸‹à¸·à¹‰à¸­à¸‚à¸­à¸‡à¸¥à¸¹à¸à¸„à¹‰à¸²à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸«à¸¥à¸±à¸‡ COVID-19\n",
      "- à¸„à¸§à¸²à¸¡à¸«à¸¡à¸²à¸¢à¸‚à¸­à¸‡ \"spam email\" à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹„à¸›à¸•à¸²à¸¡à¹€à¸§à¸¥à¸²\n",
      "\n",
      "**Code Reference** - à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Concept Drift:\n",
      "```python\n",
      "def generate_concept_drift_data():\n",
      "    # Training: à¸à¸à¸à¸²à¸£à¸‹à¸·à¹‰à¸­à¹€à¸”à¸´à¸¡ - à¸‹à¸·à¹‰à¸­à¸–à¹‰à¸² income > 45000\n",
      "    purchase_train = (income_train > 45000).astype(int)\n",
      "    \n",
      "    # Production: à¸à¸à¸à¸²à¸£à¸‹à¸·à¹‰à¸­à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ - à¸‹à¸·à¹‰à¸­à¸–à¹‰à¸² income > 55000\n",
      "    # Threshold à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ = Concept Drift!\n",
      "    purchase_prod = (income_prod > 55000).astype(int)\n",
      "```\n",
      "\n",
      "#### à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š Covariate Shift vs Concept Drift\n",
      "\n",
      "| à¸¥à¸±à¸à¸©à¸“à¸° | Covariate Shift | Concept Drift |\n",
      "|--------|-----------------|---------------|\n",
      "| à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ | P(X) | P(Y\\|X) |\n",
      "| à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡ | à¸à¸¥à¸¸à¹ˆà¸¡à¸¥à¸¹à¸à¸„à¹‰à¸²à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ | à¸à¸¤à¸•à¸´à¸à¸£à¸£à¸¡à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ |\n",
      "| à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š | à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š feature distributions | à¸•à¹‰à¸­à¸‡à¸¡à¸µ labels à¸«à¸£à¸·à¸­ performance |\n",
      "| à¸§à¸´à¸˜à¸µà¹à¸à¹‰ | Sample weighting, Retrain | Retrain with new data |\n",
      "\n",
      "---\n",
      "\n",
      "### Statistical Tests à¸ªà¸³à¸«à¸£à¸±à¸š Drift Detection\n",
      "\n",
      "#### 1. Kolmogorov-Smirnov (KS) Test\n",
      "\n",
      "**à¸—à¸¤à¸©à¸à¸µ**:\n",
      "- à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š Cumulative Distribution Function (CDF) à¸‚à¸­à¸‡ 2 samples\n",
      "- à¸§à¸±à¸”à¸„à¸§à¸²à¸¡à¹à¸•à¸à¸•à¹ˆà¸²à¸‡à¸ªà¸¹à¸‡à¸ªà¸¸à¸”à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ 2 CDFs\n",
      "\n",
      "```\n",
      "KS Statistic = max|Fâ‚(x) - Fâ‚‚(x)|\n",
      "\n",
      "à¹‚à¸”à¸¢à¸—à¸µà¹ˆ:\n",
      "- Fâ‚(x) = CDF à¸‚à¸­à¸‡ reference data\n",
      "- Fâ‚‚(x) = CDF à¸‚à¸­à¸‡ current data\n",
      "```\n",
      "\n",
      "**à¸à¸²à¸£à¸•à¸µà¸„à¸§à¸²à¸¡**:\n",
      "- KS Statistic: 0-1 (à¸¢à¸´à¹ˆà¸‡à¸ªà¸¹à¸‡ = à¸¢à¸´à¹ˆà¸‡à¹à¸•à¸à¸•à¹ˆà¸²à¸‡)\n",
      "- p-value < 0.05: reject null hypothesis â†’ à¸¡à¸µ drift\n",
      "\n",
      "**à¸‚à¹‰à¸­à¸”à¸µ**:\n",
      "- à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸ªà¸¡à¸¡à¸•à¸´ distribution (non-parametric)\n",
      "- Sensitive à¸•à¹ˆà¸­à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡\n",
      "\n",
      "**à¸‚à¹‰à¸­à¹€à¸ªà¸µà¸¢**:\n",
      "- à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¸à¸±à¸š continuous variables à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™\n",
      "\n",
      "**Code Reference**:\n",
      "```python\n",
      "def kolmogorov_smirnov_test(data1, data2, feature_name=\"feature\"):\n",
      "    statistic, p_value = stats.ks_2samp(data1, data2)\n",
      "    drift_detected = p_value < 0.05\n",
      "    \n",
      "    return {\n",
      "        'statistic': statistic,\n",
      "        'p_value': p_value,\n",
      "        'drift_detected': drift_detected\n",
      "    }\n",
      "```\n",
      "\n",
      "#### 2. Population Stability Index (PSI)\n",
      "\n",
      "**à¸—à¸¤à¸©à¸à¸µ**:\n",
      "- à¸§à¸±à¸”à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸‚à¸­à¸‡ distribution à¹‚à¸”à¸¢à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š proportions à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸° bin\n",
      "- à¸™à¸´à¸¢à¸¡à¹ƒà¸Šà¹‰à¹ƒà¸™ credit scoring à¹à¸¥à¸° financial models\n",
      "\n",
      "**à¸ªà¸¹à¸•à¸£**:\n",
      "```\n",
      "PSI = Î£ (Actual% - Expected%) Ã— ln(Actual% / Expected%)\n",
      "\n",
      "à¹‚à¸”à¸¢à¸—à¸µà¹ˆ:\n",
      "- Expected% = proportion à¹ƒà¸™ reference data\n",
      "- Actual% = proportion à¹ƒà¸™ current data\n",
      "```\n",
      "\n",
      "**à¸à¸²à¸£à¸•à¸µà¸„à¸§à¸²à¸¡ PSI**:\n",
      "\n",
      "| à¸„à¹ˆà¸² PSI | à¸„à¸§à¸²à¸¡à¸«à¸¡à¸²à¸¢ | Action |\n",
      "|---------|----------|--------|\n",
      "| < 0.1 | à¹„à¸¡à¹ˆà¸¡à¸µà¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸ªà¸³à¸„à¸±à¸ | à¸›à¸à¸•à¸´ |\n",
      "| 0.1 - 0.25 | à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸›à¸²à¸™à¸à¸¥à¸²à¸‡ | à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹€à¸à¸´à¹ˆà¸¡ |\n",
      "| â‰¥ 0.25 | à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸¡à¸²à¸ | à¸•à¹‰à¸­à¸‡à¸”à¸³à¹€à¸™à¸´à¸™à¸à¸²à¸£ |\n",
      "\n",
      "**Code Reference**:\n",
      "```python\n",
      "def calculate_psi(expected, actual, bins=10, eps=1e-6):\n",
      "    # à¸ªà¸£à¹‰à¸²à¸‡ bins à¸ˆà¸²à¸ expected data\n",
      "    breakpoints = np.percentile(expected, np.linspace(0, 100, bins + 1))\n",
      "    \n",
      "    # à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸° bin\n",
      "    expected_counts, _ = np.histogram(expected, bins=breakpoints)\n",
      "    actual_counts, _ = np.histogram(actual, bins=breakpoints)\n",
      "    \n",
      "    # à¸„à¸³à¸™à¸§à¸“ proportions\n",
      "    expected_props = expected_counts / len(expected) + eps\n",
      "    actual_props = actual_counts / len(actual) + eps\n",
      "    \n",
      "    # à¸„à¸³à¸™à¸§à¸“ PSI\n",
      "    psi = np.sum((actual_props - expected_props) * np.log(actual_props / expected_props))\n",
      "    return psi\n",
      "```\n",
      "\n",
      "#### 3. Wasserstein Distance (Earth Mover's Distance)\n",
      "\n",
      "**à¸—à¸¤à¸©à¸à¸µ**:\n",
      "- à¸§à¸±à¸” \"à¸‡à¸²à¸™\" à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰à¹ƒà¸™à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ distribution à¸«à¸™à¸¶à¹ˆà¸‡à¹„à¸›à¹€à¸›à¹‡à¸™à¸­à¸µà¸ distribution\n",
      "- à¸„à¸¥à¹‰à¸²à¸¢à¸à¸±à¸šà¸à¸²à¸£à¸„à¸³à¸™à¸§à¸“à¸•à¹‰à¸™à¸—à¸¸à¸™à¹ƒà¸™à¸à¸²à¸£à¸‚à¸™à¸¢à¹‰à¸²à¸¢à¸”à¸´à¸™\n",
      "\n",
      "```\n",
      "Wasserstein Distance = inf âˆ«|Fâ‚â»Â¹(u) - Fâ‚‚â»Â¹(u)| du\n",
      "\n",
      "à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸ªà¸¡à¸·à¸­à¸™:\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚   Pile A    â”‚  move   â”‚   Pile B    â”‚\n",
      "â”‚   (sand)    â”‚ â”€â”€â”€â”€â”€â”€â–¶ â”‚   (sand)    â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  cost   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "```\n",
      "\n",
      "**à¸‚à¹‰à¸­à¸”à¸µ**:\n",
      "- à¸„à¸³à¸™à¸¶à¸‡à¸–à¸¶à¸‡ distance à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ bins\n",
      "- Sensitive à¸•à¹ˆà¸­ shift à¹ƒà¸™à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡\n",
      "\n",
      "**Code Reference**:\n",
      "```python\n",
      "def wasserstein_distance_test(data1, data2, feature_name=\"feature\"):\n",
      "    distance = stats.wasserstein_distance(data1, data2)\n",
      "    \n",
      "    # Normalize à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰ standard deviation\n",
      "    std_ref = np.std(data1)\n",
      "    normalized_distance = distance / std_ref if std_ref > 0 else distance\n",
      "    \n",
      "    return {\n",
      "        'distance': distance,\n",
      "        'normalized_distance': normalized_distance\n",
      "    }\n",
      "```\n",
      "\n",
      "### à¸à¸²à¸£à¹€à¸¥à¸·à¸­à¸ Drift Detection Method\n",
      "\n",
      "```\n",
      "Decision Tree:\n",
      "\n",
      "1. Data Type?\n",
      "   â”œâ”€â”€ Continuous â†’ à¹„à¸›à¸‚à¹‰à¸­ 2\n",
      "   â””â”€â”€ Categorical â†’ Chi-squared à¸«à¸£à¸·à¸­ PSI\n",
      "\n",
      "2. à¸•à¹‰à¸­à¸‡à¸à¸²à¸£ Statistical Significance?\n",
      "   â”œâ”€â”€ à¹ƒà¸Šà¹ˆ â†’ KS Test\n",
      "   â””â”€â”€ à¹„à¸¡à¹ˆà¸ˆà¸³à¹€à¸›à¹‡à¸™ â†’ PSI à¸«à¸£à¸·à¸­ Wasserstein\n",
      "\n",
      "3. Industry Requirement?\n",
      "   â”œâ”€â”€ Finance/Credit â†’ PSI (regulatory standards)\n",
      "   â””â”€â”€ à¸­à¸·à¹ˆà¸™à¹† â†’ à¹€à¸¥à¸·à¸­à¸à¸•à¸²à¸¡à¸„à¸§à¸²à¸¡à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡\n",
      "\n",
      "4. à¸•à¹‰à¸­à¸‡à¸à¸²à¸£ Sensitivity à¸ªà¸¹à¸‡?\n",
      "   â”œâ”€â”€ à¹ƒà¸Šà¹ˆ â†’ Wasserstein\n",
      "   â””â”€â”€ à¸›à¸à¸•à¸´ â†’ KS à¸«à¸£à¸·à¸­ PSI\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## LAB 2: Feature Drift Detection\n",
      "\n",
      "### ğŸ¯ à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ\n",
      "- à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š drift à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸° feature à¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸›à¹‡à¸™à¸£à¸°à¸šà¸š\n",
      "- à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ numerical vs categorical feature drift\n",
      "- à¸ªà¸£à¹‰à¸²à¸‡ visualization à¸ªà¸³à¸«à¸£à¸±à¸š feature distributions\n",
      "\n",
      "### à¸—à¸¤à¸©à¸à¸µ: Per-Feature Analysis\n",
      "\n",
      "à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ drift à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸° feature à¸¡à¸µà¸„à¸§à¸²à¸¡à¸ªà¸³à¸„à¸±à¸à¹€à¸à¸£à¸²à¸°:\n",
      "1. à¸Šà¹ˆà¸§à¸¢à¸£à¸°à¸šà¸¸ root cause à¸‚à¸­à¸‡ model performance degradation\n",
      "2. à¸—à¸³à¹ƒà¸«à¹‰à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸§à¹ˆà¸² feature à¹„à¸«à¸™à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸¡à¸²à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸”\n",
      "3. à¸ªà¸²à¸¡à¸²à¸£à¸– prioritize à¸à¸²à¸£à¹à¸à¹‰à¹„à¸‚à¹„à¸”à¹‰\n",
      "\n",
      "### Numerical Features vs Categorical Features\n",
      "\n",
      "#### Numerical Features\n",
      "```\n",
      "Methods à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰:\n",
      "â”œâ”€â”€ KS Test - compare CDFs\n",
      "â”œâ”€â”€ PSI - compare bin proportions\n",
      "â””â”€â”€ Wasserstein - measure distribution distance\n",
      "```\n",
      "\n",
      "#### Categorical Features\n",
      "```\n",
      "Methods à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰:\n",
      "â”œâ”€â”€ Chi-squared Test - compare frequency distributions\n",
      "â””â”€â”€ PSI (category-based) - compare category proportions\n",
      "```\n",
      "\n",
      "### Feature Drift Detector Class\n",
      "\n",
      "**Architecture**:\n",
      "```\n",
      "FeatureDriftDetector\n",
      "â”œâ”€â”€ __init__()\n",
      "â”‚   â”œâ”€â”€ reference_data\n",
      "â”‚   â”œâ”€â”€ current_data\n",
      "â”‚   â”œâ”€â”€ numerical_features\n",
      "â”‚   â””â”€â”€ categorical_features\n",
      "â”‚\n",
      "â”œâ”€â”€ Numerical Methods\n",
      "â”‚   â”œâ”€â”€ ks_test()\n",
      "â”‚   â”œâ”€â”€ calculate_psi()\n",
      "â”‚   â””â”€â”€ wasserstein_test()\n",
      "â”‚\n",
      "â”œâ”€â”€ Categorical Methods\n",
      "â”‚   â”œâ”€â”€ chi_squared_test()\n",
      "â”‚   â””â”€â”€ categorical_psi()\n",
      "â”‚\n",
      "â””â”€â”€ Analysis\n",
      "    â”œâ”€â”€ analyze_numerical_feature()\n",
      "    â”œâ”€â”€ analyze_categorical_feature()\n",
      "    â”œâ”€â”€ analyze_all_features()\n",
      "    â””â”€â”€ get_summary_report()\n",
      "```\n",
      "\n",
      "**Code Reference**:\n",
      "```python\n",
      "class FeatureDriftDetector:\n",
      "    def __init__(self, reference_data, current_data, \n",
      "                 numerical_features=None, categorical_features=None):\n",
      "        self.reference = reference_data\n",
      "        self.current = current_data\n",
      "        self.numerical_features = numerical_features\n",
      "        self.categorical_features = categorical_features\n",
      "    \n",
      "    def analyze_numerical_feature(self, feature):\n",
      "        results = {\n",
      "            'ks_test': self.ks_test(feature),\n",
      "            'psi': self.calculate_psi(feature),\n",
      "            'wasserstein': self.wasserstein_test(feature)\n",
      "        }\n",
      "        # à¸ªà¸£à¸¸à¸›à¸œà¸¥\n",
      "        ks_drift = results['ks_test']['p_value'] < 0.05\n",
      "        psi_value = results['psi']['psi']\n",
      "        \n",
      "        if psi_value < 0.1:\n",
      "            psi_severity = 'none'\n",
      "        elif psi_value < 0.25:\n",
      "            psi_severity = 'mild'\n",
      "        else:\n",
      "            psi_severity = 'severe'\n",
      "        \n",
      "        results['drift_detected'] = ks_drift or psi_severity != 'none'\n",
      "        return results\n",
      "```\n",
      "\n",
      "### Feature Drift Ranking\n",
      "\n",
      "à¸ˆà¸±à¸”à¸¥à¸³à¸”à¸±à¸š features à¸•à¸²à¸¡à¸„à¸§à¸²à¸¡à¸£à¸¸à¸™à¹à¸£à¸‡à¸‚à¸­à¸‡ drift à¹€à¸à¸·à¹ˆà¸­ prioritization:\n",
      "\n",
      "```\n",
      "Ranking Algorithm:\n",
      "1. à¸„à¸³à¸™à¸§à¸“ PSI à¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸¸à¸ features\n",
      "2. à¹€à¸£à¸µà¸¢à¸‡à¸¥à¸³à¸”à¸±à¸šà¸ˆà¸²à¸à¸¡à¸²à¸à¹„à¸›à¸™à¹‰à¸­à¸¢\n",
      "3. à¸à¸³à¸«à¸™à¸” severity level (none/mild/severe)\n",
      "4. Focus à¹à¸à¹‰à¹„à¸‚ features à¸—à¸µà¹ˆà¸¡à¸µ severe drift à¸à¹ˆà¸­à¸™\n",
      "```\n",
      "\n",
      "### Time-based Distribution Analysis\n",
      "\n",
      "à¸à¸²à¸£à¸•à¸´à¸”à¸•à¸²à¸¡ drift à¹€à¸¡à¸·à¹ˆà¸­à¹€à¸§à¸¥à¸²à¸œà¹ˆà¸²à¸™à¹„à¸›:\n",
      "\n",
      "```\n",
      "Period 0 (Reference)\n",
      "    â”‚\n",
      "    â–¼\n",
      "Period 1 â”€â”€â”€â”€ PSI = 0.02 (none)\n",
      "    â”‚\n",
      "    â–¼\n",
      "Period 2 â”€â”€â”€â”€ PSI = 0.08 (none)\n",
      "    â”‚\n",
      "    â–¼\n",
      "Period 3 â”€â”€â”€â”€ PSI = 0.15 (mild) âš ï¸\n",
      "    â”‚\n",
      "    â–¼\n",
      "Period 4 â”€â”€â”€â”€ PSI = 0.28 (severe) ğŸ”´\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## LAB 3: Multivariate Drift Analysis\n",
      "\n",
      "### ğŸ¯ à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ\n",
      "- à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š drift à¸—à¸µà¹ˆà¹€à¸à¸´à¸”à¸ˆà¸²à¸à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œà¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ features\n",
      "- à¹ƒà¸Šà¹‰ Dataset-level drift detection\n",
      "- à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ Correlation changes\n",
      "\n",
      "### à¸—à¸¤à¸©à¸à¸µ: Multivariate Drift\n",
      "\n",
      "**à¸›à¸±à¸à¸«à¸²**: Univariate methods à¸­à¸²à¸ˆà¸à¸¥à¸²à¸” drift à¸—à¸µà¹ˆà¹€à¸à¸´à¸”à¸ˆà¸²à¸à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸‚à¸­à¸‡à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œà¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ features\n",
      "\n",
      "```\n",
      "à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡:\n",
      "Reference:                    Current:\n",
      "- Age mean = 35              - Age mean = 35      (à¹€à¸«à¸¡à¸·à¸­à¸™à¹€à¸”à¸´à¸¡)\n",
      "- Income mean = 50000        - Income mean = 50000 (à¹€à¸«à¸¡à¸·à¸­à¸™à¹€à¸”à¸´à¸¡)\n",
      "- Corr(Age, Income) = 0.8    - Corr(Age, Income) = 0.1 â† à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™!\n",
      "\n",
      "Univariate test: à¹„à¸¡à¹ˆà¸à¸š drift\n",
      "Multivariate test: à¸à¸š drift à¹ƒà¸™à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œ\n",
      "```\n",
      "\n",
      "### Methods à¸ªà¸³à¸«à¸£à¸±à¸š Multivariate Drift\n",
      "\n",
      "#### 1. Correlation-based Analysis\n",
      "\n",
      "**à¸—à¸¤à¸©à¸à¸µ**: à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š correlation matrix à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ reference à¹à¸¥à¸° current data\n",
      "\n",
      "**Fisher's Z Transformation** à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š correlations:\n",
      "```\n",
      "Z = arctanh(r)\n",
      "\n",
      "Z-test statistic = (Z_ref - Z_cur) / SE\n",
      "where SE = sqrt(1/(nâ‚-3) + 1/(nâ‚‚-3))\n",
      "```\n",
      "\n",
      "**Code Reference**:\n",
      "```python\n",
      "def correlation_drift_test(ref_df, cur_df, significance_level=0.05):\n",
      "    ref_corr = ref_df.corr()\n",
      "    cur_corr = cur_df.corr()\n",
      "    \n",
      "    for col1, col2 in feature_pairs:\n",
      "        r_ref = ref_corr.loc[col1, col2]\n",
      "        r_cur = cur_corr.loc[col1, col2]\n",
      "        \n",
      "        # Fisher's Z transformation\n",
      "        z_ref = np.arctanh(r_ref)\n",
      "        z_cur = np.arctanh(r_cur)\n",
      "        \n",
      "        # Z-test\n",
      "        se = np.sqrt(1/(n_ref-3) + 1/(n_cur-3))\n",
      "        z_stat = (z_ref - z_cur) / se\n",
      "        p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))\n",
      "```\n",
      "\n",
      "#### 2. PCA-based Analysis\n",
      "\n",
      "**à¸—à¸¤à¸©à¸à¸µ**: à¹ƒà¸Šà¹‰ Principal Component Analysis à¹€à¸à¸·à¹ˆà¸­à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸‚à¸­à¸‡ multivariate structure\n",
      "\n",
      "```\n",
      "PCA Drift Detection:\n",
      "â”œâ”€â”€ Explained Variance Ratio - variance à¸—à¸µà¹ˆà¹à¸•à¹ˆà¸¥à¸° PC à¸­à¸˜à¸´à¸šà¸²à¸¢à¹„à¸”à¹‰\n",
      "â”œâ”€â”€ Component Similarity - à¸—à¸´à¸¨à¸—à¸²à¸‡à¸‚à¸­à¸‡ PC à¹€à¸«à¸¡à¸·à¸­à¸™à¹€à¸”à¸´à¸¡à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ\n",
      "â””â”€â”€ Reconstruction Error - error à¹€à¸¡à¸·à¹ˆà¸­ reconstruct data\n",
      "```\n",
      "\n",
      "**Metrics à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰**:\n",
      "1. **Explained Variance Comparison**: à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸§à¹ˆà¸²à¹à¸•à¹ˆà¸¥à¸° PC à¸­à¸˜à¸´à¸šà¸²à¸¢ variance à¹€à¸—à¹ˆà¸²à¹€à¸”à¸´à¸¡à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ\n",
      "2. **Component Similarity (Cosine Similarity)**: à¸”à¸¹à¸§à¹ˆà¸² PC directions à¹€à¸«à¸¡à¸·à¸­à¸™à¹€à¸”à¸´à¸¡à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ\n",
      "3. **Reconstruction Error**: à¹ƒà¸Šà¹‰ reference PCA à¸à¸±à¸š current data à¹à¸¥à¹‰à¸§à¸”à¸¹ error\n",
      "\n",
      "**Code Reference**:\n",
      "```python\n",
      "def pca_drift_detection(ref_df, cur_df, n_components=None):\n",
      "    # Standardize\n",
      "    scaler = StandardScaler()\n",
      "    ref_scaled = scaler.fit_transform(ref_df)\n",
      "    cur_scaled = scaler.transform(cur_df)\n",
      "    \n",
      "    # Fit PCA on reference\n",
      "    pca_ref = PCA(n_components=n_components)\n",
      "    pca_ref.fit(ref_scaled)\n",
      "    \n",
      "    # Component similarities (using cosine similarity)\n",
      "    for i in range(n_components):\n",
      "        cos_sim = abs(np.dot(pca_ref.components_[i], pca_cur.components_[i]))\n",
      "        # à¸–à¹‰à¸² cos_sim < 0.9 = structure à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™\n",
      "```\n",
      "\n",
      "#### 3. Mahalanobis Distance\n",
      "\n",
      "**à¸—à¸¤à¸©à¸à¸µ**: à¸§à¸±à¸”à¸§à¹ˆà¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¸¡à¹ˆà¸­à¸¢à¸¹à¹ˆà¸«à¹ˆà¸²à¸‡à¸ˆà¸²à¸ distribution à¸‚à¸­à¸‡ reference data à¹€à¸—à¹ˆà¸²à¹„à¸£ à¹‚à¸”à¸¢à¸„à¸³à¸™à¸¶à¸‡à¸–à¸¶à¸‡ covariance\n",
      "\n",
      "```\n",
      "Mahalanobis Distance = âˆš((x - Î¼)áµ€ Î£â»Â¹ (x - Î¼))\n",
      "\n",
      "à¹‚à¸”à¸¢à¸—à¸µà¹ˆ:\n",
      "- x = data point\n",
      "- Î¼ = mean à¸‚à¸­à¸‡ reference\n",
      "- Î£ = covariance matrix à¸‚à¸­à¸‡ reference\n",
      "```\n",
      "\n",
      "**à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™**:\n",
      "1. Fit covariance à¸šà¸™ reference data\n",
      "2. à¸„à¸³à¸™à¸§à¸“ Mahalanobis distance à¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸¸à¸ points\n",
      "3. à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š distribution à¸‚à¸­à¸‡ distances\n",
      "\n",
      "**Code Reference**:\n",
      "```python\n",
      "def mahalanobis_drift_detection(ref_df, cur_df, threshold_percentile=95):\n",
      "    # Fit covariance on reference\n",
      "    cov = EmpiricalCovariance().fit(ref_scaled)\n",
      "    \n",
      "    # Calculate distances\n",
      "    ref_distances = cov.mahalanobis(ref_scaled)\n",
      "    cur_distances = cov.mahalanobis(cur_scaled)\n",
      "    \n",
      "    # Compare distributions\n",
      "    ks_stat, ks_pval = stats.ks_2samp(ref_distances, cur_distances)\n",
      "    drift_detected = ks_pval < 0.05\n",
      "```\n",
      "\n",
      "### Comprehensive Multivariate Analysis\n",
      "\n",
      "```\n",
      "MultivariateriftDetector\n",
      "â”œâ”€â”€ Correlation Analysis\n",
      "â”‚   â””â”€â”€ à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š pairwise correlation changes\n",
      "â”œâ”€â”€ PCA Analysis\n",
      "â”‚   â””â”€â”€ à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š structure changes\n",
      "â”œâ”€â”€ Mahalanobis Analysis\n",
      "â”‚   â””â”€â”€ à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š distribution shift\n",
      "â””â”€â”€ Consensus\n",
      "    â””â”€â”€ à¸£à¸§à¸¡à¸œà¸¥à¸ˆà¸²à¸à¸—à¸¸à¸ methods\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## LAB 4: Drift Detection in Production Simulation\n",
      "\n",
      "### ğŸ¯ à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ\n",
      "- à¸ªà¸£à¹‰à¸²à¸‡ simulated data stream à¸—à¸µà¹ˆà¸¡à¸µ drift\n",
      "- à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š sudden vs gradual drift\n",
      "- Implement sliding window monitoring\n",
      "\n",
      "### à¸—à¸¤à¸©à¸à¸µ: Drift Patterns à¹ƒà¸™ Production\n",
      "\n",
      "#### Types of Drift\n",
      "\n",
      "```\n",
      "1. Sudden Drift (Abrupt)\n",
      "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "               â”‚\n",
      "               â–¼ Drift Point\n",
      "   à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸—à¸±à¸™à¸—à¸µ\n",
      "\n",
      "2. Gradual Drift\n",
      "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸Šà¹‰à¸²à¹† à¸•à¸²à¸¡à¹€à¸§à¸¥à¸²\n",
      "\n",
      "3. Incremental Drift\n",
      "   â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "       â”‚   â”‚   â”‚   â”‚\n",
      "   à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹€à¸›à¹‡à¸™à¸‚à¸±à¹‰à¸™à¸šà¸±à¸™à¹„à¸”\n",
      "\n",
      "4. Seasonal/Recurring Drift\n",
      "   â”€â”€â”€â”€â•²â•±â”€â”€â”€â”€â•²â•±â”€â”€â”€â”€â•²â•±â”€â”€â”€â”€\n",
      "   à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸•à¸²à¸¡ pattern à¸‹à¹‰à¸³\n",
      "```\n",
      "\n",
      "**Code Reference** - Data Stream Simulator:\n",
      "```python\n",
      "class DataStreamSimulator:\n",
      "    def generate_stream(self, n_samples, drift_type='no_drift', drift_params=None):\n",
      "        if drift_type == 'sudden':\n",
      "            # à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸—à¸±à¸™à¸—à¸µà¸—à¸µà¹ˆ drift_point\n",
      "            data[:drift_point] = np.random.normal(base_mean, ...)\n",
      "            data[drift_point:] = np.random.normal(new_mean, ...)\n",
      "            \n",
      "        elif drift_type == 'gradual':\n",
      "            # Linear interpolation\n",
      "            for i in range(n_samples):\n",
      "                if drift_start <= i <= drift_end:\n",
      "                    progress = (i - drift_start) / (drift_end - drift_start)\n",
      "                    current_mean = base_mean + progress * (final_mean - base_mean)\n",
      "```\n",
      "\n",
      "### Sliding Window Drift Detection\n",
      "\n",
      "**à¸«à¸¥à¸±à¸à¸à¸²à¸£**:\n",
      "```\n",
      "Time â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶\n",
      "\n",
      "Reference Window          Test Window\n",
      "[â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•]     [â•â•â•â•â•â•â•â•â•]\n",
      "        â–²                      â–²\n",
      "        â”‚                      â”‚\n",
      "   Fixed/Slow moving    Current data\n",
      "```\n",
      "\n",
      "**Architecture**:\n",
      "```\n",
      "SlidingWindowDriftDetector\n",
      "â”œâ”€â”€ reference_buffer (deque with maxlen)\n",
      "â”œâ”€â”€ test_buffer (deque with maxlen)\n",
      "â”œâ”€â”€ update(value)\n",
      "â”‚   â”œâ”€â”€ Add to buffer\n",
      "â”‚   â”œâ”€â”€ Check if ready\n",
      "â”‚   â””â”€â”€ Run drift detection\n",
      "â”œâ”€â”€ Detection Methods\n",
      "â”‚   â”œâ”€â”€ KS Test\n",
      "â”‚   â””â”€â”€ PSI\n",
      "â””â”€â”€ Output\n",
      "    â”œâ”€â”€ drift_detected\n",
      "    â”œâ”€â”€ metrics\n",
      "    â””â”€â”€ history\n",
      "```\n",
      "\n",
      "**Code Reference**:\n",
      "```python\n",
      "class SlidingWindowDriftDetector:\n",
      "    def __init__(self, reference_window_size=200, test_window_size=100):\n",
      "        self.reference_buffer = deque(maxlen=reference_window_size)\n",
      "        self.test_buffer = deque(maxlen=test_window_size)\n",
      "    \n",
      "    def update(self, value, timestamp=None):\n",
      "        # à¹€à¸à¸´à¹ˆà¸¡à¸„à¹ˆà¸²à¹ƒà¸™ buffers\n",
      "        if not self.is_initialized:\n",
      "            self.reference_buffer.append(value)\n",
      "            return {'status': 'initializing'}\n",
      "        \n",
      "        self.test_buffer.append(value)\n",
      "        \n",
      "        if len(self.test_buffer) < self.test_window_size:\n",
      "            return {'status': 'collecting'}\n",
      "        \n",
      "        # à¸—à¸³ drift detection\n",
      "        ref_array = np.array(self.reference_buffer)\n",
      "        test_array = np.array(self.test_buffer)\n",
      "        \n",
      "        psi = self.calculate_psi(ref_array, test_array)\n",
      "        drift_detected = psi > self.psi_threshold\n",
      "        \n",
      "        return {\n",
      "            'drift_detected': drift_detected,\n",
      "            'psi': psi\n",
      "        }\n",
      "```\n",
      "\n",
      "### Adaptive Reference Window\n",
      "\n",
      "**à¸›à¸±à¸à¸«à¸²à¸‚à¸­à¸‡ Fixed Reference**:\n",
      "- Gradual drift à¸­à¸²à¸ˆà¸•à¸£à¸§à¸ˆà¹„à¸¡à¹ˆà¹€à¸ˆà¸­ à¹€à¸à¸£à¸²à¸° reference à¹€à¸à¹ˆà¸²à¹€à¸à¸´à¸™à¹„à¸›\n",
      "- à¸•à¹‰à¸­à¸‡ adapt reference à¹€à¸¡à¸·à¹ˆà¸­ detect drift\n",
      "\n",
      "**à¸§à¸´à¸˜à¸µà¹à¸à¹‰**:\n",
      "```python\n",
      "class AdaptiveDriftDetector:\n",
      "    def adapt_reference(self):\n",
      "        \"\"\"à¸›à¸£à¸±à¸š reference window à¹€à¸¡à¸·à¹ˆà¸­ confirm drift\"\"\"\n",
      "        # à¸œà¸ªà¸¡ old reference à¸à¸±à¸š new data\n",
      "        old_weight = 0.5\n",
      "        \n",
      "        # à¹€à¸à¸´à¹ˆà¸¡à¸šà¸²à¸‡à¸ªà¹ˆà¸§à¸™à¸ˆà¸²à¸ old reference\n",
      "        for val in old_ref[-n_old:]:\n",
      "            self.reference_buffer.append(val)\n",
      "        \n",
      "        # à¹€à¸à¸´à¹ˆà¸¡ new data\n",
      "        for val in new_data:\n",
      "            self.reference_buffer.append(val)\n",
      "```\n",
      "\n",
      "### Page-Hinkley Test\n",
      "\n",
      "**à¸—à¸¤à¸©à¸à¸µ**: Algorithm à¸ªà¸³à¸«à¸£à¸±à¸š detect mean shift à¹ƒà¸™ streaming data\n",
      "\n",
      "```\n",
      "Algorithm:\n",
      "1. Update running mean: Î¼_t = Î±Â·Î¼_{t-1} + (1-Î±)Â·x_t\n",
      "2. Update cumulative sum: S_t = S_{t-1} + (x_t - Î¼_t - Î´)\n",
      "3. Track min/max of S_t\n",
      "4. Detect if S_t - min(S) > Î» (upward shift)\n",
      "         à¸«à¸£à¸·à¸­ max(S) - S_t > Î» (downward shift)\n",
      "```\n",
      "\n",
      "**Code Reference**:\n",
      "```python\n",
      "class PageHinkleyDetector:\n",
      "    def update(self, value):\n",
      "        # Update mean (exponential moving average)\n",
      "        self.mean = self.alpha * self.mean + (1 - self.alpha) * value\n",
      "        \n",
      "        # Update cumulative sum\n",
      "        self.sum += value - self.mean - self.delta\n",
      "        \n",
      "        # Update min/max\n",
      "        self.min_sum = min(self.min_sum, self.sum)\n",
      "        self.max_sum = max(self.max_sum, self.sum)\n",
      "        \n",
      "        # Detection\n",
      "        ph_positive = self.sum - self.min_sum  # Upward shift\n",
      "        ph_negative = self.max_sum - self.sum  # Downward shift\n",
      "        \n",
      "        drift_detected = (ph_positive > self.lambda_) or (ph_negative > self.lambda_)\n",
      "```\n",
      "\n",
      "### Comparison of Methods\n",
      "\n",
      "| Method | Pros | Cons | Best For |\n",
      "|--------|------|------|----------|\n",
      "| Sliding Window | Simple, intuitive | Fixed reference | Sudden drift |\n",
      "| Adaptive | Handles gradual drift | More complex | Production |\n",
      "| Page-Hinkley | Low memory, fast | Mean shift only | Real-time |\n",
      "\n",
      "---\n",
      "\n",
      "## LAB 5: Custom Metrics & Drift Thresholds\n",
      "\n",
      "### ğŸ¯ à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ\n",
      "- à¸ªà¸£à¹‰à¸²à¸‡ custom drift metrics\n",
      "- à¸›à¸£à¸±à¸š threshold à¸•à¸²à¸¡ business requirements\n",
      "- Handle false positives/negatives\n",
      "\n",
      "### à¸—à¸¤à¸©à¸à¸µ: Threshold Selection\n",
      "\n",
      "**à¸›à¸±à¸à¸«à¸²**: Default thresholds à¸­à¸²à¸ˆà¹„à¸¡à¹ˆà¹€à¸«à¸¡à¸²à¸°à¸à¸±à¸šà¸—à¸¸à¸ use case\n",
      "\n",
      "```\n",
      "Trade-off:\n",
      "                    Threshold\n",
      "           Low â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ High\n",
      "           \n",
      "Sensitivity: High                    Low\n",
      "False Positive: High                 Low\n",
      "False Negative: Low                  High\n",
      "```\n",
      "\n",
      "### Custom Drift Metrics\n",
      "\n",
      "#### 1. Combined Score\n",
      "```python\n",
      "def combined_score(reference, current, weights=None):\n",
      "    \"\"\"à¸£à¸§à¸¡à¸«à¸¥à¸²à¸¢ metrics à¹€à¸‚à¹‰à¸²à¸”à¹‰à¸§à¸¢à¸à¸±à¸™\"\"\"\n",
      "    if weights is None:\n",
      "        weights = {\n",
      "            'psi': 0.3,\n",
      "            'wasserstein': 0.3,\n",
      "            'mean_shift': 0.2,\n",
      "            'percentile': 0.2\n",
      "        }\n",
      "    \n",
      "    # Normalize à¹à¸•à¹ˆà¸¥à¸° metric à¹ƒà¸«à¹‰à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸Šà¹ˆà¸§à¸‡ 0-1\n",
      "    psi = min(calculate_psi(reference, current), 1.0)\n",
      "    wasserstein = min(normalized_wasserstein(reference, current) / 3, 1.0)\n",
      "    mean_shift = min(mean_shift_ratio(reference, current) / 3, 1.0)\n",
      "    percentile = min(percentile_shift(reference, current) / 3, 1.0)\n",
      "    \n",
      "    score = (weights['psi'] * psi + \n",
      "             weights['wasserstein'] * wasserstein +\n",
      "             weights['mean_shift'] * mean_shift +\n",
      "             weights['percentile'] * percentile)\n",
      "    \n",
      "    return score\n",
      "```\n",
      "\n",
      "#### 2. Jensen-Shannon Divergence\n",
      "```python\n",
      "def jensen_shannon_divergence(reference, current, bins=10):\n",
      "    \"\"\"Symmetric version of KL Divergence\"\"\"\n",
      "    # à¸ªà¸£à¹‰à¸²à¸‡ normalized histograms\n",
      "    ref_hist = np.histogram(reference, bins=bins, density=True)[0]\n",
      "    cur_hist = np.histogram(current, bins=bins, density=True)[0]\n",
      "    \n",
      "    # Average distribution\n",
      "    m = 0.5 * (ref_hist + cur_hist)\n",
      "    \n",
      "    # JS Divergence = 0.5 * (KL(P||M) + KL(Q||M))\n",
      "    js = 0.5 * (kl_divergence(ref_hist, m) + kl_divergence(cur_hist, m))\n",
      "    return js\n",
      "```\n",
      "\n",
      "### Threshold Optimization\n",
      "\n",
      "#### F1-based Optimization\n",
      "\n",
      "```python\n",
      "def find_optimal_threshold(scenarios, metric_func, thresholds, optimize_for='f1'):\n",
      "    \"\"\"à¸«à¸² threshold à¸—à¸µà¹ˆà¹ƒà¸«à¹‰ F1 score à¸ªà¸¹à¸‡à¸ªà¸¸à¸”\"\"\"\n",
      "    results = []\n",
      "    \n",
      "    for t in thresholds:\n",
      "        y_true = [s['has_drift'] for s in scenarios]\n",
      "        y_pred = [metric_func(s['reference'], s['current']) > t for s in scenarios]\n",
      "        \n",
      "        precision = precision_score(y_true, y_pred)\n",
      "        recall = recall_score(y_true, y_pred)\n",
      "        f1 = f1_score(y_true, y_pred)\n",
      "        \n",
      "        results.append({'threshold': t, 'f1': f1})\n",
      "    \n",
      "    # à¸«à¸² optimal\n",
      "    optimal = max(results, key=lambda x: x['f1'])\n",
      "    return optimal\n",
      "```\n",
      "\n",
      "#### Cost-based Optimization\n",
      "\n",
      "**à¸—à¸¤à¸©à¸à¸µ**: à¸›à¸£à¸±à¸š threshold à¸•à¸²à¸¡ cost à¸‚à¸­à¸‡ false positive vs false negative\n",
      "\n",
      "```\n",
      "Total Cost = FP_count Ã— FP_cost + FN_count Ã— FN_cost\n",
      "\n",
      "Scenarios:\n",
      "â”œâ”€â”€ High FN cost (à¹€à¸Šà¹ˆà¸™ fraud detection)\n",
      "â”‚   â””â”€â”€ à¹ƒà¸Šà¹‰ Low threshold â†’ detect more, accept false alarms\n",
      "â”œâ”€â”€ High FP cost (à¹€à¸Šà¹ˆà¸™ expensive retraining)\n",
      "â”‚   â””â”€â”€ à¹ƒà¸Šà¹‰ High threshold â†’ conservative detection\n",
      "â””â”€â”€ Balanced cost\n",
      "    â””â”€â”€ Optimize for F1\n",
      "```\n",
      "\n",
      "**Code Reference**:\n",
      "```python\n",
      "class BusinessDriftThreshold:\n",
      "    def __init__(self, false_positive_cost=1, false_negative_cost=10):\n",
      "        self.fp_cost = false_positive_cost\n",
      "        self.fn_cost = false_negative_cost\n",
      "    \n",
      "    def calculate_total_cost(self, y_true, y_pred):\n",
      "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
      "        return fp * self.fp_cost + fn * self.fn_cost\n",
      "    \n",
      "    def find_cost_optimal_threshold(self, scenarios, metric_func, thresholds):\n",
      "        costs = []\n",
      "        for t in thresholds:\n",
      "            y_pred = [metric_func(s['reference'], s['current']) > t \n",
      "                     for s in scenarios]\n",
      "            cost = self.calculate_total_cost(y_true, y_pred)\n",
      "            costs.append({'threshold': t, 'cost': cost})\n",
      "        \n",
      "        optimal = min(costs, key=lambda x: x['cost'])\n",
      "        return optimal\n",
      "```\n",
      "\n",
      "### Handling False Positives/Negatives\n",
      "\n",
      "#### Ensemble Approach\n",
      "```python\n",
      "class RobustDriftDetector:\n",
      "    \"\"\"à¹ƒà¸Šà¹‰à¸«à¸¥à¸²à¸¢ methods à¸£à¹ˆà¸§à¸¡à¸à¸±à¸™\"\"\"\n",
      "    \n",
      "    def detect(self, reference, current):\n",
      "        all_metrics = self._calculate_all_metrics(reference, current)\n",
      "        \n",
      "        # Majority voting\n",
      "        drift_votes = sum(\n",
      "            1 for m, v in all_metrics.items() \n",
      "            if v > self.thresholds[m]\n",
      "        )\n",
      "        \n",
      "        # à¸•à¹‰à¸­à¸‡ 3/4 methods agree\n",
      "        ensemble_drift = drift_votes >= 3\n",
      "        \n",
      "        return ensemble_drift\n",
      "```\n",
      "\n",
      "#### Confirmation Mechanism\n",
      "```python\n",
      "def detect_with_confirmation(self, reference, current):\n",
      "    \"\"\"à¸•à¹‰à¸­à¸‡ detect à¸«à¸¥à¸²à¸¢à¸„à¸£à¸±à¹‰à¸‡à¸•à¸´à¸”à¸à¸±à¸™à¸–à¸¶à¸‡à¸¢à¸·à¸™à¸¢à¸±à¸™\"\"\"\n",
      "    \n",
      "    potential_drift = self.primary_metric(reference, current) > threshold\n",
      "    \n",
      "    if potential_drift:\n",
      "        self.consecutive_count += 1\n",
      "    else:\n",
      "        self.consecutive_count = 0\n",
      "    \n",
      "    # Confirmed à¸–à¹‰à¸² detect 3 à¸„à¸£à¸±à¹‰à¸‡à¸•à¸´à¸”à¸à¸±à¸™\n",
      "    confirmed = self.consecutive_count >= 3\n",
      "    return confirmed\n",
      "```\n",
      "\n",
      "### Best Practices à¸ªà¸³à¸«à¸£à¸±à¸š Threshold Setting\n",
      "\n",
      "```\n",
      "1ï¸âƒ£ DOMAIN-SPECIFIC THRESHOLDS\n",
      "   - à¹„à¸¡à¹ˆà¹ƒà¸Šà¹‰ default à¹‚à¸”à¸¢à¹„à¸¡à¹ˆ validate\n",
      "   - à¸—à¸”à¸ªà¸­à¸šà¸à¸±à¸š labeled data\n",
      "   - à¸›à¸£à¸¶à¸à¸©à¸² domain experts\n",
      "\n",
      "2ï¸âƒ£ COST-BASED OPTIMIZATION\n",
      "   - à¸à¸´à¸ˆà¸²à¸£à¸“à¸² cost à¸‚à¸­à¸‡ FP vs FN\n",
      "   - FN à¹à¸à¸‡ â†’ Lower threshold\n",
      "   - FP à¹à¸à¸‡ â†’ Higher threshold\n",
      "\n",
      "3ï¸âƒ£ ENSEMBLE APPROACH\n",
      "   - à¹ƒà¸Šà¹‰à¸«à¸¥à¸²à¸¢ metrics à¸£à¹ˆà¸§à¸¡à¸à¸±à¸™\n",
      "   - Voting mechanism à¸¥à¸” false positives\n",
      "\n",
      "4ï¸âƒ£ CONFIRMATION MECHANISM\n",
      "   - Require consecutive detections\n",
      "   - à¸›à¹‰à¸­à¸‡à¸à¸±à¸™ temporary spikes\n",
      "\n",
      "5ï¸âƒ£ PERIODIC REVIEW\n",
      "   - Review thresholds à¹€à¸›à¹‡à¸™à¸£à¸°à¸¢à¸°\n",
      "   - Business requirements à¸­à¸²à¸ˆà¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## LAB 6: End-to-End Monitoring Pipeline\n",
      "\n",
      "### ğŸ¯ à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ\n",
      "- à¸£à¸§à¸¡à¸—à¸¸à¸ components à¹€à¸‚à¹‰à¸²à¸”à¹‰à¸§à¸¢à¸à¸±à¸™\n",
      "- à¸ªà¸£à¹‰à¸²à¸‡ automated monitoring workflow\n",
      "- Integrate à¸à¸±à¸š MLflow\n",
      "\n",
      "### Architecture Overview\n",
      "\n",
      "```\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚                 Drift Monitoring Pipeline                    â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚                                                              â”‚\n",
      "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚\n",
      "â”‚  â”‚  Data Source   â”‚â”€â”€â”€â–¶â”‚  Data Buffer   â”‚                   â”‚\n",
      "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚\n",
      "â”‚                                â”‚                             â”‚\n",
      "â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚\n",
      "â”‚                    â”‚   Drift Calculator    â”‚                â”‚\n",
      "â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚\n",
      "â”‚                                â”‚                             â”‚\n",
      "â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚\n",
      "â”‚           â”‚                    â”‚                    â”‚       â”‚\n",
      "â”‚           â–¼                    â–¼                    â–¼       â”‚\n",
      "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\n",
      "â”‚  â”‚   Alert     â”‚      â”‚   Report    â”‚      â”‚   MLflow    â”‚ â”‚\n",
      "â”‚  â”‚   Manager   â”‚      â”‚   Generator â”‚      â”‚   Tracker   â”‚ â”‚\n",
      "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\n",
      "â”‚                                                              â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "```\n",
      "\n",
      "### Core Components\n",
      "\n",
      "#### 1. Data Classes\n",
      "\n",
      "```python\n",
      "from dataclasses import dataclass\n",
      "from enum import Enum\n",
      "\n",
      "class AlertSeverity(Enum):\n",
      "    INFO = \"info\"\n",
      "    WARNING = \"warning\"\n",
      "    CRITICAL = \"critical\"\n",
      "\n",
      "class DriftType(Enum):\n",
      "    NONE = \"none\"\n",
      "    MILD = \"mild\"\n",
      "    MODERATE = \"moderate\"\n",
      "    SEVERE = \"severe\"\n",
      "\n",
      "@dataclass\n",
      "class DriftResult:\n",
      "    timestamp: datetime\n",
      "    feature: str\n",
      "    drift_detected: bool\n",
      "    drift_type: DriftType\n",
      "    psi: float\n",
      "    ks_statistic: float\n",
      "    ks_pvalue: float\n",
      "    reference_mean: float\n",
      "    current_mean: float\n",
      "\n",
      "@dataclass\n",
      "class Alert:\n",
      "    timestamp: datetime\n",
      "    severity: AlertSeverity\n",
      "    message: str\n",
      "    details: Dict\n",
      "    acknowledged: bool = False\n",
      "```\n",
      "\n",
      "#### 2. Configuration\n",
      "\n",
      "```python\n",
      "@dataclass\n",
      "class MonitoringConfig:\n",
      "    reference_window_size: int = 1000\n",
      "    current_window_size: int = 200\n",
      "    psi_mild_threshold: float = 0.1\n",
      "    psi_moderate_threshold: float = 0.2\n",
      "    psi_severe_threshold: float = 0.25\n",
      "    ks_significance: float = 0.05\n",
      "    check_interval_seconds: int = 60\n",
      "    alert_cooldown_minutes: int = 30\n",
      "    features_to_monitor: List[str] = field(default_factory=list)\n",
      "```\n",
      "\n",
      "#### 3. Data Buffer\n",
      "\n",
      "```python\n",
      "class DataBuffer:\n",
      "    \"\"\"Buffer à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸à¹‡à¸š reference à¹à¸¥à¸° current data\"\"\"\n",
      "    \n",
      "    def __init__(self, config: MonitoringConfig):\n",
      "        self.reference_data: Dict[str, deque] = {}\n",
      "        self.current_data: Dict[str, deque] = {}\n",
      "    \n",
      "    def initialize(self, reference_df: pd.DataFrame):\n",
      "        \"\"\"Initialize with reference data\"\"\"\n",
      "        for feature in self.config.features_to_monitor:\n",
      "            self.reference_data[feature] = deque(\n",
      "                reference_df[feature].values,\n",
      "                maxlen=self.config.reference_window_size\n",
      "            )\n",
      "    \n",
      "    def add_data(self, data: Dict[str, float]):\n",
      "        \"\"\"Add new data point\"\"\"\n",
      "        for feature, value in data.items():\n",
      "            self.current_data[feature].append(value)\n",
      "```\n",
      "\n",
      "#### 4. Alert Manager\n",
      "\n",
      "```python\n",
      "class AlertManager:\n",
      "    \"\"\"à¸ˆà¸±à¸”à¸à¸²à¸£ alerts à¸à¸£à¹‰à¸­à¸¡ cooldown\"\"\"\n",
      "    \n",
      "    def __init__(self, config: MonitoringConfig):\n",
      "        self.alerts: List[Alert] = []\n",
      "        self.last_alert_time: Dict[str, datetime] = {}\n",
      "    \n",
      "    def should_alert(self, feature: str) -> bool:\n",
      "        \"\"\"Check cooldown\"\"\"\n",
      "        if feature not in self.last_alert_time:\n",
      "            return True\n",
      "        elapsed = datetime.now() - self.last_alert_time[feature]\n",
      "        return elapsed > timedelta(minutes=self.config.alert_cooldown_minutes)\n",
      "    \n",
      "    def create_alert(self, drift_result: DriftResult) -> Optional[Alert]:\n",
      "        if not drift_result.drift_detected:\n",
      "            return None\n",
      "        \n",
      "        if not self.should_alert(drift_result.feature):\n",
      "            return None\n",
      "        \n",
      "        # Determine severity\n",
      "        severity = self._determine_severity(drift_result.drift_type)\n",
      "        \n",
      "        alert = Alert(\n",
      "            timestamp=drift_result.timestamp,\n",
      "            severity=severity,\n",
      "            message=f\"Drift detected in {drift_result.feature}\",\n",
      "            details=drift_result.to_dict()\n",
      "        )\n",
      "        \n",
      "        self.alerts.append(alert)\n",
      "        self.last_alert_time[drift_result.feature] = datetime.now()\n",
      "        \n",
      "        return alert\n",
      "```\n",
      "\n",
      "#### 5. Main Pipeline\n",
      "\n",
      "```python\n",
      "class DriftMonitoringPipeline:\n",
      "    def __init__(self, config: MonitoringConfig):\n",
      "        self.config = config\n",
      "        self.data_buffer = DataBuffer(config)\n",
      "        self.alert_manager = AlertManager(config)\n",
      "        self.drift_calculator = DriftCalculator()\n",
      "        self.results_history: List[DriftResult] = []\n",
      "    \n",
      "    def initialize(self, reference_data: pd.DataFrame):\n",
      "        self.data_buffer.initialize(reference_data)\n",
      "    \n",
      "    def process_batch(self, batch_data: pd.DataFrame) -> List[DriftResult]:\n",
      "        results = []\n",
      "        \n",
      "        # Add data to buffer\n",
      "        for idx, row in batch_data.iterrows():\n",
      "            self.data_buffer.add_data(row.to_dict())\n",
      "        \n",
      "        # Check if ready\n",
      "        if not self.data_buffer.is_current_ready():\n",
      "            return results\n",
      "        \n",
      "        # Detect drift for each feature\n",
      "        for feature in self.config.features_to_monitor:\n",
      "            result = self._detect_drift_for_feature(feature)\n",
      "            if result:\n",
      "                results.append(result)\n",
      "                \n",
      "                # Create alert if needed\n",
      "                if result.drift_detected:\n",
      "                    self.alert_manager.create_alert(result)\n",
      "        \n",
      "        return results\n",
      "```\n",
      "\n",
      "### Report Generation\n",
      "\n",
      "```python\n",
      "class ReportGenerator:\n",
      "    def generate_html_report(self, output_path: str):\n",
      "        \"\"\"Generate HTML report\"\"\"\n",
      "        summary = self.pipeline.get_summary_report()\n",
      "        \n",
      "        html_content = f\"\"\"\n",
      "        <html>\n",
      "        <head><title>Drift Monitoring Report</title></head>\n",
      "        <body>\n",
      "            <h1>Drift Monitoring Report</h1>\n",
      "            <p>Generated: {datetime.now()}</p>\n",
      "            \n",
      "            <h2>Summary</h2>\n",
      "            <p>Total Checks: {summary['total_checks']}</p>\n",
      "            <p>Drifts Detected: {summary['total_drifts_detected']}</p>\n",
      "            \n",
      "            <h2>Feature Summary</h2>\n",
      "            <table>\n",
      "                <tr><th>Feature</th><th>PSI</th><th>Status</th></tr>\n",
      "                {self._generate_feature_rows(summary)}\n",
      "            </table>\n",
      "            \n",
      "            <h2>Active Alerts</h2>\n",
      "            {self._generate_alerts_section()}\n",
      "        </body>\n",
      "        </html>\n",
      "        \"\"\"\n",
      "        \n",
      "        with open(output_path, 'w') as f:\n",
      "            f.write(html_content)\n",
      "```\n",
      "\n",
      "### MLflow Integration\n",
      "\n",
      "```python\n",
      "class MLflowDriftTracker:\n",
      "    def __init__(self, experiment_name: str = \"drift_monitoring\"):\n",
      "        mlflow.set_experiment(experiment_name)\n",
      "    \n",
      "    def log_drift_result(self, result: DriftResult):\n",
      "        mlflow.log_metric(f\"{result.feature}_psi\", result.psi)\n",
      "        mlflow.log_metric(f\"{result.feature}_drift\", 1 if result.drift_detected else 0)\n",
      "        mlflow.log_param(f\"{result.feature}_drift_type\", result.drift_type.value)\n",
      "    \n",
      "    def log_summary(self, summary: Dict):\n",
      "        mlflow.log_metric(\"total_drifts\", summary.get('total_drifts_detected', 0))\n",
      "        for feature, data in summary.get('feature_summary', {}).items():\n",
      "            mlflow.log_metric(f\"{feature}_drift_rate\", data['drift_rate'])\n",
      "    \n",
      "    def log_artifact(self, artifact_path: str):\n",
      "        mlflow.log_artifact(artifact_path)\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## à¸ªà¸£à¸¸à¸›à¹à¸¥à¸° Best Practices\n",
      "\n",
      "### Summary Table\n",
      "\n",
      "| Lab | à¸«à¸±à¸§à¸‚à¹‰à¸­ | Key Concepts |\n",
      "|-----|--------|--------------|\n",
      "| 1 | Understanding Data Drift | Covariate/Concept Shift, KS/PSI/Wasserstein |\n",
      "| 2 | Feature Drift Detection | Per-feature analysis, Numerical vs Categorical |\n",
      "| 3 | Multivariate Drift | Correlation, PCA, Mahalanobis Distance |\n",
      "| 4 | Production Simulation | Streaming, Sliding Window, Page-Hinkley |\n",
      "| 5 | Custom Metrics & Thresholds | Optimization, Cost-based, Ensemble |\n",
      "| 6 | End-to-End Pipeline | Architecture, Alerting, Reporting, MLflow |\n",
      "\n",
      "### Decision Framework\n",
      "\n",
      "```\n",
      "à¹€à¸¡à¸·à¹ˆà¸­à¸à¸š Drift à¸„à¸§à¸£à¸—à¸³à¸­à¸¢à¹ˆà¸²à¸‡à¹„à¸£?\n",
      "\n",
      "1. Assess Severity\n",
      "   â”œâ”€â”€ MILD â†’ Monitor closely\n",
      "   â”œâ”€â”€ MODERATE â†’ Investigate root cause\n",
      "   â””â”€â”€ SEVERE â†’ Immediate action required\n",
      "\n",
      "2. Investigate Root Cause\n",
      "   â”œâ”€â”€ Data collection issue?\n",
      "   â”œâ”€â”€ Upstream data change?\n",
      "   â”œâ”€â”€ Real-world change?\n",
      "   â””â”€â”€ Seasonal pattern?\n",
      "\n",
      "3. Decide Action\n",
      "   â”œâ”€â”€ Retrain model\n",
      "   â”œâ”€â”€ Update feature engineering\n",
      "   â”œâ”€â”€ Adjust thresholds\n",
      "   â””â”€â”€ Business process change\n",
      "```\n",
      "\n",
      "### Production Checklist\n",
      "\n",
      "```\n",
      "â–¡ Define monitoring strategy\n",
      "  â–¡ Which features to monitor?\n",
      "  â–¡ What thresholds to use?\n",
      "  â–¡ How often to check?\n",
      "\n",
      "â–¡ Implement detection\n",
      "  â–¡ Choose appropriate methods\n",
      "  â–¡ Handle both numerical and categorical\n",
      "  â–¡ Consider multivariate drift\n",
      "\n",
      "â–¡ Set up alerting\n",
      "  â–¡ Define severity levels\n",
      "  â–¡ Configure notification channels\n",
      "  â–¡ Set cooldown periods\n",
      "\n",
      "â–¡ Create reporting\n",
      "  â–¡ Automated dashboards\n",
      "  â–¡ Periodic reports\n",
      "  â–¡ Historical analysis\n",
      "\n",
      "â–¡ Plan remediation\n",
      "  â–¡ When to retrain?\n",
      "  â–¡ How to validate new model?\n",
      "  â–¡ Rollback procedures\n",
      "```\n",
      "\n",
      "### Final Thoughts\n",
      "\n",
      "à¸à¸²à¸£à¸—à¸³ Drift Detection à¸—à¸µà¹ˆà¸”à¸µà¸•à¹‰à¸­à¸‡:\n",
      "\n",
      "1. **à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆ Business Context**: Drift à¸—à¸µà¹ˆà¸ªà¸³à¸„à¸±à¸à¹ƒà¸™ domain à¸«à¸™à¸¶à¹ˆà¸‡à¸­à¸²à¸ˆà¹„à¸¡à¹ˆà¸ªà¸³à¸„à¸±à¸à¹ƒà¸™ domain à¸­à¸·à¹ˆà¸™\n",
      "\n",
      "2. **à¹ƒà¸Šà¹‰à¸«à¸¥à¸²à¸¢ Methods**: à¹„à¸¡à¹ˆà¸¡à¸µ method à¹ƒà¸”à¸—à¸µà¹ˆà¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œà¹à¸šà¸š à¸„à¸§à¸£à¹ƒà¸Šà¹‰à¸«à¸¥à¸²à¸¢ methods à¸£à¹ˆà¸§à¸¡à¸à¸±à¸™\n",
      "\n",
      "3. **Tune Thresholds**: Default thresholds à¸¡à¸±à¸à¹„à¸¡à¹ˆà¹€à¸«à¸¡à¸²à¸° à¸•à¹‰à¸­à¸‡à¸›à¸£à¸±à¸šà¸•à¸²à¸¡ use case\n",
      "\n",
      "4. **Automate**: à¸à¸²à¸£à¸—à¸³ manual monitoring à¹„à¸¡à¹ˆà¸¢à¸±à¹ˆà¸‡à¸¢à¸·à¸™ à¸•à¹‰à¸­à¸‡à¸¡à¸µ automated pipeline\n",
      "\n",
      "5. **Monitor the Monitor**: à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² monitoring system à¸—à¸³à¸‡à¸²à¸™à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡\n",
      "\n",
      "---\n",
      "\n",
      "## à¹à¸«à¸¥à¹ˆà¸‡à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¹€à¸à¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡\n",
      "\n",
      "- [Evidently AI Documentation](https://docs.evidentlyai.com/)\n",
      "- [NannyML Documentation](https://docs.nannyml.com/)\n",
      "- [Alibi Detect](https://docs.seldon.io/projects/alibi-detect/)\n",
      "- [Great Expectations](https://docs.greatexpectations.io/)\n",
      "\n",
      "---\n",
      "\n",
      "*à¹€à¸­à¸à¸ªà¸²à¸£à¸™à¸µà¹‰à¸ˆà¸±à¸”à¸—à¸³à¹€à¸à¸·à¹ˆà¸­à¸›à¸£à¸°à¸à¸­à¸šà¸à¸²à¸£à¹€à¸£à¸µà¸¢à¸™à¸à¸²à¸£à¸ªà¸­à¸™à¸§à¸´à¸Šà¸² MLOps*\n"
     ]
    }
   ],
   "source": [
    "# Simple extraction\n",
    "text = response[\"content\"][0][\"text\"]\n",
    "print(text)\n",
    "\n",
    "# Save to file\n",
    "with open(\"output.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c858923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
