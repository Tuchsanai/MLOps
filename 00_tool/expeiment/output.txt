# ğŸ“š Data Drift Detection: Complete Guide for MLOps

## à¸ªà¸²à¸£à¸šà¸±à¸
1. [à¸šà¸—à¸™à¸³: à¸—à¸³à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆ Data Drift](#à¸šà¸—à¸™à¸³-à¸—à¸³à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆ-data-drift)
2. [LAB 1: Understanding Data Drift Concepts](#lab-1-understanding-data-drift-concepts)
3. [LAB 2: Feature Drift Detection](#lab-2-feature-drift-detection)
4. [LAB 3: Multivariate Drift Analysis](#lab-3-multivariate-drift-analysis)
5. [LAB 4: Drift Detection in Production Simulation](#lab-4-drift-detection-in-production-simulation)
6. [LAB 5: Custom Metrics & Drift Thresholds](#lab-5-custom-metrics--drift-thresholds)
7. [LAB 6: End-to-End Monitoring Pipeline](#lab-6-end-to-end-monitoring-pipeline)
8. [à¸ªà¸£à¸¸à¸›à¹à¸¥à¸° Best Practices](#à¸ªà¸£à¸¸à¸›à¹à¸¥à¸°-best-practices)

---

## à¸šà¸—à¸™à¸³: à¸—à¸³à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆ Data Drift

### Data Drift à¸„à¸·à¸­à¸­à¸°à¹„à¸£?

**Data Drift** (à¸«à¸£à¸·à¸­ Dataset Shift) à¸„à¸·à¸­à¸›à¸£à¸²à¸à¸à¸à¸²à¸£à¸“à¹Œà¸—à¸µà¹ˆà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¸£à¸°à¸šà¸š production à¸¡à¸µà¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¹„à¸›à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰ train à¹‚à¸¡à¹€à¸”à¸¥ à¸‹à¸¶à¹ˆà¸‡à¹€à¸›à¹‡à¸™à¸«à¸™à¸¶à¹ˆà¸‡à¹ƒà¸™à¸ªà¸²à¹€à¸«à¸•à¸¸à¸«à¸¥à¸±à¸à¸—à¸µà¹ˆà¸—à¸³à¹ƒà¸«à¹‰ ML Model à¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸à¸¥à¸”à¸¥à¸‡à¹€à¸¡à¸·à¹ˆà¸­à¹€à¸§à¸¥à¸²à¸œà¹ˆà¸²à¸™à¹„à¸›

```
Training Time                    Production Time
     â”‚                                â”‚
     â–¼                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Training    â”‚               â”‚ Production  â”‚
â”‚ Data        â”‚â”€â”€â”€â”€ Drift â”€â”€â”€â–¶â”‚ Data        â”‚
â”‚ P(X,Y)_trainâ”‚               â”‚ P(X,Y)_prod â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                                â”‚
     â–¼                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Good Model  â”‚               â”‚ Degraded    â”‚
â”‚ Performance â”‚               â”‚ Performance â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### à¸—à¸³à¹„à¸¡ Drift Detection à¸–à¸¶à¸‡à¸ªà¸³à¸„à¸±à¸?

1. **Model Degradation**: à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸µà¹ˆ train à¸”à¹‰à¸§à¸¢à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸à¹ˆà¸²à¸­à¸²à¸ˆà¸—à¸³à¸™à¸²à¸¢à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¸à¸±à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¸¡à¹ˆ
2. **Business Impact**: à¸à¸²à¸£à¸•à¸±à¸”à¸ªà¸´à¸™à¹ƒà¸ˆà¸œà¸´à¸”à¸à¸¥à¸²à¸”à¸ªà¹ˆà¸‡à¸œà¸¥à¸•à¹ˆà¸­à¸˜à¸¸à¸£à¸à¸´à¸ˆà¹‚à¸”à¸¢à¸•à¸£à¸‡
3. **Regulatory Compliance**: à¸«à¸¥à¸²à¸¢à¸­à¸¸à¸•à¸ªà¸²à¸«à¸à¸£à¸£à¸¡à¸•à¹‰à¸­à¸‡à¸à¸²à¸£ monitoring à¸­à¸¢à¹ˆà¸²à¸‡à¸•à¹ˆà¸­à¹€à¸™à¸·à¹ˆà¸­à¸‡
4. **Resource Optimization**: à¸£à¸¹à¹‰à¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡ retrain à¸Šà¹ˆà¸§à¸¢à¸›à¸£à¸°à¸«à¸¢à¸±à¸”à¸—à¸£à¸±à¸à¸¢à¸²à¸à¸£

---

## LAB 1: Understanding Data Drift Concepts

### ğŸ¯ à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ
- à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸„à¸§à¸²à¸¡à¹à¸•à¸à¸•à¹ˆà¸²à¸‡à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ Covariate Shift à¹à¸¥à¸° Concept Drift
- à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰ Statistical tests à¸ªà¸³à¸«à¸£à¸±à¸š drift detection
- à¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸¥à¸·à¸­à¸ drift detection method à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡

### à¸—à¸¤à¸©à¸à¸µ: à¸›à¸£à¸°à¹€à¸ à¸—à¸‚à¸­à¸‡ Data Drift

#### 1. Covariate Shift (Feature Drift)

**à¸™à¸´à¸¢à¸²à¸¡**: à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸‚à¸­à¸‡ distribution à¸‚à¸­à¸‡ input features P(X) à¹‚à¸”à¸¢à¸—à¸µà¹ˆà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œ P(Y|X) à¸¢à¸±à¸‡à¸„à¸‡à¹€à¸”à¸´à¸¡

```
Covariate Shift:
â”œâ”€â”€ P(X)_train â‰  P(X)_prod     â† Distribution à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™
â””â”€â”€ P(Y|X)_train = P(Y|X)_prod  â† Relationship à¸„à¸‡à¹€à¸”à¸´à¸¡
```

**à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¹ƒà¸™à¸Šà¸µà¸§à¸´à¸•à¸ˆà¸£à¸´à¸‡**:
- à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸³à¸™à¸²à¸¢à¸£à¸²à¸„à¸²à¸šà¹‰à¸²à¸™à¸—à¸µà¹ˆ train à¸à¸±à¸šà¸šà¹‰à¸²à¸™à¹ƒà¸™à¹€à¸¡à¸·à¸­à¸‡ à¹à¸•à¹ˆà¸•à¹‰à¸­à¸‡à¸—à¸³à¸™à¸²à¸¢à¸šà¹‰à¸²à¸™à¹ƒà¸™à¸Šà¸™à¸šà¸—
- à¹‚à¸¡à¹€à¸”à¸¥à¸­à¸²à¸¢à¸¸à¸¥à¸¹à¸à¸„à¹‰à¸²à¸—à¸µà¹ˆ train à¸à¸±à¸šà¸à¸¥à¸¸à¹ˆà¸¡à¸­à¸²à¸¢à¸¸ 20-40 à¸›à¸µ à¹à¸•à¹ˆ production à¸¡à¸µà¸¥à¸¹à¸à¸„à¹‰à¸²à¸­à¸²à¸¢à¸¸ 40-60 à¸›à¸µ

**Code Reference** - à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Covariate Shift:
```python
def generate_covariate_shift_data():
    # Training data: à¸¥à¸¹à¸à¸„à¹‰à¸²à¸­à¸²à¸¢à¸¸à¸™à¹‰à¸­à¸¢ (20-40)
    age_train = np.random.normal(30, 5, n_train)
    
    # Production data: à¸¥à¸¹à¸à¸„à¹‰à¸²à¸­à¸²à¸¢à¸¸à¸¡à¸²à¸à¸‚à¸¶à¹‰à¸™ (40-60) - Covariate Shift!
    age_prod = np.random.normal(50, 5, n_prod)
    
    # à¸à¸à¸à¸²à¸£à¸‹à¸·à¹‰à¸­à¹€à¸«à¸¡à¸·à¸­à¸™à¹€à¸”à¸´à¸¡ (à¹„à¸¡à¹ˆà¸¡à¸µ Concept Drift)
    # P(Y|X) à¸¢à¸±à¸‡à¸„à¸‡à¹€à¸”à¸´à¸¡
```

#### 2. Concept Drift (Label Drift)

**à¸™à¸´à¸¢à¸²à¸¡**: à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸‚à¸­à¸‡à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œà¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ input à¹à¸¥à¸° output P(Y|X)

```
Concept Drift:
â”œâ”€â”€ P(X) à¸­à¸²à¸ˆà¸„à¸‡à¸—à¸µà¹ˆà¸«à¸£à¸·à¸­à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸à¹‡à¹„à¸”à¹‰
â””â”€â”€ P(Y|X)_train â‰  P(Y|X)_prod  â† Relationship à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™!
```

**à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¹ƒà¸™à¸Šà¸µà¸§à¸´à¸•à¸ˆà¸£à¸´à¸‡**:
- à¸à¸¤à¸•à¸´à¸à¸£à¸£à¸¡à¸à¸²à¸£à¸‹à¸·à¹‰à¸­à¸‚à¸­à¸‡à¸¥à¸¹à¸à¸„à¹‰à¸²à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸«à¸¥à¸±à¸‡ COVID-19
- à¸„à¸§à¸²à¸¡à¸«à¸¡à¸²à¸¢à¸‚à¸­à¸‡ "spam email" à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹„à¸›à¸•à¸²à¸¡à¹€à¸§à¸¥à¸²

**Code Reference** - à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Concept Drift:
```python
def generate_concept_drift_data():
    # Training: à¸à¸à¸à¸²à¸£à¸‹à¸·à¹‰à¸­à¹€à¸”à¸´à¸¡ - à¸‹à¸·à¹‰à¸­à¸–à¹‰à¸² income > 45000
    purchase_train = (income_train > 45000).astype(int)
    
    # Production: à¸à¸à¸à¸²à¸£à¸‹à¸·à¹‰à¸­à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ - à¸‹à¸·à¹‰à¸­à¸–à¹‰à¸² income > 55000
    # Threshold à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ = Concept Drift!
    purchase_prod = (income_prod > 55000).astype(int)
```

#### à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š Covariate Shift vs Concept Drift

| à¸¥à¸±à¸à¸©à¸“à¸° | Covariate Shift | Concept Drift |
|--------|-----------------|---------------|
| à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ | P(X) | P(Y\|X) |
| à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡ | à¸à¸¥à¸¸à¹ˆà¸¡à¸¥à¸¹à¸à¸„à¹‰à¸²à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ | à¸à¸¤à¸•à¸´à¸à¸£à¸£à¸¡à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ |
| à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š | à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š feature distributions | à¸•à¹‰à¸­à¸‡à¸¡à¸µ labels à¸«à¸£à¸·à¸­ performance |
| à¸§à¸´à¸˜à¸µà¹à¸à¹‰ | Sample weighting, Retrain | Retrain with new data |

---

### Statistical Tests à¸ªà¸³à¸«à¸£à¸±à¸š Drift Detection

#### 1. Kolmogorov-Smirnov (KS) Test

**à¸—à¸¤à¸©à¸à¸µ**:
- à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š Cumulative Distribution Function (CDF) à¸‚à¸­à¸‡ 2 samples
- à¸§à¸±à¸”à¸„à¸§à¸²à¸¡à¹à¸•à¸à¸•à¹ˆà¸²à¸‡à¸ªà¸¹à¸‡à¸ªà¸¸à¸”à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ 2 CDFs

```
KS Statistic = max|Fâ‚(x) - Fâ‚‚(x)|

à¹‚à¸”à¸¢à¸—à¸µà¹ˆ:
- Fâ‚(x) = CDF à¸‚à¸­à¸‡ reference data
- Fâ‚‚(x) = CDF à¸‚à¸­à¸‡ current data
```

**à¸à¸²à¸£à¸•à¸µà¸„à¸§à¸²à¸¡**:
- KS Statistic: 0-1 (à¸¢à¸´à¹ˆà¸‡à¸ªà¸¹à¸‡ = à¸¢à¸´à¹ˆà¸‡à¹à¸•à¸à¸•à¹ˆà¸²à¸‡)
- p-value < 0.05: reject null hypothesis â†’ à¸¡à¸µ drift

**à¸‚à¹‰à¸­à¸”à¸µ**:
- à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸ªà¸¡à¸¡à¸•à¸´ distribution (non-parametric)
- Sensitive à¸•à¹ˆà¸­à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡

**à¸‚à¹‰à¸­à¹€à¸ªà¸µà¸¢**:
- à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¸à¸±à¸š continuous variables à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™

**Code Reference**:
```python
def kolmogorov_smirnov_test(data1, data2, feature_name="feature"):
    statistic, p_value = stats.ks_2samp(data1, data2)
    drift_detected = p_value < 0.05
    
    return {
        'statistic': statistic,
        'p_value': p_value,
        'drift_detected': drift_detected
    }
```

#### 2. Population Stability Index (PSI)

**à¸—à¸¤à¸©à¸à¸µ**:
- à¸§à¸±à¸”à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸‚à¸­à¸‡ distribution à¹‚à¸”à¸¢à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š proportions à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸° bin
- à¸™à¸´à¸¢à¸¡à¹ƒà¸Šà¹‰à¹ƒà¸™ credit scoring à¹à¸¥à¸° financial models

**à¸ªà¸¹à¸•à¸£**:
```
PSI = Î£ (Actual% - Expected%) Ã— ln(Actual% / Expected%)

à¹‚à¸”à¸¢à¸—à¸µà¹ˆ:
- Expected% = proportion à¹ƒà¸™ reference data
- Actual% = proportion à¹ƒà¸™ current data
```

**à¸à¸²à¸£à¸•à¸µà¸„à¸§à¸²à¸¡ PSI**:

| à¸„à¹ˆà¸² PSI | à¸„à¸§à¸²à¸¡à¸«à¸¡à¸²à¸¢ | Action |
|---------|----------|--------|
| < 0.1 | à¹„à¸¡à¹ˆà¸¡à¸µà¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸ªà¸³à¸„à¸±à¸ | à¸›à¸à¸•à¸´ |
| 0.1 - 0.25 | à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸›à¸²à¸™à¸à¸¥à¸²à¸‡ | à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹€à¸à¸´à¹ˆà¸¡ |
| â‰¥ 0.25 | à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸¡à¸²à¸ | à¸•à¹‰à¸­à¸‡à¸”à¸³à¹€à¸™à¸´à¸™à¸à¸²à¸£ |

**Code Reference**:
```python
def calculate_psi(expected, actual, bins=10, eps=1e-6):
    # à¸ªà¸£à¹‰à¸²à¸‡ bins à¸ˆà¸²à¸ expected data
    breakpoints = np.percentile(expected, np.linspace(0, 100, bins + 1))
    
    # à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸° bin
    expected_counts, _ = np.histogram(expected, bins=breakpoints)
    actual_counts, _ = np.histogram(actual, bins=breakpoints)
    
    # à¸„à¸³à¸™à¸§à¸“ proportions
    expected_props = expected_counts / len(expected) + eps
    actual_props = actual_counts / len(actual) + eps
    
    # à¸„à¸³à¸™à¸§à¸“ PSI
    psi = np.sum((actual_props - expected_props) * np.log(actual_props / expected_props))
    return psi
```

#### 3. Wasserstein Distance (Earth Mover's Distance)

**à¸—à¸¤à¸©à¸à¸µ**:
- à¸§à¸±à¸” "à¸‡à¸²à¸™" à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰à¹ƒà¸™à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ distribution à¸«à¸™à¸¶à¹ˆà¸‡à¹„à¸›à¹€à¸›à¹‡à¸™à¸­à¸µà¸ distribution
- à¸„à¸¥à¹‰à¸²à¸¢à¸à¸±à¸šà¸à¸²à¸£à¸„à¸³à¸™à¸§à¸“à¸•à¹‰à¸™à¸—à¸¸à¸™à¹ƒà¸™à¸à¸²à¸£à¸‚à¸™à¸¢à¹‰à¸²à¸¢à¸”à¸´à¸™

```
Wasserstein Distance = inf âˆ«|Fâ‚â»Â¹(u) - Fâ‚‚â»Â¹(u)| du

à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸ªà¸¡à¸·à¸­à¸™:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Pile A    â”‚  move   â”‚   Pile B    â”‚
â”‚   (sand)    â”‚ â”€â”€â”€â”€â”€â”€â–¶ â”‚   (sand)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  cost   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**à¸‚à¹‰à¸­à¸”à¸µ**:
- à¸„à¸³à¸™à¸¶à¸‡à¸–à¸¶à¸‡ distance à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ bins
- Sensitive à¸•à¹ˆà¸­ shift à¹ƒà¸™à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡

**Code Reference**:
```python
def wasserstein_distance_test(data1, data2, feature_name="feature"):
    distance = stats.wasserstein_distance(data1, data2)
    
    # Normalize à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰ standard deviation
    std_ref = np.std(data1)
    normalized_distance = distance / std_ref if std_ref > 0 else distance
    
    return {
        'distance': distance,
        'normalized_distance': normalized_distance
    }
```

### à¸à¸²à¸£à¹€à¸¥à¸·à¸­à¸ Drift Detection Method

```
Decision Tree:

1. Data Type?
   â”œâ”€â”€ Continuous â†’ à¹„à¸›à¸‚à¹‰à¸­ 2
   â””â”€â”€ Categorical â†’ Chi-squared à¸«à¸£à¸·à¸­ PSI

2. à¸•à¹‰à¸­à¸‡à¸à¸²à¸£ Statistical Significance?
   â”œâ”€â”€ à¹ƒà¸Šà¹ˆ â†’ KS Test
   â””â”€â”€ à¹„à¸¡à¹ˆà¸ˆà¸³à¹€à¸›à¹‡à¸™ â†’ PSI à¸«à¸£à¸·à¸­ Wasserstein

3. Industry Requirement?
   â”œâ”€â”€ Finance/Credit â†’ PSI (regulatory standards)
   â””â”€â”€ à¸­à¸·à¹ˆà¸™à¹† â†’ à¹€à¸¥à¸·à¸­à¸à¸•à¸²à¸¡à¸„à¸§à¸²à¸¡à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡

4. à¸•à¹‰à¸­à¸‡à¸à¸²à¸£ Sensitivity à¸ªà¸¹à¸‡?
   â”œâ”€â”€ à¹ƒà¸Šà¹ˆ â†’ Wasserstein
   â””â”€â”€ à¸›à¸à¸•à¸´ â†’ KS à¸«à¸£à¸·à¸­ PSI
```

---

## LAB 2: Feature Drift Detection

### ğŸ¯ à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ
- à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š drift à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸° feature à¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸›à¹‡à¸™à¸£à¸°à¸šà¸š
- à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ numerical vs categorical feature drift
- à¸ªà¸£à¹‰à¸²à¸‡ visualization à¸ªà¸³à¸«à¸£à¸±à¸š feature distributions

### à¸—à¸¤à¸©à¸à¸µ: Per-Feature Analysis

à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ drift à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸° feature à¸¡à¸µà¸„à¸§à¸²à¸¡à¸ªà¸³à¸„à¸±à¸à¹€à¸à¸£à¸²à¸°:
1. à¸Šà¹ˆà¸§à¸¢à¸£à¸°à¸šà¸¸ root cause à¸‚à¸­à¸‡ model performance degradation
2. à¸—à¸³à¹ƒà¸«à¹‰à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸§à¹ˆà¸² feature à¹„à¸«à¸™à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸¡à¸²à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸”
3. à¸ªà¸²à¸¡à¸²à¸£à¸– prioritize à¸à¸²à¸£à¹à¸à¹‰à¹„à¸‚à¹„à¸”à¹‰

### Numerical Features vs Categorical Features

#### Numerical Features
```
Methods à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰:
â”œâ”€â”€ KS Test - compare CDFs
â”œâ”€â”€ PSI - compare bin proportions
â””â”€â”€ Wasserstein - measure distribution distance
```

#### Categorical Features
```
Methods à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰:
â”œâ”€â”€ Chi-squared Test - compare frequency distributions
â””â”€â”€ PSI (category-based) - compare category proportions
```

### Feature Drift Detector Class

**Architecture**:
```
FeatureDriftDetector
â”œâ”€â”€ __init__()
â”‚   â”œâ”€â”€ reference_data
â”‚   â”œâ”€â”€ current_data
â”‚   â”œâ”€â”€ numerical_features
â”‚   â””â”€â”€ categorical_features
â”‚
â”œâ”€â”€ Numerical Methods
â”‚   â”œâ”€â”€ ks_test()
â”‚   â”œâ”€â”€ calculate_psi()
â”‚   â””â”€â”€ wasserstein_test()
â”‚
â”œâ”€â”€ Categorical Methods
â”‚   â”œâ”€â”€ chi_squared_test()
â”‚   â””â”€â”€ categorical_psi()
â”‚
â””â”€â”€ Analysis
    â”œâ”€â”€ analyze_numerical_feature()
    â”œâ”€â”€ analyze_categorical_feature()
    â”œâ”€â”€ analyze_all_features()
    â””â”€â”€ get_summary_report()
```

**Code Reference**:
```python
class FeatureDriftDetector:
    def __init__(self, reference_data, current_data, 
                 numerical_features=None, categorical_features=None):
        self.reference = reference_data
        self.current = current_data
        self.numerical_features = numerical_features
        self.categorical_features = categorical_features
    
    def analyze_numerical_feature(self, feature):
        results = {
            'ks_test': self.ks_test(feature),
            'psi': self.calculate_psi(feature),
            'wasserstein': self.wasserstein_test(feature)
        }
        # à¸ªà¸£à¸¸à¸›à¸œà¸¥
        ks_drift = results['ks_test']['p_value'] < 0.05
        psi_value = results['psi']['psi']
        
        if psi_value < 0.1:
            psi_severity = 'none'
        elif psi_value < 0.25:
            psi_severity = 'mild'
        else:
            psi_severity = 'severe'
        
        results['drift_detected'] = ks_drift or psi_severity != 'none'
        return results
```

### Feature Drift Ranking

à¸ˆà¸±à¸”à¸¥à¸³à¸”à¸±à¸š features à¸•à¸²à¸¡à¸„à¸§à¸²à¸¡à¸£à¸¸à¸™à¹à¸£à¸‡à¸‚à¸­à¸‡ drift à¹€à¸à¸·à¹ˆà¸­ prioritization:

```
Ranking Algorithm:
1. à¸„à¸³à¸™à¸§à¸“ PSI à¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸¸à¸ features
2. à¹€à¸£à¸µà¸¢à¸‡à¸¥à¸³à¸”à¸±à¸šà¸ˆà¸²à¸à¸¡à¸²à¸à¹„à¸›à¸™à¹‰à¸­à¸¢
3. à¸à¸³à¸«à¸™à¸” severity level (none/mild/severe)
4. Focus à¹à¸à¹‰à¹„à¸‚ features à¸—à¸µà¹ˆà¸¡à¸µ severe drift à¸à¹ˆà¸­à¸™
```

### Time-based Distribution Analysis

à¸à¸²à¸£à¸•à¸´à¸”à¸•à¸²à¸¡ drift à¹€à¸¡à¸·à¹ˆà¸­à¹€à¸§à¸¥à¸²à¸œà¹ˆà¸²à¸™à¹„à¸›:

```
Period 0 (Reference)
    â”‚
    â–¼
Period 1 â”€â”€â”€â”€ PSI = 0.02 (none)
    â”‚
    â–¼
Period 2 â”€â”€â”€â”€ PSI = 0.08 (none)
    â”‚
    â–¼
Period 3 â”€â”€â”€â”€ PSI = 0.15 (mild) âš ï¸
    â”‚
    â–¼
Period 4 â”€â”€â”€â”€ PSI = 0.28 (severe) ğŸ”´
```

---

## LAB 3: Multivariate Drift Analysis

### ğŸ¯ à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ
- à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š drift à¸—à¸µà¹ˆà¹€à¸à¸´à¸”à¸ˆà¸²à¸à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œà¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ features
- à¹ƒà¸Šà¹‰ Dataset-level drift detection
- à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ Correlation changes

### à¸—à¸¤à¸©à¸à¸µ: Multivariate Drift

**à¸›à¸±à¸à¸«à¸²**: Univariate methods à¸­à¸²à¸ˆà¸à¸¥à¸²à¸” drift à¸—à¸µà¹ˆà¹€à¸à¸´à¸”à¸ˆà¸²à¸à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸‚à¸­à¸‡à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œà¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ features

```
à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡:
Reference:                    Current:
- Age mean = 35              - Age mean = 35      (à¹€à¸«à¸¡à¸·à¸­à¸™à¹€à¸”à¸´à¸¡)
- Income mean = 50000        - Income mean = 50000 (à¹€à¸«à¸¡à¸·à¸­à¸™à¹€à¸”à¸´à¸¡)
- Corr(Age, Income) = 0.8    - Corr(Age, Income) = 0.1 â† à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™!

Univariate test: à¹„à¸¡à¹ˆà¸à¸š drift
Multivariate test: à¸à¸š drift à¹ƒà¸™à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œ
```

### Methods à¸ªà¸³à¸«à¸£à¸±à¸š Multivariate Drift

#### 1. Correlation-based Analysis

**à¸—à¸¤à¸©à¸à¸µ**: à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š correlation matrix à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ reference à¹à¸¥à¸° current data

**Fisher's Z Transformation** à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š correlations:
```
Z = arctanh(r)

Z-test statistic = (Z_ref - Z_cur) / SE
where SE = sqrt(1/(nâ‚-3) + 1/(nâ‚‚-3))
```

**Code Reference**:
```python
def correlation_drift_test(ref_df, cur_df, significance_level=0.05):
    ref_corr = ref_df.corr()
    cur_corr = cur_df.corr()
    
    for col1, col2 in feature_pairs:
        r_ref = ref_corr.loc[col1, col2]
        r_cur = cur_corr.loc[col1, col2]
        
        # Fisher's Z transformation
        z_ref = np.arctanh(r_ref)
        z_cur = np.arctanh(r_cur)
        
        # Z-test
        se = np.sqrt(1/(n_ref-3) + 1/(n_cur-3))
        z_stat = (z_ref - z_cur) / se
        p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))
```

#### 2. PCA-based Analysis

**à¸—à¸¤à¸©à¸à¸µ**: à¹ƒà¸Šà¹‰ Principal Component Analysis à¹€à¸à¸·à¹ˆà¸­à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸‚à¸­à¸‡ multivariate structure

```
PCA Drift Detection:
â”œâ”€â”€ Explained Variance Ratio - variance à¸—à¸µà¹ˆà¹à¸•à¹ˆà¸¥à¸° PC à¸­à¸˜à¸´à¸šà¸²à¸¢à¹„à¸”à¹‰
â”œâ”€â”€ Component Similarity - à¸—à¸´à¸¨à¸—à¸²à¸‡à¸‚à¸­à¸‡ PC à¹€à¸«à¸¡à¸·à¸­à¸™à¹€à¸”à¸´à¸¡à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
â””â”€â”€ Reconstruction Error - error à¹€à¸¡à¸·à¹ˆà¸­ reconstruct data
```

**Metrics à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰**:
1. **Explained Variance Comparison**: à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸§à¹ˆà¸²à¹à¸•à¹ˆà¸¥à¸° PC à¸­à¸˜à¸´à¸šà¸²à¸¢ variance à¹€à¸—à¹ˆà¸²à¹€à¸”à¸´à¸¡à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
2. **Component Similarity (Cosine Similarity)**: à¸”à¸¹à¸§à¹ˆà¸² PC directions à¹€à¸«à¸¡à¸·à¸­à¸™à¹€à¸”à¸´à¸¡à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
3. **Reconstruction Error**: à¹ƒà¸Šà¹‰ reference PCA à¸à¸±à¸š current data à¹à¸¥à¹‰à¸§à¸”à¸¹ error

**Code Reference**:
```python
def pca_drift_detection(ref_df, cur_df, n_components=None):
    # Standardize
    scaler = StandardScaler()
    ref_scaled = scaler.fit_transform(ref_df)
    cur_scaled = scaler.transform(cur_df)
    
    # Fit PCA on reference
    pca_ref = PCA(n_components=n_components)
    pca_ref.fit(ref_scaled)
    
    # Component similarities (using cosine similarity)
    for i in range(n_components):
        cos_sim = abs(np.dot(pca_ref.components_[i], pca_cur.components_[i]))
        # à¸–à¹‰à¸² cos_sim < 0.9 = structure à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™
```

#### 3. Mahalanobis Distance

**à¸—à¸¤à¸©à¸à¸µ**: à¸§à¸±à¸”à¸§à¹ˆà¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¸¡à¹ˆà¸­à¸¢à¸¹à¹ˆà¸«à¹ˆà¸²à¸‡à¸ˆà¸²à¸ distribution à¸‚à¸­à¸‡ reference data à¹€à¸—à¹ˆà¸²à¹„à¸£ à¹‚à¸”à¸¢à¸„à¸³à¸™à¸¶à¸‡à¸–à¸¶à¸‡ covariance

```
Mahalanobis Distance = âˆš((x - Î¼)áµ€ Î£â»Â¹ (x - Î¼))

à¹‚à¸”à¸¢à¸—à¸µà¹ˆ:
- x = data point
- Î¼ = mean à¸‚à¸­à¸‡ reference
- Î£ = covariance matrix à¸‚à¸­à¸‡ reference
```

**à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™**:
1. Fit covariance à¸šà¸™ reference data
2. à¸„à¸³à¸™à¸§à¸“ Mahalanobis distance à¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸¸à¸ points
3. à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š distribution à¸‚à¸­à¸‡ distances

**Code Reference**:
```python
def mahalanobis_drift_detection(ref_df, cur_df, threshold_percentile=95):
    # Fit covariance on reference
    cov = EmpiricalCovariance().fit(ref_scaled)
    
    # Calculate distances
    ref_distances = cov.mahalanobis(ref_scaled)
    cur_distances = cov.mahalanobis(cur_scaled)
    
    # Compare distributions
    ks_stat, ks_pval = stats.ks_2samp(ref_distances, cur_distances)
    drift_detected = ks_pval < 0.05
```

### Comprehensive Multivariate Analysis

```
MultivariateriftDetector
â”œâ”€â”€ Correlation Analysis
â”‚   â””â”€â”€ à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š pairwise correlation changes
â”œâ”€â”€ PCA Analysis
â”‚   â””â”€â”€ à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š structure changes
â”œâ”€â”€ Mahalanobis Analysis
â”‚   â””â”€â”€ à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š distribution shift
â””â”€â”€ Consensus
    â””â”€â”€ à¸£à¸§à¸¡à¸œà¸¥à¸ˆà¸²à¸à¸—à¸¸à¸ methods
```

---

## LAB 4: Drift Detection in Production Simulation

### ğŸ¯ à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ
- à¸ªà¸£à¹‰à¸²à¸‡ simulated data stream à¸—à¸µà¹ˆà¸¡à¸µ drift
- à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š sudden vs gradual drift
- Implement sliding window monitoring

### à¸—à¸¤à¸©à¸à¸µ: Drift Patterns à¹ƒà¸™ Production

#### Types of Drift

```
1. Sudden Drift (Abrupt)
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
               â”‚
               â–¼ Drift Point
   à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸—à¸±à¸™à¸—à¸µ

2. Gradual Drift
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸Šà¹‰à¸²à¹† à¸•à¸²à¸¡à¹€à¸§à¸¥à¸²

3. Incremental Drift
   â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€
       â”‚   â”‚   â”‚   â”‚
   à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹€à¸›à¹‡à¸™à¸‚à¸±à¹‰à¸™à¸šà¸±à¸™à¹„à¸”

4. Seasonal/Recurring Drift
   â”€â”€â”€â”€â•²â•±â”€â”€â”€â”€â•²â•±â”€â”€â”€â”€â•²â•±â”€â”€â”€â”€
   à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸•à¸²à¸¡ pattern à¸‹à¹‰à¸³
```

**Code Reference** - Data Stream Simulator:
```python
class DataStreamSimulator:
    def generate_stream(self, n_samples, drift_type='no_drift', drift_params=None):
        if drift_type == 'sudden':
            # à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸—à¸±à¸™à¸—à¸µà¸—à¸µà¹ˆ drift_point
            data[:drift_point] = np.random.normal(base_mean, ...)
            data[drift_point:] = np.random.normal(new_mean, ...)
            
        elif drift_type == 'gradual':
            # Linear interpolation
            for i in range(n_samples):
                if drift_start <= i <= drift_end:
                    progress = (i - drift_start) / (drift_end - drift_start)
                    current_mean = base_mean + progress * (final_mean - base_mean)
```

### Sliding Window Drift Detection

**à¸«à¸¥à¸±à¸à¸à¸²à¸£**:
```
Time â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶

Reference Window          Test Window
[â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•]     [â•â•â•â•â•â•â•â•â•]
        â–²                      â–²
        â”‚                      â”‚
   Fixed/Slow moving    Current data
```

**Architecture**:
```
SlidingWindowDriftDetector
â”œâ”€â”€ reference_buffer (deque with maxlen)
â”œâ”€â”€ test_buffer (deque with maxlen)
â”œâ”€â”€ update(value)
â”‚   â”œâ”€â”€ Add to buffer
â”‚   â”œâ”€â”€ Check if ready
â”‚   â””â”€â”€ Run drift detection
â”œâ”€â”€ Detection Methods
â”‚   â”œâ”€â”€ KS Test
â”‚   â””â”€â”€ PSI
â””â”€â”€ Output
    â”œâ”€â”€ drift_detected
    â”œâ”€â”€ metrics
    â””â”€â”€ history
```

**Code Reference**:
```python
class SlidingWindowDriftDetector:
    def __init__(self, reference_window_size=200, test_window_size=100):
        self.reference_buffer = deque(maxlen=reference_window_size)
        self.test_buffer = deque(maxlen=test_window_size)
    
    def update(self, value, timestamp=None):
        # à¹€à¸à¸´à¹ˆà¸¡à¸„à¹ˆà¸²à¹ƒà¸™ buffers
        if not self.is_initialized:
            self.reference_buffer.append(value)
            return {'status': 'initializing'}
        
        self.test_buffer.append(value)
        
        if len(self.test_buffer) < self.test_window_size:
            return {'status': 'collecting'}
        
        # à¸—à¸³ drift detection
        ref_array = np.array(self.reference_buffer)
        test_array = np.array(self.test_buffer)
        
        psi = self.calculate_psi(ref_array, test_array)
        drift_detected = psi > self.psi_threshold
        
        return {
            'drift_detected': drift_detected,
            'psi': psi
        }
```

### Adaptive Reference Window

**à¸›à¸±à¸à¸«à¸²à¸‚à¸­à¸‡ Fixed Reference**:
- Gradual drift à¸­à¸²à¸ˆà¸•à¸£à¸§à¸ˆà¹„à¸¡à¹ˆà¹€à¸ˆà¸­ à¹€à¸à¸£à¸²à¸° reference à¹€à¸à¹ˆà¸²à¹€à¸à¸´à¸™à¹„à¸›
- à¸•à¹‰à¸­à¸‡ adapt reference à¹€à¸¡à¸·à¹ˆà¸­ detect drift

**à¸§à¸´à¸˜à¸µà¹à¸à¹‰**:
```python
class AdaptiveDriftDetector:
    def adapt_reference(self):
        """à¸›à¸£à¸±à¸š reference window à¹€à¸¡à¸·à¹ˆà¸­ confirm drift"""
        # à¸œà¸ªà¸¡ old reference à¸à¸±à¸š new data
        old_weight = 0.5
        
        # à¹€à¸à¸´à¹ˆà¸¡à¸šà¸²à¸‡à¸ªà¹ˆà¸§à¸™à¸ˆà¸²à¸ old reference
        for val in old_ref[-n_old:]:
            self.reference_buffer.append(val)
        
        # à¹€à¸à¸´à¹ˆà¸¡ new data
        for val in new_data:
            self.reference_buffer.append(val)
```

### Page-Hinkley Test

**à¸—à¸¤à¸©à¸à¸µ**: Algorithm à¸ªà¸³à¸«à¸£à¸±à¸š detect mean shift à¹ƒà¸™ streaming data

```
Algorithm:
1. Update running mean: Î¼_t = Î±Â·Î¼_{t-1} + (1-Î±)Â·x_t
2. Update cumulative sum: S_t = S_{t-1} + (x_t - Î¼_t - Î´)
3. Track min/max of S_t
4. Detect if S_t - min(S) > Î» (upward shift)
         à¸«à¸£à¸·à¸­ max(S) - S_t > Î» (downward shift)
```

**Code Reference**:
```python
class PageHinkleyDetector:
    def update(self, value):
        # Update mean (exponential moving average)
        self.mean = self.alpha * self.mean + (1 - self.alpha) * value
        
        # Update cumulative sum
        self.sum += value - self.mean - self.delta
        
        # Update min/max
        self.min_sum = min(self.min_sum, self.sum)
        self.max_sum = max(self.max_sum, self.sum)
        
        # Detection
        ph_positive = self.sum - self.min_sum  # Upward shift
        ph_negative = self.max_sum - self.sum  # Downward shift
        
        drift_detected = (ph_positive > self.lambda_) or (ph_negative > self.lambda_)
```

### Comparison of Methods

| Method | Pros | Cons | Best For |
|--------|------|------|----------|
| Sliding Window | Simple, intuitive | Fixed reference | Sudden drift |
| Adaptive | Handles gradual drift | More complex | Production |
| Page-Hinkley | Low memory, fast | Mean shift only | Real-time |

---

## LAB 5: Custom Metrics & Drift Thresholds

### ğŸ¯ à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ
- à¸ªà¸£à¹‰à¸²à¸‡ custom drift metrics
- à¸›à¸£à¸±à¸š threshold à¸•à¸²à¸¡ business requirements
- Handle false positives/negatives

### à¸—à¸¤à¸©à¸à¸µ: Threshold Selection

**à¸›à¸±à¸à¸«à¸²**: Default thresholds à¸­à¸²à¸ˆà¹„à¸¡à¹ˆà¹€à¸«à¸¡à¸²à¸°à¸à¸±à¸šà¸—à¸¸à¸ use case

```
Trade-off:
                    Threshold
           Low â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ High
           
Sensitivity: High                    Low
False Positive: High                 Low
False Negative: Low                  High
```

### Custom Drift Metrics

#### 1. Combined Score
```python
def combined_score(reference, current, weights=None):
    """à¸£à¸§à¸¡à¸«à¸¥à¸²à¸¢ metrics à¹€à¸‚à¹‰à¸²à¸”à¹‰à¸§à¸¢à¸à¸±à¸™"""
    if weights is None:
        weights = {
            'psi': 0.3,
            'wasserstein': 0.3,
            'mean_shift': 0.2,
            'percentile': 0.2
        }
    
    # Normalize à¹à¸•à¹ˆà¸¥à¸° metric à¹ƒà¸«à¹‰à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸Šà¹ˆà¸§à¸‡ 0-1
    psi = min(calculate_psi(reference, current), 1.0)
    wasserstein = min(normalized_wasserstein(reference, current) / 3, 1.0)
    mean_shift = min(mean_shift_ratio(reference, current) / 3, 1.0)
    percentile = min(percentile_shift(reference, current) / 3, 1.0)
    
    score = (weights['psi'] * psi + 
             weights['wasserstein'] * wasserstein +
             weights['mean_shift'] * mean_shift +
             weights['percentile'] * percentile)
    
    return score
```

#### 2. Jensen-Shannon Divergence
```python
def jensen_shannon_divergence(reference, current, bins=10):
    """Symmetric version of KL Divergence"""
    # à¸ªà¸£à¹‰à¸²à¸‡ normalized histograms
    ref_hist = np.histogram(reference, bins=bins, density=True)[0]
    cur_hist = np.histogram(current, bins=bins, density=True)[0]
    
    # Average distribution
    m = 0.5 * (ref_hist + cur_hist)
    
    # JS Divergence = 0.5 * (KL(P||M) + KL(Q||M))
    js = 0.5 * (kl_divergence(ref_hist, m) + kl_divergence(cur_hist, m))
    return js
```

### Threshold Optimization

#### F1-based Optimization

```python
def find_optimal_threshold(scenarios, metric_func, thresholds, optimize_for='f1'):
    """à¸«à¸² threshold à¸—à¸µà¹ˆà¹ƒà¸«à¹‰ F1 score à¸ªà¸¹à¸‡à¸ªà¸¸à¸”"""
    results = []
    
    for t in thresholds:
        y_true = [s['has_drift'] for s in scenarios]
        y_pred = [metric_func(s['reference'], s['current']) > t for s in scenarios]
        
        precision = precision_score(y_true, y_pred)
        recall = recall_score(y_true, y_pred)
        f1 = f1_score(y_true, y_pred)
        
        results.append({'threshold': t, 'f1': f1})
    
    # à¸«à¸² optimal
    optimal = max(results, key=lambda x: x['f1'])
    return optimal
```

#### Cost-based Optimization

**à¸—à¸¤à¸©à¸à¸µ**: à¸›à¸£à¸±à¸š threshold à¸•à¸²à¸¡ cost à¸‚à¸­à¸‡ false positive vs false negative

```
Total Cost = FP_count Ã— FP_cost + FN_count Ã— FN_cost

Scenarios:
â”œâ”€â”€ High FN cost (à¹€à¸Šà¹ˆà¸™ fraud detection)
â”‚   â””â”€â”€ à¹ƒà¸Šà¹‰ Low threshold â†’ detect more, accept false alarms
â”œâ”€â”€ High FP cost (à¹€à¸Šà¹ˆà¸™ expensive retraining)
â”‚   â””â”€â”€ à¹ƒà¸Šà¹‰ High threshold â†’ conservative detection
â””â”€â”€ Balanced cost
    â””â”€â”€ Optimize for F1
```

**Code Reference**:
```python
class BusinessDriftThreshold:
    def __init__(self, false_positive_cost=1, false_negative_cost=10):
        self.fp_cost = false_positive_cost
        self.fn_cost = false_negative_cost
    
    def calculate_total_cost(self, y_true, y_pred):
        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
        return fp * self.fp_cost + fn * self.fn_cost
    
    def find_cost_optimal_threshold(self, scenarios, metric_func, thresholds):
        costs = []
        for t in thresholds:
            y_pred = [metric_func(s['reference'], s['current']) > t 
                     for s in scenarios]
            cost = self.calculate_total_cost(y_true, y_pred)
            costs.append({'threshold': t, 'cost': cost})
        
        optimal = min(costs, key=lambda x: x['cost'])
        return optimal
```

### Handling False Positives/Negatives

#### Ensemble Approach
```python
class RobustDriftDetector:
    """à¹ƒà¸Šà¹‰à¸«à¸¥à¸²à¸¢ methods à¸£à¹ˆà¸§à¸¡à¸à¸±à¸™"""
    
    def detect(self, reference, current):
        all_metrics = self._calculate_all_metrics(reference, current)
        
        # Majority voting
        drift_votes = sum(
            1 for m, v in all_metrics.items() 
            if v > self.thresholds[m]
        )
        
        # à¸•à¹‰à¸­à¸‡ 3/4 methods agree
        ensemble_drift = drift_votes >= 3
        
        return ensemble_drift
```

#### Confirmation Mechanism
```python
def detect_with_confirmation(self, reference, current):
    """à¸•à¹‰à¸­à¸‡ detect à¸«à¸¥à¸²à¸¢à¸„à¸£à¸±à¹‰à¸‡à¸•à¸´à¸”à¸à¸±à¸™à¸–à¸¶à¸‡à¸¢à¸·à¸™à¸¢à¸±à¸™"""
    
    potential_drift = self.primary_metric(reference, current) > threshold
    
    if potential_drift:
        self.consecutive_count += 1
    else:
        self.consecutive_count = 0
    
    # Confirmed à¸–à¹‰à¸² detect 3 à¸„à¸£à¸±à¹‰à¸‡à¸•à¸´à¸”à¸à¸±à¸™
    confirmed = self.consecutive_count >= 3
    return confirmed
```

### Best Practices à¸ªà¸³à¸«à¸£à¸±à¸š Threshold Setting

```
1ï¸âƒ£ DOMAIN-SPECIFIC THRESHOLDS
   - à¹„à¸¡à¹ˆà¹ƒà¸Šà¹‰ default à¹‚à¸”à¸¢à¹„à¸¡à¹ˆ validate
   - à¸—à¸”à¸ªà¸­à¸šà¸à¸±à¸š labeled data
   - à¸›à¸£à¸¶à¸à¸©à¸² domain experts

2ï¸âƒ£ COST-BASED OPTIMIZATION
   - à¸à¸´à¸ˆà¸²à¸£à¸“à¸² cost à¸‚à¸­à¸‡ FP vs FN
   - FN à¹à¸à¸‡ â†’ Lower threshold
   - FP à¹à¸à¸‡ â†’ Higher threshold

3ï¸âƒ£ ENSEMBLE APPROACH
   - à¹ƒà¸Šà¹‰à¸«à¸¥à¸²à¸¢ metrics à¸£à¹ˆà¸§à¸¡à¸à¸±à¸™
   - Voting mechanism à¸¥à¸” false positives

4ï¸âƒ£ CONFIRMATION MECHANISM
   - Require consecutive detections
   - à¸›à¹‰à¸­à¸‡à¸à¸±à¸™ temporary spikes

5ï¸âƒ£ PERIODIC REVIEW
   - Review thresholds à¹€à¸›à¹‡à¸™à¸£à¸°à¸¢à¸°
   - Business requirements à¸­à¸²à¸ˆà¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™
```

---

## LAB 6: End-to-End Monitoring Pipeline

### ğŸ¯ à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ
- à¸£à¸§à¸¡à¸—à¸¸à¸ components à¹€à¸‚à¹‰à¸²à¸”à¹‰à¸§à¸¢à¸à¸±à¸™
- à¸ªà¸£à¹‰à¸²à¸‡ automated monitoring workflow
- Integrate à¸à¸±à¸š MLflow

### Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Drift Monitoring Pipeline                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚  Data Source   â”‚â”€â”€â”€â–¶â”‚  Data Buffer   â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                â”‚                             â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚                    â”‚   Drift Calculator    â”‚                â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                â”‚                             â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚           â”‚                    â”‚                    â”‚       â”‚
â”‚           â–¼                    â–¼                    â–¼       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Alert     â”‚      â”‚   Report    â”‚      â”‚   MLflow    â”‚ â”‚
â”‚  â”‚   Manager   â”‚      â”‚   Generator â”‚      â”‚   Tracker   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Components

#### 1. Data Classes

```python
from dataclasses import dataclass
from enum import Enum

class AlertSeverity(Enum):
    INFO = "info"
    WARNING = "warning"
    CRITICAL = "critical"

class DriftType(Enum):
    NONE = "none"
    MILD = "mild"
    MODERATE = "moderate"
    SEVERE = "severe"

@dataclass
class DriftResult:
    timestamp: datetime
    feature: str
    drift_detected: bool
    drift_type: DriftType
    psi: float
    ks_statistic: float
    ks_pvalue: float
    reference_mean: float
    current_mean: float

@dataclass
class Alert:
    timestamp: datetime
    severity: AlertSeverity
    message: str
    details: Dict
    acknowledged: bool = False
```

#### 2. Configuration

```python
@dataclass
class MonitoringConfig:
    reference_window_size: int = 1000
    current_window_size: int = 200
    psi_mild_threshold: float = 0.1
    psi_moderate_threshold: float = 0.2
    psi_severe_threshold: float = 0.25
    ks_significance: float = 0.05
    check_interval_seconds: int = 60
    alert_cooldown_minutes: int = 30
    features_to_monitor: List[str] = field(default_factory=list)
```

#### 3. Data Buffer

```python
class DataBuffer:
    """Buffer à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸à¹‡à¸š reference à¹à¸¥à¸° current data"""
    
    def __init__(self, config: MonitoringConfig):
        self.reference_data: Dict[str, deque] = {}
        self.current_data: Dict[str, deque] = {}
    
    def initialize(self, reference_df: pd.DataFrame):
        """Initialize with reference data"""
        for feature in self.config.features_to_monitor:
            self.reference_data[feature] = deque(
                reference_df[feature].values,
                maxlen=self.config.reference_window_size
            )
    
    def add_data(self, data: Dict[str, float]):
        """Add new data point"""
        for feature, value in data.items():
            self.current_data[feature].append(value)
```

#### 4. Alert Manager

```python
class AlertManager:
    """à¸ˆà¸±à¸”à¸à¸²à¸£ alerts à¸à¸£à¹‰à¸­à¸¡ cooldown"""
    
    def __init__(self, config: MonitoringConfig):
        self.alerts: List[Alert] = []
        self.last_alert_time: Dict[str, datetime] = {}
    
    def should_alert(self, feature: str) -> bool:
        """Check cooldown"""
        if feature not in self.last_alert_time:
            return True
        elapsed = datetime.now() - self.last_alert_time[feature]
        return elapsed > timedelta(minutes=self.config.alert_cooldown_minutes)
    
    def create_alert(self, drift_result: DriftResult) -> Optional[Alert]:
        if not drift_result.drift_detected:
            return None
        
        if not self.should_alert(drift_result.feature):
            return None
        
        # Determine severity
        severity = self._determine_severity(drift_result.drift_type)
        
        alert = Alert(
            timestamp=drift_result.timestamp,
            severity=severity,
            message=f"Drift detected in {drift_result.feature}",
            details=drift_result.to_dict()
        )
        
        self.alerts.append(alert)
        self.last_alert_time[drift_result.feature] = datetime.now()
        
        return alert
```

#### 5. Main Pipeline

```python
class DriftMonitoringPipeline:
    def __init__(self, config: MonitoringConfig):
        self.config = config
        self.data_buffer = DataBuffer(config)
        self.alert_manager = AlertManager(config)
        self.drift_calculator = DriftCalculator()
        self.results_history: List[DriftResult] = []
    
    def initialize(self, reference_data: pd.DataFrame):
        self.data_buffer.initialize(reference_data)
    
    def process_batch(self, batch_data: pd.DataFrame) -> List[DriftResult]:
        results = []
        
        # Add data to buffer
        for idx, row in batch_data.iterrows():
            self.data_buffer.add_data(row.to_dict())
        
        # Check if ready
        if not self.data_buffer.is_current_ready():
            return results
        
        # Detect drift for each feature
        for feature in self.config.features_to_monitor:
            result = self._detect_drift_for_feature(feature)
            if result:
                results.append(result)
                
                # Create alert if needed
                if result.drift_detected:
                    self.alert_manager.create_alert(result)
        
        return results
```

### Report Generation

```python
class ReportGenerator:
    def generate_html_report(self, output_path: str):
        """Generate HTML report"""
        summary = self.pipeline.get_summary_report()
        
        html_content = f"""
        <html>
        <head><title>Drift Monitoring Report</title></head>
        <body>
            <h1>Drift Monitoring Report</h1>
            <p>Generated: {datetime.now()}</p>
            
            <h2>Summary</h2>
            <p>Total Checks: {summary['total_checks']}</p>
            <p>Drifts Detected: {summary['total_drifts_detected']}</p>
            
            <h2>Feature Summary</h2>
            <table>
                <tr><th>Feature</th><th>PSI</th><th>Status</th></tr>
                {self._generate_feature_rows(summary)}
            </table>
            
            <h2>Active Alerts</h2>
            {self._generate_alerts_section()}
        </body>
        </html>
        """
        
        with open(output_path, 'w') as f:
            f.write(html_content)
```

### MLflow Integration

```python
class MLflowDriftTracker:
    def __init__(self, experiment_name: str = "drift_monitoring"):
        mlflow.set_experiment(experiment_name)
    
    def log_drift_result(self, result: DriftResult):
        mlflow.log_metric(f"{result.feature}_psi", result.psi)
        mlflow.log_metric(f"{result.feature}_drift", 1 if result.drift_detected else 0)
        mlflow.log_param(f"{result.feature}_drift_type", result.drift_type.value)
    
    def log_summary(self, summary: Dict):
        mlflow.log_metric("total_drifts", summary.get('total_drifts_detected', 0))
        for feature, data in summary.get('feature_summary', {}).items():
            mlflow.log_metric(f"{feature}_drift_rate", data['drift_rate'])
    
    def log_artifact(self, artifact_path: str):
        mlflow.log_artifact(artifact_path)
```

---

## à¸ªà¸£à¸¸à¸›à¹à¸¥à¸° Best Practices

### Summary Table

| Lab | à¸«à¸±à¸§à¸‚à¹‰à¸­ | Key Concepts |
|-----|--------|--------------|
| 1 | Understanding Data Drift | Covariate/Concept Shift, KS/PSI/Wasserstein |
| 2 | Feature Drift Detection | Per-feature analysis, Numerical vs Categorical |
| 3 | Multivariate Drift | Correlation, PCA, Mahalanobis Distance |
| 4 | Production Simulation | Streaming, Sliding Window, Page-Hinkley |
| 5 | Custom Metrics & Thresholds | Optimization, Cost-based, Ensemble |
| 6 | End-to-End Pipeline | Architecture, Alerting, Reporting, MLflow |

### Decision Framework

```
à¹€à¸¡à¸·à¹ˆà¸­à¸à¸š Drift à¸„à¸§à¸£à¸—à¸³à¸­à¸¢à¹ˆà¸²à¸‡à¹„à¸£?

1. Assess Severity
   â”œâ”€â”€ MILD â†’ Monitor closely
   â”œâ”€â”€ MODERATE â†’ Investigate root cause
   â””â”€â”€ SEVERE â†’ Immediate action required

2. Investigate Root Cause
   â”œâ”€â”€ Data collection issue?
   â”œâ”€â”€ Upstream data change?
   â”œâ”€â”€ Real-world change?
   â””â”€â”€ Seasonal pattern?

3. Decide Action
   â”œâ”€â”€ Retrain model
   â”œâ”€â”€ Update feature engineering
   â”œâ”€â”€ Adjust thresholds
   â””â”€â”€ Business process change
```

### Production Checklist

```
â–¡ Define monitoring strategy
  â–¡ Which features to monitor?
  â–¡ What thresholds to use?
  â–¡ How often to check?

â–¡ Implement detection
  â–¡ Choose appropriate methods
  â–¡ Handle both numerical and categorical
  â–¡ Consider multivariate drift

â–¡ Set up alerting
  â–¡ Define severity levels
  â–¡ Configure notification channels
  â–¡ Set cooldown periods

â–¡ Create reporting
  â–¡ Automated dashboards
  â–¡ Periodic reports
  â–¡ Historical analysis

â–¡ Plan remediation
  â–¡ When to retrain?
  â–¡ How to validate new model?
  â–¡ Rollback procedures
```

### Final Thoughts

à¸à¸²à¸£à¸—à¸³ Drift Detection à¸—à¸µà¹ˆà¸”à¸µà¸•à¹‰à¸­à¸‡:

1. **à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆ Business Context**: Drift à¸—à¸µà¹ˆà¸ªà¸³à¸„à¸±à¸à¹ƒà¸™ domain à¸«à¸™à¸¶à¹ˆà¸‡à¸­à¸²à¸ˆà¹„à¸¡à¹ˆà¸ªà¸³à¸„à¸±à¸à¹ƒà¸™ domain à¸­à¸·à¹ˆà¸™

2. **à¹ƒà¸Šà¹‰à¸«à¸¥à¸²à¸¢ Methods**: à¹„à¸¡à¹ˆà¸¡à¸µ method à¹ƒà¸”à¸—à¸µà¹ˆà¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œà¹à¸šà¸š à¸„à¸§à¸£à¹ƒà¸Šà¹‰à¸«à¸¥à¸²à¸¢ methods à¸£à¹ˆà¸§à¸¡à¸à¸±à¸™

3. **Tune Thresholds**: Default thresholds à¸¡à¸±à¸à¹„à¸¡à¹ˆà¹€à¸«à¸¡à¸²à¸° à¸•à¹‰à¸­à¸‡à¸›à¸£à¸±à¸šà¸•à¸²à¸¡ use case

4. **Automate**: à¸à¸²à¸£à¸—à¸³ manual monitoring à¹„à¸¡à¹ˆà¸¢à¸±à¹ˆà¸‡à¸¢à¸·à¸™ à¸•à¹‰à¸­à¸‡à¸¡à¸µ automated pipeline

5. **Monitor the Monitor**: à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² monitoring system à¸—à¸³à¸‡à¸²à¸™à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡

---

## à¹à¸«à¸¥à¹ˆà¸‡à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¹€à¸à¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡

- [Evidently AI Documentation](https://docs.evidentlyai.com/)
- [NannyML Documentation](https://docs.nannyml.com/)
- [Alibi Detect](https://docs.seldon.io/projects/alibi-detect/)
- [Great Expectations](https://docs.greatexpectations.io/)

---

*à¹€à¸­à¸à¸ªà¸²à¸£à¸™à¸µà¹‰à¸ˆà¸±à¸”à¸—à¸³à¹€à¸à¸·à¹ˆà¸­à¸›à¸£à¸°à¸à¸­à¸šà¸à¸²à¸£à¹€à¸£à¸µà¸¢à¸™à¸à¸²à¸£à¸ªà¸­à¸™à¸§à¸´à¸Šà¸² MLOps*