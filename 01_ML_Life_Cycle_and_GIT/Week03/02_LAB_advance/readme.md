# ðŸ§ª LAB: MLOps with Scikit-Learn à¹à¸¥à¸° Git Branch Workflow

## ðŸ“‹ à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œà¸à¸²à¸£à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰

à¸«à¸¥à¸±à¸‡à¸ˆà¸²à¸à¸—à¸³ LAB à¸™à¸µà¹‰à¹€à¸ªà¸£à¹‡à¸ˆ à¸™à¸±à¸à¸¨à¸¶à¸à¸©à¸²à¸ˆà¸°à¸ªà¸²à¸¡à¸²à¸£à¸–:
- âœ… à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œ Machine Learning à¸”à¹‰à¸§à¸¢ Scikit-Learn
- âœ… à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Git Branch à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸—à¸”à¸¥à¸­à¸‡ ML Models à¸•à¹ˆà¸²à¸‡à¹†
- âœ… à¸ˆà¸±à¸”à¸à¸²à¸£ Feature Engineering à¹ƒà¸™ Branch à¹à¸¢à¸
- âœ… à¹ƒà¸Šà¹‰ Pipeline à¹ƒà¸™ Linux à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ
- âœ… à¹ƒà¸Šà¹‰ `tree` à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œ ML
- âœ… à¹ƒà¸Šà¹‰ Here Document à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ Python à¹à¸¥à¸° Config
- âœ… à¸•à¸´à¸”à¸•à¸²à¸¡ Model Experiments à¸”à¹‰à¸§à¸¢ Git
- âœ… à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆ MLOps Workflow à¸žà¸·à¹‰à¸™à¸à¸²à¸™

---

## ðŸ“š à¸„à¸§à¸²à¸¡à¸£à¸¹à¹‰à¸žà¸·à¹‰à¸™à¸à¸²à¸™

### MLOps à¸„à¸·à¸­à¸­à¸°à¹„à¸£?

**MLOps** (Machine Learning Operations) à¸„à¸·à¸­à¹à¸™à¸§à¸›à¸à¸´à¸šà¸±à¸•à¸´à¸—à¸µà¹ˆà¸£à¸§à¸¡ ML, DevOps à¹à¸¥à¸° Data Engineering à¹€à¸‚à¹‰à¸²à¸”à¹‰à¸§à¸¢à¸à¸±à¸™ à¹€à¸žà¸·à¹ˆà¸­:
- à¸ˆà¸±à¸”à¸à¸²à¸£ ML Models à¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸›à¹‡à¸™à¸£à¸°à¸šà¸š
- à¸—à¸³à¹ƒà¸«à¹‰à¸à¸²à¸£ Deploy à¹à¸¥à¸° Monitor à¹€à¸›à¹‡à¸™à¹„à¸›à¸­à¸¢à¹ˆà¸²à¸‡à¸£à¸²à¸šà¸£à¸·à¹ˆà¸™
- à¸•à¸´à¸”à¸•à¸²à¸¡ Experiments à¹à¸¥à¸° Versions

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      MLOps Lifecycle                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚   Data â†’ Feature Engineering â†’ Model Training â†’ Evaluation  â”‚
â”‚     â†‘                                                   â†“    â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Monitoring â†â”€â”€ Deployment â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                              â”‚
â”‚   ðŸ”§ Git: Version Control for all steps                     â”‚
â”‚   â˜ï¸  Remote: Backup & Collaboration (GitHub/GitLab)        â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### à¸—à¸³à¹„à¸¡à¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰ Git Branch à¸à¸±à¸š ML Projects?

| à¸ªà¸–à¸²à¸™à¸à¸²à¸£à¸“à¹Œ | Branch à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰ | à¸›à¸£à¸°à¹‚à¸¢à¸Šà¸™à¹Œ |
|-----------|--------------|---------|
| à¸—à¸”à¸¥à¸­à¸‡ Model à¹ƒà¸«à¸¡à¹ˆ | `experiment/random-forest` | à¹„à¸¡à¹ˆà¸à¸£à¸°à¸—à¸š code à¸«à¸¥à¸±à¸ |
| Feature Engineering | `feature/scaling-normalization` | à¸žà¸±à¸’à¸™à¸²à¹à¸¢à¸ merge à¸—à¸µà¸«à¸¥à¸±à¸‡ |
| Hyperparameter Tuning | `tune/grid-search-rf` | à¹€à¸à¹‡à¸š config à¹à¸•à¹ˆà¸¥à¸°à¸„à¸£à¸±à¹‰à¸‡ |
| Bug Fix | `fix/data-leakage` | à¹à¸à¹‰à¹„à¸‚à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸à¸£à¸°à¸—à¸šà¸à¸²à¸£à¸—à¸”à¸¥à¸­à¸‡ |

---

## ðŸ”§ à¸„à¸§à¸²à¸¡à¸£à¸¹à¹‰à¹€à¸šà¸·à¹‰à¸­à¸‡à¸•à¹‰à¸™: Pipeline à¹ƒà¸™ Linux à¸ªà¸³à¸«à¸£à¸±à¸š ML

### Pipeline (`|`) à¸„à¸·à¸­à¸­à¸°à¹„à¸£?

**Pipeline** à¸„à¸·à¸­à¸à¸²à¸£à¸ªà¹ˆà¸‡à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸ˆà¸²à¸à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸«à¸™à¸¶à¹ˆà¸‡à¹„à¸›à¹€à¸›à¹‡à¸™ input à¸‚à¸­à¸‡à¸­à¸µà¸à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸«à¸™à¸¶à¹ˆà¸‡ à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸«à¸¡à¸²à¸¢ `|` (pipe)

```
Command 1  |  Command 2  |  Command 3
    â†“              â†“              â†“
  output    â†’    input     â†’   output
            â†’              â†’    input
                           â†’   output (final)
```

### à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡ Pipeline à¸ªà¸³à¸«à¸£à¸±à¸š ML Projects

```bash
# Example 1: Count Python files
ls *.py | wc -l
```

**à¸­à¸˜à¸´à¸šà¸²à¸¢à¸—à¸µà¸¥à¸°à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™:**
```
ls *.py         â†’  List all .py files
                   train.py
                   model.py
                   evaluate.py
        |
        â†“
wc -l           â†’  Count lines
                   Result: 3
```

```bash
# Example 2: Find experiment branches
git branch | grep "experiment"
```

**à¸­à¸˜à¸´à¸šà¸²à¸¢à¸—à¸µà¸¥à¸°à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™:**
```
git branch      â†’  List all branches
                   * main
                     experiment/random-forest
                     experiment/svm
                     feature/scaling
        |
        â†“
grep "experiment" â†’  Filter lines containing "experiment"
                      Result:
                        experiment/random-forest
                        experiment/svm
```

```bash
# Example 3: View commits related to model
git log --oneline | grep -i "model" | head -5
```

```bash
# Example 4: Count experiment branches
git branch | grep "experiment" | wc -l
```

### à¸ªà¸£à¸¸à¸›à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸šà¹ˆà¸­à¸¢à¸à¸±à¸š Pipeline

| à¸„à¸³à¸ªà¸±à¹ˆà¸‡ | à¸«à¸™à¹‰à¸²à¸—à¸µà¹ˆ | à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡ |
|--------|--------|----------|
| `grep "text"` | à¸à¸£à¸­à¸‡à¸šà¸£à¸£à¸—à¸±à¸”à¸—à¸µà¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡ | `cat log.txt \| grep "accuracy"` |
| `wc -l` | à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¸šà¸£à¸£à¸—à¸±à¸” | `ls *.py \| wc -l` |
| `head -n` | à¹€à¸­à¸² n à¸šà¸£à¸£à¸—à¸±à¸”à¹à¸£à¸ | `cat results.csv \| head -10` |
| `tail -n` | à¹€à¸­à¸² n à¸šà¸£à¸£à¸—à¸±à¸”à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢ | `cat training.log \| tail -20` |
| `sort` | à¹€à¸£à¸µà¸¢à¸‡à¸¥à¸³à¸”à¸±à¸š | `cat scores.txt \| sort -n` |
| `cut -d, -f1` | à¸•à¸±à¸”à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸ˆà¸²à¸ CSV | `cat data.csv \| cut -d, -f1` |

---

## ðŸ”§ à¸„à¸§à¸²à¸¡à¸£à¸¹à¹‰à¹€à¸šà¸·à¹‰à¸­à¸‡à¸•à¹‰à¸™: Here Document (Heredoc)

### Here Document à¸„à¸·à¸­à¸­à¸°à¹„à¸£?

**Here Document** à¸„à¸·à¸­à¸§à¸´à¸˜à¸µà¸à¸²à¸£à¹€à¸‚à¸µà¸¢à¸™à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸«à¸¥à¸²à¸¢à¸šà¸£à¸£à¸—à¸±à¸”à¸¥à¸‡à¹„à¸Ÿà¸¥à¹Œà¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸à¸” Ctrl+D

```bash
cat > filename << 'EOF'
Content line 1
Content line 2
Content line 3
EOF
```

**à¸­à¸˜à¸´à¸šà¸²à¸¢:**
- `cat > filename` = à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œà¹ƒà¸«à¸¡à¹ˆ
- `<< 'EOF'` = à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™ Here Document (EOF = End Of File, à¹ƒà¸Šà¹‰à¸„à¸³à¸­à¸·à¹ˆà¸™à¸à¹‡à¹„à¸”à¹‰)
- `EOF` = à¸ªà¸´à¹‰à¸™à¸ªà¸¸à¸” Here Document

### à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸§à¸´à¸˜à¸µà¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ

| à¸§à¸´à¸˜à¸µ | à¸‚à¹‰à¸­à¸”à¸µ | à¸‚à¹‰à¸­à¹€à¸ªà¸µà¸¢ |
|------|-------|---------|
| `echo "text" > file` | à¸‡à¹ˆà¸²à¸¢ à¸£à¸§à¸”à¹€à¸£à¹‡à¸§ | à¹€à¸‚à¸µà¸¢à¸™à¹„à¸”à¹‰à¹à¸„à¹ˆà¸šà¸£à¸£à¸—à¸±à¸”à¹€à¸”à¸µà¸¢à¸§ |
| `cat > file` à¹à¸¥à¹‰à¸§ Ctrl+D | à¹€à¸‚à¸µà¸¢à¸™à¹„à¸”à¹‰à¸«à¸¥à¸²à¸¢à¸šà¸£à¸£à¸—à¸±à¸” | à¸•à¹‰à¸­à¸‡à¸ˆà¸³à¸à¸” Ctrl+D |
| `cat > file << 'EOF'` | à¹€à¸‚à¸µà¸¢à¸™à¹„à¸”à¹‰à¸«à¸¥à¸²à¸¢à¸šà¸£à¸£à¸—à¸±à¸”, à¸Šà¸±à¸”à¹€à¸ˆà¸™ | à¸žà¸´à¸¡à¸žà¹Œà¸¢à¸²à¸§à¸à¸§à¹ˆà¸² |

---

## ðŸ› ï¸ à¹€à¸•à¸£à¸µà¸¢à¸¡à¸„à¸§à¸²à¸¡à¸žà¸£à¹‰à¸­à¸¡

### à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 1: à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² Git (à¸–à¹‰à¸²à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹€à¸„à¸¢à¸•à¸±à¹‰à¸‡)

```bash
# Set username
git config --global user.name "Your Name"

# Set email
git config --global user.email "your.email@example.com"

# Verify settings
git config --list
```

### à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 2: à¸ªà¸£à¹‰à¸²à¸‡ Remote Repository

à¸à¹ˆà¸­à¸™à¹€à¸£à¸´à¹ˆà¸¡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œ à¹ƒà¸«à¹‰à¸ªà¸£à¹‰à¸²à¸‡ repository à¸šà¸™ GitHub/GitLab à¸à¹ˆà¸­à¸™:

1. à¹„à¸›à¸—à¸µà¹ˆ [GitHub](https://github.com) à¸«à¸£à¸·à¸­ [GitLab](https://gitlab.com)
2. à¸„à¸¥à¸´à¸ **New Repository** à¸«à¸£à¸·à¸­ **New Project**
3. à¸•à¸±à¹‰à¸‡à¸Šà¸·à¹ˆà¸­ repository: `sklearn-mlops-lab`
4. **à¸­à¸¢à¹ˆà¸²à¹€à¸¥à¸·à¸­à¸** Initialize with README (à¹€à¸£à¸²à¸ˆà¸°à¸ªà¸£à¹‰à¸²à¸‡à¹€à¸­à¸‡)
5. à¸„à¸¥à¸´à¸ **Create Repository**

à¸ˆà¸”à¸ˆà¸³ URL à¸‚à¸­à¸‡ repository à¹„à¸§à¹‰ à¹€à¸Šà¹ˆà¸™:
- GitHub: `https://github.com/username/sklearn-mlops-lab.git`
- GitLab: `https://gitlab.com/username/sklearn-mlops-lab.git`

### à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 3: à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œ ML à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸¶à¸

```bash
# Create new folder
mkdir sklearn-mlops-lab
cd sklearn-mlops-lab

# Initialize Git repository
git init

# Check status
git status
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
Initialized empty Git repository in /path/to/sklearn-mlops-lab/.git/
```

### à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 4: à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­ Remote Repository

```bash
# Add remote origin (replace with your repository URL)
git remote add origin https://github.com/username/sklearn-mlops-lab.git

# Verify remote
git remote -v
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
origin  https://github.com/username/sklearn-mlops-lab.git (fetch)
origin  https://github.com/username/sklearn-mlops-lab.git (push)
```

> ðŸ’¡ **à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸:** à¸–à¹‰à¸²à¹ƒà¸Šà¹‰ SSH key à¹ƒà¸«à¹‰à¹ƒà¸Šà¹‰ URL à¹à¸šà¸š SSH à¹à¸—à¸™:
> `git remote add origin git@github.com:username/sklearn-mlops-lab.git`

### à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 5: à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Python à¹à¸¥à¸° Scikit-Learn

```bash
# Check Python version
python3 --version

# Check pip
pip3 --version

# Install scikit-learn (if not installed)
pip3 install scikit-learn pandas numpy joblib

# Verify installation
python3 -c "import sklearn; print(f'sklearn version: {sklearn.__version__}')"
```

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 0: à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œ ML à¸”à¹‰à¸§à¸¢ Here Document

### 0.1 à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ README.md

```bash
cat > README.md << 'EOF'
# Sklearn MLOps Lab
A project for learning MLOps with Scikit-Learn and Git

## ðŸ“ Project Structure

    sklearn-mlops-lab/
    â”œâ”€â”€ data/           # Training data
    â”œâ”€â”€ models/         # Trained models
    â”œâ”€â”€ src/            # Source code
    â”œâ”€â”€ notebooks/      # Jupyter notebooks
    â”œâ”€â”€ configs/        # Configuration files
    â”œâ”€â”€ results/        # Experiment results
    â””â”€â”€ tests/          # Unit tests

## ðŸŽ¯ Goals
- Learn Git Branch workflow with ML Projects
- Experiment with multiple models in different branches
- Track experiments systematically

## ðŸ‘¤ Author
- Student: [Your Name]
- ID: [Student ID]
EOF
```

```bash
# Verify created file
cat README.md
```

### 0.2 à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ

```bash
# Create all folders
mkdir -p data/raw data/processed
mkdir -p models
mkdir -p src/data src/features src/models src/utils
mkdir -p notebooks
mkdir -p configs
mkdir -p results
mkdir -p tests
```

### 0.3 à¹ƒà¸Šà¹‰ tree à¸”à¸¹à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œ

```bash
# View folder structure
tree
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ configs
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ processed
â”‚   â””â”€â”€ raw
â”œâ”€â”€ models
â”œâ”€â”€ notebooks
â”œâ”€â”€ results
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ data
â”‚   â”œâ”€â”€ features
â”‚   â”œâ”€â”€ models
â”‚   â””â”€â”€ utils
â””â”€â”€ tests

13 directories, 1 file
```

### 0.4 à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ requirements.txt

```bash
cat > requirements.txt << 'EOF'
# Core ML Libraries
scikit-learn>=1.3.0
pandas>=2.0.0
numpy>=1.24.0

# Model Persistence
joblib>=1.3.0

# Visualization
matplotlib>=3.7.0
seaborn>=0.12.0

# Utilities
python-dotenv>=1.0.0
PyYAML>=6.0

# Testing
pytest>=7.4.0
EOF
```

### 0.5 à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ .gitignore à¸ªà¸³à¸«à¸£à¸±à¸š ML Projects

```bash
cat > .gitignore << 'EOF'
# Python
__pycache__/
*.py[cod]
*.so
.Python
*.egg-info/
dist/
build/

# Virtual environments
venv/
.env/
env/

# Jupyter Notebooks
.ipynb_checkpoints/
*.ipynb_checkpoints

# Data files (large files)
data/raw/*.csv
data/raw/*.xlsx
data/processed/*.pkl
*.parquet

# Model files (large files)
models/*.pkl
models/*.joblib
*.h5
*.pt
*.pth

# IDE
.vscode/
.idea/
*.swp

# OS
.DS_Store
Thumbs.db

# Logs
*.log
logs/

# Results (optional - may want to track)
# results/

# Secrets
.env
*.key
EOF
```

### 0.6 à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ __init__.py à¸ªà¸³à¸«à¸£à¸±à¸š packages

```bash
# Create __init__.py in all packages
touch src/__init__.py
touch src/data/__init__.py
touch src/features/__init__.py
touch src/models/__init__.py
touch src/utils/__init__.py
touch tests/__init__.py
```

### 0.7 à¸”à¸¹à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¸—à¸µà¹ˆà¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œ

```bash
# View structure with files
tree -a -I '.git'
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
.
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ configs
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ processed
â”‚   â””â”€â”€ raw
â”œâ”€â”€ models
â”œâ”€â”€ notebooks
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ results
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ features
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ models
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â””â”€â”€ utils
â”‚       â””â”€â”€ __init__.py
â””â”€â”€ tests
    â””â”€â”€ __init__.py
```

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 1: à¸ªà¸£à¹‰à¸²à¸‡ Data Loading Module

### 1.1 à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ load_data.py

```bash
cat > src/data/load_data.py << 'EOF'
"""
Data Loading Module
Module for loading and managing data
"""

import pandas as pd
import numpy as np
from sklearn.datasets import load_iris, load_wine, load_breast_cancer
from sklearn.model_selection import train_test_split


def load_sklearn_dataset(name: str = 'iris') -> tuple:
    """
    Load dataset from sklearn
    
    Args:
        name: Dataset name ('iris', 'wine', 'breast_cancer')
    
    Returns:
        tuple: (X, y, feature_names, target_names)
    """
    datasets = {
        'iris': load_iris,
        'wine': load_wine,
        'breast_cancer': load_breast_cancer
    }
    
    if name not in datasets:
        raise ValueError(f"Dataset '{name}' not found. Available: {list(datasets.keys())}")
    
    data = datasets[name]()
    
    print(f"âœ“ Loaded {name} dataset")
    print(f"  Samples: {data.data.shape[0]}")
    print(f"  Features: {data.data.shape[1]}")
    print(f"  Classes: {len(data.target_names)}")
    
    return data.data, data.target, data.feature_names, data.target_names


def split_data(X, y, test_size: float = 0.2, random_state: int = 42) -> tuple:
    """
    Split data into train and test sets
    
    Args:
        X: features
        y: targets
        test_size: Proportion of test set
        random_state: Seed for reproducibility
    
    Returns:
        tuple: (X_train, X_test, y_train, y_test)
    """
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state, stratify=y
    )
    
    print(f"âœ“ Data split completed")
    print(f"  Train: {X_train.shape[0]} samples")
    print(f"  Test: {X_test.shape[0]} samples")
    
    return X_train, X_test, y_train, y_test


def create_dataframe(X, y, feature_names) -> pd.DataFrame:
    """
    Create DataFrame from numpy arrays
    """
    df = pd.DataFrame(X, columns=feature_names)
    df['target'] = y
    return df


if __name__ == "__main__":
    # Test module
    X, y, features, targets = load_sklearn_dataset('iris')
    X_train, X_test, y_train, y_test = split_data(X, y)
    df = create_dataframe(X, y, features)
    print(f"\nðŸ“Š DataFrame shape: {df.shape}")
    print(df.head())
EOF
```

### 1.2 à¸—à¸”à¸ªà¸­à¸š Data Loading Module

```bash
# Run module
python3 src/data/load_data.py
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
âœ“ Loaded iris dataset
  Samples: 150
  Features: 4
  Classes: 3
âœ“ Data split completed
  Train: 120 samples
  Test: 30 samples

ðŸ“Š DataFrame shape: (150, 5)
   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  target
0                5.1               3.5                1.4               0.2       0
1                4.9               3.0                1.4               0.2       0
2                4.7               3.2                1.3               0.2       0
3                4.6               3.1                1.5               0.2       0
4                5.0               3.6                1.4               0.2       0
```

### 1.3 Commit Initial Structure à¹à¸¥à¸° Push à¹„à¸› Remote

```bash
# Check status
git status

# Add all files
git add .

# First commit
git commit -m "Initial commit: Create ML project structure with data loading module"

# View log
git log --oneline

# Push to remote (first time - set upstream)
git push -u origin main
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
Enumerating objects: 15, done.
Counting objects: 100% (15/15), done.
Delta compression using up to 8 threads
Compressing objects: 100% (10/10), done.
Writing objects: 100% (15/15), 2.50 KiB | 2.50 MiB/s, done.
Total 15 (delta 0), reused 0 (delta 0)
To https://github.com/username/sklearn-mlops-lab.git
 * [new branch]      main -> main
Branch 'main' set up to track remote branch 'main' from 'origin'.
```

> ðŸ’¡ **à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸:** `-u origin main` à¹ƒà¸Šà¹‰à¸„à¸£à¸±à¹‰à¸‡à¹à¸£à¸à¹€à¸žà¸·à¹ˆà¸­à¸•à¸±à¹‰à¸‡ upstream à¸«à¸¥à¸±à¸‡à¸ˆà¸²à¸à¸™à¸µà¹‰à¹ƒà¸Šà¹‰à¹à¸„à¹ˆ `git push` à¹„à¸”à¹‰à¹€à¸¥à¸¢

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 2: à¸ªà¸£à¹‰à¸²à¸‡ Feature Engineering Module à¹ƒà¸™ Branch à¹ƒà¸«à¸¡à¹ˆ

### 2.1 à¸ªà¸£à¹‰à¸²à¸‡ Branch à¸ªà¸³à¸«à¸£à¸±à¸š Feature Engineering

```bash
# Create and switch to new branch
git switch -c feature/preprocessing

# Verify current branch
git branch
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
* feature/preprocessing
  main
```

### 2.2 à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ preprocessing.py

```bash
cat > src/features/preprocessing.py << 'EOF'
"""
Feature Preprocessing Module
Module for preprocessing features
"""

import numpy as np
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler
from sklearn.preprocessing import LabelEncoder, OneHotEncoder


class FeaturePreprocessor:
    """
    Class for preprocessing features
    """
    
    def __init__(self, scaling_method: str = 'standard'):
        """
        Initialize preprocessor
        
        Args:
            scaling_method: Scaling method ('standard', 'minmax', 'robust')
        """
        self.scaling_method = scaling_method
        self.scaler = self._get_scaler()
        self.is_fitted = False
    
    def _get_scaler(self):
        """Select scaler based on specified method"""
        scalers = {
            'standard': StandardScaler(),
            'minmax': MinMaxScaler(),
            'robust': RobustScaler()
        }
        
        if self.scaling_method not in scalers:
            raise ValueError(f"Unknown scaling method: {self.scaling_method}")
        
        return scalers[self.scaling_method]
    
    def fit(self, X):
        """Fit scaler with training data"""
        self.scaler.fit(X)
        self.is_fitted = True
        print(f"âœ“ Fitted {self.scaling_method} scaler")
        return self
    
    def transform(self, X):
        """Transform data with fitted scaler"""
        if not self.is_fitted:
            raise RuntimeError("Scaler has not been fitted. Call fit() first.")
        
        X_scaled = self.scaler.transform(X)
        print(f"âœ“ Transformed data with {self.scaling_method} scaler")
        return X_scaled
    
    def fit_transform(self, X):
        """Fit and transform in one step"""
        self.fit(X)
        return self.transform(X)
    
    def get_stats(self):
        """Display scaler statistics"""
        if not self.is_fitted:
            return None
        
        if hasattr(self.scaler, 'mean_'):
            print("\nðŸ“Š Scaler Statistics:")
            print(f"  Mean: {self.scaler.mean_}")
            print(f"  Scale: {self.scaler.scale_}")
        elif hasattr(self.scaler, 'data_min_'):
            print("\nðŸ“Š Scaler Statistics:")
            print(f"  Min: {self.scaler.data_min_}")
            print(f"  Max: {self.scaler.data_max_}")


def preprocess_pipeline(X_train, X_test, method: str = 'standard'):
    """
    Pipeline for preprocessing data
    
    Args:
        X_train: training features
        X_test: test features
        method: scaling method
    
    Returns:
        tuple: (X_train_scaled, X_test_scaled, preprocessor)
    """
    preprocessor = FeaturePreprocessor(scaling_method=method)
    
    # Fit only with train data!
    X_train_scaled = preprocessor.fit_transform(X_train)
    
    # Transform test data with parameters from train
    X_test_scaled = preprocessor.transform(X_test)
    
    return X_train_scaled, X_test_scaled, preprocessor


if __name__ == "__main__":
    # Test module
    import sys
    sys.path.insert(0, '.')
    from src.data.load_data import load_sklearn_dataset, split_data
    
    # Load data
    X, y, features, targets = load_sklearn_dataset('iris')
    X_train, X_test, y_train, y_test = split_data(X, y)
    
    print("\n" + "="*50)
    print("Testing StandardScaler")
    print("="*50)
    
    # Test StandardScaler
    X_train_scaled, X_test_scaled, preprocessor = preprocess_pipeline(
        X_train, X_test, method='standard'
    )
    
    preprocessor.get_stats()
    
    print(f"\nðŸ“ˆ Original X_train mean: {X_train.mean(axis=0)}")
    print(f"ðŸ“‰ Scaled X_train mean: {X_train_scaled.mean(axis=0)}")
    
    print("\n" + "="*50)
    print("Testing MinMaxScaler")
    print("="*50)
    
    # Test MinMaxScaler
    X_train_mm, X_test_mm, _ = preprocess_pipeline(
        X_train, X_test, method='minmax'
    )
    
    print(f"\nðŸ“ˆ MinMax X_train range: [{X_train_mm.min():.2f}, {X_train_mm.max():.2f}]")
EOF
```

### 2.3 à¸—à¸”à¸ªà¸­à¸š Preprocessing Module

```bash
# Run module
python3 src/features/preprocessing.py
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
âœ“ Loaded iris dataset
  Samples: 150
  Features: 4
  Classes: 3
âœ“ Data split completed
  Train: 120 samples
  Test: 30 samples

==================================================
Testing StandardScaler
==================================================
âœ“ Fitted standard scaler
âœ“ Transformed data with standard scaler
âœ“ Transformed data with standard scaler

ðŸ“Š Scaler Statistics:
  Mean: [5.84583333 3.06333333 3.7775     1.20583333]
  Scale: [0.82898063 0.44344109 1.75004544 0.76508862]

ðŸ“ˆ Original X_train mean: [5.84583333 3.06333333 3.7775     1.20583333]
ðŸ“‰ Scaled X_train mean: [-1.11022302e-15 -5.62883073e-16  3.28903977e-16  1.11022302e-16]

==================================================
Testing MinMaxScaler
==================================================
âœ“ Fitted minmax scaler
âœ“ Transformed data with minmax scaler
âœ“ Transformed data with minmax scaler

ðŸ“ˆ MinMax X_train range: [0.00, 1.00]
```

### 2.4 à¹ƒà¸Šà¹‰ tree à¸”à¸¹à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¸—à¸µà¹ˆà¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡

```bash
# View only src/features
tree src/features
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
src/features
â”œâ”€â”€ __init__.py
â””â”€â”€ preprocessing.py

0 directories, 2 files
```

### 2.5 Commit à¹à¸¥à¸° Push Branch à¹„à¸› Remote

```bash
# Check status
git status

# Commit
git add .
git commit -m "feat: Add feature preprocessing module with scalers"

# View log
git log --oneline

# Push feature branch to remote
git push -u origin feature/preprocessing
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
Enumerating objects: 8, done.
Counting objects: 100% (8/8), done.
Delta compression using up to 8 threads
Compressing objects: 100% (5/5), done.
Writing objects: 100% (6/6), 1.80 KiB | 1.80 MiB/s, done.
To https://github.com/username/sklearn-mlops-lab.git
 * [new branch]      feature/preprocessing -> feature/preprocessing
Branch 'feature/preprocessing' set up to track remote branch 'feature/preprocessing' from 'origin'.
```

### 2.6 à¸”à¸¹ refs à¸‚à¸­à¸‡ Git

```bash
# See where Git stores branches
tree .git/refs/heads
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
.git/refs/heads
â”œâ”€â”€ feature
â”‚   â””â”€â”€ preprocessing
â””â”€â”€ main

1 directory, 2 files
```

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 3: à¸ªà¸£à¹‰à¸²à¸‡ Model Training Module à¹ƒà¸™ Branch à¹ƒà¸«à¸¡à¹ˆ

### 3.1 à¸à¸¥à¸±à¸šà¹„à¸› main à¹à¸¥à¸°à¸ªà¸£à¹‰à¸²à¸‡ branch à¹ƒà¸«à¸¡à¹ˆ

```bash
# Go back to main
git switch main

# View structure - notice preprocessing.py is gone
tree src/features

# Create new branch for experiment
git switch -c experiment/logistic-regression

# Check all branches
git branch
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
* experiment/logistic-regression
  feature/preprocessing
  main
```

### 3.2 à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ train.py

```bash
cat > src/models/train.py << 'EOF'
"""
Model Training Module
Module for training ML models
"""

import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import joblib
import os
from datetime import datetime


class ModelTrainer:
    """
    Class for training and evaluating models
    """
    
    def __init__(self, model_name: str = 'logistic_regression'):
        """
        Initialize trainer
        
        Args:
            model_name: Model name
        """
        self.model_name = model_name
        self.model = self._get_model()
        self.is_trained = False
        self.training_history = {}
    
    def _get_model(self):
        """Create model instance"""
        if self.model_name == 'logistic_regression':
            return LogisticRegression(max_iter=200, random_state=42)
        else:
            raise ValueError(f"Unknown model: {self.model_name}")
    
    def train(self, X_train, y_train):
        """Train model"""
        print(f"ðŸš€ Training {self.model_name}...")
        
        start_time = datetime.now()
        self.model.fit(X_train, y_train)
        end_time = datetime.now()
        
        self.is_trained = True
        self.training_history['training_time'] = (end_time - start_time).total_seconds()
        self.training_history['n_samples'] = X_train.shape[0]
        self.training_history['n_features'] = X_train.shape[1]
        
        # Train accuracy
        train_pred = self.model.predict(X_train)
        train_acc = accuracy_score(y_train, train_pred)
        self.training_history['train_accuracy'] = train_acc
        
        print(f"âœ“ Training completed in {self.training_history['training_time']:.2f}s")
        print(f"  Train Accuracy: {train_acc:.4f}")
        
        return self
    
    def evaluate(self, X_test, y_test, target_names=None):
        """Evaluate model"""
        if not self.is_trained:
            raise RuntimeError("Model has not been trained. Call train() first.")
        
        print(f"\nðŸ“Š Evaluating {self.model_name}...")
        
        y_pred = self.model.predict(X_test)
        
        # Calculate metrics
        test_acc = accuracy_score(y_test, y_pred)
        self.training_history['test_accuracy'] = test_acc
        
        print(f"  Test Accuracy: {test_acc:.4f}")
        
        # Classification report
        print("\nðŸ“‹ Classification Report:")
        print(classification_report(y_test, y_pred, target_names=target_names))
        
        # Confusion matrix
        print("ðŸ”¢ Confusion Matrix:")
        print(confusion_matrix(y_test, y_pred))
        
        return y_pred, test_acc
    
    def save_model(self, filepath: str = None):
        """Save trained model"""
        if not self.is_trained:
            raise RuntimeError("Model has not been trained.")
        
        if filepath is None:
            os.makedirs('models', exist_ok=True)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filepath = f'models/{self.model_name}_{timestamp}.joblib'
        
        joblib.dump({
            'model': self.model,
            'model_name': self.model_name,
            'training_history': self.training_history
        }, filepath)
        
        print(f"âœ“ Model saved to: {filepath}")
        return filepath
    
    def get_summary(self):
        """Display training summary"""
        print("\n" + "="*50)
        print(f"ðŸ“ˆ Training Summary: {self.model_name}")
        print("="*50)
        for key, value in self.training_history.items():
            if isinstance(value, float):
                print(f"  {key}: {value:.4f}")
            else:
                print(f"  {key}: {value}")


if __name__ == "__main__":
    # Test module
    import sys
    sys.path.insert(0, '.')
    from src.data.load_data import load_sklearn_dataset, split_data
    
    # Load data
    X, y, features, targets = load_sklearn_dataset('iris')
    X_train, X_test, y_train, y_test = split_data(X, y)
    
    # Create and train model
    trainer = ModelTrainer('logistic_regression')
    trainer.train(X_train, y_train)
    
    # Evaluate
    y_pred, accuracy = trainer.evaluate(X_test, y_test, target_names=targets)
    
    # Show summary
    trainer.get_summary()
    
    # Save model
    model_path = trainer.save_model()
EOF
```

### 3.3 à¸—à¸”à¸ªà¸­à¸š Training Module

```bash
# Run module
python3 src/models/train.py
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
âœ“ Loaded iris dataset
  Samples: 150
  Features: 4
  Classes: 3
âœ“ Data split completed
  Train: 120 samples
  Test: 30 samples
ðŸš€ Training logistic_regression...
âœ“ Training completed in 0.02s
  Train Accuracy: 0.9750

ðŸ“Š Evaluating logistic_regression...
  Test Accuracy: 0.9667

ðŸ“‹ Classification Report:
              precision    recall  f1-score   support

      setosa       1.00      1.00      1.00        10
  versicolor       0.91      1.00      0.95        10
   virginica       1.00      0.90      0.95        10

    accuracy                           0.97        30
   macro avg       0.97      0.97      0.97        30
weighted avg       0.97      0.97      0.97        30

ðŸ”¢ Confusion Matrix:
[[10  0  0]
 [ 0 10  0]
 [ 0  1  9]]

==================================================
ðŸ“ˆ Training Summary: logistic_regression
==================================================
  training_time: 0.0234
  n_samples: 120
  n_features: 4
  train_accuracy: 0.9750
  test_accuracy: 0.9667
âœ“ Model saved to: models/logistic_regression_20241215_143022.joblib
```

### 3.4 à¹ƒà¸Šà¹‰ tree à¸”à¸¹à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡

```bash
# View entire structure
tree -I '__pycache__'
```

### 3.5 Commit à¹à¸¥à¸° Push

```bash
git add .
git commit -m "experiment: Add Logistic Regression trainer with evaluation"

# Push experiment branch to remote
git push -u origin experiment/logistic-regression

# View log for all branches
git log --oneline --graph --all
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
To https://github.com/username/sklearn-mlops-lab.git
 * [new branch]      experiment/logistic-regression -> experiment/logistic-regression
```

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 4: à¸ªà¸£à¹‰à¸²à¸‡ Experiment à¸­à¸·à¹ˆà¸™à¹† à¹ƒà¸™ Branches à¹à¸¢à¸

### 4.1 à¸ªà¸£à¹‰à¸²à¸‡ Branch à¸ªà¸³à¸«à¸£à¸±à¸š Random Forest

```bash
# Go back to main
git switch main

# Create new branch
git switch -c experiment/random-forest
```

### 4.2 à¹à¸à¹‰à¹„à¸‚ train.py à¹€à¸žà¸·à¹ˆà¸­à¹€à¸žà¸´à¹ˆà¸¡ Random Forest

```bash
cat > src/models/train.py << 'EOF'
"""
Model Training Module
Module for training ML models - Random Forest Version
"""

import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import joblib
import os
from datetime import datetime


class ModelTrainer:
    """
    Class for training and evaluating models
    """
    
    def __init__(self, model_name: str = 'random_forest', **kwargs):
        """
        Initialize trainer
        
        Args:
            model_name: Model name
            **kwargs: Hyperparameters for model
        """
        self.model_name = model_name
        self.hyperparameters = kwargs
        self.model = self._get_model()
        self.is_trained = False
        self.training_history = {}
    
    def _get_model(self):
        """Create model instance"""
        default_params = {
            'n_estimators': 100,
            'max_depth': None,
            'min_samples_split': 2,
            'random_state': 42
        }
        
        # Merge default with user params
        params = {**default_params, **self.hyperparameters}
        
        if self.model_name == 'random_forest':
            return RandomForestClassifier(**params)
        else:
            raise ValueError(f"Unknown model: {self.model_name}")
    
    def train(self, X_train, y_train):
        """Train model"""
        print(f"ðŸŒ² Training {self.model_name}...")
        print(f"   Hyperparameters: {self.hyperparameters}")
        
        start_time = datetime.now()
        self.model.fit(X_train, y_train)
        end_time = datetime.now()
        
        self.is_trained = True
        self.training_history['training_time'] = (end_time - start_time).total_seconds()
        self.training_history['n_samples'] = X_train.shape[0]
        self.training_history['n_features'] = X_train.shape[1]
        self.training_history['hyperparameters'] = self.hyperparameters
        
        # Train accuracy
        train_pred = self.model.predict(X_train)
        train_acc = accuracy_score(y_train, train_pred)
        self.training_history['train_accuracy'] = train_acc
        
        print(f"âœ“ Training completed in {self.training_history['training_time']:.2f}s")
        print(f"  Train Accuracy: {train_acc:.4f}")
        
        return self
    
    def evaluate(self, X_test, y_test, target_names=None):
        """Evaluate model"""
        if not self.is_trained:
            raise RuntimeError("Model has not been trained. Call train() first.")
        
        print(f"\nðŸ“Š Evaluating {self.model_name}...")
        
        y_pred = self.model.predict(X_test)
        
        # Calculate metrics
        test_acc = accuracy_score(y_test, y_pred)
        self.training_history['test_accuracy'] = test_acc
        
        print(f"  Test Accuracy: {test_acc:.4f}")
        
        # Classification report
        print("\nðŸ“‹ Classification Report:")
        print(classification_report(y_test, y_pred, target_names=target_names))
        
        # Feature importance
        if hasattr(self.model, 'feature_importances_'):
            print("\nðŸŽ¯ Feature Importances:")
            importances = self.model.feature_importances_
            for i, imp in enumerate(importances):
                print(f"  Feature {i}: {imp:.4f}")
        
        return y_pred, test_acc
    
    def save_model(self, filepath: str = None):
        """Save trained model"""
        if not self.is_trained:
            raise RuntimeError("Model has not been trained.")
        
        if filepath is None:
            os.makedirs('models', exist_ok=True)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filepath = f'models/{self.model_name}_{timestamp}.joblib'
        
        joblib.dump({
            'model': self.model,
            'model_name': self.model_name,
            'training_history': self.training_history
        }, filepath)
        
        print(f"âœ“ Model saved to: {filepath}")
        return filepath
    
    def get_summary(self):
        """Display training summary"""
        print("\n" + "="*50)
        print(f"ðŸŒ² Training Summary: {self.model_name}")
        print("="*50)
        for key, value in self.training_history.items():
            if isinstance(value, float):
                print(f"  {key}: {value:.4f}")
            elif isinstance(value, dict):
                print(f"  {key}:")
                for k, v in value.items():
                    print(f"    - {k}: {v}")
            else:
                print(f"  {key}: {value}")


if __name__ == "__main__":
    # Test module
    import sys
    sys.path.insert(0, '.')
    from src.data.load_data import load_sklearn_dataset, split_data
    
    # Load data
    X, y, features, targets = load_sklearn_dataset('iris')
    X_train, X_test, y_train, y_test = split_data(X, y)
    
    # Test different hyperparameters
    experiments = [
        {'n_estimators': 50, 'max_depth': 3},
        {'n_estimators': 100, 'max_depth': 5},
        {'n_estimators': 200, 'max_depth': None}
    ]
    
    results = []
    
    for exp in experiments:
        print("\n" + "="*60)
        trainer = ModelTrainer('random_forest', **exp)
        trainer.train(X_train, y_train)
        y_pred, accuracy = trainer.evaluate(X_test, y_test, target_names=targets)
        results.append({
            'params': exp,
            'test_accuracy': accuracy
        })
    
    # Summary of all experiments
    print("\n" + "="*60)
    print("ðŸ“Š EXPERIMENT SUMMARY")
    print("="*60)
    for i, result in enumerate(results):
        print(f"\nExperiment {i+1}:")
        print(f"  Params: {result['params']}")
        print(f"  Test Accuracy: {result['test_accuracy']:.4f}")
EOF
```

### 4.3 à¸—à¸”à¸ªà¸­à¸š Random Forest

```bash
python3 src/models/train.py
```

### 4.4 Commit à¹à¸¥à¸° Push

```bash
git add .
git commit -m "experiment: Test Random Forest with various hyperparameters"

# Push experiment branch to remote
git push -u origin experiment/random-forest
```

### 4.5 à¸”à¸¹ branches à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”

```bash
# View all branches
git branch -v

# Use Pipeline to count experiment branches
git branch | grep "experiment" | wc -l

# View log for all branches
git log --oneline --graph --all --decorate
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
* def5678 (HEAD -> experiment/random-forest) experiment: Test Random Forest
| * ghi9012 (experiment/logistic-regression) experiment: Add Logistic Regression
|/
| * abc1234 (feature/preprocessing) feat: Add feature preprocessing module
|/
* xyz7890 (main) Initial commit: Create ML project structure
```

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 5: à¸ªà¸£à¹‰à¸²à¸‡ Configuration Files

### 5.1 à¸ªà¸£à¹‰à¸²à¸‡ Config Branch

```bash
# Create new branch from main
git switch main
git switch -c feature/config-system
```

### 5.2 à¸ªà¸£à¹‰à¸²à¸‡ Config File à¸”à¹‰à¸§à¸¢ YAML

```bash
cat > configs/experiment_config.yaml << 'EOF'
# Experiment Configuration
# Config file for ML experiments

# Dataset settings
dataset:
  name: iris
  test_size: 0.2
  random_state: 42

# Preprocessing settings
preprocessing:
  scaling_method: standard  # standard, minmax, robust
  handle_missing: drop      # drop, impute

# Model settings
models:
  logistic_regression:
    max_iter: 200
    solver: lbfgs
    
  random_forest:
    n_estimators: 100
    max_depth: null
    min_samples_split: 2
    
  svm:
    kernel: rbf
    C: 1.0
    gamma: scale

# Training settings
training:
  cross_validation: 5
  verbose: true
  
# Output settings
output:
  save_model: true
  model_dir: models/
  results_dir: results/
  log_file: logs/training.log
EOF
```

### 5.3 à¸ªà¸£à¹‰à¸²à¸‡ Config Reader

```bash
cat > src/utils/config.py << 'EOF'
"""
Configuration Management Module
Module for managing configuration
"""

import yaml
from pathlib import Path


def load_config(config_path: str = 'configs/experiment_config.yaml') -> dict:
    """
    Load configuration from YAML file
    
    Args:
        config_path: Path to config file
    
    Returns:
        dict: Configuration dictionary
    """
    config_file = Path(config_path)
    
    if not config_file.exists():
        raise FileNotFoundError(f"Config file not found: {config_path}")
    
    with open(config_file, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    print(f"âœ“ Loaded config from: {config_path}")
    return config


def get_model_config(config: dict, model_name: str) -> dict:
    """
    Get config for specific model
    
    Args:
        config: Full configuration
        model_name: Model name
    
    Returns:
        dict: Model configuration
    """
    models = config.get('models', {})
    
    if model_name not in models:
        raise ValueError(f"Model '{model_name}' not found in config")
    
    return models[model_name]


def print_config(config: dict, indent: int = 0):
    """
    Display config nicely
    """
    for key, value in config.items():
        prefix = "  " * indent
        if isinstance(value, dict):
            print(f"{prefix}ðŸ“ {key}:")
            print_config(value, indent + 1)
        else:
            print(f"{prefix}  â€¢ {key}: {value}")


if __name__ == "__main__":
    # Test module
    config = load_config()
    
    print("\nðŸ“‹ Full Configuration:")
    print("="*50)
    print_config(config)
    
    print("\nðŸŒ² Random Forest Config:")
    print("="*50)
    rf_config = get_model_config(config, 'random_forest')
    print(rf_config)
EOF
```

### 5.4 à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ PyYAML à¹à¸¥à¸°à¸—à¸”à¸ªà¸­à¸š

```bash
# Install PyYAML (if not installed)
pip3 install pyyaml

# Test
python3 src/utils/config.py
```

### 5.5 à¹ƒà¸Šà¹‰ tree à¸”à¸¹à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡ configs

```bash
tree configs
```

### 5.6 Commit à¹à¸¥à¸° Push

```bash
git add .
git commit -m "feat: Add configuration system with YAML support"

# Push feature branch to remote
git push -u origin feature/config-system
```

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 6: à¸à¸²à¸£ Merge Branches

### 6.1 Merge Feature/Preprocessing à¹€à¸‚à¹‰à¸² Main

```bash
# Go to main
git switch main

# View status before merge
git log --oneline --graph --all

# Merge feature/preprocessing
git merge feature/preprocessing -m "Merge: Add preprocessing module to main"

# View status after merge
git log --oneline --graph --all
```

### 6.2 Merge Feature/Config-System à¹à¸¥à¸° Push

```bash
# Merge config system
git merge feature/config-system -m "Merge: Add config system to main"

# View log
git log --oneline --graph --all

# Push merged main to remote
git push origin main
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
To https://github.com/username/sklearn-mlops-lab.git
   abc1234..def5678  main -> main
```

### 6.3 à¸”à¸¹à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¸«à¸¥à¸±à¸‡ Merge

```bash
# View entire structure
tree -I '__pycache__|*.pyc|models'
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡ (à¸«à¸¥à¸±à¸‡ merge):**
```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ configs
â”‚   â””â”€â”€ experiment_config.yaml
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ processed
â”‚   â””â”€â”€ raw
â”œâ”€â”€ notebooks
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ results
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ load_data.py
â”‚   â”œâ”€â”€ features
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ models
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â””â”€â”€ utils
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ config.py
â””â”€â”€ tests
    â””â”€â”€ __init__.py
```

### 6.4 à¹ƒà¸Šà¹‰ Pipeline à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ

```bash
# Count all Python files
find . -name "*.py" | wc -l

# View only files that are not __init__.py
find . -name "*.py" | grep -v "__init__"

# Count all commits
git log --oneline | wc -l

# View merged branches
git branch --merged main
```

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 7: à¸ªà¸£à¹‰à¸²à¸‡ Complete Pipeline Script

### 7.1 à¸ªà¸£à¹‰à¸²à¸‡ Main Pipeline

```bash
cat > run_experiment.py << 'EOF'
#!/usr/bin/env python3
"""
Main Experiment Pipeline
Run complete experiment from config
"""

import sys
import argparse
from pathlib import Path

# Add project root to path
sys.path.insert(0, '.')

from src.data.load_data import load_sklearn_dataset, split_data
from src.features.preprocessing import preprocess_pipeline
from src.utils.config import load_config, get_model_config


def run_experiment(config_path: str = 'configs/experiment_config.yaml'):
    """
    Run experiment based on config
    """
    print("="*60)
    print("ðŸš€ Starting ML Experiment Pipeline")
    print("="*60)
    
    # 1. Load config
    config = load_config(config_path)
    
    # 2. Load data
    print("\nðŸ“¥ Loading Data...")
    dataset_config = config['dataset']
    X, y, features, targets = load_sklearn_dataset(dataset_config['name'])
    X_train, X_test, y_train, y_test = split_data(
        X, y, 
        test_size=dataset_config['test_size'],
        random_state=dataset_config['random_state']
    )
    
    # 3. Preprocess
    print("\nâš™ï¸ Preprocessing...")
    prep_config = config['preprocessing']
    X_train_scaled, X_test_scaled, preprocessor = preprocess_pipeline(
        X_train, X_test,
        method=prep_config['scaling_method']
    )
    
    # 4. Summary
    print("\n" + "="*60)
    print("âœ… Pipeline Summary")
    print("="*60)
    print(f"  Dataset: {dataset_config['name']}")
    print(f"  Train samples: {X_train.shape[0]}")
    print(f"  Test samples: {X_test.shape[0]}")
    print(f"  Features: {X_train.shape[1]}")
    print(f"  Scaling: {prep_config['scaling_method']}")
    print(f"  Classes: {list(targets)}")
    
    return X_train_scaled, X_test_scaled, y_train, y_test, targets


def main():
    parser = argparse.ArgumentParser(description='Run ML Experiment')
    parser.add_argument(
        '--config', '-c',
        default='configs/experiment_config.yaml',
        help='Path to config file'
    )
    
    args = parser.parse_args()
    
    try:
        run_experiment(args.config)
        print("\nðŸŽ‰ Experiment completed successfully!")
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
EOF
```

### 7.2 à¸—à¸”à¸ªà¸­à¸š Pipeline

```bash
# Run pipeline
python3 run_experiment.py

# Run with different config (if available)
# python3 run_experiment.py --config configs/another_config.yaml
```

### 7.3 Commit à¹à¸¥à¸° Push

```bash
git add .
git commit -m "feat: Add main experiment pipeline script"

# Push to remote
git push origin main
```

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 8: à¸à¸²à¸£à¸¥à¸šà¹à¸¥à¸°à¸ˆà¸±à¸”à¸à¸²à¸£ Branches

### 8.1 à¸”à¸¹ Branches à¸—à¸µà¹ˆ Merge à¹à¸¥à¹‰à¸§

```bash
# View branches merged into main
git branch --merged main

# View branches not yet merged
git branch --no-merged main
```

### 8.2 à¸¥à¸š Branch à¸—à¸µà¹ˆ Merge à¹à¸¥à¹‰à¸§ (Local à¹à¸¥à¸° Remote)

```bash
# Delete local merged feature branches
git branch -d feature/preprocessing
git branch -d feature/config-system

# Delete remote branches
git push origin --delete feature/preprocessing
git push origin --delete feature/config-system

# Verify local branches
git branch

# Verify remote branches
git branch -r
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
Deleted branch feature/preprocessing (was abc1234).
Deleted branch feature/config-system (was def5678).
To https://github.com/username/sklearn-mlops-lab.git
 - [deleted]         feature/preprocessing
 - [deleted]         feature/config-system
```

### 8.3 à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸Šà¸·à¹ˆà¸­ Branch

```bash
# Rename experiment branches
git branch -m experiment/logistic-regression experiment/lr-baseline
git branch -m experiment/random-forest experiment/rf-baseline

# View result
git branch -v
```

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 9: à¸ªà¸£à¹‰à¸²à¸‡ Results Tracking

### 9.1 à¸ªà¸£à¹‰à¸²à¸‡ Results Logger

```bash
cat > src/utils/logger.py << 'EOF'
"""
Results Logging Module
Module for logging experiment results
"""

import json
import csv
from datetime import datetime
from pathlib import Path


class ExperimentLogger:
    """
    Class for logging experiment results
    """
    
    def __init__(self, results_dir: str = 'results'):
        """
        Initialize logger
        
        Args:
            results_dir: Folder for storing results
        """
        self.results_dir = Path(results_dir)
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        # CSV file for storing results
        self.csv_file = self.results_dir / 'experiments.csv'
        self._init_csv()
    
    def _init_csv(self):
        """Create CSV header if not exists"""
        if not self.csv_file.exists():
            with open(self.csv_file, 'w', newline='') as f:
                writer = csv.writer(f)
                writer.writerow([
                    'timestamp',
                    'experiment_name',
                    'model_name',
                    'dataset',
                    'train_accuracy',
                    'test_accuracy',
                    'hyperparameters',
                    'notes'
                ])
            print(f"âœ“ Created results CSV: {self.csv_file}")
    
    def log_experiment(
        self,
        experiment_name: str,
        model_name: str,
        dataset: str,
        train_accuracy: float,
        test_accuracy: float,
        hyperparameters: dict = None,
        notes: str = ''
    ):
        """
        Log experiment results
        """
        timestamp = datetime.now().isoformat()
        
        with open(self.csv_file, 'a', newline='') as f:
            writer = csv.writer(f)
            writer.writerow([
                timestamp,
                experiment_name,
                model_name,
                dataset,
                f'{train_accuracy:.4f}',
                f'{test_accuracy:.4f}',
                json.dumps(hyperparameters) if hyperparameters else '',
                notes
            ])
        
        print(f"âœ“ Logged experiment: {experiment_name}")
    
    def get_all_results(self):
        """Read all results"""
        results = []
        
        if self.csv_file.exists():
            with open(self.csv_file, 'r') as f:
                reader = csv.DictReader(f)
                results = list(reader)
        
        return results
    
    def get_best_experiment(self, metric: str = 'test_accuracy'):
        """Find best experiment"""
        results = self.get_all_results()
        
        if not results:
            return None
        
        best = max(results, key=lambda x: float(x[metric]))
        return best
    
    def print_summary(self):
        """Display results summary"""
        results = self.get_all_results()
        
        if not results:
            print("ðŸ“­ No experiments logged yet")
            return
        
        print("\n" + "="*70)
        print("ðŸ“Š Experiment Results Summary")
        print("="*70)
        print(f"{'Experiment':<20} {'Model':<15} {'Train Acc':<12} {'Test Acc':<12}")
        print("-"*70)
        
        for r in results:
            print(f"{r['experiment_name']:<20} {r['model_name']:<15} "
                  f"{r['train_accuracy']:<12} {r['test_accuracy']:<12}")
        
        # Best experiment
        best = self.get_best_experiment()
        if best:
            print("\nðŸ† Best Experiment:")
            print(f"   {best['experiment_name']} - Test Accuracy: {best['test_accuracy']}")


if __name__ == "__main__":
    # Test logger
    logger = ExperimentLogger()
    
    # Log sample experiments
    logger.log_experiment(
        experiment_name='baseline-lr',
        model_name='logistic_regression',
        dataset='iris',
        train_accuracy=0.975,
        test_accuracy=0.967,
        hyperparameters={'max_iter': 200},
        notes='Baseline experiment'
    )
    
    logger.log_experiment(
        experiment_name='rf-100trees',
        model_name='random_forest',
        dataset='iris',
        train_accuracy=1.0,
        test_accuracy=0.933,
        hyperparameters={'n_estimators': 100, 'max_depth': 5},
        notes='Random Forest with 100 trees'
    )
    
    logger.log_experiment(
        experiment_name='rf-200trees',
        model_name='random_forest',
        dataset='iris',
        train_accuracy=1.0,
        test_accuracy=0.967,
        hyperparameters={'n_estimators': 200, 'max_depth': None},
        notes='Random Forest with 200 trees'
    )
    
    # Show summary
    logger.print_summary()
EOF
```

### 9.2 à¸—à¸”à¸ªà¸­à¸š Logger

```bash
python3 src/utils/logger.py
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
âœ“ Created results CSV: results/experiments.csv
âœ“ Logged experiment: baseline-lr
âœ“ Logged experiment: rf-100trees
âœ“ Logged experiment: rf-200trees

======================================================================
ðŸ“Š Experiment Results Summary
======================================================================
Experiment           Model           Train Acc    Test Acc    
----------------------------------------------------------------------
baseline-lr          logistic_regression 0.9750       0.9670      
rf-100trees          random_forest   1.0000       0.9330      
rf-200trees          random_forest   1.0000       0.9670      

ðŸ† Best Experiment:
   baseline-lr - Test Accuracy: 0.9670
```

### 9.3 à¸”à¸¹à¹„à¸Ÿà¸¥à¹Œà¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ

```bash
# View created CSV
cat results/experiments.csv

# Use Pipeline to analyze
cat results/experiments.csv | head -5

# Count experiments
cat results/experiments.csv | wc -l
```

### 9.4 Commit à¹à¸¥à¸° Push

```bash
git add .
git commit -m "feat: Add experiment results logger"

# Push to remote
git push origin main
```

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 10: à¸ªà¸£à¸¸à¸›à¹à¸¥à¸° Final Structure

### 10.1 à¸”à¸¹à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢

```bash
tree -I '__pycache__|*.pyc|.git'
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢:**
```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ configs
â”‚   â””â”€â”€ experiment_config.yaml
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ processed
â”‚   â””â”€â”€ raw
â”œâ”€â”€ models
â”‚   â””â”€â”€ logistic_regression_XXXXXXXX.joblib
â”œâ”€â”€ notebooks
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ results
â”‚   â””â”€â”€ experiments.csv
â”œâ”€â”€ run_experiment.py
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ load_data.py
â”‚   â”œâ”€â”€ features
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ models
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ train.py
â”‚   â””â”€â”€ utils
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py
â”‚       â””â”€â”€ logger.py
â””â”€â”€ tests
    â””â”€â”€ __init__.py
```

### 10.2 à¸”à¸¹ Git Log à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”

```bash
# View log as graph
git log --oneline --graph --all --decorate

# Use Pipeline to count "feat" commits
git log --oneline | grep "feat" | wc -l

# View commits containing "experiment"
git log --oneline | grep -i "experiment"
```

### 10.3 à¸ªà¸£à¸¸à¸› Branches (Local à¹à¸¥à¸° Remote)

```bash
# View all local branches
git branch -v

# View all remote branches
git branch -r

# View all branches (local + remote)
git branch -a -v

# Use Pipeline to count branches
echo "Total local branches: $(git branch | wc -l)"
echo "Total remote branches: $(git branch -r | wc -l)"
echo "Experiment branches: $(git branch | grep experiment | wc -l)"
echo "Feature branches: $(git branch | grep feature | wc -l)"
```

### 10.4 Push All Branches à¹„à¸› Remote (Optional)

```bash
# Push all branches to remote at once
git push --all origin

# Push all tags to remote
git push --tags origin

# View what's on remote
git remote show origin
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
* remote origin
  Fetch URL: https://github.com/username/sklearn-mlops-lab.git
  Push  URL: https://github.com/username/sklearn-mlops-lab.git
  HEAD branch: main
  Remote branches:
    experiment/lr-baseline  tracked
    experiment/rf-baseline  tracked
    main                    tracked
  Local branches configured for 'git pull':
    main merges with remote main
  Local refs configured for 'git push':
    main pushes to main (up to date)
```

---

## ðŸ“‹ à¸ªà¸£à¸¸à¸›à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸ªà¸³à¸„à¸±à¸

### à¸„à¸³à¸ªà¸±à¹ˆà¸‡ Linux Pipeline

| à¸„à¸³à¸ªà¸±à¹ˆà¸‡ | à¸„à¸³à¸­à¸˜à¸´à¸šà¸²à¸¢ |
|--------|----------|
| `cat > file << 'EOF'` | à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œà¸«à¸¥à¸²à¸¢à¸šà¸£à¸£à¸—à¸±à¸” (heredoc) |
| `tree` | à¸”à¸¹à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œà¹à¸¥à¸°à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ |
| `cmd1 \| cmd2` | Pipeline: à¸ªà¹ˆà¸‡ output à¹„à¸›à¹€à¸›à¹‡à¸™ input |
| `grep "text"` | à¸à¸£à¸­à¸‡à¸šà¸£à¸£à¸—à¸±à¸”à¸—à¸µà¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡ |
| `wc -l` | à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¸šà¸£à¸£à¸—à¸±à¸” |
| `find . -name "*.py"` | à¸„à¹‰à¸™à¸«à¸²à¹„à¸Ÿà¸¥à¹Œ Python |

### à¸„à¸³à¸ªà¸±à¹ˆà¸‡ Git Branch

| à¸„à¸³à¸ªà¸±à¹ˆà¸‡ | à¸„à¸³à¸­à¸˜à¸´à¸šà¸²à¸¢ |
|--------|----------|
| `git branch` | à¸”à¸¹à¸£à¸²à¸¢à¸à¸²à¸£ branches |
| `git switch -c <branch>` | à¸ªà¸£à¹‰à¸²à¸‡à¹à¸¥à¸°à¸ªà¸¥à¸±à¸š branch |
| `git switch <branch>` | à¸ªà¸¥à¸±à¸š branch |
| `git merge <branch>` | à¸£à¸§à¸¡ branch |
| `git branch -d <branch>` | à¸¥à¸š branch |
| `git branch -m <old> <new>` | à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸Šà¸·à¹ˆà¸­ branch |
| `git branch --merged` | à¸”à¸¹ branches à¸—à¸µà¹ˆ merge à¹à¸¥à¹‰à¸§ |

### à¸„à¸³à¸ªà¸±à¹ˆà¸‡ Git Remote

| à¸„à¸³à¸ªà¸±à¹ˆà¸‡ | à¸„à¸³à¸­à¸˜à¸´à¸šà¸²à¸¢ |
|--------|----------|
| `git remote add origin <url>` | à¹€à¸žà¸´à¹ˆà¸¡ remote repository |
| `git remote -v` | à¸”à¸¹à¸£à¸²à¸¢à¸à¸²à¸£ remote |
| `git push -u origin <branch>` | Push branch à¸„à¸£à¸±à¹‰à¸‡à¹à¸£à¸ (à¸•à¸±à¹‰à¸‡ upstream) |
| `git push` | Push changes à¹„à¸› remote |
| `git push --all origin` | Push à¸—à¸¸à¸ branches |
| `git push origin --delete <branch>` | à¸¥à¸š remote branch |
| `git branch -r` | à¸”à¸¹ remote branches |
| `git fetch origin` | à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸ remote |
| `git pull origin <branch>` | à¸”à¸¶à¸‡à¹à¸¥à¸° merge à¸ˆà¸²à¸ remote |
| `git remote show origin` | à¸”à¸¹à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸” remote |

### Git Pipeline Commands

| à¸„à¸³à¸ªà¸±à¹ˆà¸‡ | à¸„à¸³à¸­à¸˜à¸´à¸šà¸²à¸¢ |
|--------|----------|
| `git branch \| grep "feature"` | à¸«à¸² feature branches |
| `git log --oneline \| wc -l` | à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™ commits |
| `git log --oneline \| grep "fix"` | à¸«à¸² fix commits |

---

## ðŸ§ª à¹à¸šà¸šà¸—à¸”à¸ªà¸­à¸šà¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆ

1. **à¸—à¸³à¹„à¸¡à¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰ Git Branch à¸à¸±à¸š ML Projects?**

2. **à¸„à¸§à¸²à¸¡à¹à¸•à¸à¸•à¹ˆà¸²à¸‡à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ `fit()` à¹à¸¥à¸° `transform()` à¹ƒà¸™ sklearn à¸„à¸·à¸­à¸­à¸°à¹„à¸£?**

3. **à¸—à¸³à¹„à¸¡à¸•à¹‰à¸­à¸‡ fit preprocessor à¸à¸±à¸š training data à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™?**

4. **à¸„à¸³à¸ªà¸±à¹ˆà¸‡ `git branch | grep "experiment" | wc -l` à¸—à¸³à¸­à¸°à¹„à¸£?**

5. **à¸‚à¹‰à¸­à¸”à¸µà¸‚à¸­à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰ YAML config files à¸„à¸·à¸­à¸­à¸°à¹„à¸£?**

6. **à¸„à¸§à¸²à¸¡à¹à¸•à¸à¸•à¹ˆà¸²à¸‡à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ `git push` à¹à¸¥à¸° `git push -u origin <branch>` à¸„à¸·à¸­à¸­à¸°à¹„à¸£?**

7. **à¸—à¸³à¹„à¸¡à¸•à¹‰à¸­à¸‡ Push branches à¹„à¸› Remote Repository?**

<details>
<summary>ðŸ’¡ à¸„à¸¥à¸´à¸à¹€à¸žà¸·à¹ˆà¸­à¸”à¸¹à¹€à¸‰à¸¥à¸¢</summary>

1. à¹€à¸žà¸·à¹ˆà¸­à¸—à¸”à¸¥à¸­à¸‡ models/features à¸•à¹ˆà¸²à¸‡à¹† à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸à¸£à¸°à¸—à¸š code à¸«à¸¥à¸±à¸ à¹à¸¥à¸°à¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸à¹‡à¸š experiments à¹à¸•à¹ˆà¸¥à¸°à¸­à¸±à¸™à¹à¸¢à¸à¸à¸±à¸™à¹„à¸”à¹‰

2. `fit()` à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰ parameters à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ (à¹€à¸Šà¹ˆà¸™ mean, std), `transform()` à¹ƒà¸Šà¹‰ parameters à¸—à¸µà¹ˆà¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¹à¸¥à¹‰à¸§à¹€à¸žà¸·à¹ˆà¸­à¹à¸›à¸¥à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥

3. à¹€à¸žà¸·à¹ˆà¸­à¸›à¹‰à¸­à¸‡à¸à¸±à¸™ data leakage - à¸–à¹‰à¸² fit à¸à¸±à¸š test data à¸”à¹‰à¸§à¸¢ à¸ˆà¸°à¸—à¸³à¹ƒà¸«à¹‰ model "à¹€à¸«à¹‡à¸™" à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸„à¸§à¸£à¸ˆà¸°à¹€à¸›à¹‡à¸™ unseen data

4. à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™ branches à¸—à¸µà¹ˆà¸¡à¸µà¸„à¸³à¸§à¹ˆà¸² "experiment" à¹ƒà¸™à¸Šà¸·à¹ˆà¸­

5. à¸­à¹ˆà¸²à¸™à¸‡à¹ˆà¸²à¸¢, à¹à¸à¹‰à¹„à¸‚à¸‡à¹ˆà¸²à¸¢, à¸£à¸­à¸‡à¸£à¸±à¸š hierarchical data, à¸ªà¸²à¸¡à¸²à¸£à¸– version control à¹„à¸”à¹‰, à¹à¸¢à¸ config à¸­à¸­à¸à¸ˆà¸²à¸ code

6. `git push -u origin <branch>` à¹ƒà¸Šà¹‰à¸„à¸£à¸±à¹‰à¸‡à¹à¸£à¸à¹€à¸žà¸·à¹ˆà¸­à¸•à¸±à¹‰à¸‡ upstream tracking à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ local branch à¸à¸±à¸š remote branch à¸«à¸¥à¸±à¸‡à¸ˆà¸²à¸à¸™à¸±à¹‰à¸™à¹ƒà¸Šà¹‰à¹à¸„à¹ˆ `git push` à¸à¹‡à¸žà¸­ à¹€à¸žà¸£à¸²à¸° Git à¸ˆà¸³à¹„à¸”à¹‰à¸§à¹ˆà¸²à¸•à¹‰à¸­à¸‡ push à¹„à¸›à¸—à¸µà¹ˆà¹„à¸«à¸™

7. à¹€à¸žà¸·à¹ˆà¸­ backup code à¸šà¸™ server, à¸—à¸³à¸‡à¸²à¸™à¸£à¹ˆà¸§à¸¡à¸à¸±à¸šà¸—à¸µà¸¡, à¹€à¸‚à¹‰à¸²à¸–à¸¶à¸‡ code à¸ˆà¸²à¸à¸—à¸µà¹ˆà¸­à¸·à¹ˆà¸™à¹„à¸”à¹‰, à¹à¸¥à¸°à¹€à¸›à¹‡à¸™ single source of truth à¸ªà¸³à¸«à¸£à¸±à¸šà¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œ

</details>

---

## âœ… Checklist à¸à¹ˆà¸­à¸™à¸ˆà¸š LAB

- [ ] à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸à¸²à¸£à¹ƒà¸Šà¹‰ Pipeline (`|`) à¸à¸±à¸š ML workflows
- [ ] à¹ƒà¸Šà¹‰ Here Document à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ Python à¹à¸¥à¸° YAML à¹„à¸”à¹‰
- [ ] à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡ ML project à¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸›à¹‡à¸™à¸£à¸°à¸šà¸š
- [ ] à¹ƒà¸Šà¹‰ Git Branch à¸ªà¸³à¸«à¸£à¸±à¸š experiments à¸•à¹ˆà¸²à¸‡à¹† à¹„à¸”à¹‰
- [ ] à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆ sklearn preprocessing pipeline
- [ ] Merge branches à¹à¸¥à¸°à¸ˆà¸±à¸”à¸à¸²à¸£ branch à¹„à¸”à¹‰
- [ ] à¸ªà¸£à¹‰à¸²à¸‡à¸£à¸°à¸šà¸š config à¹à¸¥à¸° logging à¸ªà¸³à¸«à¸£à¸±à¸š experiments
- [ ] à¹ƒà¸Šà¹‰ `tree` à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¹„à¸”à¹‰
- [ ] à¹ƒà¸Šà¹‰ Pipeline à¸à¸±à¸š git commands à¹„à¸”à¹‰
- [ ] à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¹à¸¥à¸° Push à¹„à¸› Remote Repository à¹„à¸”à¹‰
- [ ] à¸ˆà¸±à¸”à¸à¸²à¸£ Remote Branches (à¸ªà¸£à¹‰à¸²à¸‡, à¸¥à¸š, à¸”à¸¹) à¹„à¸”à¹‰

---



## ðŸ“š à¹à¸«à¸¥à¹ˆà¸‡à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¹€à¸žà¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡

- [Scikit-Learn Documentation](https://scikit-learn.org/stable/)
- [Git Branching Strategies](https://www.atlassian.com/git/tutorials/comparing-workflows)
- [MLOps Principles](https://ml-ops.org/)
- [Python Project Structure](https://docs.python-guide.org/writing/structure/)

---

**Happy Learning! ðŸŽ“**