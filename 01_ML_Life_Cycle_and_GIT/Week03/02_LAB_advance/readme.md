# ðŸ§ª LAB: MLOps with Scikit-Learn à¹à¸¥à¸° Git Branch Workflow

## ðŸ“‹ à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œà¸à¸²à¸£à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰

à¸«à¸¥à¸±à¸‡à¸ˆà¸²à¸à¸—à¸³ LAB à¸™à¸µà¹‰à¹€à¸ªà¸£à¹‡à¸ˆ à¸™à¸±à¸à¸¨à¸¶à¸à¸©à¸²à¸ˆà¸°à¸ªà¸²à¸¡à¸²à¸£à¸–:
- âœ… à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œ Machine Learning à¸”à¹‰à¸§à¸¢ Scikit-Learn
- âœ… à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Git Branch à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸—à¸”à¸¥à¸­à¸‡ ML Models à¸•à¹ˆà¸²à¸‡à¹†
- âœ… à¸ˆà¸±à¸”à¸à¸²à¸£ Feature Engineering à¹ƒà¸™ Branch à¹à¸¢à¸
- âœ… à¹ƒà¸Šà¹‰ Pipeline à¹ƒà¸™ Linux à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ
- âœ… à¹ƒà¸Šà¹‰ `tree` à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œ ML
- âœ… à¹ƒà¸Šà¹‰ Here Document à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ Python à¹à¸¥à¸° Config
- âœ… à¸•à¸´à¸”à¸•à¸²à¸¡ Model Experiments à¸”à¹‰à¸§à¸¢ Git
- âœ… à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆ MLOps Workflow à¸žà¸·à¹‰à¸™à¸à¸²à¸™

---

## ðŸ“š à¸„à¸§à¸²à¸¡à¸£à¸¹à¹‰à¸žà¸·à¹‰à¸™à¸à¸²à¸™

### MLOps à¸„à¸·à¸­à¸­à¸°à¹„à¸£?

**MLOps** (Machine Learning Operations) à¸„à¸·à¸­à¹à¸™à¸§à¸›à¸à¸´à¸šà¸±à¸•à¸´à¸—à¸µà¹ˆà¸£à¸§à¸¡ ML, DevOps à¹à¸¥à¸° Data Engineering à¹€à¸‚à¹‰à¸²à¸”à¹‰à¸§à¸¢à¸à¸±à¸™ à¹€à¸žà¸·à¹ˆà¸­:
- à¸ˆà¸±à¸”à¸à¸²à¸£ ML Models à¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸›à¹‡à¸™à¸£à¸°à¸šà¸š
- à¸—à¸³à¹ƒà¸«à¹‰à¸à¸²à¸£ Deploy à¹à¸¥à¸° Monitor à¹€à¸›à¹‡à¸™à¹„à¸›à¸­à¸¢à¹ˆà¸²à¸‡à¸£à¸²à¸šà¸£à¸·à¹ˆà¸™
- à¸•à¸´à¸”à¸•à¸²à¸¡ Experiments à¹à¸¥à¸° Versions

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      MLOps Lifecycle                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚   Data â†’ Feature Engineering â†’ Model Training â†’ Evaluation  â”‚
â”‚     â†‘                                                   â†“    â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Monitoring â†â”€â”€ Deployment â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                              â”‚
â”‚   ðŸ”§ Git: Version Control for all steps                     â”‚
â”‚   â˜ï¸  Remote: Backup & Collaboration (GitHub/GitLab)        â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### à¸—à¸³à¹„à¸¡à¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰ Git Branch à¸à¸±à¸š ML Projects?

| à¸ªà¸–à¸²à¸™à¸à¸²à¸£à¸“à¹Œ | Branch à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰ | à¸›à¸£à¸°à¹‚à¸¢à¸Šà¸™à¹Œ |
|-----------|--------------|---------|
| à¸—à¸”à¸¥à¸­à¸‡ Model à¹ƒà¸«à¸¡à¹ˆ | `experiment/random-forest` | à¹„à¸¡à¹ˆà¸à¸£à¸°à¸—à¸š code à¸«à¸¥à¸±à¸ |
| Feature Engineering | `feature/scaling-normalization` | à¸žà¸±à¸’à¸™à¸²à¹à¸¢à¸ merge à¸—à¸µà¸«à¸¥à¸±à¸‡ |
| Hyperparameter Tuning | `tune/grid-search-rf` | à¹€à¸à¹‡à¸š config à¹à¸•à¹ˆà¸¥à¸°à¸„à¸£à¸±à¹‰à¸‡ |
| Bug Fix | `fix/data-leakage` | à¹à¸à¹‰à¹„à¸‚à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸à¸£à¸°à¸—à¸šà¸à¸²à¸£à¸—à¸”à¸¥à¸­à¸‡ |

---

## ðŸ”§ à¸„à¸§à¸²à¸¡à¸£à¸¹à¹‰à¹€à¸šà¸·à¹‰à¸­à¸‡à¸•à¹‰à¸™: Pipeline à¹ƒà¸™ Linux à¸ªà¸³à¸«à¸£à¸±à¸š ML

### Pipeline (`|`) à¸„à¸·à¸­à¸­à¸°à¹„à¸£?

**Pipeline** à¸„à¸·à¸­à¸à¸²à¸£à¸ªà¹ˆà¸‡à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸ˆà¸²à¸à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸«à¸™à¸¶à¹ˆà¸‡à¹„à¸›à¹€à¸›à¹‡à¸™ input à¸‚à¸­à¸‡à¸­à¸µà¸à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸«à¸™à¸¶à¹ˆà¸‡ à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸«à¸¡à¸²à¸¢ `|` (pipe)

```
Command 1  |  Command 2  |  Command 3
    â†“              â†“              â†“
  output    â†’    input     â†’   output
            â†’              â†’    input
                           â†’   output (final)
```

### à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡ Pipeline à¸ªà¸³à¸«à¸£à¸±à¸š ML Projects

#### à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸—à¸µà¹ˆ 1: à¸™à¸±à¸šà¹„à¸Ÿà¸¥à¹Œ Python

```bash
ls *.py | wc -l
```

**à¸­à¸˜à¸´à¸šà¸²à¸¢à¸—à¸µà¸¥à¸°à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™:**
```
ls *.py         â†’  List all .py files
                   train.py
                   model.py
                   evaluate.py
        |
        â†“
wc -l           â†’  Count lines
                   Result: 3
```

#### à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸—à¸µà¹ˆ 2: à¸«à¸² experiment branches

```bash
git branch | grep "experiment"
```

**à¸­à¸˜à¸´à¸šà¸²à¸¢à¸—à¸µà¸¥à¸°à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™:**
```
git branch      â†’  List all branches
                   * main
                     experiment/random-forest
                     experiment/svm
                     feature/scaling
        |
        â†“
grep "experiment" â†’  Filter lines containing "experiment"
                      Result:
                        experiment/random-forest
                        experiment/svm
```

#### à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸—à¸µà¹ˆ 3: à¸”à¸¹ commits à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸š model

```bash
git log --oneline | grep -i "model" | head -5
```

#### à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸—à¸µà¹ˆ 4: à¸™à¸±à¸š experiment branches

```bash
git branch | grep "experiment" | wc -l
```

### à¸ªà¸£à¸¸à¸›à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸šà¹ˆà¸­à¸¢à¸à¸±à¸š Pipeline

| à¸„à¸³à¸ªà¸±à¹ˆà¸‡ | à¸«à¸™à¹‰à¸²à¸—à¸µà¹ˆ | à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡ |
|--------|--------|----------|
| `grep "text"` | à¸à¸£à¸­à¸‡à¸šà¸£à¸£à¸—à¸±à¸”à¸—à¸µà¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡ | `cat log.txt \| grep "accuracy"` |
| `wc -l` | à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¸šà¸£à¸£à¸—à¸±à¸” | `ls *.py \| wc -l` |
| `head -n` | à¹€à¸­à¸² n à¸šà¸£à¸£à¸—à¸±à¸”à¹à¸£à¸ | `cat results.csv \| head -10` |
| `tail -n` | à¹€à¸­à¸² n à¸šà¸£à¸£à¸—à¸±à¸”à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢ | `cat training.log \| tail -20` |
| `sort` | à¹€à¸£à¸µà¸¢à¸‡à¸¥à¸³à¸”à¸±à¸š | `cat scores.txt \| sort -n` |
| `cut -d, -f1` | à¸•à¸±à¸”à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸ˆà¸²à¸ CSV | `cat data.csv \| cut -d, -f1` |

---

## ðŸ”§ à¸„à¸§à¸²à¸¡à¸£à¸¹à¹‰à¹€à¸šà¸·à¹‰à¸­à¸‡à¸•à¹‰à¸™: Here Document (Heredoc)

### Here Document à¸„à¸·à¸­à¸­à¸°à¹„à¸£?

**Here Document** à¸„à¸·à¸­à¸§à¸´à¸˜à¸µà¸à¸²à¸£à¹€à¸‚à¸µà¸¢à¸™à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸«à¸¥à¸²à¸¢à¸šà¸£à¸£à¸—à¸±à¸”à¸¥à¸‡à¹„à¸Ÿà¸¥à¹Œà¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸à¸” Ctrl+D

```bash
cat > filename << 'EOF'
Content line 1
Content line 2
Content line 3
EOF
```

**à¸­à¸˜à¸´à¸šà¸²à¸¢:**
- `cat > filename` = à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œà¹ƒà¸«à¸¡à¹ˆ
- `<< 'EOF'` = à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™ Here Document (EOF = End Of File, à¹ƒà¸Šà¹‰à¸„à¸³à¸­à¸·à¹ˆà¸™à¸à¹‡à¹„à¸”à¹‰)
- `EOF` = à¸ªà¸´à¹‰à¸™à¸ªà¸¸à¸” Here Document

### à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸§à¸´à¸˜à¸µà¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ

| à¸§à¸´à¸˜à¸µ | à¸‚à¹‰à¸­à¸”à¸µ | à¸‚à¹‰à¸­à¹€à¸ªà¸µà¸¢ |
|------|-------|---------|
| `echo "text" > file` | à¸‡à¹ˆà¸²à¸¢ à¸£à¸§à¸”à¹€à¸£à¹‡à¸§ | à¹€à¸‚à¸µà¸¢à¸™à¹„à¸”à¹‰à¹à¸„à¹ˆà¸šà¸£à¸£à¸—à¸±à¸”à¹€à¸”à¸µà¸¢à¸§ |
| `cat > file` à¹à¸¥à¹‰à¸§ Ctrl+D | à¹€à¸‚à¸µà¸¢à¸™à¹„à¸”à¹‰à¸«à¸¥à¸²à¸¢à¸šà¸£à¸£à¸—à¸±à¸” | à¸•à¹‰à¸­à¸‡à¸ˆà¸³à¸à¸” Ctrl+D |
| `cat > file << 'EOF'` | à¹€à¸‚à¸µà¸¢à¸™à¹„à¸”à¹‰à¸«à¸¥à¸²à¸¢à¸šà¸£à¸£à¸—à¸±à¸”, à¸Šà¸±à¸”à¹€à¸ˆà¸™ | à¸žà¸´à¸¡à¸žà¹Œà¸¢à¸²à¸§à¸à¸§à¹ˆà¸² |

---

## ðŸ› ï¸ à¹€à¸•à¸£à¸µà¸¢à¸¡à¸„à¸§à¸²à¸¡à¸žà¸£à¹‰à¸­à¸¡

### à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 1: à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² Git (à¸–à¹‰à¸²à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹€à¸„à¸¢à¸•à¸±à¹‰à¸‡)

**1.1 à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² username:**

```bash
git config --global user.name "Your Name"
```

**1.2 à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² email:**

```bash
git config --global user.email "your.email@example.com"
```

**1.3 à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸à¸²à¸£à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²:**

```bash
git config --list
```

> â¸ï¸ **à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š:** à¸„à¸§à¸£à¹€à¸«à¹‡à¸™à¸Šà¸·à¹ˆà¸­à¹à¸¥à¸° email à¸—à¸µà¹ˆà¸•à¸±à¹‰à¸‡à¹„à¸§à¹‰à¹ƒà¸™à¸£à¸²à¸¢à¸à¸²à¸£

---

### à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 2: à¸ªà¸£à¹‰à¸²à¸‡ Remote Repository

à¸à¹ˆà¸­à¸™à¹€à¸£à¸´à¹ˆà¸¡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œ à¹ƒà¸«à¹‰à¸ªà¸£à¹‰à¸²à¸‡ repository à¸šà¸™ GitHub/GitLab à¸à¹ˆà¸­à¸™:

1. à¹„à¸›à¸—à¸µà¹ˆ [GitHub](https://github.com) à¸«à¸£à¸·à¸­ [GitLab](https://gitlab.com)
2. à¸„à¸¥à¸´à¸ **New Repository** à¸«à¸£à¸·à¸­ **New Project**
3. à¸•à¸±à¹‰à¸‡à¸Šà¸·à¹ˆà¸­ repository: `sklearn-mlops-lab`
4. **à¸­à¸¢à¹ˆà¸²à¹€à¸¥à¸·à¸­à¸** Initialize with README (à¹€à¸£à¸²à¸ˆà¸°à¸ªà¸£à¹‰à¸²à¸‡à¹€à¸­à¸‡)
5. à¸„à¸¥à¸´à¸ **Create Repository**

à¸ˆà¸”à¸ˆà¸³ URL à¸‚à¸­à¸‡ repository à¹„à¸§à¹‰ à¹€à¸Šà¹ˆà¸™:
- GitHub: `https://github.com/username/sklearn-mlops-lab.git`
- GitLab: `https://gitlab.com/username/sklearn-mlops-lab.git`

---

### à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 3: à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œ ML à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸¶à¸

**3.1 à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œà¹ƒà¸«à¸¡à¹ˆ:**

```bash
mkdir sklearn-mlops-lab
```

**3.2 à¹€à¸‚à¹‰à¸²à¹„à¸›à¹ƒà¸™à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ:**

```bash
cd sklearn-mlops-lab
```

**3.3 Initialize Git repository:**

```bash
git init
```

> â¸ï¸ **à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š:** à¸„à¸§à¸£à¹€à¸«à¹‡à¸™à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡ `Initialized empty Git repository in /path/to/sklearn-mlops-lab/.git/`

**3.4 à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š status:**

```bash
git status
```

---

### à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 4: à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­ Remote Repository

**4.1 à¹€à¸žà¸´à¹ˆà¸¡ remote origin:**

> ðŸ“ **à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸:** à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ URL à¹€à¸›à¹‡à¸™à¸‚à¸­à¸‡à¸„à¸¸à¸“à¹€à¸­à¸‡

```bash
git remote add origin https://github.com/username/sklearn-mlops-lab.git
```

**4.2 à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š remote:**

```bash
git remote -v
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
origin  https://github.com/username/sklearn-mlops-lab.git (fetch)
origin  https://github.com/username/sklearn-mlops-lab.git (push)
```

> ðŸ’¡ **à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸:** à¸–à¹‰à¸²à¹ƒà¸Šà¹‰ SSH key à¹ƒà¸«à¹‰à¹ƒà¸Šà¹‰ URL à¹à¸šà¸š SSH à¹à¸—à¸™:
> `git remote add origin git@github.com:username/sklearn-mlops-lab.git`

---

### à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 5: à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Python à¹à¸¥à¸° Scikit-Learn

**5.1 à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Python version:**

```bash
python3 --version
```

**5.2 à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š pip:**

```bash
pip3 --version
```

**5.3 à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ packages à¸—à¸µà¹ˆà¸ˆà¸³à¹€à¸›à¹‡à¸™:**

```bash
pip3 install scikit-learn pandas numpy joblib
```

**5.4 à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸à¸²à¸£à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡:**

```bash
python3 -c "import sklearn; print(f'sklearn version: {sklearn.__version__}')"
```

> â¸ï¸ **à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š:** à¸„à¸§à¸£à¹€à¸«à¹‡à¸™ version à¸‚à¸­à¸‡ sklearn à¹€à¸Šà¹ˆà¸™ `sklearn version: 1.3.0`

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 0: à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œ ML à¸”à¹‰à¸§à¸¢ Here Document

### 0.1 à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ README.md

```bash
cat > README.md << 'EOF'
# Sklearn MLOps Lab
A project for learning MLOps with Scikit-Learn and Git

## ðŸ“ Project Structure

    sklearn-mlops-lab/
    â”œâ”€â”€ data/           # Training data
    â”œâ”€â”€ models/         # Trained models
    â”œâ”€â”€ src/            # Source code
    â”œâ”€â”€ notebooks/      # Jupyter notebooks
    â”œâ”€â”€ configs/        # Configuration files
    â”œâ”€â”€ results/        # Experiment results
    â””â”€â”€ tests/          # Unit tests

## ðŸŽ¯ Goals
- Learn Git Branch workflow with ML Projects
- Experiment with multiple models in different branches
- Track experiments systematically

## ðŸ‘¤ Author
- Student: [Your Name]
- ID: [Student ID]
EOF
```

**à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¸ªà¸£à¹‰à¸²à¸‡:**

```bash
cat README.md
```

> â¸ï¸ **à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š:** à¸„à¸§à¸£à¹€à¸«à¹‡à¸™à¹€à¸™à¸·à¹‰à¸­à¸«à¸² README à¸—à¸µà¹ˆà¹€à¸žà¸´à¹ˆà¸‡à¸ªà¸£à¹‰à¸²à¸‡

---

### 0.2 à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ

**à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ data:**

```bash
mkdir -p data/raw data/processed
```

**à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ models:**

```bash
mkdir -p models
```

**à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ src à¹à¸¥à¸° sub-packages:**

```bash
mkdir -p src/data src/features src/models src/utils
```

**à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œà¸­à¸·à¹ˆà¸™à¹†:**

```bash
mkdir -p notebooks configs results tests
```

---

### 0.3 à¹ƒà¸Šà¹‰ tree à¸”à¸¹à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œ

```bash
tree
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ configs
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ processed
â”‚   â””â”€â”€ raw
â”œâ”€â”€ models
â”œâ”€â”€ notebooks
â”œâ”€â”€ results
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ data
â”‚   â”œâ”€â”€ features
â”‚   â”œâ”€â”€ models
â”‚   â””â”€â”€ utils
â””â”€â”€ tests

13 directories, 1 file
```

---

### 0.4 à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ requirements.txt

```bash
cat > requirements.txt << 'EOF'
# Core ML Libraries
scikit-learn>=1.3.0
pandas>=2.0.0
numpy>=1.24.0

# Model Persistence
joblib>=1.3.0

# Visualization
matplotlib>=3.7.0
seaborn>=0.12.0

# Utilities
python-dotenv>=1.0.0
PyYAML>=6.0

# Testing
pytest>=7.4.0
EOF
```

**à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹„à¸Ÿà¸¥à¹Œ:**

```bash
cat requirements.txt
```

---

### 0.5 à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ .gitignore à¸ªà¸³à¸«à¸£à¸±à¸š ML Projects

```bash
cat > .gitignore << 'EOF'
# Python
__pycache__/
*.py[cod]
*.so
.Python
*.egg-info/
dist/
build/

# Virtual environments
venv/
.env/
env/

# Jupyter Notebooks
.ipynb_checkpoints/
*.ipynb_checkpoints

# Data files (large files)
data/raw/*.csv
data/raw/*.xlsx
data/processed/*.pkl
*.parquet

# Model files (large files)
models/*.pkl
models/*.joblib
*.h5
*.pt
*.pth

# IDE
.vscode/
.idea/
*.swp

# OS
.DS_Store
Thumbs.db

# Logs
*.log
logs/

# Results (optional - may want to track)
# results/

# Secrets
.env
*.key
EOF
```

---

### 0.6 à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ __init__.py à¸ªà¸³à¸«à¸£à¸±à¸š packages

**à¸ªà¸£à¹‰à¸²à¸‡à¹ƒà¸™ src:**

```bash
touch src/__init__.py
```

**à¸ªà¸£à¹‰à¸²à¸‡à¹ƒà¸™ src/data:**

```bash
touch src/data/__init__.py
```

**à¸ªà¸£à¹‰à¸²à¸‡à¹ƒà¸™ src/features:**

```bash
touch src/features/__init__.py
```

**à¸ªà¸£à¹‰à¸²à¸‡à¹ƒà¸™ src/models:**

```bash
touch src/models/__init__.py
```

**à¸ªà¸£à¹‰à¸²à¸‡à¹ƒà¸™ src/utils:**

```bash
touch src/utils/__init__.py
```

**à¸ªà¸£à¹‰à¸²à¸‡à¹ƒà¸™ tests:**

```bash
touch tests/__init__.py
```

---

### 0.7 à¸”à¸¹à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¸—à¸µà¹ˆà¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œ

```bash
tree -a -I '.git'
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
.
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ configs
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ processed
â”‚   â””â”€â”€ raw
â”œâ”€â”€ models
â”œâ”€â”€ notebooks
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ results
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ features
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ models
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â””â”€â”€ utils
â”‚       â””â”€â”€ __init__.py
â””â”€â”€ tests
    â””â”€â”€ __init__.py
```

> â¸ï¸ **Checkpoint:** à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¸•à¸£à¸‡à¸à¸±à¸šà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 1: à¸ªà¸£à¹‰à¸²à¸‡ Data Loading Module

### 1.1 à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ load_data.py

```bash
cat > src/data/load_data.py << 'EOF'
"""
Data Loading Module
Module for loading and managing data
"""

import pandas as pd
import numpy as np
from sklearn.datasets import load_iris, load_wine, load_breast_cancer
from sklearn.model_selection import train_test_split


def load_sklearn_dataset(name: str = 'iris') -> tuple:
    """
    Load dataset from sklearn
    
    Args:
        name: Dataset name ('iris', 'wine', 'breast_cancer')
    
    Returns:
        tuple: (X, y, feature_names, target_names)
    """
    datasets = {
        'iris': load_iris,
        'wine': load_wine,
        'breast_cancer': load_breast_cancer
    }
    
    if name not in datasets:
        raise ValueError(f"Dataset '{name}' not found. Available: {list(datasets.keys())}")
    
    data = datasets[name]()
    
    print(f"âœ“ Loaded {name} dataset")
    print(f"  Samples: {data.data.shape[0]}")
    print(f"  Features: {data.data.shape[1]}")
    print(f"  Classes: {len(data.target_names)}")
    
    return data.data, data.target, data.feature_names, data.target_names


def split_data(X, y, test_size: float = 0.2, random_state: int = 42) -> tuple:
    """
    Split data into train and test sets
    
    Args:
        X: features
        y: targets
        test_size: Proportion of test set
        random_state: Seed for reproducibility
    
    Returns:
        tuple: (X_train, X_test, y_train, y_test)
    """
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state, stratify=y
    )
    
    print(f"âœ“ Data split completed")
    print(f"  Train: {X_train.shape[0]} samples")
    print(f"  Test: {X_test.shape[0]} samples")
    
    return X_train, X_test, y_train, y_test


def create_dataframe(X, y, feature_names) -> pd.DataFrame:
    """
    Create DataFrame from numpy arrays
    """
    df = pd.DataFrame(X, columns=feature_names)
    df['target'] = y
    return df


if __name__ == "__main__":
    # Test module
    X, y, features, targets = load_sklearn_dataset('iris')
    X_train, X_test, y_train, y_test = split_data(X, y)
    df = create_dataframe(X, y, features)
    print(f"\nðŸ“Š DataFrame shape: {df.shape}")
    print(df.head())
EOF
```

---

### 1.2 à¸—à¸”à¸ªà¸­à¸š Data Loading Module

```bash
python3 src/data/load_data.py
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
âœ“ Loaded iris dataset
  Samples: 150
  Features: 4
  Classes: 3
âœ“ Data split completed
  Train: 120 samples
  Test: 30 samples

ðŸ“Š DataFrame shape: (150, 5)
   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  target
0                5.1               3.5                1.4               0.2       0
1                4.9               3.0                1.4               0.2       0
2                4.7               3.2                1.3               0.2       0
3                4.6               3.1                1.5               0.2       0
4                5.0               3.6                1.4               0.2       0
```

> â¸ï¸ **Checkpoint:** à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² output à¸•à¸£à¸‡à¸à¸±à¸šà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ

---

### 1.3 Commit Initial Structure à¹à¸¥à¸° Push à¹„à¸› Remote

**à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 1 - à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š status:**

```bash
git status
```

**à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 2 - à¹€à¸žà¸´à¹ˆà¸¡à¹„à¸Ÿà¸¥à¹Œà¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”:**

```bash
git add .
```

**à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 3 - Commit:**

```bash
git commit -m "Initial commit: Create ML project structure with data loading module"
```

**à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 4 - à¸”à¸¹ log:**

```bash
git log --oneline
```

**à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 5 - Push à¹„à¸› remote (à¸„à¸£à¸±à¹‰à¸‡à¹à¸£à¸):**

```bash
git push -u origin main
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
Enumerating objects: 15, done.
Counting objects: 100% (15/15), done.
Delta compression using up to 8 threads
Compressing objects: 100% (10/10), done.
Writing objects: 100% (15/15), 2.50 KiB | 2.50 MiB/s, done.
Total 15 (delta 0), reused 0 (delta 0)
To https://github.com/username/sklearn-mlops-lab.git
 * [new branch]      main -> main
Branch 'main' set up to track remote branch 'main' from 'origin'.
```

> ðŸ’¡ **à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸:** `-u origin main` à¹ƒà¸Šà¹‰à¸„à¸£à¸±à¹‰à¸‡à¹à¸£à¸à¹€à¸žà¸·à¹ˆà¸­à¸•à¸±à¹‰à¸‡ upstream à¸«à¸¥à¸±à¸‡à¸ˆà¸²à¸à¸™à¸µà¹‰à¹ƒà¸Šà¹‰à¹à¸„à¹ˆ `git push` à¹„à¸”à¹‰à¹€à¸¥à¸¢

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 2: à¸ªà¸£à¹‰à¸²à¸‡ Feature Engineering Module à¹ƒà¸™ Branch à¹ƒà¸«à¸¡à¹ˆ

### 2.1 à¸ªà¸£à¹‰à¸²à¸‡ Branch à¸ªà¸³à¸«à¸£à¸±à¸š Feature Engineering

**à¸ªà¸£à¹‰à¸²à¸‡à¹à¸¥à¸°à¸ªà¸¥à¸±à¸šà¹„à¸› branch à¹ƒà¸«à¸¡à¹ˆ:**

```bash
git switch -c feature/preprocessing
```

**à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š branch à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™:**

```bash
git branch
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
* feature/preprocessing
  main
```

> â¸ï¸ **à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š:** à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸«à¸¡à¸²à¸¢ `*` à¸„à¸§à¸£à¸­à¸¢à¸¹à¹ˆà¸«à¸™à¹‰à¸² `feature/preprocessing`

---

### 2.2 à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ preprocessing.py

```bash
cat > src/features/preprocessing.py << 'EOF'
"""
Feature Preprocessing Module
Module for preprocessing features
"""

import numpy as np
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler
from sklearn.preprocessing import LabelEncoder, OneHotEncoder


class FeaturePreprocessor:
    """
    Class for preprocessing features
    """
    
    def __init__(self, scaling_method: str = 'standard'):
        """
        Initialize preprocessor
        
        Args:
            scaling_method: Scaling method ('standard', 'minmax', 'robust')
        """
        self.scaling_method = scaling_method
        self.scaler = self._get_scaler()
        self.is_fitted = False
    
    def _get_scaler(self):
        """Select scaler based on specified method"""
        scalers = {
            'standard': StandardScaler(),
            'minmax': MinMaxScaler(),
            'robust': RobustScaler()
        }
        
        if self.scaling_method not in scalers:
            raise ValueError(f"Unknown scaling method: {self.scaling_method}")
        
        return scalers[self.scaling_method]
    
    def fit(self, X):
        """Fit scaler with training data"""
        self.scaler.fit(X)
        self.is_fitted = True
        print(f"âœ“ Fitted {self.scaling_method} scaler")
        return self
    
    def transform(self, X):
        """Transform data with fitted scaler"""
        if not self.is_fitted:
            raise RuntimeError("Scaler has not been fitted. Call fit() first.")
        
        X_scaled = self.scaler.transform(X)
        print(f"âœ“ Transformed data with {self.scaling_method} scaler")
        return X_scaled
    
    def fit_transform(self, X):
        """Fit and transform in one step"""
        self.fit(X)
        return self.transform(X)
    
    def get_stats(self):
        """Display scaler statistics"""
        if not self.is_fitted:
            return None
        
        if hasattr(self.scaler, 'mean_'):
            print("\nðŸ“Š Scaler Statistics:")
            print(f"  Mean: {self.scaler.mean_}")
            print(f"  Scale: {self.scaler.scale_}")
        elif hasattr(self.scaler, 'data_min_'):
            print("\nðŸ“Š Scaler Statistics:")
            print(f"  Min: {self.scaler.data_min_}")
            print(f"  Max: {self.scaler.data_max_}")


def preprocess_pipeline(X_train, X_test, method: str = 'standard'):
    """
    Pipeline for preprocessing data
    
    Args:
        X_train: training features
        X_test: test features
        method: scaling method
    
    Returns:
        tuple: (X_train_scaled, X_test_scaled, preprocessor)
    """
    preprocessor = FeaturePreprocessor(scaling_method=method)
    
    # Fit only with train data!
    X_train_scaled = preprocessor.fit_transform(X_train)
    
    # Transform test data with parameters from train
    X_test_scaled = preprocessor.transform(X_test)
    
    return X_train_scaled, X_test_scaled, preprocessor


if __name__ == "__main__":
    # Test module
    import sys
    sys.path.insert(0, '.')
    from src.data.load_data import load_sklearn_dataset, split_data
    
    # Load data
    X, y, features, targets = load_sklearn_dataset('iris')
    X_train, X_test, y_train, y_test = split_data(X, y)
    
    print("\n" + "="*50)
    print("Testing StandardScaler")
    print("="*50)
    
    # Test StandardScaler
    X_train_scaled, X_test_scaled, preprocessor = preprocess_pipeline(
        X_train, X_test, method='standard'
    )
    
    preprocessor.get_stats()
    
    print(f"\nðŸ“ˆ Original X_train mean: {X_train.mean(axis=0)}")
    print(f"ðŸ“‰ Scaled X_train mean: {X_train_scaled.mean(axis=0)}")
    
    print("\n" + "="*50)
    print("Testing MinMaxScaler")
    print("="*50)
    
    # Test MinMaxScaler
    X_train_mm, X_test_mm, _ = preprocess_pipeline(
        X_train, X_test, method='minmax'
    )
    
    print(f"\nðŸ“ˆ MinMax X_train range: [{X_train_mm.min():.2f}, {X_train_mm.max():.2f}]")
EOF
```

---

### 2.3 à¸—à¸”à¸ªà¸­à¸š Preprocessing Module

```bash
python3 src/features/preprocessing.py
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
âœ“ Loaded iris dataset
  Samples: 150
  Features: 4
  Classes: 3
âœ“ Data split completed
  Train: 120 samples
  Test: 30 samples

==================================================
Testing StandardScaler
==================================================
âœ“ Fitted standard scaler
âœ“ Transformed data with standard scaler
âœ“ Transformed data with standard scaler

ðŸ“Š Scaler Statistics:
  Mean: [5.84583333 3.06333333 3.7775     1.20583333]
  Scale: [0.82898063 0.44344109 1.75004544 0.76508862]

ðŸ“ˆ Original X_train mean: [5.84583333 3.06333333 3.7775     1.20583333]
ðŸ“‰ Scaled X_train mean: [-1.11022302e-15 -5.62883073e-16  3.28903977e-16  1.11022302e-16]

==================================================
Testing MinMaxScaler
==================================================
âœ“ Fitted minmax scaler
âœ“ Transformed data with minmax scaler
âœ“ Transformed data with minmax scaler

ðŸ“ˆ MinMax X_train range: [0.00, 1.00]
```

> â¸ï¸ **Checkpoint:** à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² Scaled X_train mean à¹ƒà¸à¸¥à¹‰ 0 à¹à¸¥à¸° MinMax range à¸„à¸·à¸­ [0, 1]

---

### 2.4 à¹ƒà¸Šà¹‰ tree à¸”à¸¹à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¸—à¸µà¹ˆà¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡

```bash
tree src/features
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
src/features
â”œâ”€â”€ __init__.py
â””â”€â”€ preprocessing.py

0 directories, 2 files
```

---

### 2.5 Commit à¹à¸¥à¸° Push Branch à¹„à¸› Remote

**à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 1 - à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š status:**

```bash
git status
```

**à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 2 - Add à¹à¸¥à¸° Commit:**

```bash
git add .
```

```bash
git commit -m "feat: Add feature preprocessing module with scalers"
```

**à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 3 - à¸”à¸¹ log:**

```bash
git log --oneline
```

**à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 4 - Push feature branch à¹„à¸› remote:**

```bash
git push -u origin feature/preprocessing
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
Enumerating objects: 8, done.
Counting objects: 100% (8/8), done.
Delta compression using up to 8 threads
Compressing objects: 100% (5/5), done.
Writing objects: 100% (6/6), 1.80 KiB | 1.80 MiB/s, done.
To https://github.com/username/sklearn-mlops-lab.git
 * [new branch]      feature/preprocessing -> feature/preprocessing
Branch 'feature/preprocessing' set up to track remote branch 'feature/preprocessing' from 'origin'.
```

---

### 2.6 à¸”à¸¹ refs à¸‚à¸­à¸‡ Git

```bash
tree .git/refs/heads
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
.git/refs/heads
â”œâ”€â”€ feature
â”‚   â””â”€â”€ preprocessing
â””â”€â”€ main

1 directory, 2 files
```

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 3: à¸ªà¸£à¹‰à¸²à¸‡ Model Training Module à¹ƒà¸™ Branch à¹ƒà¸«à¸¡à¹ˆ

### 3.1 à¸à¸¥à¸±à¸šà¹„à¸› main à¹à¸¥à¸°à¸ªà¸£à¹‰à¸²à¸‡ branch à¹ƒà¸«à¸¡à¹ˆ

**à¸à¸¥à¸±à¸šà¹„à¸› main:**

```bash
git switch main
```

**à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² preprocessing.py à¸«à¸²à¸¢à¹„à¸›:**

```bash
tree src/features
```

> ðŸ’¡ **à¸ªà¸±à¸‡à¹€à¸à¸•:** à¹„à¸Ÿà¸¥à¹Œ `preprocessing.py` à¸«à¸²à¸¢à¹„à¸›à¹€à¸žà¸£à¸²à¸°à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™ branch à¸­à¸·à¹ˆà¸™

**à¸ªà¸£à¹‰à¸²à¸‡ branch à¹ƒà¸«à¸¡à¹ˆà¸ªà¸³à¸«à¸£à¸±à¸š experiment:**

```bash
git switch -c experiment/logistic-regression
```

**à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š branches à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”:**

```bash
git branch
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
* experiment/logistic-regression
  feature/preprocessing
  main
```

---

### 3.2 à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ train.py

```bash
cat > src/models/train.py << 'EOF'
"""
Model Training Module
Module for training ML models
"""

import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import joblib
import os
from datetime import datetime


class ModelTrainer:
    """
    Class for training and evaluating models
    """
    
    def __init__(self, model_name: str = 'logistic_regression'):
        """
        Initialize trainer
        
        Args:
            model_name: Model name
        """
        self.model_name = model_name
        self.model = self._get_model()
        self.is_trained = False
        self.training_history = {}
    
    def _get_model(self):
        """Create model instance"""
        if self.model_name == 'logistic_regression':
            return LogisticRegression(max_iter=200, random_state=42)
        else:
            raise ValueError(f"Unknown model: {self.model_name}")
    
    def train(self, X_train, y_train):
        """Train model"""
        print(f"ðŸš€ Training {self.model_name}...")
        
        start_time = datetime.now()
        self.model.fit(X_train, y_train)
        end_time = datetime.now()
        
        self.is_trained = True
        self.training_history['training_time'] = (end_time - start_time).total_seconds()
        self.training_history['n_samples'] = X_train.shape[0]
        self.training_history['n_features'] = X_train.shape[1]
        
        # Train accuracy
        train_pred = self.model.predict(X_train)
        train_acc = accuracy_score(y_train, train_pred)
        self.training_history['train_accuracy'] = train_acc
        
        print(f"âœ“ Training completed in {self.training_history['training_time']:.2f}s")
        print(f"  Train Accuracy: {train_acc:.4f}")
        
        return self
    
    def evaluate(self, X_test, y_test, target_names=None):
        """Evaluate model"""
        if not self.is_trained:
            raise RuntimeError("Model has not been trained. Call train() first.")
        
        print(f"\nðŸ“Š Evaluating {self.model_name}...")
        
        y_pred = self.model.predict(X_test)
        
        # Calculate metrics
        test_acc = accuracy_score(y_test, y_pred)
        self.training_history['test_accuracy'] = test_acc
        
        print(f"  Test Accuracy: {test_acc:.4f}")
        
        # Classification report
        print("\nðŸ“‹ Classification Report:")
        print(classification_report(y_test, y_pred, target_names=target_names))
        
        # Confusion matrix
        print("ðŸ”¢ Confusion Matrix:")
        print(confusion_matrix(y_test, y_pred))
        
        return y_pred, test_acc
    
    def save_model(self, filepath: str = None):
        """Save trained model"""
        if not self.is_trained:
            raise RuntimeError("Model has not been trained.")
        
        if filepath is None:
            os.makedirs('models', exist_ok=True)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filepath = f'models/{self.model_name}_{timestamp}.joblib'
        
        joblib.dump({
            'model': self.model,
            'model_name': self.model_name,
            'training_history': self.training_history
        }, filepath)
        
        print(f"âœ“ Model saved to: {filepath}")
        return filepath
    
    def get_summary(self):
        """Display training summary"""
        print("\n" + "="*50)
        print(f"ðŸ“ˆ Training Summary: {self.model_name}")
        print("="*50)
        for key, value in self.training_history.items():
            if isinstance(value, float):
                print(f"  {key}: {value:.4f}")
            else:
                print(f"  {key}: {value}")


if __name__ == "__main__":
    # Test module
    import sys
    sys.path.insert(0, '.')
    from src.data.load_data import load_sklearn_dataset, split_data
    
    # Load data
    X, y, features, targets = load_sklearn_dataset('iris')
    X_train, X_test, y_train, y_test = split_data(X, y)
    
    # Create and train model
    trainer = ModelTrainer('logistic_regression')
    trainer.train(X_train, y_train)
    
    # Evaluate
    y_pred, accuracy = trainer.evaluate(X_test, y_test, target_names=targets)
    
    # Show summary
    trainer.get_summary()
    
    # Save model
    model_path = trainer.save_model()
EOF
```

---

### 3.3 à¸—à¸”à¸ªà¸­à¸š Training Module

```bash
python3 src/models/train.py
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
âœ“ Loaded iris dataset
  Samples: 150
  Features: 4
  Classes: 3
âœ“ Data split completed
  Train: 120 samples
  Test: 30 samples
ðŸš€ Training logistic_regression...
âœ“ Training completed in 0.02s
  Train Accuracy: 0.9750

ðŸ“Š Evaluating logistic_regression...
  Test Accuracy: 0.9667

ðŸ“‹ Classification Report:
              precision    recall  f1-score   support

      setosa       1.00      1.00      1.00        10
  versicolor       0.91      1.00      0.95        10
   virginica       1.00      0.90      0.95        10

    accuracy                           0.97        30
   macro avg       0.97      0.97      0.97        30
weighted avg       0.97      0.97      0.97        30

ðŸ”¢ Confusion Matrix:
[[10  0  0]
 [ 0 10  0]
 [ 0  1  9]]

==================================================
ðŸ“ˆ Training Summary: logistic_regression
==================================================
  training_time: 0.0234
  n_samples: 120
  n_features: 4
  train_accuracy: 0.9750
  test_accuracy: 0.9667
âœ“ Model saved to: models/logistic_regression_20241215_143022.joblib
```

> â¸ï¸ **Checkpoint:** à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² Test Accuracy à¸ªà¸¹à¸‡à¸à¸§à¹ˆà¸² 0.90

---

### 3.4 à¹ƒà¸Šà¹‰ tree à¸”à¸¹à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡

```bash
tree -I '__pycache__'
```

---

### 3.5 Commit à¹à¸¥à¸° Push

**Add files:**

```bash
git add .
```

**Commit:**

```bash
git commit -m "experiment: Add Logistic Regression trainer with evaluation"
```

**Push experiment branch:**

```bash
git push -u origin experiment/logistic-regression
```

**à¸”à¸¹ log à¸—à¸¸à¸ branches:**

```bash
git log --oneline --graph --all
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
To https://github.com/username/sklearn-mlops-lab.git
 * [new branch]      experiment/logistic-regression -> experiment/logistic-regression
```

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 4: à¸ªà¸£à¹‰à¸²à¸‡ Experiment à¸­à¸·à¹ˆà¸™à¹† à¹ƒà¸™ Branches à¹à¸¢à¸

### 4.1 à¸ªà¸£à¹‰à¸²à¸‡ Branch à¸ªà¸³à¸«à¸£à¸±à¸š Random Forest

**à¸à¸¥à¸±à¸šà¹„à¸› main:**

```bash
git switch main
```

**à¸ªà¸£à¹‰à¸²à¸‡ branch à¹ƒà¸«à¸¡à¹ˆ:**

```bash
git switch -c experiment/random-forest
```

---

### 4.2 à¹à¸à¹‰à¹„à¸‚ train.py à¹€à¸žà¸·à¹ˆà¸­à¹€à¸žà¸´à¹ˆà¸¡ Random Forest

```bash
cat > src/models/train.py << 'EOF'
"""
Model Training Module
Module for training ML models - Random Forest Version
"""

import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import joblib
import os
from datetime import datetime


class ModelTrainer:
    """
    Class for training and evaluating models
    """
    
    def __init__(self, model_name: str = 'random_forest', **kwargs):
        """
        Initialize trainer
        
        Args:
            model_name: Model name
            **kwargs: Hyperparameters for model
        """
        self.model_name = model_name
        self.hyperparameters = kwargs
        self.model = self._get_model()
        self.is_trained = False
        self.training_history = {}
    
    def _get_model(self):
        """Create model instance"""
        default_params = {
            'n_estimators': 100,
            'max_depth': None,
            'min_samples_split': 2,
            'random_state': 42
        }
        
        # Merge default with user params
        params = {**default_params, **self.hyperparameters}
        
        if self.model_name == 'random_forest':
            return RandomForestClassifier(**params)
        else:
            raise ValueError(f"Unknown model: {self.model_name}")
    
    def train(self, X_train, y_train):
        """Train model"""
        print(f"ðŸŒ² Training {self.model_name}...")
        print(f"   Hyperparameters: {self.hyperparameters}")
        
        start_time = datetime.now()
        self.model.fit(X_train, y_train)
        end_time = datetime.now()
        
        self.is_trained = True
        self.training_history['training_time'] = (end_time - start_time).total_seconds()
        self.training_history['n_samples'] = X_train.shape[0]
        self.training_history['n_features'] = X_train.shape[1]
        self.training_history['hyperparameters'] = self.hyperparameters
        
        # Train accuracy
        train_pred = self.model.predict(X_train)
        train_acc = accuracy_score(y_train, train_pred)
        self.training_history['train_accuracy'] = train_acc
        
        print(f"âœ“ Training completed in {self.training_history['training_time']:.2f}s")
        print(f"  Train Accuracy: {train_acc:.4f}")
        
        return self
    
    def evaluate(self, X_test, y_test, target_names=None):
        """Evaluate model"""
        if not self.is_trained:
            raise RuntimeError("Model has not been trained. Call train() first.")
        
        print(f"\nðŸ“Š Evaluating {self.model_name}...")
        
        y_pred = self.model.predict(X_test)
        
        # Calculate metrics
        test_acc = accuracy_score(y_test, y_pred)
        self.training_history['test_accuracy'] = test_acc
        
        print(f"  Test Accuracy: {test_acc:.4f}")
        
        # Classification report
        print("\nðŸ“‹ Classification Report:")
        print(classification_report(y_test, y_pred, target_names=target_names))
        
        # Feature importance
        if hasattr(self.model, 'feature_importances_'):
            print("\nðŸŽ¯ Feature Importances:")
            importances = self.model.feature_importances_
            for i, imp in enumerate(importances):
                print(f"  Feature {i}: {imp:.4f}")
        
        return y_pred, test_acc
    
    def save_model(self, filepath: str = None):
        """Save trained model"""
        if not self.is_trained:
            raise RuntimeError("Model has not been trained.")
        
        if filepath is None:
            os.makedirs('models', exist_ok=True)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filepath = f'models/{self.model_name}_{timestamp}.joblib'
        
        joblib.dump({
            'model': self.model,
            'model_name': self.model_name,
            'training_history': self.training_history
        }, filepath)
        
        print(f"âœ“ Model saved to: {filepath}")
        return filepath
    
    def get_summary(self):
        """Display training summary"""
        print("\n" + "="*50)
        print(f"ðŸŒ² Training Summary: {self.model_name}")
        print("="*50)
        for key, value in self.training_history.items():
            if isinstance(value, float):
                print(f"  {key}: {value:.4f}")
            elif isinstance(value, dict):
                print(f"  {key}:")
                for k, v in value.items():
                    print(f"    - {k}: {v}")
            else:
                print(f"  {key}: {value}")


if __name__ == "__main__":
    # Test module
    import sys
    sys.path.insert(0, '.')
    from src.data.load_data import load_sklearn_dataset, split_data
    
    # Load data
    X, y, features, targets = load_sklearn_dataset('iris')
    X_train, X_test, y_train, y_test = split_data(X, y)
    
    # Test different hyperparameters
    experiments = [
        {'n_estimators': 50, 'max_depth': 3},
        {'n_estimators': 100, 'max_depth': 5},
        {'n_estimators': 200, 'max_depth': None}
    ]
    
    results = []
    
    for exp in experiments:
        print("\n" + "="*60)
        trainer = ModelTrainer('random_forest', **exp)
        trainer.train(X_train, y_train)
        y_pred, accuracy = trainer.evaluate(X_test, y_test, target_names=targets)
        results.append({
            'params': exp,
            'test_accuracy': accuracy
        })
    
    # Summary of all experiments
    print("\n" + "="*60)
    print("ðŸ“Š EXPERIMENT SUMMARY")
    print("="*60)
    for i, result in enumerate(results):
        print(f"\nExperiment {i+1}:")
        print(f"  Params: {result['params']}")
        print(f"  Test Accuracy: {result['test_accuracy']:.4f}")
EOF
```

---

### 4.3 à¸—à¸”à¸ªà¸­à¸š Random Forest

```bash
python3 src/models/train.py
```

---

### 4.4 Commit à¹à¸¥à¸° Push

**Add files:**

```bash
git add .
```

**Commit:**

```bash
git commit -m "experiment: Test Random Forest with various hyperparameters"
```

**Push:**

```bash
git push -u origin experiment/random-forest
```

---

### 4.5 à¸”à¸¹ branches à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”

**à¸”à¸¹à¸—à¸¸à¸ branches à¸žà¸£à¹‰à¸­à¸¡à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”:**

```bash
git branch -v
```

**à¹ƒà¸Šà¹‰ Pipeline à¸™à¸±à¸š experiment branches:**

```bash
git branch | grep "experiment" | wc -l
```

**à¸”à¸¹ log à¹à¸šà¸š graph:**

```bash
git log --oneline --graph --all --decorate
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
* def5678 (HEAD -> experiment/random-forest) experiment: Test Random Forest
| * ghi9012 (experiment/logistic-regression) experiment: Add Logistic Regression
|/
| * abc1234 (feature/preprocessing) feat: Add feature preprocessing module
|/
* xyz7890 (main) Initial commit: Create ML project structure
```

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 5: à¸ªà¸£à¹‰à¸²à¸‡ Configuration Files

### 5.1 à¸ªà¸£à¹‰à¸²à¸‡ Config Branch

**à¸à¸¥à¸±à¸šà¹„à¸› main:**

```bash
git switch main
```

**à¸ªà¸£à¹‰à¸²à¸‡ branch à¹ƒà¸«à¸¡à¹ˆ:**

```bash
git switch -c feature/config-system
```

---

### 5.2 à¸ªà¸£à¹‰à¸²à¸‡ Config File à¸”à¹‰à¸§à¸¢ YAML

```bash
cat > configs/experiment_config.yaml << 'EOF'
# Experiment Configuration
# Config file for ML experiments

# Dataset settings
dataset:
  name: iris
  test_size: 0.2
  random_state: 42

# Preprocessing settings
preprocessing:
  scaling_method: standard  # standard, minmax, robust
  handle_missing: drop      # drop, impute

# Model settings
models:
  logistic_regression:
    max_iter: 200
    solver: lbfgs
    
  random_forest:
    n_estimators: 100
    max_depth: null
    min_samples_split: 2
    
  svm:
    kernel: rbf
    C: 1.0
    gamma: scale

# Training settings
training:
  cross_validation: 5
  verbose: true
  
# Output settings
output:
  save_model: true
  model_dir: models/
  results_dir: results/
  log_file: logs/training.log
EOF
```

**à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹„à¸Ÿà¸¥à¹Œ:**

```bash
cat configs/experiment_config.yaml
```

---

### 5.3 à¸ªà¸£à¹‰à¸²à¸‡ Config Reader

```bash
cat > src/utils/config.py << 'EOF'
"""
Configuration Management Module
Module for managing configuration
"""

import yaml
from pathlib import Path


def load_config(config_path: str = 'configs/experiment_config.yaml') -> dict:
    """
    Load configuration from YAML file
    
    Args:
        config_path: Path to config file
    
    Returns:
        dict: Configuration dictionary
    """
    config_file = Path(config_path)
    
    if not config_file.exists():
        raise FileNotFoundError(f"Config file not found: {config_path}")
    
    with open(config_file, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    print(f"âœ“ Loaded config from: {config_path}")
    return config


def get_model_config(config: dict, model_name: str) -> dict:
    """
    Get config for specific model
    
    Args:
        config: Full configuration
        model_name: Model name
    
    Returns:
        dict: Model configuration
    """
    models = config.get('models', {})
    
    if model_name not in models:
        raise ValueError(f"Model '{model_name}' not found in config")
    
    return models[model_name]


def print_config(config: dict, indent: int = 0):
    """
    Display config nicely
    """
    for key, value in config.items():
        prefix = "  " * indent
        if isinstance(value, dict):
            print(f"{prefix}ðŸ“ {key}:")
            print_config(value, indent + 1)
        else:
            print(f"{prefix}  â€¢ {key}: {value}")


if __name__ == "__main__":
    # Test module
    config = load_config()
    
    print("\nðŸ“‹ Full Configuration:")
    print("="*50)
    print_config(config)
    
    print("\nðŸŒ² Random Forest Config:")
    print("="*50)
    rf_config = get_model_config(config, 'random_forest')
    print(rf_config)
EOF
```

---

### 5.4 à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ PyYAML à¹à¸¥à¸°à¸—à¸”à¸ªà¸­à¸š

**à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ PyYAML:**

```bash
pip3 install pyyaml
```

**à¸—à¸”à¸ªà¸­à¸š config module:**

```bash
python3 src/utils/config.py
```

---

### 5.5 à¹ƒà¸Šà¹‰ tree à¸”à¸¹à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡ configs

```bash
tree configs
```

---

### 5.6 Commit à¹à¸¥à¸° Push

**Add files:**

```bash
git add .
```

**Commit:**

```bash
git commit -m "feat: Add configuration system with YAML support"
```

**Push:**

```bash
git push -u origin feature/config-system
```

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 6: à¸à¸²à¸£ Merge Branches

### 6.1 Merge Feature/Preprocessing à¹€à¸‚à¹‰à¸² Main

**à¸ªà¸¥à¸±à¸šà¹„à¸› main:**

```bash
git switch main
```

**à¸”à¸¹ status à¸à¹ˆà¸­à¸™ merge:**

```bash
git log --oneline --graph --all
```

**Merge feature/preprocessing:**

```bash
git merge feature/preprocessing -m "Merge: Add preprocessing module to main"
```

**à¸”à¸¹ status à¸«à¸¥à¸±à¸‡ merge:**

```bash
git log --oneline --graph --all
```

---

### 6.2 Merge Feature/Config-System à¹à¸¥à¸° Push

**Merge config system:**

```bash
git merge feature/config-system -m "Merge: Add config system to main"
```

**à¸”à¸¹ log:**

```bash
git log --oneline --graph --all
```

**Push merged main à¹„à¸› remote:**

```bash
git push origin main
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
To https://github.com/username/sklearn-mlops-lab.git
   abc1234..def5678  main -> main
```

---

### 6.3 à¸”à¸¹à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¸«à¸¥à¸±à¸‡ Merge

```bash
tree -I '__pycache__|*.pyc|models'
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡ (à¸«à¸¥à¸±à¸‡ merge):**
```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ configs
â”‚   â””â”€â”€ experiment_config.yaml
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ processed
â”‚   â””â”€â”€ raw
â”œâ”€â”€ notebooks
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ results
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ load_data.py
â”‚   â”œâ”€â”€ features
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ models
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â””â”€â”€ utils
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ config.py
â””â”€â”€ tests
    â””â”€â”€ __init__.py
```

---

### 6.4 à¹ƒà¸Šà¹‰ Pipeline à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ

**à¸™à¸±à¸šà¹„à¸Ÿà¸¥à¹Œ Python à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”:**

```bash
find . -name "*.py" | wc -l
```

**à¸”à¸¹à¹€à¸‰à¸žà¸²à¸°à¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆ __init__.py:**

```bash
find . -name "*.py" | grep -v "__init__"
```

**à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™ commits:**

```bash
git log --oneline | wc -l
```

**à¸”à¸¹ branches à¸—à¸µà¹ˆ merge à¹à¸¥à¹‰à¸§:**

```bash
git branch --merged main
```

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 7: à¸ªà¸£à¹‰à¸²à¸‡ Complete Pipeline Script

### 7.1 à¸ªà¸£à¹‰à¸²à¸‡ Main Pipeline

```bash
cat > run_experiment.py << 'EOF'
#!/usr/bin/env python3
"""
Main Experiment Pipeline
Run complete experiment from config
"""

import sys
import argparse
from pathlib import Path

# Add project root to path
sys.path.insert(0, '.')

from src.data.load_data import load_sklearn_dataset, split_data
from src.features.preprocessing import preprocess_pipeline
from src.utils.config import load_config, get_model_config


def run_experiment(config_path: str = 'configs/experiment_config.yaml'):
    """
    Run experiment based on config
    """
    print("="*60)
    print("ðŸš€ Starting ML Experiment Pipeline")
    print("="*60)
    
    # 1. Load config
    config = load_config(config_path)
    
    # 2. Load data
    print("\nðŸ“¥ Loading Data...")
    dataset_config = config['dataset']
    X, y, features, targets = load_sklearn_dataset(dataset_config['name'])
    X_train, X_test, y_train, y_test = split_data(
        X, y, 
        test_size=dataset_config['test_size'],
        random_state=dataset_config['random_state']
    )
    
    # 3. Preprocess
    print("\nâš™ï¸ Preprocessing...")
    prep_config = config['preprocessing']
    X_train_scaled, X_test_scaled, preprocessor = preprocess_pipeline(
        X_train, X_test,
        method=prep_config['scaling_method']
    )
    
    # 4. Summary
    print("\n" + "="*60)
    print("âœ… Pipeline Summary")
    print("="*60)
    print(f"  Dataset: {dataset_config['name']}")
    print(f"  Train samples: {X_train.shape[0]}")
    print(f"  Test samples: {X_test.shape[0]}")
    print(f"  Features: {X_train.shape[1]}")
    print(f"  Scaling: {prep_config['scaling_method']}")
    print(f"  Classes: {list(targets)}")
    
    return X_train_scaled, X_test_scaled, y_train, y_test, targets


def main():
    parser = argparse.ArgumentParser(description='Run ML Experiment')
    parser.add_argument(
        '--config', '-c',
        default='configs/experiment_config.yaml',
        help='Path to config file'
    )
    
    args = parser.parse_args()
    
    try:
        run_experiment(args.config)
        print("\nðŸŽ‰ Experiment completed successfully!")
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
EOF
```

---

### 7.2 à¸—à¸”à¸ªà¸­à¸š Pipeline

```bash
python3 run_experiment.py
```

---

### 7.3 Commit à¹à¸¥à¸° Push

**Add files:**

```bash
git add .
```

**Commit:**

```bash
git commit -m "feat: Add main experiment pipeline script"
```

**Push:**

```bash
git push origin main
```

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 8: à¸à¸²à¸£à¸¥à¸šà¹à¸¥à¸°à¸ˆà¸±à¸”à¸à¸²à¸£ Branches

### 8.1 à¸”à¸¹ Branches à¸—à¸µà¹ˆ Merge à¹à¸¥à¹‰à¸§

**à¸”à¸¹ branches à¸—à¸µà¹ˆ merge à¹€à¸‚à¹‰à¸² main à¹à¸¥à¹‰à¸§:**

```bash
git branch --merged main
```

**à¸”à¸¹ branches à¸—à¸µà¹ˆà¸¢à¸±à¸‡à¹„à¸¡à¹ˆ merge:**

```bash
git branch --no-merged main
```

---

### 8.2 à¸¥à¸š Branch à¸—à¸µà¹ˆ Merge à¹à¸¥à¹‰à¸§ (Local à¹à¸¥à¸° Remote)

**à¸¥à¸š local feature branches:**

```bash
git branch -d feature/preprocessing
```

```bash
git branch -d feature/config-system
```

**à¸¥à¸š remote branches:**

```bash
git push origin --delete feature/preprocessing
```

```bash
git push origin --delete feature/config-system
```

**à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š local branches:**

```bash
git branch
```

**à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š remote branches:**

```bash
git branch -r
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
Deleted branch feature/preprocessing (was abc1234).
Deleted branch feature/config-system (was def5678).
To https://github.com/username/sklearn-mlops-lab.git
 - [deleted]         feature/preprocessing
 - [deleted]         feature/config-system
```

---

### 8.3 à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸Šà¸·à¹ˆà¸­ Branch

**à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸Šà¸·à¹ˆà¸­ experiment/logistic-regression:**

```bash
git branch -m experiment/logistic-regression experiment/lr-baseline
```

**à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸Šà¸·à¹ˆà¸­ experiment/random-forest:**

```bash
git branch -m experiment/random-forest experiment/rf-baseline
```

**à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ:**

```bash
git branch -v
```

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 9: à¸ªà¸£à¹‰à¸²à¸‡ Results Tracking

### 9.1 à¸ªà¸£à¹‰à¸²à¸‡ Results Logger

```bash
cat > src/utils/logger.py << 'EOF'
"""
Results Logging Module
Module for logging experiment results
"""

import json
import csv
from datetime import datetime
from pathlib import Path


class ExperimentLogger:
    """
    Class for logging experiment results
    """
    
    def __init__(self, results_dir: str = 'results'):
        """
        Initialize logger
        
        Args:
            results_dir: Folder for storing results
        """
        self.results_dir = Path(results_dir)
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        # CSV file for storing results
        self.csv_file = self.results_dir / 'experiments.csv'
        self._init_csv()
    
    def _init_csv(self):
        """Create CSV header if not exists"""
        if not self.csv_file.exists():
            with open(self.csv_file, 'w', newline='') as f:
                writer = csv.writer(f)
                writer.writerow([
                    'timestamp',
                    'experiment_name',
                    'model_name',
                    'dataset',
                    'train_accuracy',
                    'test_accuracy',
                    'hyperparameters',
                    'notes'
                ])
            print(f"âœ“ Created results CSV: {self.csv_file}")
    
    def log_experiment(
        self,
        experiment_name: str,
        model_name: str,
        dataset: str,
        train_accuracy: float,
        test_accuracy: float,
        hyperparameters: dict = None,
        notes: str = ''
    ):
        """
        Log experiment results
        """
        timestamp = datetime.now().isoformat()
        
        with open(self.csv_file, 'a', newline='') as f:
            writer = csv.writer(f)
            writer.writerow([
                timestamp,
                experiment_name,
                model_name,
                dataset,
                f'{train_accuracy:.4f}',
                f'{test_accuracy:.4f}',
                json.dumps(hyperparameters) if hyperparameters else '',
                notes
            ])
        
        print(f"âœ“ Logged experiment: {experiment_name}")
    
    def get_all_results(self):
        """Read all results"""
        results = []
        
        if self.csv_file.exists():
            with open(self.csv_file, 'r') as f:
                reader = csv.DictReader(f)
                results = list(reader)
        
        return results
    
    def get_best_experiment(self, metric: str = 'test_accuracy'):
        """Find best experiment"""
        results = self.get_all_results()
        
        if not results:
            return None
        
        best = max(results, key=lambda x: float(x[metric]))
        return best
    
    def print_summary(self):
        """Display results summary"""
        results = self.get_all_results()
        
        if not results:
            print("ðŸ“­ No experiments logged yet")
            return
        
        print("\n" + "="*70)
        print("ðŸ“Š Experiment Results Summary")
        print("="*70)
        print(f"{'Experiment':<20} {'Model':<15} {'Train Acc':<12} {'Test Acc':<12}")
        print("-"*70)
        
        for r in results:
            print(f"{r['experiment_name']:<20} {r['model_name']:<15} "
                  f"{r['train_accuracy']:<12} {r['test_accuracy']:<12}")
        
        # Best experiment
        best = self.get_best_experiment()
        if best:
            print("\nðŸ† Best Experiment:")
            print(f"   {best['experiment_name']} - Test Accuracy: {best['test_accuracy']}")


if __name__ == "__main__":
    # Test logger
    logger = ExperimentLogger()
    
    # Log sample experiments
    logger.log_experiment(
        experiment_name='baseline-lr',
        model_name='logistic_regression',
        dataset='iris',
        train_accuracy=0.975,
        test_accuracy=0.967,
        hyperparameters={'max_iter': 200},
        notes='Baseline experiment'
    )
    
    logger.log_experiment(
        experiment_name='rf-100trees',
        model_name='random_forest',
        dataset='iris',
        train_accuracy=1.0,
        test_accuracy=0.933,
        hyperparameters={'n_estimators': 100, 'max_depth': 5},
        notes='Random Forest with 100 trees'
    )
    
    logger.log_experiment(
        experiment_name='rf-200trees',
        model_name='random_forest',
        dataset='iris',
        train_accuracy=1.0,
        test_accuracy=0.967,
        hyperparameters={'n_estimators': 200, 'max_depth': None},
        notes='Random Forest with 200 trees'
    )
    
    # Show summary
    logger.print_summary()
EOF
```

---

### 9.2 à¸—à¸”à¸ªà¸­à¸š Logger

```bash
python3 src/utils/logger.py
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
âœ“ Created results CSV: results/experiments.csv
âœ“ Logged experiment: baseline-lr
âœ“ Logged experiment: rf-100trees
âœ“ Logged experiment: rf-200trees

======================================================================
ðŸ“Š Experiment Results Summary
======================================================================
Experiment           Model           Train Acc    Test Acc    
----------------------------------------------------------------------
baseline-lr          logistic_regression 0.9750       0.9670      
rf-100trees          random_forest   1.0000       0.9330      
rf-200trees          random_forest   1.0000       0.9670      

ðŸ† Best Experiment:
   baseline-lr - Test Accuracy: 0.9670
```

---

### 9.3 à¸”à¸¹à¹„à¸Ÿà¸¥à¹Œà¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ

**à¸”à¸¹ CSV à¸—à¸µà¹ˆà¸ªà¸£à¹‰à¸²à¸‡:**

```bash
cat results/experiments.csv
```

**à¹ƒà¸Šà¹‰ Pipeline à¸”à¸¹ 5 à¸šà¸£à¸£à¸—à¸±à¸”à¹à¸£à¸:**

```bash
cat results/experiments.csv | head -5
```

**à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™ experiments:**

```bash
cat results/experiments.csv | wc -l
```

---

### 9.4 Commit à¹à¸¥à¸° Push

**Add files:**

```bash
git add .
```

**Commit:**

```bash
git commit -m "feat: Add experiment results logger"
```

**Push:**

```bash
git push origin main
```

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 10: à¸ªà¸£à¸¸à¸›à¹à¸¥à¸° Final Structure

### 10.1 à¸”à¸¹à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢

```bash
tree -I '__pycache__|*.pyc|.git'
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢:**
```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ configs
â”‚   â””â”€â”€ experiment_config.yaml
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ processed
â”‚   â””â”€â”€ raw
â”œâ”€â”€ models
â”‚   â””â”€â”€ logistic_regression_XXXXXXXX.joblib
â”œâ”€â”€ notebooks
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ results
â”‚   â””â”€â”€ experiments.csv
â”œâ”€â”€ run_experiment.py
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ load_data.py
â”‚   â”œâ”€â”€ features
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ models
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ train.py
â”‚   â””â”€â”€ utils
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py
â”‚       â””â”€â”€ logger.py
â””â”€â”€ tests
    â””â”€â”€ __init__.py
```

---

### 10.2 à¸”à¸¹ Git Log à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”

**à¸”à¸¹ log à¹à¸šà¸š graph:**

```bash
git log --oneline --graph --all --decorate
```

**à¹ƒà¸Šà¹‰ Pipeline à¸™à¸±à¸š "feat" commits:**

```bash
git log --oneline | grep "feat" | wc -l
```

**à¸”à¸¹ commits à¸—à¸µà¹ˆà¸¡à¸µ "experiment":**

```bash
git log --oneline | grep -i "experiment"
```

---

### 10.3 à¸ªà¸£à¸¸à¸› Branches (Local à¹à¸¥à¸° Remote)

**à¸”à¸¹ local branches:**

```bash
git branch -v
```

**à¸”à¸¹ remote branches:**

```bash
git branch -r
```

**à¸”à¸¹à¸—à¸¸à¸ branches (local + remote):**

```bash
git branch -a -v
```

**à¹ƒà¸Šà¹‰ Pipeline à¸™à¸±à¸š branches:**

```bash
echo "Total local branches: $(git branch | wc -l)"
```

```bash
echo "Total remote branches: $(git branch -r | wc -l)"
```

```bash
echo "Experiment branches: $(git branch | grep experiment | wc -l)"
```

```bash
echo "Feature branches: $(git branch | grep feature | wc -l)"
```

---

### 10.4 Push All Branches à¹„à¸› Remote (Optional)

**Push à¸—à¸¸à¸ branches à¸žà¸£à¹‰à¸­à¸¡à¸à¸±à¸™:**

```bash
git push --all origin
```

**Push à¸—à¸¸à¸ tags:**

```bash
git push --tags origin
```

**à¸”à¸¹à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸” remote:**

```bash
git remote show origin
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
* remote origin
  Fetch URL: https://github.com/username/sklearn-mlops-lab.git
  Push  URL: https://github.com/username/sklearn-mlops-lab.git
  HEAD branch: main
  Remote branches:
    experiment/lr-baseline  tracked
    experiment/rf-baseline  tracked
    main                    tracked
  Local branches configured for 'git pull':
    main merges with remote main
  Local refs configured for 'git push':
    main pushes to main (up to date)
```

---

## ðŸ“‹ à¸ªà¸£à¸¸à¸›à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸ªà¸³à¸„à¸±à¸

### à¸„à¸³à¸ªà¸±à¹ˆà¸‡ Linux Pipeline

| à¸„à¸³à¸ªà¸±à¹ˆà¸‡ | à¸„à¸³à¸­à¸˜à¸´à¸šà¸²à¸¢ |
|--------|----------|
| `cat > file << 'EOF'` | à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œà¸«à¸¥à¸²à¸¢à¸šà¸£à¸£à¸—à¸±à¸” (heredoc) |
| `tree` | à¸”à¸¹à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œà¹à¸¥à¸°à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ |
| `cmd1 \| cmd2` | Pipeline: à¸ªà¹ˆà¸‡ output à¹„à¸›à¹€à¸›à¹‡à¸™ input |
| `grep "text"` | à¸à¸£à¸­à¸‡à¸šà¸£à¸£à¸—à¸±à¸”à¸—à¸µà¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡ |
| `wc -l` | à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¸šà¸£à¸£à¸—à¸±à¸” |
| `find . -name "*.py"` | à¸„à¹‰à¸™à¸«à¸²à¹„à¸Ÿà¸¥à¹Œ Python |

### à¸„à¸³à¸ªà¸±à¹ˆà¸‡ Git Branch

| à¸„à¸³à¸ªà¸±à¹ˆà¸‡ | à¸„à¸³à¸­à¸˜à¸´à¸šà¸²à¸¢ |
|--------|----------|
| `git branch` | à¸”à¸¹à¸£à¸²à¸¢à¸à¸²à¸£ branches |
| `git switch -c <branch>` | à¸ªà¸£à¹‰à¸²à¸‡à¹à¸¥à¸°à¸ªà¸¥à¸±à¸š branch |
| `git switch <branch>` | à¸ªà¸¥à¸±à¸š branch |
| `git merge <branch>` | à¸£à¸§à¸¡ branch |
| `git branch -d <branch>` | à¸¥à¸š branch |
| `git branch -m <old> <new>` | à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸Šà¸·à¹ˆà¸­ branch |
| `git branch --merged` | à¸”à¸¹ branches à¸—à¸µà¹ˆ merge à¹à¸¥à¹‰à¸§ |

### à¸„à¸³à¸ªà¸±à¹ˆà¸‡ Git Remote

| à¸„à¸³à¸ªà¸±à¹ˆà¸‡ | à¸„à¸³à¸­à¸˜à¸´à¸šà¸²à¸¢ |
|--------|----------|
| `git remote add origin <url>` | à¹€à¸žà¸´à¹ˆà¸¡ remote repository |
| `git remote -v` | à¸”à¸¹à¸£à¸²à¸¢à¸à¸²à¸£ remote |
| `git push -u origin <branch>` | Push branch à¸„à¸£à¸±à¹‰à¸‡à¹à¸£à¸ (à¸•à¸±à¹‰à¸‡ upstream) |
| `git push` | Push changes à¹„à¸› remote |
| `git push --all origin` | Push à¸—à¸¸à¸ branches |
| `git push origin --delete <branch>` | à¸¥à¸š remote branch |
| `git branch -r` | à¸”à¸¹ remote branches |
| `git fetch origin` | à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸ remote |
| `git pull origin <branch>` | à¸”à¸¶à¸‡à¹à¸¥à¸° merge à¸ˆà¸²à¸ remote |
| `git remote show origin` | à¸”à¸¹à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸” remote |

### Git Pipeline Commands

| à¸„à¸³à¸ªà¸±à¹ˆà¸‡ | à¸„à¸³à¸­à¸˜à¸´à¸šà¸²à¸¢ |
|--------|----------|
| `git branch \| grep "feature"` | à¸«à¸² feature branches |
| `git log --oneline \| wc -l` | à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™ commits |
| `git log --oneline \| grep "fix"` | à¸«à¸² fix commits |

---

## ðŸ§ª à¹à¸šà¸šà¸—à¸”à¸ªà¸­à¸šà¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆ

1. **à¸—à¸³à¹„à¸¡à¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰ Git Branch à¸à¸±à¸š ML Projects?**

2. **à¸„à¸§à¸²à¸¡à¹à¸•à¸à¸•à¹ˆà¸²à¸‡à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ `fit()` à¹à¸¥à¸° `transform()` à¹ƒà¸™ sklearn à¸„à¸·à¸­à¸­à¸°à¹„à¸£?**

3. **à¸—à¸³à¹„à¸¡à¸•à¹‰à¸­à¸‡ fit preprocessor à¸à¸±à¸š training data à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™?**

4. **à¸„à¸³à¸ªà¸±à¹ˆà¸‡ `git branch | grep "experiment" | wc -l` à¸—à¸³à¸­à¸°à¹„à¸£?**

5. **à¸‚à¹‰à¸­à¸”à¸µà¸‚à¸­à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰ YAML config files à¸„à¸·à¸­à¸­à¸°à¹„à¸£?**

6. **à¸„à¸§à¸²à¸¡à¹à¸•à¸à¸•à¹ˆà¸²à¸‡à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ `git push` à¹à¸¥à¸° `git push -u origin <branch>` à¸„à¸·à¸­à¸­à¸°à¹„à¸£?**

7. **à¸—à¸³à¹„à¸¡à¸•à¹‰à¸­à¸‡ Push branches à¹„à¸› Remote Repository?**

<details>
<summary>ðŸ’¡ à¸„à¸¥à¸´à¸à¹€à¸žà¸·à¹ˆà¸­à¸”à¸¹à¹€à¸‰à¸¥à¸¢</summary>

1. à¹€à¸žà¸·à¹ˆà¸­à¸—à¸”à¸¥à¸­à¸‡ models/features à¸•à¹ˆà¸²à¸‡à¹† à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸à¸£à¸°à¸—à¸š code à¸«à¸¥à¸±à¸ à¹à¸¥à¸°à¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸à¹‡à¸š experiments à¹à¸•à¹ˆà¸¥à¸°à¸­à¸±à¸™à¹à¸¢à¸à¸à¸±à¸™à¹„à¸”à¹‰

2. `fit()` à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰ parameters à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ (à¹€à¸Šà¹ˆà¸™ mean, std), `transform()` à¹ƒà¸Šà¹‰ parameters à¸—à¸µà¹ˆà¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¹à¸¥à¹‰à¸§à¹€à¸žà¸·à¹ˆà¸­à¹à¸›à¸¥à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥

3. à¹€à¸žà¸·à¹ˆà¸­à¸›à¹‰à¸­à¸‡à¸à¸±à¸™ data leakage - à¸–à¹‰à¸² fit à¸à¸±à¸š test data à¸”à¹‰à¸§à¸¢ à¸ˆà¸°à¸—à¸³à¹ƒà¸«à¹‰ model "à¹€à¸«à¹‡à¸™" à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸„à¸§à¸£à¸ˆà¸°à¹€à¸›à¹‡à¸™ unseen data

4. à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™ branches à¸—à¸µà¹ˆà¸¡à¸µà¸„à¸³à¸§à¹ˆà¸² "experiment" à¹ƒà¸™à¸Šà¸·à¹ˆà¸­

5. à¸­à¹ˆà¸²à¸™à¸‡à¹ˆà¸²à¸¢, à¹à¸à¹‰à¹„à¸‚à¸‡à¹ˆà¸²à¸¢, à¸£à¸­à¸‡à¸£à¸±à¸š hierarchical data, à¸ªà¸²à¸¡à¸²à¸£à¸– version control à¹„à¸”à¹‰, à¹à¸¢à¸ config à¸­à¸­à¸à¸ˆà¸²à¸ code

6. `git push -u origin <branch>` à¹ƒà¸Šà¹‰à¸„à¸£à¸±à¹‰à¸‡à¹à¸£à¸à¹€à¸žà¸·à¹ˆà¸­à¸•à¸±à¹‰à¸‡ upstream tracking à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ local branch à¸à¸±à¸š remote branch à¸«à¸¥à¸±à¸‡à¸ˆà¸²à¸à¸™à¸±à¹‰à¸™à¹ƒà¸Šà¹‰à¹à¸„à¹ˆ `git push` à¸à¹‡à¸žà¸­ à¹€à¸žà¸£à¸²à¸° Git à¸ˆà¸³à¹„à¸”à¹‰à¸§à¹ˆà¸²à¸•à¹‰à¸­à¸‡ push à¹„à¸›à¸—à¸µà¹ˆà¹„à¸«à¸™

7. à¹€à¸žà¸·à¹ˆà¸­ backup code à¸šà¸™ server, à¸—à¸³à¸‡à¸²à¸™à¸£à¹ˆà¸§à¸¡à¸à¸±à¸šà¸—à¸µà¸¡, à¹€à¸‚à¹‰à¸²à¸–à¸¶à¸‡ code à¸ˆà¸²à¸à¸—à¸µà¹ˆà¸­à¸·à¹ˆà¸™à¹„à¸”à¹‰, à¹à¸¥à¸°à¹€à¸›à¹‡à¸™ single source of truth à¸ªà¸³à¸«à¸£à¸±à¸šà¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œ

</details>

---

## âœ… Checklist à¸à¹ˆà¸­à¸™à¸ˆà¸š LAB

- [ ] à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸à¸²à¸£à¹ƒà¸Šà¹‰ Pipeline (`|`) à¸à¸±à¸š ML workflows
- [ ] à¹ƒà¸Šà¹‰ Here Document à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ Python à¹à¸¥à¸° YAML à¹„à¸”à¹‰
- [ ] à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡ ML project à¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸›à¹‡à¸™à¸£à¸°à¸šà¸š
- [ ] à¹ƒà¸Šà¹‰ Git Branch à¸ªà¸³à¸«à¸£à¸±à¸š experiments à¸•à¹ˆà¸²à¸‡à¹† à¹„à¸”à¹‰
- [ ] à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆ sklearn preprocessing pipeline
- [ ] Merge branches à¹à¸¥à¸°à¸ˆà¸±à¸”à¸à¸²à¸£ branch à¹„à¸”à¹‰
- [ ] à¸ªà¸£à¹‰à¸²à¸‡à¸£à¸°à¸šà¸š config à¹à¸¥à¸° logging à¸ªà¸³à¸«à¸£à¸±à¸š experiments
- [ ] à¹ƒà¸Šà¹‰ `tree` à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¹„à¸”à¹‰
- [ ] à¹ƒà¸Šà¹‰ Pipeline à¸à¸±à¸š git commands à¹„à¸”à¹‰
- [ ] à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¹à¸¥à¸° Push à¹„à¸› Remote Repository à¹„à¸”à¹‰
- [ ] à¸ˆà¸±à¸”à¸à¸²à¸£ Remote Branches (à¸ªà¸£à¹‰à¸²à¸‡, à¸¥à¸š, à¸”à¸¹) à¹„à¸”à¹‰

---

## ðŸ“š à¹à¸«à¸¥à¹ˆà¸‡à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¹€à¸žà¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡

- [Scikit-Learn Documentation](https://scikit-learn.org/stable/)
- [Git Branching Strategies](https://www.atlassian.com/git/tutorials/comparing-workflows)
- [MLOps Principles](https://ml-ops.org/)
- [Python Project Structure](https://docs.python-guide.org/writing/structure/)

---

**Happy Learning! ðŸŽ“**