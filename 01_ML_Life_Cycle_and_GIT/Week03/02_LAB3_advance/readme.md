# ðŸ§ª LAB: MLOps with Scikit-Learn à¹à¸¥à¸° Git Branch Workflow

## ðŸ“‹ à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œà¸à¸²à¸£à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰

à¸«à¸¥à¸±à¸‡à¸ˆà¸²à¸à¸—à¸³ LAB à¸™à¸µà¹‰à¹€à¸ªà¸£à¹‡à¸ˆ à¸™à¸±à¸à¸¨à¸¶à¸à¸©à¸²à¸ˆà¸°à¸ªà¸²à¸¡à¸²à¸£à¸–:
- âœ… à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œ Machine Learning à¸”à¹‰à¸§à¸¢ Scikit-Learn
- âœ… à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Git Branch à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸—à¸”à¸¥à¸­à¸‡ ML Models à¸•à¹ˆà¸²à¸‡à¹†
- âœ… à¸ˆà¸±à¸”à¸à¸²à¸£ Feature Engineering à¹ƒà¸™ Branch à¹à¸¢à¸
- âœ… à¹ƒà¸Šà¹‰ Pipeline à¹ƒà¸™ Linux à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ
- âœ… à¹ƒà¸Šà¹‰ `tree` à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œ ML
- âœ… à¹ƒà¸Šà¹‰ Here Document à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ Python à¹à¸¥à¸° Config
- âœ… à¸•à¸´à¸”à¸•à¸²à¸¡ Model Experiments à¸”à¹‰à¸§à¸¢ Git
- âœ… à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆ MLOps Workflow à¸žà¸·à¹‰à¸™à¸à¸²à¸™

---

## ðŸ“š à¸„à¸§à¸²à¸¡à¸£à¸¹à¹‰à¸žà¸·à¹‰à¸™à¸à¸²à¸™

### MLOps à¸„à¸·à¸­à¸­à¸°à¹„à¸£?

**MLOps** (Machine Learning Operations) à¸„à¸·à¸­à¹à¸™à¸§à¸›à¸à¸´à¸šà¸±à¸•à¸´à¸—à¸µà¹ˆà¸£à¸§à¸¡ ML, DevOps à¹à¸¥à¸° Data Engineering à¹€à¸‚à¹‰à¸²à¸”à¹‰à¸§à¸¢à¸à¸±à¸™ à¹€à¸žà¸·à¹ˆà¸­:
- à¸ˆà¸±à¸”à¸à¸²à¸£ ML Models à¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸›à¹‡à¸™à¸£à¸°à¸šà¸š
- à¸—à¸³à¹ƒà¸«à¹‰à¸à¸²à¸£ Deploy à¹à¸¥à¸° Monitor à¹€à¸›à¹‡à¸™à¹„à¸›à¸­à¸¢à¹ˆà¸²à¸‡à¸£à¸²à¸šà¸£à¸·à¹ˆà¸™
- à¸•à¸´à¸”à¸•à¸²à¸¡ Experiments à¹à¸¥à¸° Versions

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      MLOps Lifecycle                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚   Data â†’ Feature Engineering â†’ Model Training â†’ Evaluation  â”‚
â”‚     â†‘                                                   â†“    â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Monitoring â†â”€â”€ Deployment â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                              â”‚
â”‚   ðŸ”§ Git: Version Control à¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸¸à¸à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™                   â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### à¸—à¸³à¹„à¸¡à¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰ Git Branch à¸à¸±à¸š ML Projects?

| à¸ªà¸–à¸²à¸™à¸à¸²à¸£à¸“à¹Œ | Branch à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰ | à¸›à¸£à¸°à¹‚à¸¢à¸Šà¸™à¹Œ |
|-----------|--------------|---------|
| à¸—à¸”à¸¥à¸­à¸‡ Model à¹ƒà¸«à¸¡à¹ˆ | `experiment/random-forest` | à¹„à¸¡à¹ˆà¸à¸£à¸°à¸—à¸š code à¸«à¸¥à¸±à¸ |
| Feature Engineering | `feature/scaling-normalization` | à¸žà¸±à¸’à¸™à¸²à¹à¸¢à¸ merge à¸—à¸µà¸«à¸¥à¸±à¸‡ |
| Hyperparameter Tuning | `tune/grid-search-rf` | à¹€à¸à¹‡à¸š config à¹à¸•à¹ˆà¸¥à¸°à¸„à¸£à¸±à¹‰à¸‡ |
| Bug Fix | `fix/data-leakage` | à¹à¸à¹‰à¹„à¸‚à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸à¸£à¸°à¸—à¸šà¸à¸²à¸£à¸—à¸”à¸¥à¸­à¸‡ |

---

## ðŸ”§ à¸„à¸§à¸²à¸¡à¸£à¸¹à¹‰à¹€à¸šà¸·à¹‰à¸­à¸‡à¸•à¹‰à¸™: Pipeline à¹ƒà¸™ Linux à¸ªà¸³à¸«à¸£à¸±à¸š ML

### Pipeline (`|`) à¸„à¸·à¸­à¸­à¸°à¹„à¸£?

**Pipeline** à¸„à¸·à¸­à¸à¸²à¸£à¸ªà¹ˆà¸‡à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸ˆà¸²à¸à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸«à¸™à¸¶à¹ˆà¸‡à¹„à¸›à¹€à¸›à¹‡à¸™ input à¸‚à¸­à¸‡à¸­à¸µà¸à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸«à¸™à¸¶à¹ˆà¸‡ à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸«à¸¡à¸²à¸¢ `|` (pipe)

```
à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸—à¸µà¹ˆ 1  |  à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸—à¸µà¹ˆ 2  |  à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸—à¸µà¹ˆ 3
    â†“              â†“              â†“
  output    â†’    input     â†’   output
            â†’              â†’    input
                           â†’   output (à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢)
```

### à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡ Pipeline à¸ªà¸³à¸«à¸£à¸±à¸š ML Projects

```bash
# à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸—à¸µà¹ˆ 1: à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™ Python files
ls *.py | wc -l
```

**à¸­à¸˜à¸´à¸šà¸²à¸¢à¸—à¸µà¸¥à¸°à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™:**
```
ls *.py         â†’  à¹à¸ªà¸”à¸‡à¹„à¸Ÿà¸¥à¹Œ .py à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”
                   train.py
                   model.py
                   evaluate.py
        |
        â†“
wc -l           â†’  à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¸šà¸£à¸£à¸—à¸±à¸”
                   à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ: 3
```

```bash
# à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸—à¸µà¹ˆ 2: à¸„à¹‰à¸™à¸«à¸² experiments branches
git branch | grep "experiment"
```

**à¸­à¸˜à¸´à¸šà¸²à¸¢à¸—à¸µà¸¥à¸°à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™:**
```
git branch      â†’  à¹à¸ªà¸”à¸‡à¸£à¸²à¸¢à¸Šà¸·à¹ˆà¸­ branch
                   * main
                     experiment/random-forest
                     experiment/svm
                     feature/scaling
        |
        â†“
grep "experiment" â†’  à¸à¸£à¸­à¸‡à¹€à¸‰à¸žà¸²à¸°à¸šà¸£à¸£à¸—à¸±à¸”à¸—à¸µà¹ˆà¸¡à¸µ "experiment"
                      à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ:
                        experiment/random-forest
                        experiment/svm
```

```bash
# à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸—à¸µà¹ˆ 3: à¸”à¸¹ commit à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸š model
git log --oneline | grep -i "model" | head -5
```

```bash
# à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸—à¸µà¹ˆ 4: à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™ experiment branches
git branch | grep "experiment" | wc -l
```

### à¸ªà¸£à¸¸à¸›à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸šà¹ˆà¸­à¸¢à¸à¸±à¸š Pipeline

| à¸„à¸³à¸ªà¸±à¹ˆà¸‡ | à¸«à¸™à¹‰à¸²à¸—à¸µà¹ˆ | à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡ |
|--------|--------|----------|
| `grep "text"` | à¸à¸£à¸­à¸‡à¸šà¸£à¸£à¸—à¸±à¸”à¸—à¸µà¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡ | `cat log.txt \| grep "accuracy"` |
| `wc -l` | à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¸šà¸£à¸£à¸—à¸±à¸” | `ls *.py \| wc -l` |
| `head -n` | à¹€à¸­à¸² n à¸šà¸£à¸£à¸—à¸±à¸”à¹à¸£à¸ | `cat results.csv \| head -10` |
| `tail -n` | à¹€à¸­à¸² n à¸šà¸£à¸£à¸—à¸±à¸”à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢ | `cat training.log \| tail -20` |
| `sort` | à¹€à¸£à¸µà¸¢à¸‡à¸¥à¸³à¸”à¸±à¸š | `cat scores.txt \| sort -n` |
| `cut -d, -f1` | à¸•à¸±à¸”à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸ˆà¸²à¸ CSV | `cat data.csv \| cut -d, -f1` |

---

## ðŸ”§ à¸„à¸§à¸²à¸¡à¸£à¸¹à¹‰à¹€à¸šà¸·à¹‰à¸­à¸‡à¸•à¹‰à¸™: Here Document (Heredoc)

### Here Document à¸„à¸·à¸­à¸­à¸°à¹„à¸£?

**Here Document** à¸„à¸·à¸­à¸§à¸´à¸˜à¸µà¸à¸²à¸£à¹€à¸‚à¸µà¸¢à¸™à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸«à¸¥à¸²à¸¢à¸šà¸£à¸£à¸—à¸±à¸”à¸¥à¸‡à¹„à¸Ÿà¸¥à¹Œà¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸à¸” Ctrl+D

```bash
cat > à¸Šà¸·à¹ˆà¸­à¹„à¸Ÿà¸¥à¹Œ << 'EOF'
à¹€à¸™à¸·à¹‰à¸­à¸«à¸²à¸šà¸£à¸£à¸—à¸±à¸”à¸—à¸µà¹ˆ 1
à¹€à¸™à¸·à¹‰à¸­à¸«à¸²à¸šà¸£à¸£à¸—à¸±à¸”à¸—à¸µà¹ˆ 2
à¹€à¸™à¸·à¹‰à¸­à¸«à¸²à¸šà¸£à¸£à¸—à¸±à¸”à¸—à¸µà¹ˆ 3
EOF
```

**à¸­à¸˜à¸´à¸šà¸²à¸¢:**
- `cat > à¸Šà¸·à¹ˆà¸­à¹„à¸Ÿà¸¥à¹Œ` = à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œà¹ƒà¸«à¸¡à¹ˆ
- `<< 'EOF'` = à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™ Here Document (EOF = End Of File, à¹ƒà¸Šà¹‰à¸„à¸³à¸­à¸·à¹ˆà¸™à¸à¹‡à¹„à¸”à¹‰)
- `EOF` = à¸ªà¸´à¹‰à¸™à¸ªà¸¸à¸” Here Document

### à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸§à¸´à¸˜à¸µà¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ

| à¸§à¸´à¸˜à¸µ | à¸‚à¹‰à¸­à¸”à¸µ | à¸‚à¹‰à¸­à¹€à¸ªà¸µà¸¢ |
|------|-------|---------|
| `echo "text" > file` | à¸‡à¹ˆà¸²à¸¢ à¸£à¸§à¸”à¹€à¸£à¹‡à¸§ | à¹€à¸‚à¸µà¸¢à¸™à¹„à¸”à¹‰à¹à¸„à¹ˆà¸šà¸£à¸£à¸—à¸±à¸”à¹€à¸”à¸µà¸¢à¸§ |
| `cat > file` à¹à¸¥à¹‰à¸§ Ctrl+D | à¹€à¸‚à¸µà¸¢à¸™à¹„à¸”à¹‰à¸«à¸¥à¸²à¸¢à¸šà¸£à¸£à¸—à¸±à¸” | à¸•à¹‰à¸­à¸‡à¸ˆà¸³à¸à¸” Ctrl+D |
| `cat > file << 'EOF'` | à¹€à¸‚à¸µà¸¢à¸™à¹„à¸”à¹‰à¸«à¸¥à¸²à¸¢à¸šà¸£à¸£à¸—à¸±à¸”, à¸Šà¸±à¸”à¹€à¸ˆà¸™ | à¸žà¸´à¸¡à¸žà¹Œà¸¢à¸²à¸§à¸à¸§à¹ˆà¸² |

---

## ðŸ› ï¸ à¹€à¸•à¸£à¸µà¸¢à¸¡à¸„à¸§à¸²à¸¡à¸žà¸£à¹‰à¸­à¸¡

### à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 1: à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² Git (à¸–à¹‰à¸²à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹€à¸„à¸¢à¸•à¸±à¹‰à¸‡)

```bash
# à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¸Šà¸·à¹ˆà¸­à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰
git config --global user.name "à¸Šà¸·à¹ˆà¸­à¸‚à¸­à¸‡à¸„à¸¸à¸“"

# à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¸­à¸µà¹€à¸¡à¸¥
git config --global user.email "your.email@example.com"

# à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸à¸²à¸£à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²
git config --list
```

### à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 2: à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œ ML à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸¶à¸

```bash
# à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œà¹ƒà¸«à¸¡à¹ˆ
mkdir sklearn-mlops-lab
cd sklearn-mlops-lab

# à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™ Git repository
git init

# à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸ªà¸–à¸²à¸™à¸°
git status
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
Initialized empty Git repository in /path/to/sklearn-mlops-lab/.git/
```

### à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 3: à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Python à¹à¸¥à¸° Scikit-Learn

```bash
# à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Python version
python3 --version

# à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š pip
pip3 --version

# à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ scikit-learn (à¸–à¹‰à¸²à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µ)
pip3 install scikit-learn pandas numpy joblib

# à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡à¸ªà¸³à¹€à¸£à¹‡à¸ˆ
python3 -c "import sklearn; print(f'sklearn version: {sklearn.__version__}')"
```

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 0: à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œ ML à¸”à¹‰à¸§à¸¢ Here Document

### 0.1 à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ README.md

```bash
cat > README.md << 'EOF'
# Sklearn MLOps Lab
à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰ MLOps à¸”à¹‰à¸§à¸¢ Scikit-Learn à¹à¸¥à¸° Git

## ðŸ“ à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œ
```
sklearn-mlops-lab/
â”œâ”€â”€ data/           # à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸š training
â”œâ”€â”€ models/         # à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸µà¹ˆ train à¹à¸¥à¹‰à¸§
â”œâ”€â”€ src/            # source code
â”œâ”€â”€ notebooks/      # Jupyter notebooks
â”œâ”€â”€ configs/        # configuration files
â”œâ”€â”€ results/        # à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸à¸²à¸£à¸—à¸”à¸¥à¸­à¸‡
â””â”€â”€ tests/          # unit tests
```

## ðŸŽ¯ à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢
- à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¸à¸²à¸£à¹ƒà¸Šà¹‰ Git Branch à¸à¸±à¸š ML Projects
- à¸—à¸”à¸¥à¸­à¸‡ Models à¸«à¸¥à¸²à¸¢à¹† à¹à¸šà¸šà¹ƒà¸™ Branches à¸•à¹ˆà¸²à¸‡à¹†
- à¸•à¸´à¸”à¸•à¸²à¸¡ Experiments à¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸›à¹‡à¸™à¸£à¸°à¸šà¸š

## ðŸ‘¤ à¸œà¸¹à¹‰à¸ˆà¸±à¸”à¸—à¸³
- à¸™à¸±à¸à¸¨à¸¶à¸à¸©à¸²: [à¸Šà¸·à¹ˆà¸­à¸‚à¸­à¸‡à¸„à¸¸à¸“]
- à¸£à¸«à¸±à¸ª: [à¸£à¸«à¸±à¸ªà¸™à¸±à¸à¸¨à¸¶à¸à¸©à¸²]
EOF
```

```bash
# à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¸ªà¸£à¹‰à¸²à¸‡
cat README.md
```

### 0.2 à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ

```bash
# à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œà¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”
mkdir -p data/raw data/processed
mkdir -p models
mkdir -p src/data src/features src/models src/utils
mkdir -p notebooks
mkdir -p configs
mkdir -p results
mkdir -p tests
```

### 0.3 à¹ƒà¸Šà¹‰ tree à¸”à¸¹à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œ

```bash
# à¸”à¸¹à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ
tree
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ configs
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ processed
â”‚   â””â”€â”€ raw
â”œâ”€â”€ models
â”œâ”€â”€ notebooks
â”œâ”€â”€ results
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ data
â”‚   â”œâ”€â”€ features
â”‚   â”œâ”€â”€ models
â”‚   â””â”€â”€ utils
â””â”€â”€ tests

13 directories, 1 file
```

### 0.4 à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ requirements.txt

```bash
cat > requirements.txt << 'EOF'
# Core ML Libraries
scikit-learn>=1.3.0
pandas>=2.0.0
numpy>=1.24.0

# Model Persistence
joblib>=1.3.0

# Visualization
matplotlib>=3.7.0
seaborn>=0.12.0

# Utilities
python-dotenv>=1.0.0
PyYAML>=6.0

# Testing
pytest>=7.4.0
EOF
```

### 0.5 à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ .gitignore à¸ªà¸³à¸«à¸£à¸±à¸š ML Projects

```bash
cat > .gitignore << 'EOF'
# Python
__pycache__/
*.py[cod]
*.so
.Python
*.egg-info/
dist/
build/

# Virtual environments
venv/
.env/
env/

# Jupyter Notebooks
.ipynb_checkpoints/
*.ipynb_checkpoints

# Data files (large files)
data/raw/*.csv
data/raw/*.xlsx
data/processed/*.pkl
*.parquet

# Model files (large files)
models/*.pkl
models/*.joblib
*.h5
*.pt
*.pth

# IDE
.vscode/
.idea/
*.swp

# OS
.DS_Store
Thumbs.db

# Logs
*.log
logs/

# Results (optional - à¸­à¸²à¸ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£ track)
# results/

# Secrets
.env
*.key
EOF
```

### 0.6 à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ __init__.py à¸ªà¸³à¸«à¸£à¸±à¸š packages

```bash
# à¸ªà¸£à¹‰à¸²à¸‡ __init__.py à¹ƒà¸™à¸—à¸¸à¸ package
touch src/__init__.py
touch src/data/__init__.py
touch src/features/__init__.py
touch src/models/__init__.py
touch src/utils/__init__.py
touch tests/__init__.py
```

### 0.7 à¸”à¸¹à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¸—à¸µà¹ˆà¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œ

```bash
# à¸”à¸¹à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¸žà¸£à¹‰à¸­à¸¡à¹„à¸Ÿà¸¥à¹Œ
tree -a -I '.git'
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
.
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ configs
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ processed
â”‚   â””â”€â”€ raw
â”œâ”€â”€ models
â”œâ”€â”€ notebooks
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ results
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ features
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ models
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â””â”€â”€ utils
â”‚       â””â”€â”€ __init__.py
â””â”€â”€ tests
    â””â”€â”€ __init__.py
```

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 1: à¸ªà¸£à¹‰à¸²à¸‡ Data Loading Module

### 1.1 à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ load_data.py

```bash
cat > src/data/load_data.py << 'EOF'
"""
Data Loading Module
à¹‚à¸¡à¸”à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸šà¹‚à¸«à¸¥à¸”à¹à¸¥à¸°à¸ˆà¸±à¸”à¸à¸²à¸£à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
"""

import pandas as pd
import numpy as np
from sklearn.datasets import load_iris, load_wine, load_breast_cancer
from sklearn.model_selection import train_test_split


def load_sklearn_dataset(name: str = 'iris') -> tuple:
    """
    à¹‚à¸«à¸¥à¸” dataset à¸ˆà¸²à¸ sklearn
    
    Args:
        name: à¸Šà¸·à¹ˆà¸­ dataset ('iris', 'wine', 'breast_cancer')
    
    Returns:
        tuple: (X, y, feature_names, target_names)
    """
    datasets = {
        'iris': load_iris,
        'wine': load_wine,
        'breast_cancer': load_breast_cancer
    }
    
    if name not in datasets:
        raise ValueError(f"Dataset '{name}' not found. Available: {list(datasets.keys())}")
    
    data = datasets[name]()
    
    print(f"âœ“ Loaded {name} dataset")
    print(f"  Samples: {data.data.shape[0]}")
    print(f"  Features: {data.data.shape[1]}")
    print(f"  Classes: {len(data.target_names)}")
    
    return data.data, data.target, data.feature_names, data.target_names


def split_data(X, y, test_size: float = 0.2, random_state: int = 42) -> tuple:
    """
    à¹à¸šà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸›à¹‡à¸™ train à¹à¸¥à¸° test sets
    
    Args:
        X: features
        y: targets
        test_size: à¸ªà¸±à¸”à¸ªà¹ˆà¸§à¸™à¸‚à¸­à¸‡ test set
        random_state: seed à¸ªà¸³à¸«à¸£à¸±à¸š reproducibility
    
    Returns:
        tuple: (X_train, X_test, y_train, y_test)
    """
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state, stratify=y
    )
    
    print(f"âœ“ Data split completed")
    print(f"  Train: {X_train.shape[0]} samples")
    print(f"  Test: {X_test.shape[0]} samples")
    
    return X_train, X_test, y_train, y_test


def create_dataframe(X, y, feature_names) -> pd.DataFrame:
    """
    à¸ªà¸£à¹‰à¸²à¸‡ DataFrame à¸ˆà¸²à¸ numpy arrays
    """
    df = pd.DataFrame(X, columns=feature_names)
    df['target'] = y
    return df


if __name__ == "__main__":
    # à¸—à¸”à¸ªà¸­à¸š module
    X, y, features, targets = load_sklearn_dataset('iris')
    X_train, X_test, y_train, y_test = split_data(X, y)
    df = create_dataframe(X, y, features)
    print(f"\nðŸ“Š DataFrame shape: {df.shape}")
    print(df.head())
EOF
```

### 1.2 à¸—à¸”à¸ªà¸­à¸š Data Loading Module

```bash
# à¸£à¸±à¸™ module
python3 src/data/load_data.py
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
âœ“ Loaded iris dataset
  Samples: 150
  Features: 4
  Classes: 3
âœ“ Data split completed
  Train: 120 samples
  Test: 30 samples

ðŸ“Š DataFrame shape: (150, 5)
   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  target
0                5.1               3.5                1.4               0.2       0
1                4.9               3.0                1.4               0.2       0
2                4.7               3.2                1.3               0.2       0
3                4.6               3.1                1.5               0.2       0
4                5.0               3.6                1.4               0.2       0
```

### 1.3 Commit Initial Structure

```bash
# à¸”à¸¹à¸ªà¸–à¸²à¸™à¸°
git status

# à¹€à¸žà¸´à¹ˆà¸¡à¹„à¸Ÿà¸¥à¹Œà¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”
git add .

# Commit à¸„à¸£à¸±à¹‰à¸‡à¹à¸£à¸
git commit -m "Initial commit: à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡ ML project à¸žà¸£à¹‰à¸­à¸¡ data loading module"

# à¸”à¸¹ log
git log --oneline
```

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 2: à¸ªà¸£à¹‰à¸²à¸‡ Feature Engineering Module à¹ƒà¸™ Branch à¹ƒà¸«à¸¡à¹ˆ

### 2.1 à¸ªà¸£à¹‰à¸²à¸‡ Branch à¸ªà¸³à¸«à¸£à¸±à¸š Feature Engineering

```bash
# à¸ªà¸£à¹‰à¸²à¸‡ branch à¹ƒà¸«à¸¡à¹ˆà¹à¸¥à¸°à¸ªà¸¥à¸±à¸šà¹„à¸›
git switch -c feature/preprocessing

# à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸­à¸¢à¸¹à¹ˆ branch à¹„à¸«à¸™
git branch
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
* feature/preprocessing
  main
```

### 2.2 à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ preprocessing.py

```bash
cat > src/features/preprocessing.py << 'EOF'
"""
Feature Preprocessing Module
à¹‚à¸¡à¸”à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸š preprocessing features
"""

import numpy as np
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler
from sklearn.preprocessing import LabelEncoder, OneHotEncoder


class FeaturePreprocessor:
    """
    Class à¸ªà¸³à¸«à¸£à¸±à¸š preprocessing features
    """
    
    def __init__(self, scaling_method: str = 'standard'):
        """
        Initialize preprocessor
        
        Args:
            scaling_method: à¸§à¸´à¸˜à¸µà¸à¸²à¸£ scale ('standard', 'minmax', 'robust')
        """
        self.scaling_method = scaling_method
        self.scaler = self._get_scaler()
        self.is_fitted = False
    
    def _get_scaler(self):
        """à¹€à¸¥à¸·à¸­à¸ scaler à¸•à¸²à¸¡ method à¸—à¸µà¹ˆà¸à¸³à¸«à¸™à¸”"""
        scalers = {
            'standard': StandardScaler(),
            'minmax': MinMaxScaler(),
            'robust': RobustScaler()
        }
        
        if self.scaling_method not in scalers:
            raise ValueError(f"Unknown scaling method: {self.scaling_method}")
        
        return scalers[self.scaling_method]
    
    def fit(self, X):
        """Fit scaler à¸à¸±à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ training"""
        self.scaler.fit(X)
        self.is_fitted = True
        print(f"âœ“ Fitted {self.scaling_method} scaler")
        return self
    
    def transform(self, X):
        """Transform à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸”à¹‰à¸§à¸¢ scaler à¸—à¸µà¹ˆ fit à¹à¸¥à¹‰à¸§"""
        if not self.is_fitted:
            raise RuntimeError("Scaler has not been fitted. Call fit() first.")
        
        X_scaled = self.scaler.transform(X)
        print(f"âœ“ Transformed data with {self.scaling_method} scaler")
        return X_scaled
    
    def fit_transform(self, X):
        """Fit à¹à¸¥à¸° transform à¹ƒà¸™à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¹€à¸”à¸µà¸¢à¸§"""
        self.fit(X)
        return self.transform(X)
    
    def get_stats(self):
        """à¹à¸ªà¸”à¸‡à¸ªà¸–à¸´à¸•à¸´à¸‚à¸­à¸‡ scaler"""
        if not self.is_fitted:
            return None
        
        if hasattr(self.scaler, 'mean_'):
            print("\nðŸ“Š Scaler Statistics:")
            print(f"  Mean: {self.scaler.mean_}")
            print(f"  Scale: {self.scaler.scale_}")
        elif hasattr(self.scaler, 'data_min_'):
            print("\nðŸ“Š Scaler Statistics:")
            print(f"  Min: {self.scaler.data_min_}")
            print(f"  Max: {self.scaler.data_max_}")


def preprocess_pipeline(X_train, X_test, method: str = 'standard'):
    """
    Pipeline à¸ªà¸³à¸«à¸£à¸±à¸š preprocessing à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
    
    Args:
        X_train: training features
        X_test: test features
        method: scaling method
    
    Returns:
        tuple: (X_train_scaled, X_test_scaled, preprocessor)
    """
    preprocessor = FeaturePreprocessor(scaling_method=method)
    
    # Fit à¸à¸±à¸š train data à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™!
    X_train_scaled = preprocessor.fit_transform(X_train)
    
    # Transform test data à¸”à¹‰à¸§à¸¢ parameters à¸ˆà¸²à¸ train
    X_test_scaled = preprocessor.transform(X_test)
    
    return X_train_scaled, X_test_scaled, preprocessor


if __name__ == "__main__":
    # à¸—à¸”à¸ªà¸­à¸š module
    import sys
    sys.path.insert(0, '.')
    from src.data.load_data import load_sklearn_dataset, split_data
    
    # à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
    X, y, features, targets = load_sklearn_dataset('iris')
    X_train, X_test, y_train, y_test = split_data(X, y)
    
    print("\n" + "="*50)
    print("Testing StandardScaler")
    print("="*50)
    
    # à¸—à¸”à¸ªà¸­à¸š StandardScaler
    X_train_scaled, X_test_scaled, preprocessor = preprocess_pipeline(
        X_train, X_test, method='standard'
    )
    
    preprocessor.get_stats()
    
    print(f"\nðŸ“ˆ Original X_train mean: {X_train.mean(axis=0)}")
    print(f"ðŸ“‰ Scaled X_train mean: {X_train_scaled.mean(axis=0)}")
    
    print("\n" + "="*50)
    print("Testing MinMaxScaler")
    print("="*50)
    
    # à¸—à¸”à¸ªà¸­à¸š MinMaxScaler
    X_train_mm, X_test_mm, _ = preprocess_pipeline(
        X_train, X_test, method='minmax'
    )
    
    print(f"\nðŸ“ˆ MinMax X_train range: [{X_train_mm.min():.2f}, {X_train_mm.max():.2f}]")
EOF
```

### 2.3 à¸—à¸”à¸ªà¸­à¸š Preprocessing Module

```bash
# à¸£à¸±à¸™ module
python3 src/features/preprocessing.py
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
âœ“ Loaded iris dataset
  Samples: 150
  Features: 4
  Classes: 3
âœ“ Data split completed
  Train: 120 samples
  Test: 30 samples

==================================================
Testing StandardScaler
==================================================
âœ“ Fitted standard scaler
âœ“ Transformed data with standard scaler
âœ“ Transformed data with standard scaler

ðŸ“Š Scaler Statistics:
  Mean: [5.84583333 3.06333333 3.7775     1.20583333]
  Scale: [0.82898063 0.44344109 1.75004544 0.76508862]

ðŸ“ˆ Original X_train mean: [5.84583333 3.06333333 3.7775     1.20583333]
ðŸ“‰ Scaled X_train mean: [-1.11022302e-15 -5.62883073e-16  3.28903977e-16  1.11022302e-16]

==================================================
Testing MinMaxScaler
==================================================
âœ“ Fitted minmax scaler
âœ“ Transformed data with minmax scaler
âœ“ Transformed data with minmax scaler

ðŸ“ˆ MinMax X_train range: [0.00, 1.00]
```

### 2.4 à¹ƒà¸Šà¹‰ tree à¸”à¸¹à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¸—à¸µà¹ˆà¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡

```bash
# à¸”à¸¹à¹€à¸‰à¸žà¸²à¸° src/features
tree src/features
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
src/features
â”œâ”€â”€ __init__.py
â””â”€â”€ preprocessing.py

0 directories, 2 files
```

### 2.5 Commit à¹à¸¥à¸°à¸”à¸¹ Branch

```bash
# à¸”à¸¹à¸ªà¸–à¸²à¸™à¸°
git status

# Commit
git add .
git commit -m "feat: à¹€à¸žà¸´à¹ˆà¸¡ feature preprocessing module à¸žà¸£à¹‰à¸­à¸¡ scalers"

# à¸”à¸¹ log
git log --oneline
```

### 2.6 à¸”à¸¹ refs à¸‚à¸­à¸‡ Git

```bash
# à¸”à¸¹à¸§à¹ˆà¸² Git à¹€à¸à¹‡à¸š branch à¹„à¸§à¹‰à¸—à¸µà¹ˆà¹„à¸«à¸™
tree .git/refs/heads
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
.git/refs/heads
â”œâ”€â”€ feature
â”‚   â””â”€â”€ preprocessing
â””â”€â”€ main

1 directory, 2 files
```

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 3: à¸ªà¸£à¹‰à¸²à¸‡ Model Training Module à¹ƒà¸™ Branch à¹ƒà¸«à¸¡à¹ˆ

### 3.1 à¸à¸¥à¸±à¸šà¹„à¸› main à¹à¸¥à¸°à¸ªà¸£à¹‰à¸²à¸‡ branch à¹ƒà¸«à¸¡à¹ˆ

```bash
# à¸à¸¥à¸±à¸šà¹„à¸› main
git switch main

# à¸”à¸¹à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡ - à¸ªà¸±à¸‡à¹€à¸à¸•à¸§à¹ˆà¸² preprocessing.py à¸«à¸²à¸¢à¹„à¸›
tree src/features

# à¸ªà¸£à¹‰à¸²à¸‡ branch à¹ƒà¸«à¸¡à¹ˆà¸ªà¸³à¸«à¸£à¸±à¸š experiment
git switch -c experiment/logistic-regression

# à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š branches à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”
git branch
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
* experiment/logistic-regression
  feature/preprocessing
  main
```

### 3.2 à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ train.py

```bash
cat > src/models/train.py << 'EOF'
"""
Model Training Module
à¹‚à¸¡à¸”à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸š training ML models
"""

import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import joblib
import os
from datetime import datetime


class ModelTrainer:
    """
    Class à¸ªà¸³à¸«à¸£à¸±à¸š training à¹à¸¥à¸° evaluate models
    """
    
    def __init__(self, model_name: str = 'logistic_regression'):
        """
        Initialize trainer
        
        Args:
            model_name: à¸Šà¸·à¹ˆà¸­ model
        """
        self.model_name = model_name
        self.model = self._get_model()
        self.is_trained = False
        self.training_history = {}
    
    def _get_model(self):
        """à¸ªà¸£à¹‰à¸²à¸‡ model instance"""
        if self.model_name == 'logistic_regression':
            return LogisticRegression(max_iter=200, random_state=42)
        else:
            raise ValueError(f"Unknown model: {self.model_name}")
    
    def train(self, X_train, y_train):
        """Train model"""
        print(f"ðŸš€ Training {self.model_name}...")
        
        start_time = datetime.now()
        self.model.fit(X_train, y_train)
        end_time = datetime.now()
        
        self.is_trained = True
        self.training_history['training_time'] = (end_time - start_time).total_seconds()
        self.training_history['n_samples'] = X_train.shape[0]
        self.training_history['n_features'] = X_train.shape[1]
        
        # Train accuracy
        train_pred = self.model.predict(X_train)
        train_acc = accuracy_score(y_train, train_pred)
        self.training_history['train_accuracy'] = train_acc
        
        print(f"âœ“ Training completed in {self.training_history['training_time']:.2f}s")
        print(f"  Train Accuracy: {train_acc:.4f}")
        
        return self
    
    def evaluate(self, X_test, y_test, target_names=None):
        """Evaluate model"""
        if not self.is_trained:
            raise RuntimeError("Model has not been trained. Call train() first.")
        
        print(f"\nðŸ“Š Evaluating {self.model_name}...")
        
        y_pred = self.model.predict(X_test)
        
        # Calculate metrics
        test_acc = accuracy_score(y_test, y_pred)
        self.training_history['test_accuracy'] = test_acc
        
        print(f"  Test Accuracy: {test_acc:.4f}")
        
        # Classification report
        print("\nðŸ“‹ Classification Report:")
        print(classification_report(y_test, y_pred, target_names=target_names))
        
        # Confusion matrix
        print("ðŸ”¢ Confusion Matrix:")
        print(confusion_matrix(y_test, y_pred))
        
        return y_pred, test_acc
    
    def save_model(self, filepath: str = None):
        """Save trained model"""
        if not self.is_trained:
            raise RuntimeError("Model has not been trained.")
        
        if filepath is None:
            os.makedirs('models', exist_ok=True)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filepath = f'models/{self.model_name}_{timestamp}.joblib'
        
        joblib.dump({
            'model': self.model,
            'model_name': self.model_name,
            'training_history': self.training_history
        }, filepath)
        
        print(f"âœ“ Model saved to: {filepath}")
        return filepath
    
    def get_summary(self):
        """à¹à¸ªà¸”à¸‡à¸ªà¸£à¸¸à¸›à¸œà¸¥à¸à¸²à¸£ training"""
        print("\n" + "="*50)
        print(f"ðŸ“ˆ Training Summary: {self.model_name}")
        print("="*50)
        for key, value in self.training_history.items():
            if isinstance(value, float):
                print(f"  {key}: {value:.4f}")
            else:
                print(f"  {key}: {value}")


if __name__ == "__main__":
    # à¸—à¸”à¸ªà¸­à¸š module
    import sys
    sys.path.insert(0, '.')
    from src.data.load_data import load_sklearn_dataset, split_data
    
    # à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
    X, y, features, targets = load_sklearn_dataset('iris')
    X_train, X_test, y_train, y_test = split_data(X, y)
    
    # à¸ªà¸£à¹‰à¸²à¸‡à¹à¸¥à¸° train model
    trainer = ModelTrainer('logistic_regression')
    trainer.train(X_train, y_train)
    
    # Evaluate
    y_pred, accuracy = trainer.evaluate(X_test, y_test, target_names=targets)
    
    # à¹à¸ªà¸”à¸‡à¸ªà¸£à¸¸à¸›
    trainer.get_summary()
    
    # Save model
    model_path = trainer.save_model()
EOF
```

### 3.3 à¸—à¸”à¸ªà¸­à¸š Training Module

```bash
# à¸£à¸±à¸™ module
python3 src/models/train.py
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
âœ“ Loaded iris dataset
  Samples: 150
  Features: 4
  Classes: 3
âœ“ Data split completed
  Train: 120 samples
  Test: 30 samples
ðŸš€ Training logistic_regression...
âœ“ Training completed in 0.02s
  Train Accuracy: 0.9750

ðŸ“Š Evaluating logistic_regression...
  Test Accuracy: 0.9667

ðŸ“‹ Classification Report:
              precision    recall  f1-score   support

      setosa       1.00      1.00      1.00        10
  versicolor       0.91      1.00      0.95        10
   virginica       1.00      0.90      0.95        10

    accuracy                           0.97        30
   macro avg       0.97      0.97      0.97        30
weighted avg       0.97      0.97      0.97        30

ðŸ”¢ Confusion Matrix:
[[10  0  0]
 [ 0 10  0]
 [ 0  1  9]]

==================================================
ðŸ“ˆ Training Summary: logistic_regression
==================================================
  training_time: 0.0234
  n_samples: 120
  n_features: 4
  train_accuracy: 0.9750
  test_accuracy: 0.9667
âœ“ Model saved to: models/logistic_regression_20241215_143022.joblib
```

### 3.4 à¹ƒà¸Šà¹‰ tree à¸”à¸¹à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡

```bash
# à¸”à¸¹à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”
tree -I '__pycache__'
```

### 3.5 Commit

```bash
git add .
git commit -m "experiment: à¹€à¸žà¸´à¹ˆà¸¡ Logistic Regression trainer à¸žà¸£à¹‰à¸­à¸¡ evaluation"

# à¸”à¸¹ log à¸—à¸¸à¸ branch
git log --oneline --graph --all
```

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 4: à¸ªà¸£à¹‰à¸²à¸‡ Experiment à¸­à¸·à¹ˆà¸™à¹† à¹ƒà¸™ Branches à¹à¸¢à¸

### 4.1 à¸ªà¸£à¹‰à¸²à¸‡ Branch à¸ªà¸³à¸«à¸£à¸±à¸š Random Forest

```bash
# à¸à¸¥à¸±à¸šà¹„à¸› main
git switch main

# à¸ªà¸£à¹‰à¸²à¸‡ branch à¹ƒà¸«à¸¡à¹ˆ
git switch -c experiment/random-forest
```

### 4.2 à¹à¸à¹‰à¹„à¸‚ train.py à¹€à¸žà¸·à¹ˆà¸­à¹€à¸žà¸´à¹ˆà¸¡ Random Forest

```bash
cat > src/models/train.py << 'EOF'
"""
Model Training Module
à¹‚à¸¡à¸”à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸š training ML models - Random Forest Version
"""

import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import joblib
import os
from datetime import datetime


class ModelTrainer:
    """
    Class à¸ªà¸³à¸«à¸£à¸±à¸š training à¹à¸¥à¸° evaluate models
    """
    
    def __init__(self, model_name: str = 'random_forest', **kwargs):
        """
        Initialize trainer
        
        Args:
            model_name: à¸Šà¸·à¹ˆà¸­ model
            **kwargs: hyperparameters à¸ªà¸³à¸«à¸£à¸±à¸š model
        """
        self.model_name = model_name
        self.hyperparameters = kwargs
        self.model = self._get_model()
        self.is_trained = False
        self.training_history = {}
    
    def _get_model(self):
        """à¸ªà¸£à¹‰à¸²à¸‡ model instance"""
        default_params = {
            'n_estimators': 100,
            'max_depth': None,
            'min_samples_split': 2,
            'random_state': 42
        }
        
        # à¸£à¸§à¸¡ default à¸à¸±à¸š user params
        params = {**default_params, **self.hyperparameters}
        
        if self.model_name == 'random_forest':
            return RandomForestClassifier(**params)
        else:
            raise ValueError(f"Unknown model: {self.model_name}")
    
    def train(self, X_train, y_train):
        """Train model"""
        print(f"ðŸŒ² Training {self.model_name}...")
        print(f"   Hyperparameters: {self.hyperparameters}")
        
        start_time = datetime.now()
        self.model.fit(X_train, y_train)
        end_time = datetime.now()
        
        self.is_trained = True
        self.training_history['training_time'] = (end_time - start_time).total_seconds()
        self.training_history['n_samples'] = X_train.shape[0]
        self.training_history['n_features'] = X_train.shape[1]
        self.training_history['hyperparameters'] = self.hyperparameters
        
        # Train accuracy
        train_pred = self.model.predict(X_train)
        train_acc = accuracy_score(y_train, train_pred)
        self.training_history['train_accuracy'] = train_acc
        
        print(f"âœ“ Training completed in {self.training_history['training_time']:.2f}s")
        print(f"  Train Accuracy: {train_acc:.4f}")
        
        return self
    
    def evaluate(self, X_test, y_test, target_names=None):
        """Evaluate model"""
        if not self.is_trained:
            raise RuntimeError("Model has not been trained. Call train() first.")
        
        print(f"\nðŸ“Š Evaluating {self.model_name}...")
        
        y_pred = self.model.predict(X_test)
        
        # Calculate metrics
        test_acc = accuracy_score(y_test, y_pred)
        self.training_history['test_accuracy'] = test_acc
        
        print(f"  Test Accuracy: {test_acc:.4f}")
        
        # Classification report
        print("\nðŸ“‹ Classification Report:")
        print(classification_report(y_test, y_pred, target_names=target_names))
        
        # Feature importance
        if hasattr(self.model, 'feature_importances_'):
            print("\nðŸŽ¯ Feature Importances:")
            importances = self.model.feature_importances_
            for i, imp in enumerate(importances):
                print(f"  Feature {i}: {imp:.4f}")
        
        return y_pred, test_acc
    
    def save_model(self, filepath: str = None):
        """Save trained model"""
        if not self.is_trained:
            raise RuntimeError("Model has not been trained.")
        
        if filepath is None:
            os.makedirs('models', exist_ok=True)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filepath = f'models/{self.model_name}_{timestamp}.joblib'
        
        joblib.dump({
            'model': self.model,
            'model_name': self.model_name,
            'training_history': self.training_history
        }, filepath)
        
        print(f"âœ“ Model saved to: {filepath}")
        return filepath
    
    def get_summary(self):
        """à¹à¸ªà¸”à¸‡à¸ªà¸£à¸¸à¸›à¸œà¸¥à¸à¸²à¸£ training"""
        print("\n" + "="*50)
        print(f"ðŸŒ² Training Summary: {self.model_name}")
        print("="*50)
        for key, value in self.training_history.items():
            if isinstance(value, float):
                print(f"  {key}: {value:.4f}")
            elif isinstance(value, dict):
                print(f"  {key}:")
                for k, v in value.items():
                    print(f"    - {k}: {v}")
            else:
                print(f"  {key}: {value}")


if __name__ == "__main__":
    # à¸—à¸”à¸ªà¸­à¸š module
    import sys
    sys.path.insert(0, '.')
    from src.data.load_data import load_sklearn_dataset, split_data
    
    # à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
    X, y, features, targets = load_sklearn_dataset('iris')
    X_train, X_test, y_train, y_test = split_data(X, y)
    
    # à¸—à¸”à¸¥à¸­à¸‡ hyperparameters à¸•à¹ˆà¸²à¸‡à¹†
    experiments = [
        {'n_estimators': 50, 'max_depth': 3},
        {'n_estimators': 100, 'max_depth': 5},
        {'n_estimators': 200, 'max_depth': None}
    ]
    
    results = []
    
    for exp in experiments:
        print("\n" + "="*60)
        trainer = ModelTrainer('random_forest', **exp)
        trainer.train(X_train, y_train)
        y_pred, accuracy = trainer.evaluate(X_test, y_test, target_names=targets)
        results.append({
            'params': exp,
            'test_accuracy': accuracy
        })
    
    # à¸ªà¸£à¸¸à¸›à¸œà¸¥à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”
    print("\n" + "="*60)
    print("ðŸ“Š EXPERIMENT SUMMARY")
    print("="*60)
    for i, result in enumerate(results):
        print(f"\nExperiment {i+1}:")
        print(f"  Params: {result['params']}")
        print(f"  Test Accuracy: {result['test_accuracy']:.4f}")
EOF
```

### 4.3 à¸—à¸”à¸ªà¸­à¸š Random Forest

```bash
python3 src/models/train.py
```

### 4.4 Commit

```bash
git add .
git commit -m "experiment: à¸—à¸”à¸¥à¸­à¸‡ Random Forest à¸à¸±à¸š hyperparameters à¸•à¹ˆà¸²à¸‡à¹†"
```

### 4.5 à¸”à¸¹ branches à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”

```bash
# à¸”à¸¹ branches à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”
git branch -v

# à¹ƒà¸Šà¹‰ Pipeline à¸™à¸±à¸š experiment branches
git branch | grep "experiment" | wc -l

# à¸”à¸¹ log à¸—à¸¸à¸ branch
git log --oneline --graph --all --decorate
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
* def5678 (HEAD -> experiment/random-forest) experiment: à¸—à¸”à¸¥à¸­à¸‡ Random Forest
| * ghi9012 (experiment/logistic-regression) experiment: à¹€à¸žà¸´à¹ˆà¸¡ Logistic Regression
|/
| * abc1234 (feature/preprocessing) feat: à¹€à¸žà¸´à¹ˆà¸¡ feature preprocessing module
|/
* xyz7890 (main) Initial commit: à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡ ML project
```

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 5: à¸ªà¸£à¹‰à¸²à¸‡ Configuration Files

### 5.1 à¸ªà¸£à¹‰à¸²à¸‡ Config Branch

```bash
# à¸ªà¸£à¹‰à¸²à¸‡ branch à¹ƒà¸«à¸¡à¹ˆà¸ˆà¸²à¸ main
git switch main
git switch -c feature/config-system
```

### 5.2 à¸ªà¸£à¹‰à¸²à¸‡ Config File à¸”à¹‰à¸§à¸¢ YAML

```bash
cat > configs/experiment_config.yaml << 'EOF'
# Experiment Configuration
# à¹„à¸Ÿà¸¥à¹Œ config à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸—à¸”à¸¥à¸­à¸‡ ML

# Dataset settings
dataset:
  name: iris
  test_size: 0.2
  random_state: 42

# Preprocessing settings
preprocessing:
  scaling_method: standard  # standard, minmax, robust
  handle_missing: drop      # drop, impute

# Model settings
models:
  logistic_regression:
    max_iter: 200
    solver: lbfgs
    
  random_forest:
    n_estimators: 100
    max_depth: null
    min_samples_split: 2
    
  svm:
    kernel: rbf
    C: 1.0
    gamma: scale

# Training settings
training:
  cross_validation: 5
  verbose: true
  
# Output settings
output:
  save_model: true
  model_dir: models/
  results_dir: results/
  log_file: logs/training.log
EOF
```

### 5.3 à¸ªà¸£à¹‰à¸²à¸‡ Config Reader

```bash
cat > src/utils/config.py << 'EOF'
"""
Configuration Management Module
à¹‚à¸¡à¸”à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸šà¸ˆà¸±à¸”à¸à¸²à¸£ configuration
"""

import yaml
from pathlib import Path


def load_config(config_path: str = 'configs/experiment_config.yaml') -> dict:
    """
    à¹‚à¸«à¸¥à¸” configuration à¸ˆà¸²à¸à¹„à¸Ÿà¸¥à¹Œ YAML
    
    Args:
        config_path: path à¹„à¸›à¸¢à¸±à¸‡à¹„à¸Ÿà¸¥à¹Œ config
    
    Returns:
        dict: configuration dictionary
    """
    config_file = Path(config_path)
    
    if not config_file.exists():
        raise FileNotFoundError(f"Config file not found: {config_path}")
    
    with open(config_file, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    print(f"âœ“ Loaded config from: {config_path}")
    return config


def get_model_config(config: dict, model_name: str) -> dict:
    """
    à¸”à¸¶à¸‡ config à¸ªà¸³à¸«à¸£à¸±à¸š model à¹€à¸‰à¸žà¸²à¸°
    
    Args:
        config: full configuration
        model_name: à¸Šà¸·à¹ˆà¸­ model
    
    Returns:
        dict: model configuration
    """
    models = config.get('models', {})
    
    if model_name not in models:
        raise ValueError(f"Model '{model_name}' not found in config")
    
    return models[model_name]


def print_config(config: dict, indent: int = 0):
    """
    à¹à¸ªà¸”à¸‡ config à¹à¸šà¸šà¸ªà¸§à¸¢à¸‡à¸²à¸¡
    """
    for key, value in config.items():
        prefix = "  " * indent
        if isinstance(value, dict):
            print(f"{prefix}ðŸ“ {key}:")
            print_config(value, indent + 1)
        else:
            print(f"{prefix}  â€¢ {key}: {value}")


if __name__ == "__main__":
    # à¸—à¸”à¸ªà¸­à¸š module
    config = load_config()
    
    print("\nðŸ“‹ Full Configuration:")
    print("="*50)
    print_config(config)
    
    print("\nðŸŒ² Random Forest Config:")
    print("="*50)
    rf_config = get_model_config(config, 'random_forest')
    print(rf_config)
EOF
```

### 5.4 à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ PyYAML à¹à¸¥à¸°à¸—à¸”à¸ªà¸­à¸š

```bash
# à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ PyYAML (à¸–à¹‰à¸²à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µ)
pip3 install pyyaml

# à¸—à¸”à¸ªà¸­à¸š
python3 src/utils/config.py
```

### 5.5 à¹ƒà¸Šà¹‰ tree à¸”à¸¹à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡ configs

```bash
tree configs
```

### 5.6 Commit

```bash
git add .
git commit -m "feat: à¹€à¸žà¸´à¹ˆà¸¡à¸£à¸°à¸šà¸š configuration à¸žà¸£à¹‰à¸­à¸¡ YAML support"
```

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 6: à¸à¸²à¸£ Merge Branches

### 6.1 Merge Feature/Preprocessing à¹€à¸‚à¹‰à¸² Main

```bash
# à¹„à¸›à¸—à¸µà¹ˆ main
git switch main

# à¸”à¸¹à¸ªà¸–à¸²à¸™à¸°à¸à¹ˆà¸­à¸™ merge
git log --oneline --graph --all

# Merge feature/preprocessing
git merge feature/preprocessing -m "Merge: à¸£à¸§à¸¡ preprocessing module à¹€à¸‚à¹‰à¸² main"

# à¸”à¸¹à¸ªà¸–à¸²à¸™à¸°à¸«à¸¥à¸±à¸‡ merge
git log --oneline --graph --all
```

### 6.2 Merge Feature/Config-System

```bash
# Merge config system
git merge feature/config-system -m "Merge: à¸£à¸§à¸¡ config system à¹€à¸‚à¹‰à¸² main"

# à¸”à¸¹ log
git log --oneline --graph --all
```

### 6.3 à¸”à¸¹à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¸«à¸¥à¸±à¸‡ Merge

```bash
# à¸”à¸¹à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”
tree -I '__pycache__|*.pyc|models'
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡ (à¸«à¸¥à¸±à¸‡ merge):**
```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ configs
â”‚   â””â”€â”€ experiment_config.yaml
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ processed
â”‚   â””â”€â”€ raw
â”œâ”€â”€ notebooks
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ results
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ load_data.py
â”‚   â”œâ”€â”€ features
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ models
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â””â”€â”€ utils
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ config.py
â””â”€â”€ tests
    â””â”€â”€ __init__.py
```

### 6.4 à¹ƒà¸Šà¹‰ Pipeline à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ

```bash
# à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¹„à¸Ÿà¸¥à¹Œ Python à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”
find . -name "*.py" | wc -l

# à¸”à¸¹à¹€à¸‰à¸žà¸²à¸°à¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆ __init__.py
find . -name "*.py" | grep -v "__init__"

# à¸™à¸±à¸š commits à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”
git log --oneline | wc -l

# à¸”à¸¹ branches à¸—à¸µà¹ˆ merge à¹à¸¥à¹‰à¸§
git branch --merged main
```

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 7: à¸ªà¸£à¹‰à¸²à¸‡ Complete Pipeline Script

### 7.1 à¸ªà¸£à¹‰à¸²à¸‡ Main Pipeline

```bash
cat > run_experiment.py << 'EOF'
#!/usr/bin/env python3
"""
Main Experiment Pipeline
à¸£à¸±à¸™ experiment à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸ˆà¸²à¸ config
"""

import sys
import argparse
from pathlib import Path

# Add project root to path
sys.path.insert(0, '.')

from src.data.load_data import load_sklearn_dataset, split_data
from src.features.preprocessing import preprocess_pipeline
from src.utils.config import load_config, get_model_config


def run_experiment(config_path: str = 'configs/experiment_config.yaml'):
    """
    à¸£à¸±à¸™ experiment à¸•à¸²à¸¡ config
    """
    print("="*60)
    print("ðŸš€ Starting ML Experiment Pipeline")
    print("="*60)
    
    # 1. Load config
    config = load_config(config_path)
    
    # 2. Load data
    print("\nðŸ“¥ Loading Data...")
    dataset_config = config['dataset']
    X, y, features, targets = load_sklearn_dataset(dataset_config['name'])
    X_train, X_test, y_train, y_test = split_data(
        X, y, 
        test_size=dataset_config['test_size'],
        random_state=dataset_config['random_state']
    )
    
    # 3. Preprocess
    print("\nâš™ï¸ Preprocessing...")
    prep_config = config['preprocessing']
    X_train_scaled, X_test_scaled, preprocessor = preprocess_pipeline(
        X_train, X_test,
        method=prep_config['scaling_method']
    )
    
    # 4. Summary
    print("\n" + "="*60)
    print("âœ… Pipeline Summary")
    print("="*60)
    print(f"  Dataset: {dataset_config['name']}")
    print(f"  Train samples: {X_train.shape[0]}")
    print(f"  Test samples: {X_test.shape[0]}")
    print(f"  Features: {X_train.shape[1]}")
    print(f"  Scaling: {prep_config['scaling_method']}")
    print(f"  Classes: {list(targets)}")
    
    return X_train_scaled, X_test_scaled, y_train, y_test, targets


def main():
    parser = argparse.ArgumentParser(description='Run ML Experiment')
    parser.add_argument(
        '--config', '-c',
        default='configs/experiment_config.yaml',
        help='Path to config file'
    )
    
    args = parser.parse_args()
    
    try:
        run_experiment(args.config)
        print("\nðŸŽ‰ Experiment completed successfully!")
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
EOF
```

### 7.2 à¸—à¸”à¸ªà¸­à¸š Pipeline

```bash
# à¸£à¸±à¸™ pipeline
python3 run_experiment.py

# à¸£à¸±à¸™à¸”à¹‰à¸§à¸¢ config à¸­à¸·à¹ˆà¸™ (à¸–à¹‰à¸²à¸¡à¸µ)
# python3 run_experiment.py --config configs/another_config.yaml
```

### 7.3 Commit

```bash
git add .
git commit -m "feat: à¹€à¸žà¸´à¹ˆà¸¡ main experiment pipeline script"
```

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 8: à¸à¸²à¸£à¸¥à¸šà¹à¸¥à¸°à¸ˆà¸±à¸”à¸à¸²à¸£ Branches

### 8.1 à¸”à¸¹ Branches à¸—à¸µà¹ˆ Merge à¹à¸¥à¹‰à¸§

```bash
# à¸”à¸¹ branches à¸—à¸µà¹ˆ merge à¹€à¸‚à¹‰à¸² main à¹à¸¥à¹‰à¸§
git branch --merged main

# à¸”à¸¹ branches à¸—à¸µà¹ˆà¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰ merge
git branch --no-merged main
```

### 8.2 à¸¥à¸š Branch à¸—à¸µà¹ˆ Merge à¹à¸¥à¹‰à¸§

```bash
# à¸¥à¸š feature branches à¸—à¸µà¹ˆ merge à¹à¸¥à¹‰à¸§
git branch -d feature/preprocessing
git branch -d feature/config-system

# à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š
git branch
```

### 8.3 à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸Šà¸·à¹ˆà¸­ Branch

```bash
# à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸Šà¸·à¹ˆà¸­ experiment branch
git branch -m experiment/logistic-regression experiment/lr-baseline
git branch -m experiment/random-forest experiment/rf-baseline

# à¸”à¸¹à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ
git branch -v
```

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 9: à¸ªà¸£à¹‰à¸²à¸‡ Results Tracking

### 9.1 à¸ªà¸£à¹‰à¸²à¸‡ Results Logger

```bash
cat > src/utils/logger.py << 'EOF'
"""
Results Logging Module
à¹‚à¸¡à¸”à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸š log à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸à¸²à¸£à¸—à¸”à¸¥à¸­à¸‡
"""

import json
import csv
from datetime import datetime
from pathlib import Path


class ExperimentLogger:
    """
    Class à¸ªà¸³à¸«à¸£à¸±à¸š log à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ experiment
    """
    
    def __init__(self, results_dir: str = 'results'):
        """
        Initialize logger
        
        Args:
            results_dir: à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œà¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸à¹‡à¸š results
        """
        self.results_dir = Path(results_dir)
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        # CSV file à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸à¹‡à¸šà¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ
        self.csv_file = self.results_dir / 'experiments.csv'
        self._init_csv()
    
    def _init_csv(self):
        """à¸ªà¸£à¹‰à¸²à¸‡ CSV header à¸–à¹‰à¸²à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µ"""
        if not self.csv_file.exists():
            with open(self.csv_file, 'w', newline='') as f:
                writer = csv.writer(f)
                writer.writerow([
                    'timestamp',
                    'experiment_name',
                    'model_name',
                    'dataset',
                    'train_accuracy',
                    'test_accuracy',
                    'hyperparameters',
                    'notes'
                ])
            print(f"âœ“ Created results CSV: {self.csv_file}")
    
    def log_experiment(
        self,
        experiment_name: str,
        model_name: str,
        dataset: str,
        train_accuracy: float,
        test_accuracy: float,
        hyperparameters: dict = None,
        notes: str = ''
    ):
        """
        Log à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ experiment
        """
        timestamp = datetime.now().isoformat()
        
        with open(self.csv_file, 'a', newline='') as f:
            writer = csv.writer(f)
            writer.writerow([
                timestamp,
                experiment_name,
                model_name,
                dataset,
                f'{train_accuracy:.4f}',
                f'{test_accuracy:.4f}',
                json.dumps(hyperparameters) if hyperparameters else '',
                notes
            ])
        
        print(f"âœ“ Logged experiment: {experiment_name}")
    
    def get_all_results(self):
        """à¸­à¹ˆà¸²à¸™à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”"""
        results = []
        
        if self.csv_file.exists():
            with open(self.csv_file, 'r') as f:
                reader = csv.DictReader(f)
                results = list(reader)
        
        return results
    
    def get_best_experiment(self, metric: str = 'test_accuracy'):
        """à¸«à¸² experiment à¸—à¸µà¹ˆà¸”à¸µà¸—à¸µà¹ˆà¸ªà¸¸à¸”"""
        results = self.get_all_results()
        
        if not results:
            return None
        
        best = max(results, key=lambda x: float(x[metric]))
        return best
    
    def print_summary(self):
        """à¹à¸ªà¸”à¸‡à¸ªà¸£à¸¸à¸›à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ"""
        results = self.get_all_results()
        
        if not results:
            print("ðŸ“­ No experiments logged yet")
            return
        
        print("\n" + "="*70)
        print("ðŸ“Š Experiment Results Summary")
        print("="*70)
        print(f"{'Experiment':<20} {'Model':<15} {'Train Acc':<12} {'Test Acc':<12}")
        print("-"*70)
        
        for r in results:
            print(f"{r['experiment_name']:<20} {r['model_name']:<15} "
                  f"{r['train_accuracy']:<12} {r['test_accuracy']:<12}")
        
        # Best experiment
        best = self.get_best_experiment()
        if best:
            print("\nðŸ† Best Experiment:")
            print(f"   {best['experiment_name']} - Test Accuracy: {best['test_accuracy']}")


if __name__ == "__main__":
    # à¸—à¸”à¸ªà¸­à¸š logger
    logger = ExperimentLogger()
    
    # Log à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡ experiments
    logger.log_experiment(
        experiment_name='baseline-lr',
        model_name='logistic_regression',
        dataset='iris',
        train_accuracy=0.975,
        test_accuracy=0.967,
        hyperparameters={'max_iter': 200},
        notes='Baseline experiment'
    )
    
    logger.log_experiment(
        experiment_name='rf-100trees',
        model_name='random_forest',
        dataset='iris',
        train_accuracy=1.0,
        test_accuracy=0.933,
        hyperparameters={'n_estimators': 100, 'max_depth': 5},
        notes='Random Forest with 100 trees'
    )
    
    logger.log_experiment(
        experiment_name='rf-200trees',
        model_name='random_forest',
        dataset='iris',
        train_accuracy=1.0,
        test_accuracy=0.967,
        hyperparameters={'n_estimators': 200, 'max_depth': None},
        notes='Random Forest with 200 trees'
    )
    
    # à¹à¸ªà¸”à¸‡à¸ªà¸£à¸¸à¸›
    logger.print_summary()
EOF
```

### 9.2 à¸—à¸”à¸ªà¸­à¸š Logger

```bash
python3 src/utils/logger.py
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
âœ“ Created results CSV: results/experiments.csv
âœ“ Logged experiment: baseline-lr
âœ“ Logged experiment: rf-100trees
âœ“ Logged experiment: rf-200trees

======================================================================
ðŸ“Š Experiment Results Summary
======================================================================
Experiment           Model           Train Acc    Test Acc    
----------------------------------------------------------------------
baseline-lr          logistic_regression 0.9750       0.9670      
rf-100trees          random_forest   1.0000       0.9330      
rf-200trees          random_forest   1.0000       0.9670      

ðŸ† Best Experiment:
   baseline-lr - Test Accuracy: 0.9670
```

### 9.3 à¸”à¸¹à¹„à¸Ÿà¸¥à¹Œà¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ

```bash
# à¸”à¸¹ CSV à¸—à¸µà¹ˆà¸ªà¸£à¹‰à¸²à¸‡
cat results/experiments.csv

# à¹ƒà¸Šà¹‰ Pipeline à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ
cat results/experiments.csv | head -5

# à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™ experiments
cat results/experiments.csv | wc -l
```

### 9.4 Commit

```bash
git add .
git commit -m "feat: à¹€à¸žà¸´à¹ˆà¸¡ experiment results logger"
```

---

## ðŸ“ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¸—à¸µà¹ˆ 10: à¸ªà¸£à¸¸à¸›à¹à¸¥à¸° Final Structure

### 10.1 à¸”à¸¹à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢

```bash
tree -I '__pycache__|*.pyc|.git'
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢:**
```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ configs
â”‚   â””â”€â”€ experiment_config.yaml
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ processed
â”‚   â””â”€â”€ raw
â”œâ”€â”€ models
â”‚   â””â”€â”€ logistic_regression_XXXXXXXX.joblib
â”œâ”€â”€ notebooks
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ results
â”‚   â””â”€â”€ experiments.csv
â”œâ”€â”€ run_experiment.py
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ load_data.py
â”‚   â”œâ”€â”€ features
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ models
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ train.py
â”‚   â””â”€â”€ utils
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py
â”‚       â””â”€â”€ logger.py
â””â”€â”€ tests
    â””â”€â”€ __init__.py
```

### 10.2 à¸”à¸¹ Git Log à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”

```bash
# à¸”à¸¹ log à¹à¸šà¸š graph
git log --oneline --graph --all --decorate

# à¹ƒà¸Šà¹‰ Pipeline à¸™à¸±à¸š commits à¸—à¸µà¹ˆà¸¡à¸µ "feat"
git log --oneline | grep "feat" | wc -l

# à¸”à¸¹ commits à¸—à¸µà¹ˆà¸¡à¸µ "experiment"
git log --oneline | grep -i "experiment"
```

### 10.3 à¸ªà¸£à¸¸à¸› Branches

```bash
# à¸”à¸¹ branches à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”
git branch -a -v

# à¹ƒà¸Šà¹‰ Pipeline à¸™à¸±à¸š branches
echo "Total branches: $(git branch | wc -l)"
echo "Experiment branches: $(git branch | grep experiment | wc -l)"
echo "Feature branches: $(git branch | grep feature | wc -l)"
```

---

## ðŸ“‹ à¸ªà¸£à¸¸à¸›à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸ªà¸³à¸„à¸±à¸

### à¸„à¸³à¸ªà¸±à¹ˆà¸‡ Linux Pipeline

| à¸„à¸³à¸ªà¸±à¹ˆà¸‡ | à¸„à¸³à¸­à¸˜à¸´à¸šà¸²à¸¢ |
|--------|----------|
| `cat > file << 'EOF'` | à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œà¸«à¸¥à¸²à¸¢à¸šà¸£à¸£à¸—à¸±à¸” (heredoc) |
| `tree` | à¸”à¸¹à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œà¹à¸¥à¸°à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ |
| `cmd1 \| cmd2` | Pipeline: à¸ªà¹ˆà¸‡ output à¹„à¸›à¹€à¸›à¹‡à¸™ input |
| `grep "text"` | à¸à¸£à¸­à¸‡à¸šà¸£à¸£à¸—à¸±à¸”à¸—à¸µà¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡ |
| `wc -l` | à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¸šà¸£à¸£à¸—à¸±à¸” |
| `find . -name "*.py"` | à¸„à¹‰à¸™à¸«à¸²à¹„à¸Ÿà¸¥à¹Œ Python |

### à¸„à¸³à¸ªà¸±à¹ˆà¸‡ Git Branch

| à¸„à¸³à¸ªà¸±à¹ˆà¸‡ | à¸„à¸³à¸­à¸˜à¸´à¸šà¸²à¸¢ |
|--------|----------|
| `git branch` | à¸”à¸¹à¸£à¸²à¸¢à¸à¸²à¸£ branches |
| `git switch -c <branch>` | à¸ªà¸£à¹‰à¸²à¸‡à¹à¸¥à¸°à¸ªà¸¥à¸±à¸š branch |
| `git switch <branch>` | à¸ªà¸¥à¸±à¸š branch |
| `git merge <branch>` | à¸£à¸§à¸¡ branch |
| `git branch -d <branch>` | à¸¥à¸š branch |
| `git branch -m <old> <new>` | à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸Šà¸·à¹ˆà¸­ branch |
| `git branch --merged` | à¸”à¸¹ branches à¸—à¸µà¹ˆ merge à¹à¸¥à¹‰à¸§ |

### Git Pipeline Commands

| à¸„à¸³à¸ªà¸±à¹ˆà¸‡ | à¸„à¸³à¸­à¸˜à¸´à¸šà¸²à¸¢ |
|--------|----------|
| `git branch \| grep "feature"` | à¸«à¸² feature branches |
| `git log --oneline \| wc -l` | à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™ commits |
| `git log --oneline \| grep "fix"` | à¸«à¸² fix commits |

---

## ðŸ§ª à¹à¸šà¸šà¸—à¸”à¸ªà¸­à¸šà¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆ

1. **à¸—à¸³à¹„à¸¡à¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰ Git Branch à¸à¸±à¸š ML Projects?**

2. **à¸„à¸§à¸²à¸¡à¹à¸•à¸à¸•à¹ˆà¸²à¸‡à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ `fit()` à¹à¸¥à¸° `transform()` à¹ƒà¸™ sklearn à¸„à¸·à¸­à¸­à¸°à¹„à¸£?**

3. **à¸—à¸³à¹„à¸¡à¸•à¹‰à¸­à¸‡ fit preprocessor à¸à¸±à¸š training data à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™?**

4. **à¸„à¸³à¸ªà¸±à¹ˆà¸‡ `git branch | grep "experiment" | wc -l` à¸—à¸³à¸­à¸°à¹„à¸£?**

5. **à¸‚à¹‰à¸­à¸”à¸µà¸‚à¸­à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰ YAML config files à¸„à¸·à¸­à¸­à¸°à¹„à¸£?**

<details>
<summary>ðŸ’¡ à¸„à¸¥à¸´à¸à¹€à¸žà¸·à¹ˆà¸­à¸”à¸¹à¹€à¸‰à¸¥à¸¢</summary>

1. à¹€à¸žà¸·à¹ˆà¸­à¸—à¸”à¸¥à¸­à¸‡ models/features à¸•à¹ˆà¸²à¸‡à¹† à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸à¸£à¸°à¸—à¸š code à¸«à¸¥à¸±à¸ à¹à¸¥à¸°à¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸à¹‡à¸š experiments à¹à¸•à¹ˆà¸¥à¸°à¸­à¸±à¸™à¹à¸¢à¸à¸à¸±à¸™à¹„à¸”à¹‰

2. `fit()` à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰ parameters à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ (à¹€à¸Šà¹ˆà¸™ mean, std), `transform()` à¹ƒà¸Šà¹‰ parameters à¸—à¸µà¹ˆà¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¹à¸¥à¹‰à¸§à¹€à¸žà¸·à¹ˆà¸­à¹à¸›à¸¥à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥

3. à¹€à¸žà¸·à¹ˆà¸­à¸›à¹‰à¸­à¸‡à¸à¸±à¸™ data leakage - à¸–à¹‰à¸² fit à¸à¸±à¸š test data à¸”à¹‰à¸§à¸¢ à¸ˆà¸°à¸—à¸³à¹ƒà¸«à¹‰ model "à¹€à¸«à¹‡à¸™" à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸„à¸§à¸£à¸ˆà¸°à¹€à¸›à¹‡à¸™ unseen data

4. à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™ branches à¸—à¸µà¹ˆà¸¡à¸µà¸„à¸³à¸§à¹ˆà¸² "experiment" à¹ƒà¸™à¸Šà¸·à¹ˆà¸­

5. à¸­à¹ˆà¸²à¸™à¸‡à¹ˆà¸²à¸¢, à¹à¸à¹‰à¹„à¸‚à¸‡à¹ˆà¸²à¸¢, à¸£à¸­à¸‡à¸£à¸±à¸š hierarchical data, à¸ªà¸²à¸¡à¸²à¸£à¸– version control à¹„à¸”à¹‰, à¹à¸¢à¸ config à¸­à¸­à¸à¸ˆà¸²à¸ code

</details>

---

## âœ… Checklist à¸à¹ˆà¸­à¸™à¸ˆà¸š LAB

- [ ] à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸à¸²à¸£à¹ƒà¸Šà¹‰ Pipeline (`|`) à¸à¸±à¸š ML workflows
- [ ] à¹ƒà¸Šà¹‰ Here Document à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ Python à¹à¸¥à¸° YAML à¹„à¸”à¹‰
- [ ] à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡ ML project à¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸›à¹‡à¸™à¸£à¸°à¸šà¸š
- [ ] à¹ƒà¸Šà¹‰ Git Branch à¸ªà¸³à¸«à¸£à¸±à¸š experiments à¸•à¹ˆà¸²à¸‡à¹† à¹„à¸”à¹‰
- [ ] à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆ sklearn preprocessing pipeline
- [ ] Merge branches à¹à¸¥à¸°à¸ˆà¸±à¸”à¸à¸²à¸£ branch à¹„à¸”à¹‰
- [ ] à¸ªà¸£à¹‰à¸²à¸‡à¸£à¸°à¸šà¸š config à¹à¸¥à¸° logging à¸ªà¸³à¸«à¸£à¸±à¸š experiments
- [ ] à¹ƒà¸Šà¹‰ `tree` à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¹„à¸”à¹‰
- [ ] à¹ƒà¸Šà¹‰ Pipeline à¸à¸±à¸š git commands à¹„à¸”à¹‰

---

## ðŸŽ¯ à¹à¸šà¸šà¸à¸¶à¸à¸«à¸±à¸”à¹€à¸žà¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡

### Challenge 1: à¹€à¸žà¸´à¹ˆà¸¡ SVM Experiment
à¸ªà¸£à¹‰à¸²à¸‡ branch à¹ƒà¸«à¸¡à¹ˆ `experiment/svm` à¹à¸¥à¸°à¸—à¸”à¸¥à¸­à¸‡ SVM classifier à¸à¸±à¸š hyperparameters à¸•à¹ˆà¸²à¸‡à¹†

### Challenge 2: Cross-Validation
à¹€à¸žà¸´à¹ˆà¸¡ cross-validation à¹ƒà¸™ training pipeline à¹à¸¥à¸° log à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ

### Challenge 3: Feature Selection
à¸ªà¸£à¹‰à¸²à¸‡ branch `feature/selection` à¹à¸¥à¸°à¹€à¸žà¸´à¹ˆà¸¡ feature selection methods (SelectKBest, RFE)

### Challenge 4: Model Comparison Report
à¸ªà¸£à¹‰à¸²à¸‡ script à¸—à¸µà¹ˆà¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š models à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸ˆà¸²à¸ experiments.csv à¹à¸¥à¸°à¸ªà¸£à¹‰à¸²à¸‡ visualization

---

## ðŸ“š à¹à¸«à¸¥à¹ˆà¸‡à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¹€à¸žà¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡

- [Scikit-Learn Documentation](https://scikit-learn.org/stable/)
- [Git Branching Strategies](https://www.atlassian.com/git/tutorials/comparing-workflows)
- [MLOps Principles](https://ml-ops.org/)
- [Python Project Structure](https://docs.python-guide.org/writing/structure/)

---

**Happy Learning! ðŸŽ“**